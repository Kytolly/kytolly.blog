<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>A web service recommendation algorithm  based on BaisSVD</title>
    <url>/2025/07/02/A-web-service-recommendation-algorithm-based-on-BaisSVD/</url>
    <content><![CDATA[Source
Da Sun ,Tong Nie  Beijing Engineering Research Center for IoT Software and Systems, Information Department, Beijing University of Technology
Abstract
随着网络技术和网络服务的发展，Web服务的数量也将呈爆炸式增长，能够提供类似功能的Web服务的数量也将迅速增加。
服务质量(Quality of Service，QoS)被广泛用于描述和评价Web服务的非功能性能，并已成功地应用于服务推荐。
然而，目前的Web服务建议大多仍局限于传统的协同过滤，没有考虑用户和Web服务本身的偏向。
本文首先介绍了Web服务推荐的现状，然后分析了存在的问题和数据集的特点。最后，应用BiasSVD算法预测服务质量，并推荐给用户，将实验结果与传统的协同过滤算法进行了比较，得出了该算法在Web服务推荐场景中的可行性和优越性。
Keywords
Web服务;推荐;服务质量预测;协同过滤;矩阵分解;
Introduction
随着互联网技术的发展，Web服务的便利性导致了用户对Web服务的需求不断增加。如今，大量的Web服务充斥着互联网，用户的选择越来越多。同时，它们也提出了更高的要求：在相同的业务类型和条件下，用户除了满足功能需求外，还希望获得更高的服务质量(Qos)。
目前，通过预测服务质量并推荐给用户已经成为解决Web服务信息过载的一种方法。协同过滤是一种广泛使用的推荐技术，已被证明是最准确的预测方法。基于历史数据的经典协同过滤主要从三个方面进行研究。

第一种是从用户的角度出发，即基于用户的算法(UPCC)。
第二种是从项目的角度，即基于项目的算法(IPCC)。
第三种算法结合了用户和项目两个方面，即基于用户和项目的算法(UIPCC)。

UPCC的前提是，在现有数据中，两个用户之间的相似度越高，那些无法访问该项目的用户出现类似结果的可能性就越大。
IPCC正在从项目的角度寻找类似的项目进行预测。
UIPCC是UPCC和IPCC的加权结果。
一般来说，用户与项目之间的相似度可以通过余弦相似度或皮尔逊相关系数来获得。然而，传统的协同过滤Web服务推荐算法也存在一些不足：

如果项目之间存在相关性，信息量不会随着向量维度的增加而线性增加；
评分矩阵元素稀疏，计算结果不稳定，向量维度的增加或减少都会导致近邻结果的较大差异。

针对这些问题，本文使用BiasSVD来解决这些问题，从而提高推荐结果的准确性和用户体验。
RELATED WORK
A. Traditional collaborative filtering
目前，协同过滤推荐算法有两种：

基于用户的协同过滤推荐算法
基于项目的协同过滤推荐算法。

前者是基于这样的假设：如果用户对某些项目具有相似的分数，那么他们对其他项目也具有相似的分数，基于目标用户的最近邻居（最相似的用户），算法逼近目标用户对项目的分数。
对于后者，用户对不同项目的评分是相似的，要估计用户对某个物品的评分，可以估计用户物品的几个类似物品的评分。
协同过滤的关键步骤是计算用户之间的相似度。协同过滤算法中使用了多种方法来计算用户之间的相似度。其中大多数是基于用户对具有共同偏好的产品的评级。两种最常用的方法是Pearson correlation和included angle cosine；
这两种方法都将用户和频繁使用(overplay)的产品集定义为：

用户和之间的Pearson correlation定义为：

在included angle cosine方法中，用户和由维载体表示。两个载体之间的相似度可以通过以下方式获得

基于用户的方法利用来自类似用户的历史Qos体验进行个性化Qos预测，而基于服务的方法使用来自类似服务的方法进行预测。混合方法是前两种方法的结合，因此可以达到更高的预测准确率。
基于传统的协同过滤算法，UPCC和IPCC预测和推荐服务质量的基本步骤如下：

准备数据集;
计算用户（Web服务）的相似度并获取用户（Web服务）的相似度;
选择最近的邻居用户（Web Service）获取相似用户（Web Service）的集合;
服务质量预测并获取预测结果;
推荐

不同的系统使用不同的相似度计算来使预测分数尽可能准确。协同过滤推荐系统虽然已得到广泛应用，但也面临着推荐效果不佳、系统扩展性弱等诸多问题。
B. Matrix factorization in Recommendation System
基于模型的协同过滤算法一般基于定义的随机参数模型。根据已有的Qos数据集，通过机器学习的方法训练预测模型来预测个性化QOS值，推荐系统的得分预测问题可以看作是一场补全矩阵的游戏，这是推荐系统的任务，而矩阵分解是为了实现其目标。
矩阵分解算法应用于个性化推荐的核心思想是将用户评分矩阵分解为一个低秩矩阵(low rank)，使产品尽可能接近原始评分矩阵，并使预测矩阵与原始矩阵之间的误差平方最小。
奇异值分解(SVD)由于既可以用于降维算法的特征分解，也可以用于推荐算法的特征分解，因此在机器学习中得到了广泛的应用。我们把个用户和个项目的得分作为一个矩阵，然后用矩阵分解来解决推荐问题。

低秩矩阵为什么有用？
在矩阵论中，矩阵满秩当且仅当其各行各列线性无关，也就是说，矩阵的秩衡量矩阵内部的相关性；
在机器学习领域，矩阵往往表示图像，用户-物品推荐表等结构性信息，若行列间的相关性很低，意味着矩阵可以被降维，投影到更低维度的子空间，用较少的线性无关的向量表示，以表达矩阵其余的冗余信息；
在图像处理领域，如果图像的秩比较高，这意味着图像的噪声严重，低秩的矩阵往往被用于恢复图像；
注意到，对于矩阵，其秩;
经验表明，对于海量的用户和项目的集合，决定用户对项目的打分往往和看起来只和若干指标有关，我们用这些指标构建低秩的矩阵，用于还原和近似原先的评分矩阵，换句话说，我们将评分矩阵近似分解成这些低秩矩阵的乘积；

FunkSVD
原始的奇异值矩阵分解(PureSVD)需要先填充矩阵，然后分解降维，由于逆运算，具有复杂度高的缺点。因此，Simon提出了FunkSVD的方法。他没有将矩阵分解为三个矩阵，而是将其分解为两个低等级用户项目矩阵，这降低了计算复杂性。

对于用户评分，FunkSVD用于矩阵分解，相应的表示为;
FunkSVD使用线性回归(linear regression)的思想，通过最小化观察数据的平方来找到用户和项目的最佳隐式载体表示(the optimal implicit vector representation)。如果我们考虑所有物品和样本的组合，最小化以下公式:

如果上述公式被最小化并找到相应的极端值(extreme value)，则将得到矩阵和;
对于矩阵的任何空白分数，分数可以通过以下公式计算。同时，为了避免过度匹配观察数据(overfitting)，提出了带正则项的FunkSVD;

因此，使用FunkMVD进行推荐的步骤如下：

通过梯度下降法求出和，使损失函数最小化;
通过和完成矩阵;
对于用户，找到上一个值缺失的位置，并根据完成值从大到小进行推荐。

BiasSVD
基于FunkSVD算法有很多改进版本，其中BiasSVD是最受欢迎的一个。
提出的算法基于以下假设：一些用户或项目会带来自己的特征。BiasSVD推荐系统由三个部分组成：

有些与用户项目无关，称为用户偏向项;
有些与项目中的用户无关，称为项目偏向项。

假设评分系统的平均得分为，则添加偏差项后的优化目标函数如下：

在Web服务推荐中，有很多有关Web服务调用历史的偏好信息。例如，Web服务本身的服务质量一般较高，因此当需要预测Web服务的服务质量值时，预测的服务质量值应该包含Web服务的偏差信息。另一个用户可能更喜欢质量方面的吞吐量或响应时间。这些是用户或网络服务包含的偏见信息。将这些偏差信息添加到服务质量预测中可以提高预测准确率并具有更好的推荐效果。
与FunkSVD和BiasSVD相比，BiasSVD的最终推荐效果优于FunkSVD;本文中，作者还使用了BiasSVD算法作为Web服务的推荐模型。
RESULT OF EXPERIMENTS
首先介绍实验中使用的数据集，然后说明传统协同过滤算法和BiasSVD算法的真实算法流程、评估指标和实验结果。
A. DataSet
本文中的所有实验都基于来自香港中 文大学的郑先生收集的Web服务数据集。来自30个国家/地区的339名服务用户在73个国家/地区的5825个现实世界Web服务上总共执行了1974675次现实世界Web服务调用。每条记录还包含响应时间和吞吐量。
B. Algorithm flow
Input
QoS矩阵、正规化参数,学习率;
Process


根据相应的稀疏度对QoS矩阵进行稀疏化;


考虑用户偏见信息和Web服务的偏见信息部分，并设置偏见;


:所有记录的总体平均值
:用户补偿信息(user offset information)
:web服务补偿信息(web service offset information)



在迭代过程中，可以将的初始值设置为，然后进行迭代;



优化目标函数：



output
服务质量预测值,构成矩阵QoS的预测值；
C. Evaluation indices
协同过滤推荐算法的评估方法有多种，两个主要的评估标准是MAE和RMSE，以及精确率、召回率等指标。本文使用了MAE和RMSE；
MAE的定义如下：

RMSE的定义如下：

从上面的公式可以看出，MAE重点关注预测误差的绝对值，无论误差的大小如何，其对所有误差的权重都是相同的;
RSSE对预测值与实际值的差进行平方运算，然后将差相加，差异大的结果赋予更大的权重，结果也会相应改变
Mae和RSSE的值与预测的准确性成正比，即值越小，预测越准确。
D. Experimental results and analysis
在本文中，作者比较了UPCC、IPCC、UPICC和FunkDID作为最终的比较算法，以验证该算法的效果。
UPCC、IPCC和UIPCC是基于用户、基于项目的混合协作过滤算法。FunkSVD是一种没有偏差的矩阵分解算法。  在经验中，我们主要验证在相同稀疏数据下，BiasDID算法是否能够与传统协同过滤算法相比提高预测准确率。
Fig.1显示了使用5%、15%和25%训练矩阵密度在不同响应时间和吞吐量预测方法下的MAE和RSSE结果。

总而言之，依靠平均值预测效果最差，而基于传统的协同过滤方法，包括UPCC、IPCC和UPICC，预测效果优于平均值预测，但仍然不理想。
关键是，在数据稀疏的情况下，基于矩阵分解的方法明显优于传统的协同过滤。随着密度的增加，所有方法的性能都有所提高，这表明更高质量的信息可以提高预测准确率，而且Bias奇异值在预测准确率方面更具优势。
CONCLUSION AND FUTURE WORK
传统的基于用户的协同过滤推荐算法在计算用户相似度时往往面临数据稀疏性和可扩展性差的缺点。然而，在矩阵分解中使用BiasSVD来计算用户相似度可以改善数据稀疏性的缺点，而且本身的可扩展性也很好。
因此，作者提出了一种基于BiasSVD的推荐算法。该算法在考虑用户偏好的同时，利用FunkSVD分解相似度矩阵。通过郑收集的数据集表明，与传统算法相比，该算法有效地克服了数据稀疏性的缺点，提高了服务质量预测的准确性。
但是，在计算相似度的过程中，迭代的时间复杂度需要进一步优化。此外，当面临冷启动时，BiasSVD的性能仍然较弱。因此，下一步需要寻找解决方案，优化时间复杂度，改善冷启动问题。
同时，对于近几年的热点技术，比如深度学习也可以应用到推荐算法中，以后的研究也会考虑深度学习在推荐算法中的应用。
]]></content>
      <tags>
        <tag>papers</tag>
        <tag>Information-Retrieval</tag>
      </tags>
  </entry>
  <entry>
    <title>Artificial Neural Network</title>
    <url>/2025/06/21/Artificial-Neural-Network/</url>
    <content><![CDATA[Idea
人工神经网络（ANN，Artificial Neural Networks）是在人类对大脑神经网络认识理解的基础上，人工构造的能够实现某种功能的神经网络。它是理论化的人脑神经网络的数学模型，是基于模仿大脑神经网络结构和功能而建立起来的一种信息处理系统。

并行分布式的处理结构
具有局部内存，可以完成局部操作
每个处理单元有一个单一的输出连接；

神经网络结构和工作机理基本上是以人脑的组织结构和活动规律为背景的，它反映了脑的某些基本特征，但并不是要对人脑部分的真正实现，可以说它是某种抽象、简化或模仿。
如果将大量功能简单的形式神经元通过一定的拓扑结构组织起来，构成群体并行分布式处理的计算结构，那么这种结构就是人工神经网络，在不引起混淆的情况下，统称为神经网络。
ANN有三大要素如下：

神经元的激活规则：主要是指神经元输入到输出之间的映射关系，一般为非线性函数
网络的拓扑结构：不同神经元之间的连接关系
学习算法：通过训练数据来学习神经网络的参数

激活函数
性质要求

连续并可导（允许少数点上不可导）的非线性函数。
可导的激活函数 可以直接利用数值优化的方法来学习网络参数。
激活函数及其导函数要尽可能的简单，有利于提高网络计算效率。
激活函数的导函数的值域要在一个合适的区间内，不能太大也不能太小，否则会影响训练的效率和稳定性。

Logistic函数系

它有一个良好的性质：
它具有挤压的功能，输出可以看作某种概率分布；

有一个线性近似函数

可降低计算开销
Tanh函数系

特点是零中心化，可以提升收敛速度

也存在如下线性近似


ReLU函数系

性质如下：

ReLU：是目前最常用的激活函数，具有单侧抑制、宽兴奋边界的生物学合理性，可缓解梯度消失问题，但有可能导致神经元的死亡
带泄露的ReLU：在时也保持一个很小的梯度，避免 永远不能被激活的情况，为超参
指数线性单元ELU:近似零中心化,为超参
Softplus可以看成ReLU的平滑版本，其导数刚好为Logistic函数 也有单侧抑制、宽兴奋边界的特性，但不具有稀疏性

多层感知机
两层感知机构造
要解决复杂问题，单层神经网络是不够用的，因此引入隐层和多层前反馈神经网络：其中输入层神经元接收外界输入，隐层与输出层神经元对信号进行加工，最终结果由输出层神经元输出；
采用多层感知机可以解决异或问题;输入仍为

隐藏层：包含两个神经元
输出层包含一个神经元
隐藏层采用线性整流激活函数ReLU


取


可以看到，学习的隐藏空间时一个非线性的空间变换

万能近似定理
万能近似定理（universal approximation theorem）表述如下：一个两层人工神经网络如果具有足够多的隐藏单元，它可以以任意的精度来近似任何一个函数（即可以表示任意的复杂输入-输出关系）。
神经网络可以作为一个万能函数来使用，可以用来进行复杂的特征转换，或逼近一个复杂的条件分布。
根据万能近似定理，对于具有线性输出层和至少一个使用"挤压"性质的激活函数的隐藏层组成的前馈神经网络，只要其隐藏层神经元的数量足够，它可以以任意的精度来近似任何从一个定义在实数空间中的有界闭集函数。因此神经网络经常被当作一个万能函数使用，进行复杂的特征转换，或者逼近一个复杂的条件分布；
前馈神经网络如何学习分类器？

若为Logistic回归，那么Logistic回归分类器可以看成神经网络的最后一层；
如果使用softmax回归分类器，相当于网络最后一层设置  个神经元，其输出经过softmax函数进行归一化后可以作为每个类的后验概率，\hat{\mathbf{y}}=\mathrm{softmax}(\mathbf{z}^{(L)})
采用交叉熵损失函数，对于样本(x, y)，其损失函数为


神经网络能够通过训练，改变其内部表示，使输入-输出变换朝好的方向发展。训练实质是用同一个训练集的样本反复作用于网络，网络按照一定的训练规则（学习规则或学习算法），自动调节神经元之间的连接强度或拓扑结构，当网络的实际输出满足期望的要求，或者趋于稳定，这认为训练圆满结束。神经网络的学习成果蕴含在权值和阈值当中；
但是有如下潜在问题：


单隐层网络可以近似任何函数，但其规模可能巨大，在最坏的情况下，需要指数级的隐藏单元才能近似某个函数；


随着深度的增加，网络的表示能力呈指数增加，一个具有个输入、深度为、每个隐藏层具有个单元的深度整流网络可以描述线性区域的数量为



有研究注意到，更深层的网络具有更好的泛化能力，参数数量的增加未必一定会带来模型效果的提升；
更深的模型往往表现更好，不仅仅是因为模型更大。 想要学得的函数应该由许多更简单的函数复合在一起而得到
多层感知机
在多层感知机(Multi-layer Perceptron, MLP)中，更常见的名字是前馈神经网络(Feedforward Neural Network, FNN)

输入层神经元接收外界输入，隐层与输出层神经元对信号进行
加工，最终结果由输出层神经元输出；
各神经元分别属于不同的层，层内无连接
相邻两层之间的神经元全部两两连接
整个网络中无反馈，信号从输入层向输出层单向传播，可用一个有向无环图表示


FNN一般采取交叉熵损失函数,对样本

其中， 为标签的one-hot编码表示；
考察结构化风险函数

正则化项

前馈神经网络信息向前（单向）传递，层内节点之间并不连接，适合于处理静态数据分析，如回归、分类等任务；
对于全连接前馈神经网络来说，有不少缺点：

容易过拟合；
训练比较慢，可解释性差;
权重矩阵参数非常多，不满足局部不变性特征；


局部不变性特征：自然图像中的物体都具有局部不变性特征，比如尺度缩放、平 移、旋转等操作不影响其语义信息。而全连接前馈网络很难提取这些局部不变性 特征，一般需要进行数据增强来提高性能。

其他网络结构
记忆网络/反馈网络
神经元不但可以接收其他神经元的信息，也可以接收自己的历史信息神经元具有记忆功能，在不同的时刻具有不同的状态，信息传播可以是单向或者双向传递，可用一个有向循环图或无向图来表示记忆网络包括循环神经网络、Hopfield网络、玻尔兹曼机、受限玻尔兹曼机等

图网络
图网络是定义在图结构数据上的神经网络,图中的每个节点都是由一个或者一组神经元构成节点之间的连接可以是有向的，也可以是无向的,每个节点可以接收来自相邻节点或者自身的信息,图网络是前馈网络和记忆网络的方法，包含许多
不同的实现方式，如图卷积网络、图注意力网络、消息传递网络等

残差连接
残差连接 (residual connection)是指,增加跳跃连接从第层与第层甚至更高层之间建立连接 ，使得梯度更容易从输出层流向更接近输入的层，利于模型优化

除残差连接外，还可以改变层与层之间的连接方式

前一层的每个单元仅与后一层的一个小单元子集相连
可以极大地减少参数的数量
具体的连接方式高度依赖于具体的问题


梯度计算
误差反向传播算法
BP(误差反向传播)算法是指，一个BP网络（BP算法训练的多层前反馈神经网络）
会连续不断地在相对于误差函数斜率下降的方向上计算网络权值和偏差的变化而逐渐逼近目标的。
每一次权值和偏差的变化都与网络误差的影响成正比，并以反向传播的方式传递到每一层的。
具体来说，设置学习率,将阈值看作固定输入-1的 dummy node；将对权重和阈值的学习统一看成权重的调整，前向计算迭代过程为：

学习率控制着算法每一轮迭代中的更新步长，若太大则容易振荡，太小则收敛速度又会过慢.


各神经元分别属于不同的层，层内无连接


相邻两层之间的神经元全部两两连接


整个网络中无反馈，信号从输入层向输出层单向传播，可用一个有向无环图表示


对于训练样例,ANN的预测结果为

BP算法的目标是最小化均方误差：

BP算法的策略是基于梯度下降的，也即，以目标的负梯度方向对参数进行调整：

数学上：

得到BP算法的迭代方程：

如果取损失函数为结构化风险函数：

那么梯度下降策略可表示为：

算法流程：

将输入样本提供给输入层神经元
逐层将信号前传至隐层、输出层，产生输出层的结果
计算输出层误差
将误差反向传播至隐藏层神经元行调整
根据隐层神经元对连接权重和阈值进
上述过程循环进行，直至达到某些停止条件为止


自动梯度计算
自动微分将符号微分法应用于最基本的算子，比如常数、幂函数、指数函数、对 数函数、三角函数等，将其代入数值，保留中间结果，最后再应用于整个函数；
现代深度学习框架(Pytorch, Tensorflow etc)多采用计算图(computer graph)的方式进行自动梯度计算

将复合函数分解为一系列基本操作，并以图的形式连接起来
是数学运算的图结构表示，每个非叶子节点代表一个基本操作，每个叶子节点代表一个输入变量或常量


通常分为静态计算图和动态计算图，在当前深度学习框架中，Theano和Tensorflow采用的是静态计算图，而DyNet、Chainer和PyTorch采用的是动态计图。Tensorflow 2.0 也开始支持动态计算图。

静态计算图在编译时构建计算图，构建好后在程序运行时不能改变，在构建时可以进行优化、并行能力强，灵活性较差
动态计算图 在程序运行时动态构建计算图，不容易优化，当不同输入所使用的网络结构不一样时，难以并行计算，灵活性比较高

]]></content>
      <tags>
        <tag>Machine-Learning</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>Application</title>
    <url>/2025/07/02/Application/</url>
    <content><![CDATA[网络应用
协议特点
每个应用层协议都是为了解决某一类应用问题，而问题的解决又往往是通过位于不同主机中的多个应用进程之间的通信和协同工作来完成的。应用层的具体内容就是规定应用进程在通信时所遵循的协议。
应用层的许多协议都是基于客户服务器方式。
客户(client)和服务器(server)都是指通信中所涉及的两个应用进程。客户服务器方式所描述的是进程之间服务和被服务的关系。客户是服务请求方，服务器是服务提供方。
研发
网络应用是计算机网络存在的理由，它存在于不同的端系统上，而不是网络核心设备上，这种设计促进了应用程序的研发；
常见的应用有电子邮件，Web，即时讯息，远程登陆，P2P文件共享，多用户网络游戏，流式存储视频片段，因特网电话，实时视频会议；
体系结构
应用体系结构(application architecture)由应用程序研发者设计，常见的包括

客户端-服务器体系架构(client-server architecture)：总是存在一个打开的服务器主机，接受来自客户主机的请求，具有固定的、众所周知的地址，主机群集常被用于创建强大的虚拟服务器；客户之间不能相互通信，同服务端通信，间断和服务器进行连接，拥有动态的地址；
P2P体系结构(P2P architecture)：对数据中心专用服务器几乎没有依赖，应用程序在对等主机间通信；通常不需要庞大的服务器群和带宽；对等放间歇连接并改变地址，具有自拓展性和高度非集中式结构；但可能难以管理；

有时也会有将两种体系结构混合使用的应用，比如Napster，即时讯息；
进程通信
从操作系统的角度来看，通信的实体是进程；同一主机上的两个进程通过内部进程通信机制进行通信；不同主机上的进程通过跨越计算机网络交换报文而相互通信；

成对的进程中，发起通信方表示为客户，会话开始时等待联系方标识为服务器；
进程通过套接字接口向网络发送和接受报文；
进程寻址需要定义1. 主机地址 2. 目的主机指定接受进程的标识符；

套接字
套接字(socket)是应用程序进程和运输层协议之间的接口，也称应用程序编程接口API ；

发送端的应用将报文推给套接字；
运输层负责将从套接字获得报文；


可以用门户类比套接字；

用户通过API对传输层的控制仅限于选择传输协议或设定一些参数；
进程寻址
为了一个进程能接收报文，它需要一个标识

主机有唯一的32位IP地址
主机上的进程标识包括IP地址和端口号

比如Web服务经常运行在80端口，而SSH服务运行在22端口上；
应用层协议
回忆协议的基本要素：交换的报文类型，报文类型的语法，字段的语义，进程何时、如何发送报文及对报文进行响应；
由RFC定义一些公共领域协议供大家使用，比如HTTP，SMTP；也有一些专用协议KaZaA；
传输层的服务
回忆协议栈知识，下层协议向上层提供服务，
运输层协议的选择的依据是应用程序服务要求，常见如下：

可靠数据传输：应用要求数据的可靠性，但是网络传输是不可靠的；选择提供可靠数据传输服务的协议时，进程将数据传给套接字后，就可以相信数据能无差错到达接收进程；但是有些应用是容忍丢失的，比如多媒体应用；
吞吐量：通常是一些带宽敏感(bandwidth-sensitive)的应用，比如多媒体；而弹性(elastic)应用能够自主决定使用的吞吐量；
定时：比如电话等，需要提供定时保证的运输层协议；
安全性：有些应用要求数据必须加密传输；

更直接地说，开发Internet应用程序，需要选择的两个运输层协议是：TCP和UDP；
它们的共同点是：都没有提供时延保证和最小带宽保证；没有提供任何加密机制；
它们的区别可以用下表概括：



特性
TCP (Transmission Control Protocol)
UDP (User Datagram Protocol)




连接类型
面向连接：在数据传输前需要建立连接（三次握手），结束后终止连接。
无连接：直接发送数据，不建立或维护连接。


可靠性
可靠：保证数据按序、无差错地到达，提供错误检查、重传和确认机制。
不可靠：不保证数据到达、顺序或无差错，不提供错误检查或重传。


速度与效率
较慢：由于连接管理、流量控制和拥塞控制，开销较大，传输速度相对慢。
较快：开销小，传输速度快，适合对实时性要求高的应用。


流量控制
有：通过滑动窗口等机制防止发送方淹没接收方。
无：不控制发送速率，可能导致接收方过载或数据丢失。


拥塞控制
有：通过算法避免网络拥塞，并在拥塞发生时减缓发送速率。
无：不检测或避免网络拥塞，可能加剧拥塞。


有序传输
有：通过序号确保数据包按序到达。
无：数据包可能乱序到达，由应用层处理排序。


头部长度
可变：20-60字节。
固定：8字节。


广播/多播
不支持：点对点通信。
支持：适用于一对多通信。


典型应用
Web浏览 (HTTP/HTTPS), 文件传输 (FTP), 电子邮件 (SMTP/POP3/IMAP), SSH
在线游戏, 视频/音频流 (实时), VoIP (网络电话), DNS 查询, 网络监控



HTTP协议
Web层应用层协议为超文本传输协议(hypertext transfer protocol, HTTP)，是Web应用的核心；遵循C/S架构，浏览器browser请求, 接收, 解释显示 Web对象，Web服务器响应请求,发送 Web对象；
Web
万维网www是一个大规模的、联机式的信息储藏所，用链接(link)的方法能非常方便地从因特网上的一个站点访问另一个站点；

提供分布式服务；
万维网以客户服务器方式工作。
浏览器就是在用户计算机上的万维网客户程序。万维网文档所驻留的计算机则运行服务器程序(Apache, IIS)，因此这个计算机也称为万维网服务器。
客户程序向服务器程序发出请求，服务器程序向客户程序送回客户所要的万维网文档。
在一个客户程序主窗口上显示出的万维网文档称为页面(page)。

统一资源定位符  (Uniform Resource Locator，URL)来标志万维网上的各种文档；是对可以从因特网上得到的资源的位置和访问方法的一种简洁的表示。URL 给资源的位置提供一种抽象的识别方法，并用这种方法给资源定位。只要能够对资源定位，系统就可以对资源进行各种操作，如存取、更新、替换和查找其属性。
URL 相当于一个文件名在网络范围的扩展，可以理解是与因特网相连的机器上的任何可访问对象的一个指针，一般格式如下：

访问方式：ftp ，http，News 等数据访问的协议
主机：存放资源的主机在因特网中的域名
端口：有时可省略，比如HTTP 的默认端口号是 80；
路径：有时可省略，URL 就指到因特网上的某个主页(home page)；

&lt;URL的访问方式&gt;://&lt;主机&gt;:&lt;端口&gt;/&lt;路径&gt;  
超文本标记语言  (HyperText Markup Language)使得万维网页面的设计者可以很方便地用一个超链从本页面的某处链接到因特网上的任何一个万维网页面，并且能够在自己的计算机屏幕上将这些页面显示出来。
一个Web文档(Web page)是由Web对象组成的;

Web对象对应一个实际的文件，比如HTML文件，JEPG图片，Javascript文件，Css样式表文件；
一个页面有一个HTML基本文件和若干引用对象；

一个Web浏览器(Web browser)是一个实现了HTTP的客户端；因此我们常把浏览器和客户等同；
一个Web服务器(Web server)是一个HTTP的服务器端；

用于存储Web对象；
对象通过一个URL寻址；

报文格式
HTTP报文是客户端和服务器之间交换数据的机制，主要分为两种类型：请求报文（由客户端发送）和响应报文（由服务器发送）。
所有HTTP/1.x报文都具有相似的通用结构，包括：

**起始行 **(start line)：一行文本，包含报文类型的基本信息，分为请求行和响应行；
头部字段 (header line)：零行或多行键值对，提供关于报文的元数据，例如主机、内容类型、长度等。
空行：一个回车符和换行符，表示头部字段的结束。
报文主体：可选部分，包含实际传输的数据（如HTML文件、图片、表单数据等）。

TTP请求报文格式用于客户端向服务器请求某个资源或提交数据，其格式如下：

方法：指示对资源执行的动作，如 GET（获取资源）、POST（提交数据）、HEAD（获取资源头部）、PUT（更新资源）、DELETE（删除资源）等。
请求URI：标识所请求资源的统一资源标识符（URL的路径部分）。
HTTP版本：表示请求使用的HTTP协议版本，通常是 HTTP/1.1。
头部字段：提供请求的附加信息，例如：

Host: 目的主机和端口号。
User-Agent: 发送请求的用户代理（浏览器）信息。
Accept: 客户端能够处理的媒体类型。
Content-Type: 报文主体的媒体类型（如果存在报文主体）。
Content-Length: 报文主体的长度（如果存在报文主体）。


报文主体 (Message Body)：包含客户端发送给服务器的数据，主要用于 POST 和 PUT 请求。

&lt;方法&gt; &lt;请求URI&gt; &lt;HTTP版本&gt;&lt;头部字段1&gt;: &lt;值&gt;&lt;头部字段2&gt;: &lt;值&gt;...&lt;空行&gt;[报文主体]

HTTP响应报文用于服务器对客户端请求的回复，其格式如下：

HTTP版本：表示响应使用的HTTP协议版本。
状态码(status code)：一个三位数字代码，指示请求的处理结果，如 200 (OK), 301(Move Permanently), 400(Bad Request),404 (Not Found), 500 (Internal Server Error) , 505(HTTP Version Not Support)等。
原因短语：状态码的简短文字描述，帮助人类理解。
头部字段：提供响应的附加信息，例如：

Server: 服务器软件信息。
Date: 响应生成的时间。
Content-Type: 响应报文主体的媒体类型。
Content-Length: 响应报文主体的长度。
Last-Modified: 资源的最后修改时间。


报文主体：包含服务器返回给客户端的实际数据，如HTML页面内容、图片等。

&lt;HTTP版本&gt; &lt;状态码&gt; &lt;原因短语&gt;&lt;头部字段1&gt;: &lt;值&gt;&lt;头部字段2&gt;: &lt;值&gt;...&lt;空行&gt;[报文主体]

工作流程
HTTP使用TCP作为运输层协议

客户初始化一个与HTTP服务器80端口的TCP连接 (创建套接字)
HTTP服务器接受来自客户的TCP连接请求, 建立连接
Browser (HTTP client)和Web服务器 (HTTP server) 交换HTTP报文(应用层协议消息)包括HTTP请求和响应消息
最后结束(或叫关闭)TCP连接


HTTP连接以下分类，对应不同的响应时间模型

持久HTTP连接：在一个TCP连接上传送多个对象，所有的请求-响应经过相同的TCP连接发送；
非持久HTTP连接：在一个TCP连接上只传送一个对象，每个请求-响应对通过一个单独的TCP连接上发送；

定义往返时间RTT为一个小分组从客户主机到服务器，再到客户主机花费的时间，则以下动作都需要花费一个RTT

建立TCP连接；
一对请求-响应消息的交互；

HTML文件传输时间单独算作传输时延；

HTTP/1.0采用非持久HTTP连接，每个对象需要两个RTT，且每个TCP连接都需要由OS分配主机资源，不利于大量客户的并发；
HTTP/1.1采用带流水线的持久HTTP连接中，服务器发送响应消息后保持连接，后续消息也在该连接上传送，用户遇到一个所有引用对象就发送请求，所有引用对象经历1个RTT；
而一类不带流水线的HTTP连接，客户必须先收到先前请求的响应消息后才能发出新的请求，每个引用对象经历一个RTT；
Cookie
虽然说HTTP是一种无状态(stateless)协议，服务器不维护客户先前的状态信息；

维护状态的协议比较复杂，关键在于一致性如何保证；
但是一般部分网站会搭配Cookie技术一起使用，来达成维护状态的目的，以跟踪用户数据，达成会话管理，个性化推荐，跟踪分析用户行为的目的；

Cookie是服务器发送到用户Web浏览器的一小段数据。

浏览器可以存储Cookie，创建新的Cookie，修改现有的Cookie，并在后续请求中将其发送回同一服务器。
Cookie使Web应用程序能够存储有限的数据并记住状态信息；

Cookie技术组件包括

响应报文中的一个cookie首部行；
请求报文中的一个cookie首部行；
浏览器保存的cookie文件；
Web站点后端的数据库；


Cookie的工作流程如下：


服务器设置Cookie：当服务器收到HTTP请求并希望在客户端存储一些信息时，它会在HTTP响应头中包含一个或多个Set-Cookie字段。例如：
HTTP/1.1 200 OKContent-Type: text/htmlSet-Cookie: session_id=abc123; Expires=Wed, 31 Dec 2025 23:59:59 GMT; Path=/Set-Cookie: user_preference=dark_mode[页面内容]
这个例子中，服务器设置了两个Cookie：session_id和user_preference。


浏览器存储Cookie：浏览器收到Set-Cookie头后，会根据其中的指令将Cookie存储起来。


浏览器发送Cookie：当浏览器向同一域发送后续HTTP请求时，会自动在请求头中包含之前存储的、与当前请求域和路径匹配的Cookie。服务器收到这些Cookie后，就可以识别用户并提供个性化服务。


Web缓存
Web缓存(Web cache)，更常见的名字为代理服务器(proxy server)，代表初始Web服务器满足HTTP请求的网络实体；

一般认为Web缓存既是服务器也是客户机；
设计的目的是减少对客户机请求的响应时间，减少内部网络与接入链路上的通信量，以减少Internet上的Web流量；

内容分发网络(content distribution network, CDN) 是通过网关缓存/反向代理，它们在全球部署缓存节点，以实现快速内容分发。通常由网站开发者部署，以提高网站的可伸缩性、可靠性和性能。
条件GET方法用于证实缓存器中的对象是否为最新，避免获取缓存下来的陈旧的对象副本；
缓存器：在请求报文中包含对象最后修改时间 If-modified-since: &lt;date&gt;
服务器: 如果对象是最新的则响应报文中不包含对象HTTP/1.0 304 Not Modified;
FTP
特点
FTP协议的主要工作是将文件从一台主机中复制到远程主机中；其中需要关注不同系统文件系统的差异性，减少不同操作系统处理文件的不兼容性；
FTP协议提供文件传送的基本服务：

主要依靠TCP的可靠运输服务；
采取C/S架构，一个FTP服务器可为多个多个客户进程提供服务；
服务器包含一个主进程（用于处理新请求）和若干从属进程（用于处理单个请求）；

设计
FTP的工作流程如下

主进程运行在端口21上，等待客户进程的连接请求；
启动从属进程来处理客户进程发来的请求。
从属进程对客户进程的请求处理完毕后即终止，但从属进程在运行期间根据需要还可能创建其他一些子进程。
回到等待状态，继续接受其他客户进程发来的请求。主进程与从属进程的处理是并发地进行。

值得注意的是，FTP协议采取两个TCP连接

控制连接在整个会话期间一直保持打开，但是控制连接不用来传送文件；
服务器端的控制进程在接收到 FTP 客户发送来的文件传输请求后就创建"数据传送进程"和"数据连接"；

数据传送进程用来连接客户端和服务器端；
数据连接用于传输文件；
数据传送进程实际完成文件的传送，在传送完毕后关闭数据传送连接并结束运行；


两个连接运行在不同的端口号上，控制连接和数据连接不会混乱

当客户进程向服务器进程发出建立连接请求时，要寻找连接服务器进程的熟知端口(21)，同时还要告诉服务器进程自己的另一个端口号码，用于建立数据传送连接。
接着，服务器进程用自己传送数据的熟知端口(20)与客户进程所提供的端口号码建立数据传送连接。




这样的设计可能有如下考虑：

协议更简单，易于实现；
传输文件可以操作控制连接，比如发送请求终止传输；

命令 &amp; 应答
所有命令在控制连接上以ASCII文本形式发送



命令
描述




USER &lt;username&gt;
指定用户名


PASS &lt;password&gt;
指定密码


LIST
返回当前远程目录的文件列表


RETR &lt;filename&gt;
获取远程主机当前目录下的1个文件(get)


STOR &lt;filename&gt;
存放1个文件到远程主机当前目录下(put)



下表是常见的状态码对应的短语



状态码
描述




331
Username OK, password required


125
data connection already open; transfer starting


425
Can't open data connection


452
Error writing file



以下是一个FTP控制台信息的举例
[01] ftp nic.ddn.mil [02] connected to nic.ddn.mil[03] 220 nic FTP server (Sunos 4.1)ready.[04] Name: anonymous[05] 331 Guest login ok, send ident as password.[06] Password: abc@xyz.math.yale.edu[07] 230 Guest login ok, access restrictions apply.[08] ftp&gt; cd rfc[09] 250 CWD command successful.[10] ftp&gt; get rfc1261.txt nicinfo[11] 200 PORT command successful.[12] 150 ASCII data connection for rfc1261.txt     (128.36.12.27,1401) (4318 bytes).[13] 226 ASCII Transfer complete.     local: nicinfo remote: rfc1261.txt     4488 bytes received in 15 seconds (0.3 Kbytes/s).[14] ftp&gt; quit[15] 221 Goodbye.
这些信息的注释如下：
[01] 用户要用 FTP 和远地主机(网络信息中心NIC 上的主机)建立连接。 [02] 本地 FTP 发出的连接成功信息。 [03] 从远地服务器返回的信息，220 表示&quot;服务就绪&quot;。 [04] 本地 FTP 提示用户键入名字。用户键入的名字表示&quot;匿名&quot;。用户只需键入 anonymous 即可。 [05] 数字 331 表示&quot;用户名正确&quot;，需要口令。 [06] 本地 FTP 提示用户键入口令。用户这时可键入guest 作为匿名的口令，也可以键入自己的电子邮件地址，即耶鲁大学数学系名为 xyz 的主机上的 abc。 [07] 数字 230 表示用户已经注册完毕。 [08] &quot;&quot;ftp&gt;&quot;是 FTP 的提示信息。用户键入的是将目录改变为包含 RFC 文件的目录。 [09] 字符 CWD 是 FTP 的标准命令，代表 Change Working Directory。 [10] 用户要求将名为 rfc1261.txt 的文件复制到本地主机上，并改名为 nicinfo。 [11] 字符 PORT 是 FTP 的标准命令，表示要建立数据连接。200 表示&quot;命令正确&quot;。 [12] 数字 150 表示&quot;文件状态正确，即将建立数据连接&quot;。 [13] 数字 226 是&quot;释放数据连接&quot;。现在一个新的本地文件已产生。 [14] 用户键入退出命令。 [15] 表明 FTP 工作结束。 
Email
设计
因特网的电子邮件系统有三个重要组件

用户代理(user agent)：常见的用户代理有微软的Outlook，Apple Mail等，用户代理允许用户阅读，回复，转发，保存，编辑邮件消息，用户经由代理发送写好的邮件给服务器；
邮件服务器(mail server)：电子邮件体系的核心，每个接收方在某个邮件服务器上有一个邮箱(mailbox)；邮件服务器维护一个外出报文队列(outgoing message queue)，用于处理故障等；
简单邮件传输协议(simple mail transfer protocol, SMTP)：作为邮件的主要应用层协议，采取TCP可靠数据传输服务，实现邮件服务器之间的互发消息；


值得注意的，与HTTP协议相比，

SMTP采取持久连接；而HTTP对于两类连接都有设计；
HTTP一类典型的PULL协议，而SMTP是典型的PUSH协议；
都有ASCII命令和应答交互，状态码的设计；
HTTP把Web对象封装到HTTP消息中，而SMTP将邮件中的对象置于同一个邮件消息的多目部分发送；

SMTP
客户采用TCP来将邮件消息直接发送到服务器端口号25，有如下三个步骤

握手：介绍双方基本信息，其中命令和应答交互的交互方式仍为ASCII文本和状态码短语；
邮件消息的传输：SMTP规定必须是7bitASCII码，这是一个比较陈旧的特性；
结束

一个邮件的发送和接收过程如下图所示

发信人调用用户代理来编辑要发送的邮件。用户代理用 SMTP 把邮件传送给发送端邮件服务器。
发送端邮件服务器将邮件放入邮件缓存队列中，等待发送。
运行在发送端邮件服务器的 SMTP 客户进程，发现在邮件缓存中有待发送的邮件，就向运行在接收端邮件服务器的 SMTP 服务器进程发起 TCP 连接的建立。若对方没有开机，则会稍后尝试；
TCP 连接建立后，SMTP 客户进程开始向远程的 SMTP 服务器进程发送邮件。当所有的待发送邮件发完了，SMTP 就关闭所建立的 TCP 连接。
运行在接收端邮件服务器中的 SMTP 服务器进程收到邮件后，将邮件放入收信人的用户邮箱中，等待收信人在方便时进行读取。
收信人在打算收信时，调用用户代理，使用 POP3（或 IMAP）协议将自己的邮件从接收端邮件服务器的用户邮箱中的取回（如果邮箱中有来信的话）。


指令 &amp; 应答
下表是常见的指令对应的短语含义



命令
说明
备注




HELO
邮件服务器标志用户身份
发送者欺骗说谎，伪造合法服务器身份


MAIL FROM
指定发件人地址
伪造成合法用户身份


RCPT TO
标志单个收件人地址，可有多个 RCPT TO
伪造收件人地址，如使用字典攻击或利用工具收集合法用户的邮箱地址


DATA
初始化数据传输并以 CRLF 结束
基于内容的垃圾邮件


QUIT
结束会话




邮件消息的格式
SMTP是用于交换邮件消息的协议，RFC822定义了文本邮件格式的标准。一个RFC822消息包含：

头部 (Headers)：由一系列"字段名: 字段体"对组成，每个字段占据一行，用于描述邮件的元数据，例如发件人（From）、收件人（To）、主题（Subject）、日期（Date）等。

字段名：标识字段的类型（如 From, To, Subject）。
字段体：包含字段的实际内容。
空行：一个空行（CRLF）表示头部的结束，将头部与邮件体分开。


邮件体 (Body)：包含实际的邮件内容，可以是纯文本。RFC822最初只支持7位ASCII文本。

多用途Internet邮件拓展(Multipurpose Internet Mail Extensions, MIME)在RFC2045中提出，用于邮件内容的多媒体拓展，它扩展了RFC822的限制，允许邮件包含：

非ASCII字符集：支持除ASCII之外的字符集，如UTF-8，使得邮件可以包含各种语言的文本。
非文本内容：支持在邮件中嵌入图片、音频、视频、应用程序文件等多种二进制数据类型。
多部分邮件：允许将邮件内容分成多个"部分"（parts），每个部分可以有不同的内容类型和编码方式，这些部分可以按层级结构组织。

MIME通过在邮件头部添加额外的字段来描述邮件内容的类型和编码，主要包括：

MIME-Version：指示邮件遵循MIME标准，通常为 1.0。
Content-Type：描述邮件或邮件部分的媒体类型和子类型（如 text/plain, text/html, image/jpeg, application/pdf, multipart/mixed 等），并可包含参数，如字符集 (charset)。
Content-Transfer-Encoding：指定邮件体或部分内容的编码方式，以确保二进制数据能通过只支持文本的邮件系统传输（如 base64, quoted-printable, 7bit, 8bit, binary）。
Content-Disposition：指示邮件内容的呈现方式，是作为附件 (attachment) 还是内联显示 (inline)。


邮件访问协议
邮件访问协议设计为用户代理从邮件服务器获取邮件消息的任务，主流的协议有如下几类：

POP: 邮局协议(Post Office Protocol )[RFC 1939]110端口号，需要代理与服务器的身份认证并下载邮件消息
IMAP: Internet Mail Access Protocol [RFC 1730]，更多功能特征
允许用户像对待本地邮箱那样操纵远程邮箱的邮件
HTTP: Hotmail , Yahoo! Mail, etc.


例如在POP3协议中，身份认证阶段(authorization phase)可能包含如下命令和应答

客户命令: user username 和pass password等
服务器响应：+OK和-ERR等

S: +OK POP3 server ready C: user bob S: +OK C: pass hungry S: +OK user successfully logged on
而传输阶段(transaction phase)可能包括如下过程

list: 列出邮件编号
retr: 按编号取邮件
dele: 删除
quit

C: list S: 1 498 S: 2 912 S: . C: retr 1 S: &lt;message 1 contents&gt;S: . C: dele 1 C: retr 2 S: &lt;message 1 contents&gt;S: . C: dele 2 C: quit S: +OK POP3 server signing off
POP3的会话是无状态的，POP3还区分如下两类模式，

Download-and-delete换客户端后不能再读邮件
Download-and-keep在不同客户机上的邮件拷贝

而IMAP允许用户直接在服务器的各文件夹中管理邮件消息

保存所有邮件消息在服务器；
IMAP跟踪用户会话的状态信息；
文件夹和邮件消息IDs与文件夹名字的映射

DNS
互联网上的主机一般通过便于记忆的主机名(hostname)或者IP地址来标识，域名系统(domain name system,DNS)负责将主机名映射到IP地址，其组件如下：

一个有分层的DNS服务器实现的分布式数据库；
一个使得主机查询数据库的应用层协议；

DNS必须是分布式的，而不是集中式的，因为集中式可能带来的单点故障，巨大访问量，难以维护导致的不可拓展问题；
服务
一个DNS服务器通常是运行在软件BIND(Berkeley Internet Name Domain)的UNIX机器；DNS规范中在RFC1034中定义

它依靠的运输层协议是UDP；
运行在53号端口上；
采用C/S架构，但不直接和用户打交道，而是为其他应用程序提供域名解析的功能，为其他应用层协议使用；

简而言之，DNS服务器提供的服务可概括为

主机名到IP地址的映射；
主机别名：一个主机拥有一个规范主机名和多个主机别名；
邮件服务器别名；
负载分配：通过冗余服务器实现，将一个IP地址结合对应于同一个规范主机别名；

有三种类型的DNS服务器，这些大量的DNS服务器以层次的方式组织成分布式数据库，注意没有一台DNS服务区具有Internet上所有主机的映射；如图所示

根DNS服务器(root name)：根名字服务器负责记录顶级域名服务器的信息
顶级域DNS服务器(top-level domain, TLD)：负责顶级域名 com, org, net, edu, etc, 和所有国家的顶级域名 uk, fr, ca, jp.比如Network solutions 公司维护com顶级域的TLD服务器和Educause 公司维护edu顶级域的 TLD服务器
权威DNS服务器：多数大学和公司维护它们的基本权威DNS服务器。在因特网上具有公共可访问主机（如Web服务器和邮件服务器）的每个组织机构必须提供公共可访问的DNS记录，这些记录将这些主机的名字映射为IP地址。组织机构的权威DNS服务器负责保存这些DNS记录。


本地DNS服务器一般不认为属于层次结构中，每个ISP都会有一个DNS服务器，也是默认服务器；当主机发出DNS请求时，将首先发往本地DNS服务器，起代理的作用，转发请求到层次结构中；
层次树命名
连接在Internet上的主机（包括路由器）对应一个域名(domain name)；由若干分量组成，用点隔开*.三级域名.二级域名.顶级域名
这种层次结构对应了DNS服务器的层次结构；这样的结构解决了扩展性问题；
一个客户机查询主机名IP地址的自顶向下的示例过程和示例图如下：

客户机递归查询根服务器得到dns.edu DNS服务器
客户机迭代查询dns.edu 服务器得到dns.cs.umass.edu 服务器
客户机迭代查询dns.cs.umass.edu 服务器得到gaia.cs.umass.edu的IP地址


缓存
DNS缓存(DNS caching)技术用于改善时延性能和减少Internet上传输的DNS报文数量，直接的结果就是根DNS服务器不会被大量经常访问；

一旦名字服务器获得DNS映射, 它将缓存该映射到局部内存
服务器在一定时间后将丢弃缓存的信息
本地DNS服务器可以缓存TLD服务器的IP地址

IETF在RFC 2136中正在设计动态更新/通报机制；
记录
DNS作为数据库的一种，我们也关心其记录是什么格式的，有关内容记录在RFC1034中；
资源记录(resource record,RR)存储在DNS服务器中，其格式为具有如下形式的四元组：(NAME, VALUE, TYPE, TTL)
TTL (Time To Live)是该记录的生存时间，指示该记录在DNS服务器中缓存多长时间（秒）。其余的字段的有一种对应关系，如下表所示



类型 (Type)
名称 (Name)
值 (Value)
描述 (Description)
示例 (Example)




A
主机名
IP地址
将主机名映射到对应的IP地址
(gaia.cs.umass.edu, 128.119.245.12, A, TTL)


NS
域
权威DNS服务器的主机名
标识该域的权威DNS服务器
(foo.com, dns.foo.com, NS, TTL)


CNAME
别名主机名
规范主机名
将别名主机名映射到其规范主机名。别名主机名不能有其他记录
(www.foo.com, foo.com, CNAME, TTL)


MX
邮件服务器的别名
邮件服务器的规范主机名
允许一个公司的邮件服务器和Web服务器使用同一个别名
(foo.com, mail.bar.blop.com, MX, TTL)



这些不同类型的记录对应不同场景下在DNS数据库插入记录的操作


如果你想在注册登记机构注册你的域名example.com，则
需要提供你自己的基本权威DNS服务器和辅助权威DNS服务器的名字和IP地址
(example.com, dns1.example.com, NS)(dns1.example.com, 212.212.212.1, A)


建立一个网站，则可以将网址www.example.com以类型A的方式记录到你的权威DNS服务器dns1.example.com中。


建一个邮件服务器，则可以将mail.example.com以类型MX的方式记录到你的权威DNS服务器dns1.example.com中。


消息
DNS的查询报文和应答报文具有相同的格式，如图所示，前12字节为首部区域；

标识符：16比特，查询和应答报文使用相同的标识符；
标志：有若干标识位代表不同功能

查询/应答－0/ 1
查询希望是/非递归查询－1/0
应答可/否获得(支持)递归查询－1/0
应答是/否来自权威名字服务器－1/ 0


问题部分：查询的Name, type;
回答部分：对于查询,应答的资源记录，可以多个资源记录，由于可以有多个IP地址
权威部分：权威名字服务器的其他资源记录
附加信息部分：其他有帮助的记录.


P2P
有一类非常自然的P2P应用，比如发布操作系统的更新，游戏的补丁；这些用户数量巨大，全部交由服务器是不现实的，在P2P文件分发中，每个对等方向其他对等方发送它接收到文件的部分；
设计
点对点网络(Peer-to-Peer, P2P)是一种去中心化的网络架构，其中对等方直接相互交互，无需依赖中央服务器或中心机构。
在P2P网络中，每个对等方既充当客户端，也充当服务器，从而能够直接与其他对等方共享资源和服务。
这样的设计带来了如下的特点：

去中心化
资源共享
直接通信
可伸缩性
容错性和冗余
隐私和安全性......

内容分发时间
在文件分发场景中，P2P架构与传统的客户端-服务器（C/S）架构在内容分发时间上存在显著差异。假设要分发一个大小为 F 比特的文件给 N 个对等方。
在C/S架构中，文件分发由一个中央服务器独立完成，所有对等方都从该服务器下载文件。分发时间 Dcs的下限由以下两个因素决定：

服务器上传能力限制：服务器必须将文件的 N 份副本上传给 N 个对等方。如果服务器的上传速率为 Us，则至少需要 N * F / Us 的时间。
最慢客户端下载能力限制：所有 N 个对等方都必须下载文件的完整副本。如果所有对等方中下载速率最慢的为 Dmin，则最慢的对等方至少需要 F / Dmin 的时间来下载文件。

综合以上两点，客户端-服务器架构下的最小分发时间为：

对于足够大的 N，Dcs 倾向于由服务器上传能力限制，即 N * F / Us。这意味着分发时间将随对等方数量 N 线性增长，这在用户数量庞大时会成为瓶颈。
在P2P架构中，每个对等方在下载文件的同时，也可以将已下载的部分上传给其他对等方，从而协助分发。分发时间 Dp2p（P2P Distribution Time）的下限由以下三个因素决定：

服务器上传能力限制：与C/S架构类似，服务器至少需要将文件初始上传一次，时间为 F / Us。
最慢对等方下载能力限制：与C/S架构类似，最慢的对等方至少需要 F / Dmin 的时间来下载文件。
整个系统总上传能力限制：为了将文件的 N 份副本分发给 N 个对等方，系统总共需要传输 N * F 比特的数据。这些数据由服务器和所有对等方共同上传。如果系统总上传速率为 Utotal（即服务器上传速率 Us 加上所有对等方上传速率 Ui 的总和），则至少需要 N * F / Utotal 的时间。

综合以上三点，P2P架构下的最小分发时间为：

其中，；

P2P网络优缺点
P2P网络相对于传统的客户端-服务器架构具有以下优点和缺点：



优点 (Advantages)
缺点 (Disadvantages)




去中心化和弹性：没有单点故障，网络更具弹性。
缺乏集中控制：难以管理和协调网络活动，难以执行一致的策略并确保数据完整性。


易于扩展：随着对等方数量增加，可用资源和能力随之增长，可处理更大的工作负载。
网络管理复杂性：对等方责任均等，网络管理任务（如寻址、安全性、性能优化）必须在参与者之间分配，需要额外的协调和努力。


高效资源利用：通过在多个对等方之间分配负载，提高资源利用率。
依赖对等方可用性：资源和服务的可用性取决于对等方的活跃参与，如果大量对等方离线或不活跃，可能会影响性能和可用性。


成本节约：无需昂贵的专用服务器或集中式基础设施，设置和维护成本更低。
性能和效率可变性：P2P网络的性能受参与对等方的数量和质量、可用资源以及网络拓扑等因素的影响，可能导致不可预测的行为。


直接通信和更快的内容交付：对等方之间直接通信，消除中介，实现更快的交付和实时交互。
安全风险：如果未采取适当预防措施，P2P网络可能会引入安全风险。恶意对等方可能利用网络中的漏洞发起攻击或分发恶意内容。


增强隐私和安全性：对等方之间直接通信可以加密，保护数据机密性，降低单点攻击的脆弱性。
法律和版权问题：P2P网络与版权侵权和非法共享受版权保护保护材料相关联。虽然P2P技术本身不违法，但它可能促进未经授权的共享，从而引发法律和道德问题。



集中式和非集中式搜索
集中式搜索：Napster
Napster是一个早期的P2P文件共享服务，它使用一个中心服务器来维护所有在线用户的共享文件列表。当用户想要查找文件时，他们会向中心服务器发送查询。服务器返回包含该文件的用户列表，然后用户可以直接从这些用户下载文件。
非集中式搜索：Gnutella
Gnutella是一个全分布式的P2P网络协议，没有集中式服务器。它采用查询洪泛(query flooding)机制来查找文件。

工作原理：当一个对等方需要查找文件时，它会向其直接连接的对等方发送查询报文。这些对等方会进一步转发该报文给它们的连接对等方，直到达到某个跳数限制或找到文件。匹配的对等方会发送 QueryHit 报文，该报文会沿着反向路径传回发起查询的对等方。
覆盖网络(Overlay Network)：Gnutella网络中的所有活跃对等方及其TCP连接构成了一个覆盖网络（逻辑图），这些连接不是物理通信链路。通常，一个对等方在覆盖网络中连接的节点数量少于10个。
可扩展性：为了限制查询洪泛带来的网络负载，Gnutella通常采用限范围泛洪（Limited-scope flooding）机制，即查询报文只在有限的跳数内转发。
加入对等方：新的对等方（如对等方X）加入Gnutella网络时，它需要发现网络中的其他对等方。通常通过使用一个已知的对等方列表。X会尝试与列表上的对等方建立一条TCP连接，直到与某个对等方Y成功连接。X向Y发送一个 Ping 报文；Y转发该 Ping 报文。所有的对等方接收 Ping 报文并响应一个 Pong 报文。X接收到许多 Pong 报文。然后能同某些其他对等方建立TCP连接。


混合式架构：KaZaA
KaZaA是一种流行的文件共享P2P应用，它采用了混合式的P2P架构，结合了集中式和去中心化的特点。它引入了"超级对等方"（Super-peers）或"组长"的概念，这些超级对等方充当了网络的局部索引服务器。
层次结构：每个对等方要么被指派为"组长"（Super-peer），要么被指派给一个"组长"作为其"子对等方"。

对等方与组长之间的连接：对等方与它们的组长之间建立TCP连接。
组长之间的连接：组长之间也建立TCP连接，形成一个高层级的覆盖网络。

内容管理：组长负责维护其所有子对等方共享的内容的索引。当子对等方共享文件时，它们会将文件信息（如文件名、大小、哈希值等）报告给其组长。
文件查询：

客户端（对等方）向其组长发送关键词查询。
组长响应匹配的逐项信息，包括元数据、文件的散列值和持有该文件的对等方的IP地址。
如果组长没有找到匹配项，它可能会将查询转发给其他组长，其他组长会响应匹配。

文件下载：客户端选择要下载的文件后，直接向持有该文件的对等方发送HTTP请求（使用文件的哈希值作为标识符）。
下载优化机制：

请求排队：限制对等方并行上传的数量，新的下载请求进入队列等待。
激励优先权：根据不同的上传/下载比例优先服务贡献大的对等方，鼓励用户共享资源。
并行下载：将一个文件分成若干段，从多个对等方并行下载，以提高下载速度。

CDN
HTTP stream &amp; DASH
传统的流媒体（如RTP/RTCP）通常需要专门的流媒体服务器和协议来传输音视频内容。而HTTP流媒体是利用标准的HTTP协议来传输多媒体内容的一种方式。它的主要优势在于可以复用现有的Web基础设施，无需部署额外的流媒体服务器，这大大简化了内容分发。
HTTP流媒体的核心思想是将音视频内容分割成小的、独立的媒体片段，然后通过HTTP协议逐步下载这些片段并在客户端进行播放。这种方式使得内容分发能够充分利用HTTP缓存、CDN等现有技术。
DASH（Dynamic Adaptive Streaming over HTTP），用于通过HTTP传输流媒体内容。它的主要特点是"自适应"，这意味着客户端可以根据网络带宽、CPU负载等条件动态地选择不同质量（比特率、分辨率）的媒体片段进行下载和播放。
原始的音视频内容会被编码成多种不同比特率和分辨率的版本。每个版本再被分割成许多小的、固定或可变长度的媒体片段（通常是几秒钟）。
**媒体演示描述 (Media Presentation Description, MPD)：**一个XML文件作为告示文件，存储在HTTP服务器中，包含了关于所有可用媒体片段的元数据，包括：

不同质量版本的URL。
每个片段的时长。
编解码器信息。
内容版权信息等。

客户端首先下载MPD文件，然后根据其中的信息来决定下载哪些媒体片段。客户端适应性播放：

客户端持续监测当前的网络带宽状况和设备性能。
根据监测结果，客户端会智能地选择下载最适合当前条件的媒体片段。例如，如果网络带宽下降，客户端会自动切换到低比特率的视频片段，以避免卡顿；反之，如果带宽充足，则切换到高比特率以提供更好的观看体验。
客户端会维护一个缓冲区，预先下载一些片段，以应对网络波动。

CDN
内容分发网络(Content Delivery Network, CDN) 是一个地理上分散的服务器网络，用于高效地向用户分发内容。主要为视频流，网站加速，文件下载等公司采用；它们有些部署自己的CDN，有些采用第三方的服务；
CDN 的工作原理：

缓存内容：当用户首次请求某个内容（如图片、视频、网页、JavaScript 文件等）时，CDN 会从原始服务器（源站）获取该内容，并将其缓存到离用户最近的CDN节点（边缘服务器）上。
就近分发：大多数CDN利用DNS进行重定向请求，意思是后续用户再次请求相同内容时，如果该内容已经在附近的CDN节点上缓存，CDN 会直接从该节点提供服务，而无需回源到原始服务器。
流量管理：CDN 能够智能地将用户请求路由到性能最佳的边缘服务器，这通常是地理位置最近或负载最轻的服务器。
负载均衡：通过将流量分散到多个服务器上，CDN 可以有效地分担源站的压力，防止因高并发访问导致服务器过载。


CDN的部署遵循集群选择策略，动态地将用户定向到CDN中地某个数据中心地机制；可以是基于地理的，或者基于流量的；
套接字编程
套接字（Socket）是网络编程中用于实现进程间通信的一种抽象机制。它作为应用程序与网络协议栈之间的接口，允许程序通过网络发送和接收数据。在计算机网络中，不同主机上的进程通过套接字相互通信。
每个套接字都绑定到一个IP地址和端口号，从而唯一标识网络上的一个进程。

IP地址：标识主机在网络中的位置。在Python中用socket.AF_INET作为参数代表IPv4;
端口号：标识主机上运行的特定进程或服务。

Stream
流套接字(streaming sockets)使用TCP协议。

提供面向连接的、可靠的、有序的、基于字节流的数据传输。
在Python中使用SOCK_STREAM作为初始化参数传入；
适用于需要高可靠性、对数据完整性和顺序有严格要求的应用，如Web浏览（HTTP）、文件传输（FTP）和电子邮件（SMTP）。

客户端和服务端基本步骤如下：
服务器端基本步骤：


创建套接字：server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)


（服务端）绑定地址和端口：server_socket.bind(('127.0.0.1', 12345))，用户端不需要；TCP监听连接：server_socket.listen(5)；TCP接受连接：client_socket, client_address = server_socket.accept()用于获得客户端套接字（和客户端的地址。
（用户端）连接服务器：client_socket.connect(('127.0.0.1', 12345))


发送字节数据：client_socket.sendall(b"Hello from server")


接收字节数据：data = client_socket.recv(1024)


关闭套接字：server_socket.close()


Datagram
数据报套接字 (Datagram Sockets)使用UDP协议。

提供无连接的、不可靠的、无序的数据传输。
在Python中使用SOCK_DGRAM作为初始化参数传入；
适用于对实时性要求高、容忍少量数据丢失的应用，如在线游戏、VoIP（网络电话）和DNS查询。

服务器端和用户端基本步骤：


创建套接字：server_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)


（服务端）绑定地址和端口：server_socket.bind(('127.0.0.1', 12345))
（客户端）无操作


接收和发送数据：使用 recvfrom() 接收数据（同时获取发送方的地址），使用 sendto() 发送数据（需要指定目标地址）。
data, client_address = server_socket.recvfrom(1024)server_socket.sendto(b&quot;Hello back&quot;, client_address)


关闭套接字：server_socket.close()


]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Computer-Network</tag>
      </tags>
  </entry>
  <entry>
    <title>Autoencoder</title>
    <url>/2025/06/21/Autoencoder/</url>
    <content><![CDATA[Introduction
架构
CNN的训练样本是带有标签的。在很多实际应用中， 训练样本是没有标签的。应用误差反向传播算法来训练网络会遇到一些困难。
自编码器(autoencoder)采用让输入和输出相等的idea， 隐含层用于记录数据特征，这是典型的表示学习(representation learning)/特征学习(feature learning)办法,由Hinton等人提出；

autoencder是一种尽可能重构输入信号的神经网络，必须捕捉可以代表输入数据的最重要的内在因素

给定输入和输出相同的一个神经网络
训练网络获得隐藏层的权重，每一层就是一种表示/特征(representation);

训练
具体来说，在第一次编解码训练中/网络表达中


为input序列增加一个encoder，得到输入的一个representaion,记作


继续增加一个decoder，输出最终的使用信号重构的方式评估这个representaion的质量


目标是最小化输入输出的差异,训练隐含层的权重矩阵；




Autoencoder的训练过程是逐层静态进行的，通过对encoder的stack，不断将前一层输出的code作为后一层输入的信号；

在完成Autoencoder 的学习任务之后，在实际应用中，在解码阶段学习得到的权重将不进行考虑。因此，编码阶段获得的网络系统其实质是一种特征学习。层级越高，结构特征越大越明显。

对于分类任务，可以事先用Autoencoder 对数据进行学习。然后以学习得 到的权值作为始初权重，采用带有标签的数据对网络进行再次学习，即fine tuning技术。
为了实现分类任务，需要在编码阶段的最后一层加上一个分类器，比如一个 多层感知器（MLP）

扩展
在早期Hinton的工作中，采用RBM 来 预训练网络，同时采用对称的网络结构，即解码器中的权重矩阵与编码器中的权重矩 阵呈转置关系。一个原因是当时训练数据少，且计算能力有限；
正则编码器(regularized AE): 可以使得提取的特征符合某种性质，应用惩罚大权重的L2正则化

稀疏自编码器(Spare AE)基于高维稀疏表示的假设，提取稀疏的特征表示，采用神经元平均激活度为度量

采用如下的稀疏约束限制神经元平均激活度在一个很小的度

去噪自编码器(denoising AE)基于对噪声化的原始数据根据编码和解码，能还原真正原始数据的鲁棒特征，通过提取鲁棒的特征表示，完成去噪工作；
它假定污染是如下过程

采用如下的编解码过程

总的来说，这些自编码器的工作，它们的目的都是数据将为，都具有编码器和解码器的结构，具有窄的bottleneck，通过对输入信号的重建，将输入降维成一种表征；因此，autoencoder不是一种生成模型。
]]></content>
      <tags>
        <tag>Machine-Learning</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>Brown运动</title>
    <url>/2025/07/05/Brown%E8%BF%90%E5%8A%A8/</url>
    <content><![CDATA[Brown运动
随机过程如果满足：





有平稳独立增量；


对 每 个, 服从正态分布;


则称​为Brown运动，也称为Wiener过程.
等价定义如下：

(正态增量)
(独立增量)独立于过程的过去状态,
(路径的连续性)是​的连续函数.


Property

Brown运动是Gauss过程，
Brown运动具有Markov性；

Mark
如果,我们称之为标准Brown运动。如果,则可考虑​,它是标准Brown运动. 故不失一般性，可以只考虑标准Brown运动的情形。
等价定义并没有假定,因此我们称之为始于的Brown运动,所以有时为了强调起始点,也记为 ;
有限维分布
对于Brown运动,以及,有如下联合分布函数

即 的联合概率密度为

路径性质
对于Brown运动的一条样本路径, 几乎有如下性质:对区间遍取分割,且其模， 满足当极限的意义是依均方收敛；


是的连续函数；


在任意区间(无论区间多么小)上都不是单调的；


在任意点都不是可微的；


在任意区间(无论区间多么小)上都是无限变差的



对任意在上的二次变差等于



首中时刻5e70fdff-dd4d-4053-824d-fecd94dfde17
以记Brown运动首次击中的时刻，即

对, 由 全 概 率公式

若,则在中的某个时刻击中,由对称性得


再由连续性可知，不可能还未击中就大于,

由此可见

性质称为Brown运动的常返性。
根据式(3),的分布函数和概率密度函数如下：

期望如下：

虽然几乎必然是有限的，但有无穷的期望.直观地看，就是Brown运动以概率1会击中，但它的平均时间是无穷的。
Brown运动的最大值变量
对Brown运动中在达到的最大值

其分布对有

而对于Brown运动在中达到的最小值,
当时 , 有

Brown 运动的反正弦律
设 为始于的Brown运动，则在中至少有一个零点的概率为

只需要知道Brown运动的最小值分布即可；
在区间中至少有一个零点的概率为

那么没有零点的概率为
证明：
在中至少有一个零点在中至少有一个零点
取时刻之前的最后一个零点 \zeta_{t} = \sup{s\leq t,B(s)=0}
时刻之后的第一个零点\beta_{t} = \inf{s\geq t,B(s)=0} 
由反正弦律有
在中没有零点在中没有零点在中没有零点
Brown桥
设是Brown运动.令

则称随机过程为Brown桥。
Property
对



​
​
Brown桥也是Gauss过程

有吸收值的Brown运动
设为Brown运动首次击中的时刻，令
若若
则是击中后，永远停留在那里的Brown运动。
离散部分的分布为

连续部分的分布：对

在原点反射的Brown运动
,则称随机过程为在原点反射的Brown运动.它的概率分布为

几何Brown运动
由 定 义 的 随 机 过 程 称 为 几 何 Brown运动。
由于Brown运动的矩母函数为,所以几何Brown运动的均值函数与方差函数分别为

在金融市场中，人们经常假定股票的价格按照几何Brown运动变化。
有漂移的Brown运动
设 是 标 准 Brown运 动 , 我 们 称 为 有 漂 移的Brown运动;
其中常数称为漂移系数。容易看出，有漂移的 Brown运 动 是 一 个 以 速 率漂移开去的过程；
对任意常数,记  为过程在击中之前击中的概率，有
在击中之前击中
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Random Process</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake入门</title>
    <url>/2025/07/05/CMake%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[CMake入门
CMake简介
CMake 是一个跨平台的构建系统生成工具，用于管理编译过程，其主要功能如下：

通过读取配置文件（CMakeLists.txt）
生成特定于平台的构建文件（如 Makefile 或 Visual Studio 工程文件）；
帮助用户管理项目的依赖关系、编译流程等；

也就是说CMake是一套交叉编译的工具链，通过CMake我们可以更好地管理项目结构；
CMake 相比于传统的构建工具（如直接编写 Makefile），具有以下几个核心特性：


跨平台：CMake 支持多个平台（如 Windows、Linux、macOS)和编译器(GCC、Clang、MSVC 等），通过生成平台特定的构建系统文件，能够帮助开发者更轻松地在不同平台上编译项目。


依赖管理：CMake 能够自动检测并配置项目的依赖库，确保在编译过程中正确地链接外部库。例如，它可以通过 find_package 指令查找和配置第三方库。


增量编译：CMake 支持增量编译机制。当源代码部分更新时，它只会重新编译受影响的部分，减少不必要的编译时间。


模块化与可扩展性：CMake 允许用户编写模块和脚本，用于管理更复杂的项目结构。它提供了丰富的指令集来配置编译流程，并且可以通过编写自定义的模块扩展其功能。


可集成性：CMake 可以生成多种构建工具的配置文件，支持不同的 IDE 和构建系统；


C++工程目录设计最佳实践
一个典型的 C++ 项目目录结构应该具有清晰的分层，常见的目录和文件如下：
/project-root├── CMakeLists.txt       # 项目的主 CMake 配置文件├── src/                 # 源文件目录│   ├── main.cpp         # 主程序入口│   ├── module1.cpp      # 模块1的源文件│   ├── module2.cpp      # 模块2的源文件├── include/             # 公共头文件目录│   ├── module1.h        # 模块1的头文件│   ├── module2.h        # 模块2的头文件├── lib/                 # 外部库（静态或动态库）存放目录├── bin/                 # 存放二进制文件├── tests/               # 测试代码│   ├── CMakeLists.txt   # 测试目录的 CMake 文件│   ├── test_module1.cpp # 测试模块1的单元测试├── examples/            # 示例代码├── docs/                # 文档（用户指南、API 文档等）├── build/               # 构建生成目录（通常不放入源码控制系统中）├── scripts/             # 构建、部署、运行等自动化脚本├── README.md            # 项目说明文件└── LICENSE              # 项目许可证
除此之外，仍有一些细节需要注意：


src/ 和 include/ 目录分离


src/ 中应该存放项目的 .cpp、.c 文件，即项目的具体实现代码。


include/则存放公共的 .h、.hpp 文件，这些头文件定义了接口，并且其他项目或模块可以包含这些头文件。


使用这种分离策略有助于清晰地定义哪些文件是实现细节，哪些文件是对外暴露的接口；


注意在头文件中不要using namespace std;;




模块化管理


对于中大型项目，将代码划分为多个逻辑模块或库会使项目更具可维护性和可扩展性;


每个模块通常有自己的源文件和头文件;


每个模块应该尽量自包含，模块的头文件和实现文件可以放在各自的子目录下,例如：
/project-root├── src/│   ├── module1/│   │   ├── module1.cpp│   │   └── CMakeLists.txt│   ├── module2/│   │   ├── module2.cpp│   │   └── CMakeLists.txt├── include/│   ├── module1/│   │   └── module1.h│   ├── module2/│   │   └── module2.h




依赖管理

lib/ 目录：推荐通过自动化脚本或包管理工具自动下载和构建依赖，而非手动放入外部库的二进制文件；
third_party/ 目录：将外部依赖源代码放在 third_party/ 目录中，并使用 CMake 或其他工具集成；



测试目录结构

tests/ 目录应该用于存放所有的测试代码；
推荐使用与项目主目录相同的模块化结构，保证测试代码清晰、独立，方便集成到 CI/CD 流程中



文档目录

docs/ 目录用于存放项目的文档资料，文档可以包含项目概述、API 文档、使用指南、开发者指南等。
推荐使用 Doxygen并将其保存在此目录中;



构建输出目录

build/** 目录用于存放项目的构建输出文件（如中间文件、可执行文件等）。
为了避免污染源码目录，建议将构建生成的文件放入单独的 build/ 目录中，并将此目录加入 .gitignore 中，防止其被加入版本控制;



使用脚本自动化流程

scripts/ 目录可以用于存放一些常用的自动化脚本，如构建、清理、测试、打包、发布等脚本。
通常包括build.sh, test.sh, deploy.sh




CMake基本编译原理
CMake 的编译过程可以分为几个主要步骤：


配置阶段：

读取 CMakeLists.txt 文件：

CMake 通过解析项目中的 CMakeLists.txt 文件来获取项目信息（源文件、依赖库、编译选项等）;


生成构建系统：

``CMake解析CMakeLists.txt` 后，基于当前平台和用户指定的生成器生成特定的构建系统文件这些生成的文件控制项目的编译流程;





生成阶段：

CMake 根据配置阶段的结果，生成构建文件(如IDE工程文件)，详细描述了如何从源代码生成目标文件;
CMake不直接编译代码，而是通过生成的构建系统文件调用具体的编译工具链来进行编译。



编译阶段：

用户运行生成的构建系统（例如执行 make 命令），调用编译器编译源代码，生成目标文件（如 .o 文件）。
链接目标文件，生成最终的可执行文件或库文件（如 .exe 或 .so/.dll 文件）。



简要来说，如果我的项目遵循上述的最佳实践的话，可以通过一个文件编写两条命令实现：

编写CMakeLists.txt;
cmake .
cmake --build .

CMakeLists.txt编写原则


模块化:

将项目配置划分为多个 CMake 文件；
使用变量来避免重复代码，并通过函数/宏封装复杂的操作。



指定最低版本要求

每个项目的 CMakeLists.txt 中明确指定所需的最低 CMake 版本；



项目声明

定义项目名称和相关语言



管理编译选项：

设置编译器选项：通过 target_compile_options() 为目标指定编译器选项，而不是使用全局变量 CMAKE_CXX_FLAGS，这样可以避免全局配置导致的不必要副作用。
使用 CMAKE_BUILD_TYPE：通过 CMAKE_BUILD_TYPE 设置构建模式（如 Debug 或 Release）。在实际项目中，建议允许用户在命令行中指定，而非硬编码在 CMakeLists.txt 中；



处理依赖项：

如果项目依赖于外部库，使用 find_package() 查找库，并根据需要设置是否强制要求该库；
对于一些外部库，可以使用 FetchContent 下载和构建它们，避免手动配置；



管理源文件

将源文件列表集中管理，并根据项目结构清晰划分。例如，可以将源文件分组，并使用 file() 或变量存储文件路径；



启用自动化测试：

建议为项目配置测试框架，并使用 CMake 的 enable_testing() 和 add_test() 来集成测试



多平台支持：


检查系统特性：使用 if() 检查不同的平台或编译器选项，并在 CMakeLists.txt 中做出适应性调整。


设置跨平台编译选项：使用 target_compile_options() 和 target_link_libraries() 管理特定平台的编译选项；




支持安装和打包：

为了方便部署项目，可以在 CMakeLists.txt 中配置安装和打包规则。使用 install() 命令设置如何将生成的可执行文件、库和其他资源安装到系统路径;



CMakeLists.txt配置具体含义
指定CMake的最低版本
cmake_minimum_required(VERSION 3.15)
项目命名
project(MyDraft)
指定C++标准
set(CMAKE_CXX_STANDARD 20)
设置编译器路径
set(CMAKE_C_COMPILER &quot;/usr/bin/gcc&quot;)set(CMAKE_CXX_COMPILER &quot;/usr/bin/g++&quot;)
确保它们只在项目第一次运行时配置, 避免重复配置,或者即使清除CMake缓存；
设置源文件目录
file(GLOB SRC_LIST &quot;$&#123;PROJECT_SOURCE_DIR&#125;/src/tb/*.cpp&quot;)
添加头文件路径
include_directories(include)
生成目标可执行文件
add_executable(tb $&#123;SRC_LIST&#125;)
外部库的引用
fmt库
从 CMake 3.11 开始，可以使用 FetchContent 自动 在 configure 时下载 {fmt} 作为依赖项：
include(FetchContent)FetchContent_Declare(  fmt  GIT_REPOSITORY https://github.com/fmtlib/fmt  GIT_TAG        e69e5f977d458f2650bb346dadf2ad30c5320281) # 10.2.1FetchContent_MakeAvailable(fmt)target_link_libraries(&lt;your-target&gt; fmt::fmt)
注意&lt;your-target&gt;应填写可执行文件的名称

在编译的最后一步，链接器会把编译后的目标文件（即 .o 文件或 .obj 文件）与所依赖的外部库（如静态库 .a 文件或动态库 .so/.dll 文件）链接在一起，生成最终的可执行文件。因此，target 通常是这个最终生成的可执行文件的名称；
如果项目中包含多个不同的可执行文件，每个可执行文件可能会依赖不同的库。在这种情况下，你可以为每个目标定义一个不同的 target，以便生成多个不同的可执行文件；

在头文件内加入
# define FMT_HEADER_ONLY 	//  推荐# include &quot;fmt/core.h&quot; 		//  char UTF-8主要的格式化函数，支持C++20编译时检查，依赖最小化。# include &quot;fmt/format.h&quot; 	//  完整的格式化API，除了额外的格式化函数之外，支持本地化（多语言支持）。# include &quot;fmt/ranges.h&quot; 	//  格式化ranges 和 tuples# include &quot;fmt/chrono.h&quot; 	// 	日期和时间的格式化。# include &quot;fmt/std.h&quot; 		// 	c++标准库类型的格式化支持。# include &quot;fmt/compile.&quot; 	//  格式化字符串的编译 (编译时格式化字符串检测)。FMT_STRING(s)# include &quot;fmt/color.h&quot; 	// 	端颜色和文本样式。# include &quot;fmt/os.h&quot; 		// 	提供系API。# include &quot;fmt/ostream.&quot; 	//  支持std::ostream。# include &quot;fmt/printf.h&quot; 	//  支持printf格式化。# include &quot;fmt/xchar.h&quot; 	//  选的wchar_t支持。
注意
相对路径问题
通常，工作目录是在命令行中运行可执行文件的地方;
如果设置bin/为输出目录，那么需要一个上级目录..才能回到项目根目录；
对于头文件的相对路径，通常会设置include_directories(include),直接引用对应模块即可；
示例
以下是一个CMakeLists.txt
# 指定`CMake`的最低版本cmake_minimum_required(VERSION 3.15)# 项目命名project(MyDraft)# 指定 C++ 标准set(CMAKE_CXX_STANDARD 20)# 设置编译器路径# set(CMAKE_C_COMPILER &quot;/usr/bin/gcc&quot;)# set(CMAKE_CXX_COMPILER &quot;/usr/bin/g++&quot;)# 设置可执行文件的输出目录SET(CMAKE_RUNTIME_OUTPUT_DIRECTORY &quot;$&#123;PROJECT_SOURCE_DIR&#125;/bin&quot;)# 添加头文件路径include_directories(include)# 设置源文件目录file(GLOB SRC_LIST &quot;$&#123;PROJECT_SOURCE_DIR&#125;/src/hello/*.cpp&quot;)# 生成目标可执行文件add_executable(hello $&#123;SRC_LIST&#125;)# 引入外部库include(FetchContent)FetchContent_Declare(  fmt  GIT_REPOSITORY https://github.com/fmtlib/fmt  GIT_TAG        e69e5f977d458f2650bb346dadf2ad30c5320281) # 10.2.1FetchContent_MakeAvailable(fmt)target_link_libraries(hello fmt::fmt)
我的目录树如下：
.MyCMake├── bin│   └── hello├── build│   ├── CMakeCache.txt│   ├── CMakeFiles│   │   ├── 3.30.3│   │   │   ├── CMakeCCompiler.cmake│   │   │   ├── CMakeCXXCompiler.cmake│   │   │   ├── CMakeDetermineCompilerABI_C.bin│   │   │   ├── CMakeDetermineCompilerABI_CXX.bin│   │   │   ├── CMakeSystem.cmake│   │   │   ├── CompilerIdC│   │   │   │   ├── a.out│   │   │   │   ├── CMakeCCompilerId.c│   │   │   │   └── tmp│   │   │   └── CompilerIdCXX│   │   │       ├── a.out│   │   │       ├── CMakeCXXCompilerId.cpp│   │   │       └── tmp│   │   ├── cmake.check_cache│   │   ├── CMakeConfigureLog.yaml│   │   ├── CMakeDirectoryInformation.cmake│   │   ├── CMakeScratch│   │   ├── hello.dir│   │   │   ├── build.make│   │   │   ├── cmake_clean.cmake│   │   │   ├── compiler_depend.make│   │   │   ├── compiler_depend.ts│   │   │   ├── DependInfo.cmake│   │   │   ├── depend.make│   │   │   ├── flags.make│   │   │   ├── link.txt│   │   │   ├── progress.make│   │   │   └── src│   │   │       └── hello│   │   │           ├── hello.cpp.o│   │   │           └── hello.cpp.o.d│   │   ├── Makefile2│   │   ├── Makefile.cmake│   │   ├── pkgRedirects│   │   ├── progress.marks│   │   └── TargetDirectories.txt│   ├── cmake_install.cmake│   ├── _deps│   │   ├── fmt-build│   │   │   ├── CMakeFiles│   │   │   │   ├── CMakeDirectoryInformation.cmake│   │   │   │   ├── Export│   │   │   │   │   └── b834597d9b1628ff12ae4314c3a2e4b8│   │   │   │   │       ├── fmt-targets.cmake│   │   │   │   │       └── fmt-targets-noconfig.cmake│   │   │   │   ├── fmt.dir│   │   │   │   │   ├── build.make│   │   │   │   │   ├── cmake_clean.cmake│   │   │   │   │   ├── cmake_clean_target.cmake│   │   │   │   │   ├── compiler_depend.make│   │   │   │   │   ├── compiler_depend.ts│   │   │   │   │   ├── DependInfo.cmake│   │   │   │   │   ├── depend.make│   │   │   │   │   ├── flags.make│   │   │   │   │   ├── link.txt│   │   │   │   │   ├── progress.make│   │   │   │   │   └── src│   │   │   │   │       ├── format.cc.o│   │   │   │   │       ├── format.cc.o.d│   │   │   │   │       ├── os.cc.o│   │   │   │   │       └── os.cc.o.d│   │   │   │   └── progress.marks│   │   │   ├── cmake_install.cmake│   │   │   ├── fmt-config.cmake│   │   │   ├── fmt-config-version.cmake│   │   │   ├── fmt.pc│   │   │   ├── fmt-targets.cmake│   │   │   ├── libfmt.a│   │   │   └── Makefile│   │   ├── fmt-src│   │   │   ├── ChangeLog.md│   │   │   ├── CMakeLists.txt│   │   │   ├── CONTRIBUTING.md│   │   │   ├── doc│   │   │   │   ├── api.rst│   │   │   │   ├── basic-bootstrap│   │   │   │   │   ├── layout.html│   │   │   │   │   ├── README│   │   │   │   │   └── theme.conf│   │   │   │   ├── bootstrap│   │   │   │   │   ├── alerts.less│   │   │   │   │   ├── badges.less│   │   │   │   │   ├── bootstrap.less│   │   │   │   │   ├── breadcrumbs.less│   │   │   │   │   ├── button-groups.less│   │   │   │   │   ├── buttons.less│   │   │   │   │   ├── carousel.less│   │   │   │   │   ├── close.less│   │   │   │   │   ├── code.less│   │   │   │   │   ├── component-animations.less│   │   │   │   │   ├── dropdowns.less│   │   │   │   │   ├── forms.less│   │   │   │   │   ├── glyphicons.less│   │   │   │   │   ├── grid.less│   │   │   │   │   ├── input-groups.less│   │   │   │   │   ├── jumbotron.less│   │   │   │   │   ├── labels.less│   │   │   │   │   ├── list-group.less│   │   │   │   │   ├── media.less│   │   │   │   │   ├── mixins│   │   │   │   │   │   ├── alerts.less│   │   │   │   │   │   ├── background-variant.less│   │   │   │   │   │   ├── border-radius.less│   │   │   │   │   │   ├── buttons.less│   │   │   │   │   │   ├── center-block.less│   │   │   │   │   │   ├── clearfix.less│   │   │   │   │   │   ├── forms.less│   │   │   │   │   │   ├── gradients.less│   │   │   │   │   │   ├── grid-framework.less│   │   │   │   │   │   ├── grid.less│   │   │   │   │   │   ├── hide-text.less│   │   │   │   │   │   ├── image.less│   │   │   │   │   │   ├── labels.less│   │   │   │   │   │   ├── list-group.less│   │   │   │   │   │   ├── nav-divider.less│   │   │   │   │   │   ├── nav-vertical-align.less│   │   │   │   │   │   ├── opacity.less│   │   │   │   │   │   ├── pagination.less│   │   │   │   │   │   ├── panels.less│   │   │   │   │   │   ├── progress-bar.less│   │   │   │   │   │   ├── reset-filter.less│   │   │   │   │   │   ├── resize.less│   │   │   │   │   │   ├── responsive-visibility.less│   │   │   │   │   │   ├── size.less│   │   │   │   │   │   ├── tab-focus.less│   │   │   │   │   │   ├── table-row.less│   │   │   │   │   │   ├── text-emphasis.less│   │   │   │   │   │   ├── text-overflow.less│   │   │   │   │   │   └── vendor-prefixes.less│   │   │   │   │   ├── mixins.less│   │   │   │   │   ├── modals.less│   │   │   │   │   ├── navbar.less│   │   │   │   │   ├── navs.less│   │   │   │   │   ├── normalize.less│   │   │   │   │   ├── pager.less│   │   │   │   │   ├── pagination.less│   │   │   │   │   ├── panels.less│   │   │   │   │   ├── popovers.less│   │   │   │   │   ├── print.less│   │   │   │   │   ├── progress-bars.less│   │   │   │   │   ├── responsive-embed.less│   │   │   │   │   ├── responsive-utilities.less│   │   │   │   │   ├── scaffolding.less│   │   │   │   │   ├── tables.less│   │   │   │   │   ├── theme.less│   │   │   │   │   ├── thumbnails.less│   │   │   │   │   ├── tooltip.less│   │   │   │   │   ├── type.less│   │   │   │   │   ├── utilities.less│   │   │   │   │   ├── variables.less│   │   │   │   │   └── wells.less│   │   │   │   ├── build.py│   │   │   │   ├── CMakeLists.txt│   │   │   │   ├── conf.py│   │   │   │   ├── contents.rst│   │   │   │   ├── fmt.less│   │   │   │   ├── index.rst│   │   │   │   ├── python-license.txt│   │   │   │   ├── _static│   │   │   │   │   ├── bootstrap.min.js│   │   │   │   │   ├── breathe.css│   │   │   │   │   └── fonts│   │   │   │   │       ├── glyphicons-halflings-regular.eot│   │   │   │   │       ├── glyphicons-halflings-regular.svg│   │   │   │   │       ├── glyphicons-halflings-regular.ttf│   │   │   │   │       └── glyphicons-halflings-regular.woff│   │   │   │   ├── syntax.rst│   │   │   │   ├── _templates│   │   │   │   │   ├── layout.html│   │   │   │   │   └── search.html│   │   │   │   └── usage.rst│   │   │   ├── include│   │   │   │   └── fmt│   │   │   │       ├── args.h│   │   │   │       ├── chrono.h│   │   │   │       ├── color.h│   │   │   │       ├── compile.h│   │   │   │       ├── core.h│   │   │   │       ├── format.h│   │   │   │       ├── format-inl.h│   │   │   │       ├── os.h│   │   │   │       ├── ostream.h│   │   │   │       ├── printf.h│   │   │   │       ├── ranges.h│   │   │   │       ├── std.h│   │   │   │       └── xchar.h│   │   │   ├── LICENSE│   │   │   ├── README.md│   │   │   ├── src│   │   │   │   ├── fmt.cc│   │   │   │   ├── format.cc│   │   │   │   └── os.cc│   │   │   ├── support│   │   │   │   ├── AndroidManifest.xml│   │   │   │   ├── Android.mk│   │   │   │   ├── bazel│   │   │   │   │   ├── BUILD.bazel│   │   │   │   │   ├── README.md│   │   │   │   │   └── WORKSPACE.bazel│   │   │   │   ├── build-docs.py│   │   │   │   ├── build.gradle│   │   │   │   ├── cmake│   │   │   │   │   ├── FindSetEnv.cmake│   │   │   │   │   ├── fmt-config.cmake.in│   │   │   │   │   ├── fmt.pc.in│   │   │   │   │   └── JoinPaths.cmake│   │   │   │   ├── compute-powers.py│   │   │   │   ├── C++.sublime-syntax│   │   │   │   ├── docopt.py│   │   │   │   ├── manage.py│   │   │   │   ├── printable.py│   │   │   │   ├── README│   │   │   │   ├── rtd│   │   │   │   │   ├── conf.py│   │   │   │   │   ├── index.rst│   │   │   │   │   └── theme│   │   │   │   │       ├── layout.html│   │   │   │   │       └── theme.conf│   │   │   │   └── Vagrantfile│   │   │   └── test│   │   │       ├── add-subdirectory-test│   │   │       │   ├── CMakeLists.txt│   │   │       │   └── main.cc│   │   │       ├── args-test.cc│   │   │       ├── assert-test.cc│   │   │       ├── chrono-test.cc│   │   │       ├── CMakeLists.txt│   │   │       ├── color-test.cc│   │   │       ├── compile-error-test│   │   │       │   └── CMakeLists.txt│   │   │       ├── compile-fp-test.cc│   │   │       ├── compile-test.cc│   │   │       ├── core-test.cc│   │   │       ├── cuda-test│   │   │       │   ├── CMakeLists.txt│   │   │       │   ├── cpp14.cc│   │   │       │   └── cuda-cpp14.cu│   │   │       ├── detect-stdfs.cc│   │   │       ├── enforce-checks-test.cc│   │   │       ├── find-package-test│   │   │       │   ├── CMakeLists.txt│   │   │       │   └── main.cc│   │   │       ├── format-impl-test.cc│   │   │       ├── format-test.cc│   │   │       ├── fuzzing│   │   │       │   ├── build.sh│   │   │       │   ├── chrono-duration.cc│   │   │       │   ├── chrono-timepoint.cc│   │   │       │   ├── CMakeLists.txt│   │   │       │   ├── float.cc│   │   │       │   ├── fuzzer-common.h│   │   │       │   ├── main.cc│   │   │       │   ├── named-arg.cc│   │   │       │   ├── one-arg.cc│   │   │       │   ├── README.md│   │   │       │   └── two-args.cc│   │   │       ├── gtest│   │   │       │   ├── CMakeLists.txt│   │   │       │   ├── gmock│   │   │       │   │   └── gmock.h│   │   │       │   ├── gmock-gtest-all.cc│   │   │       │   └── gtest│   │   │       │       ├── gtest.h│   │   │       │       └── gtest-spi.h│   │   │       ├── gtest-extra.cc│   │   │       ├── gtest-extra.h│   │   │       ├── gtest-extra-test.cc│   │   │       ├── header-only-test.cc│   │   │       ├── mock-allocator.h│   │   │       ├── module-test.cc│   │   │       ├── noexception-test.cc│   │   │       ├── os-test.cc│   │   │       ├── ostream-test.cc│   │   │       ├── posix-mock.h│   │   │       ├── posix-mock-test.cc│   │   │       ├── printf-test.cc│   │   │       ├── ranges-odr-test.cc│   │   │       ├── ranges-test.cc│   │   │       ├── scan.h│   │   │       ├── scan-test.cc│   │   │       ├── static-export-test│   │   │       │   ├── CMakeLists.txt│   │   │       │   ├── library.cc│   │   │       │   └── main.cc│   │   │       ├── std-test.cc│   │   │       ├── test-assert.h│   │   │       ├── test-main.cc│   │   │       ├── unicode-test.cc│   │   │       ├── util.cc│   │   │       ├── util.h│   │   │       └── xchar-test.cc│   │   └── fmt-subbuild│   │       ├── CMakeCache.txt│   │       ├── CMakeFiles│   │       │   ├── 3.30.3│   │       │   │   └── CMakeSystem.cmake│   │       │   ├── cmake.check_cache│   │       │   ├── CMakeConfigureLog.yaml│   │       │   ├── CMakeDirectoryInformation.cmake│   │       │   ├── CMakeRuleHashes.txt│   │       │   ├── fmt-populate-complete│   │       │   ├── fmt-populate.dir│   │       │   │   ├── build.make│   │       │   │   ├── cmake_clean.cmake│   │       │   │   ├── compiler_depend.make│   │       │   │   ├── compiler_depend.ts│   │       │   │   ├── DependInfo.cmake│   │       │   │   ├── Labels.json│   │       │   │   ├── Labels.txt│   │       │   │   └── progress.make│   │       │   ├── Makefile2│   │       │   ├── Makefile.cmake│   │       │   ├── pkgRedirects│   │       │   ├── progress.marks│   │       │   └── TargetDirectories.txt│   │       ├── cmake_install.cmake│   │       ├── CMakeLists.txt│   │       ├── fmt-populate-prefix│   │       │   ├── src│   │       │   │   └── fmt-populate-stamp│   │       │   │       ├── fmt-populate-build│   │       │   │       ├── fmt-populate-configure│   │       │   │       ├── fmt-populate-done│   │       │   │       ├── fmt-populate-download│   │       │   │       ├── fmt-populate-gitclone-lastrun.txt│   │       │   │       ├── fmt-populate-gitinfo.txt│   │       │   │       ├── fmt-populate-install│   │       │   │       ├── fmt-populate-mkdir│   │       │   │       ├── fmt-populate-patch│   │       │   │       ├── fmt-populate-patch-info.txt│   │       │   │       ├── fmt-populate-test│   │       │   │       └── fmt-populate-update-info.txt│   │       │   └── tmp│   │       │       ├── fmt-populate-cfgcmd.txt│   │       │       ├── fmt-populate-gitclone.cmake│   │       │       ├── fmt-populate-gitupdate.cmake│   │       │       └── fmt-populate-mkdirs.cmake│   │       └── Makefile│   └── Makefile├── CMakeLists.txt├── doc│   └── CMake入门.md├── include│   └── hello│       └── hello.hpp├── lib└── src    └── hello        └── hello.cpp61 directories, 294 files
我编写了一个引用外部库fmt输出hello,world的程序src/hello/hello.cpp:
# include &quot;hello/hello.hpp&quot;void stdSayHello(int i)&#123;    while(i--) fmt::print(&quot;hello world_&#123;&#125;\n&quot;, i);&#125;void fmtSayHello(int i)&#123;    while(i--) std::cout&lt;&lt; &quot;hello world_&quot;&lt;&lt;i&lt;&lt;std::endl;&#125;int main()&#123;    stdSayHello(3);    fmtSayHello(3);&#125;
在include/中，头文件include/hello/hello.hpp也很简单：
# include &lt;iostream&gt;# define FMT_HEADER_ONLY 	//  推荐# include &quot;fmt/core.h&quot; 
cd build &amp; cmake .. &amp; cmake --build .执行便在bin/生成了可执行文件，这表明我们编译成功了！
]]></content>
      <tags>
        <tag>Cpp</tag>
        <tag>CMake</tag>
      </tags>
  </entry>
  <entry>
    <title>Cluster</title>
    <url>/2025/06/21/Cluster/</url>
    <content><![CDATA[Introduction
如果我们相信聚集在一起，有较高相似性的簇一定有有趣的知识的话，那么聚类分析就是获得数据内部结构，发现簇的意义的方法。
在讨论聚类算法时，都是在无监督学习的框架下进行的，也就是已知的数据集是没有标签可以学习的。
聚类：将数据分为多个簇(Clusters)，使得在同一个簇内对象之间具有较高的相似度，而不同簇之间的对象差别较大。
任务
已知无标记样本集 , 聚类的算法的任务就是划分样本集成个互不相交的簇，集  划分为  个不相交的簇：

对样本,应有唯一的下标,使得;
聚类的结果可用包含  个元素的簇标记向量 ​ 表示；
功能
聚类分析是获得数据内部结构的有效方法。通过观察聚类得到的每个簇的特点，可以集中对特定的某些簇作进一步分析。
聚类分析可以作为其它算法的预处理步骤；
聚类分析可以完成噪声点/孤立点的挖掘；
指标
对于聚类任务，我们希望物以类聚，直观上有两个指标：

「簇内相似度（intra-cluster similarity）」高
「簇间相似度(inter-cluster similarity)」低

外部指标
对数据集 ,聚类簇划分 , 参考模型簇划分为 ,令  与  分别表示与  和  对应的簇标记向量.
对样本配对，一定是下面四种情况之一：

显然，


Jaccard 系数(Jaccard Coefficient, JC)



FMI 指数(Fowlkes and Mallows Index, FMI)



Rand指数(Rand Index, RI)



聚类算法的距离度量
四种方式：最小距离，最大距离，中心距离，平均距离

聚类算法的分类

基于原型/划分的办法：K-Means, K-Medoids
基于层次的办法：AGENS, DIANA
基于密度的办法：DBSCAN
基于网络的办法：STING

prototype-based  clustering
Idea
基于原型的聚类算法(prototype-based  clustering)法假设聚类结构能通过一组原型刻
初始化一个划分，之后通过迭代的办法优化这个划分方式；
如何定义优化？我们需要一个聚类目标函数作为指标：簇对象到簇中心平方误差

Kmeans
对于K-means算法，我们提出一种基于expectation maximization的实现；
损失函数是最小化平方误差

此损失函数刻画了簇内样本围绕簇均值向量的紧密程度，J 值越小，则簇内样本相似度越高；
优化目标是找到使得代价最小化的和向量；
初始均值-簇分配-更新均值-收敛，如下：

一个直观的例子如图所示：

优点：经典算法，简单、快速， 对处理大数据集，该算法是相对可伸缩和高效率的。
缺点：

初始值敏感；
K需要预先设定，不是**Parameter-free **的；
只能发现类球状簇,不适合于发现非球形状的簇或者大小差别很大的簇；
离群点敏感；

这里K值的选取可以根据肘部法则，我们可能会得到一条类似于人的肘部的曲线。 代价函数的值会迅速下降，在𝐾=3的时候达 到一个肘点。在此之后，代价函数的值会就下降得非常 慢，所以，我们选择𝐾=3；

中心点的选取一般是随机初始化，计算更新为簇内数据的平均向量；通常几轮时间就收敛了；
这里有一个trick： 二分K均值方案，不容易受到初始化问题的影响，类似于一种层次聚类的思想  基本思想，为了得到K个簇，先分为2个簇，然后不断选择其中一个分裂；可以看作一个逐步求精的过程；

基于高斯混合模型的聚类实现
高斯混合聚类 (Mixture-of-Gaussian, MoG) 是一种基于概率模型的聚类方法。
与 K-Means 等基于距离原型的算法不同，MOG认为观测到的数据集是由  个不同的高斯分布混合生成的。对于数据集中的每一个点，它属于某个特定簇的可能性可以用概率来衡量。
模型假设：假设数据集  是由  个高斯分量混合生成，其概率密度函数为：

其中：

 是第  个高斯分量的混合系数（或称先验概率），表示数据点来自第  个簇的概率，满足  且 ;
 是第  个高斯分量概率密度，参数为均值向量  和协方差矩阵 ;

目标： 学习这些高斯分量的参数  ，使得这些模型参数能够最大化似然函数,问题在于数据是未标记的，学习是无监督的；
算法： 通常使用EM算法来估计模型的参数。EM 算法是一个迭代过程，包含两个步骤：


E 步 (Expectation Step)：估计观察到数据点后，每个高斯分量的后验概率（称为"责任"或"soft assignment"）。对于每个数据点  和每个簇 ，计算其属于簇  的概率 ：

这步利用当前的模型参数来计算每个点属于每个簇的概率。


M 步 (Maximization Step)：利用 E 步计算出的后验概率，重新估计每个高斯分量的参数 ，以最大化加权后的数据点的似然。这步根据每个点对每个簇的"贡献度"（后验概率）来更新簇的参数。
似然函数为

更新均值：

更新协方差：

更新混合系数:



重复 E 步和 M 步，在算法收敛后，每个数据点  可以被分配到其后验概率  最大的那个簇 。这是一种hard assignment。或者，可以保留其属于各个簇的概率信息(soft assignment)。
优点

概率解释： 提供了每个点属于每个簇的概率，不仅仅是简单的簇分配。
簇形状灵活： 通过协方差矩阵可以建模非球状的簇（K-Means 隐式假设簇是球状且方差相等）。

缺点

参数敏感： 需要预先指定簇的数量 。
局部最优： EM 算法容易陷入局部最优解，结果可能依赖于参数的初始化。
计算成本： 相对于 K-Means，计算成本更高，特别是对于大数据集或高维数据。
假设前提： 假设数据是由高斯分布生成的，如果数据分布与高斯分布差异较大，效果可能不好。
对噪声和离群点敏感： 离群点可能会对均值和协方差的估计产生较大影响。

算法流程伪代码如下：

基于层次的办法
层次聚类方法对给定的数据集进行层次的分解，直到某种条件满足为止。
凝聚的层次聚类：

一种自底向上的策略，首先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到某个终结条件被满足，
代表是AGNES算法


最小距离法（Single Linkage）


定义：在两个簇之间的所有可能配对样本点中，选择距离最小的一对样本点的距离作为簇间距离。


链状效应：由于只考虑最接近的一对点，最小距离法容易形成链状结构，即若干个样本逐个连接在一起，形成较长的"链"。


噪声敏感：对噪声和离群点（outliers）较为敏感，因为离群点可能会导致簇之间的最小距离变小，从而错误地合并簇。


效率较高：计算简单，效率较高，但结果可能不稳定。


适用场景：适用于数据集中的簇呈现不规则形状或链状结构的情况。


最大距离法（Complete Linkage）

定义：在两个簇之间的所有可能配对样本点中，选择距离最大的一对样本点的距离作为簇间距离。
紧密簇：最大距离法倾向于形成紧密、球形的簇，因为它考虑了簇中最远样本点之间的距离，从而避免形成链状结构。
抗噪声能力强：对噪声和离群点较为鲁棒，不容易被离群点影响，因为离群点的存在不会显著改变簇的最大距离。
计算复杂度高：由于需要计算所有样本点的最大距离，计算复杂度相对较高。
适用场景：适用于数据集中簇的形状较为规则、且希望得到更紧密的簇的情况。

分裂的层次聚类：


采用自顶向下的策略，它首先将所有对象置于一个簇中，然后逐渐细分为越来越小的簇，直到达到了某个终结条件。


代表是DIANA算法;
算法    DIANA（自顶向下分裂算法）输入：包含n个对象的数据库，终止条件簇的数目k。输出：k个簇，达到终止条件规定簇数目。（1）将所有对象整个当成一个初始簇；（2） FOR (i=1; i≠k; i++) DO BEGIN（3）       在所有簇中挑出具有最大直径的簇C；（4）      找出C中与其它点平均相异度最大的一个点p并把p放入splinter group，剩余的放在old party中；（5）.      REPEAT（6）             在old party里找出到最近的splinter group中的点的距离不大于到old party中最近点的距离的点，并将该点加入splinter group。（7）       UNTIL 没有新的old party的点被分配给splinter group；（8）   splinter group和old party为被选中的簇分裂成的两个簇，与其它簇一起组成新的簇集合。（9） END.


基于密度的聚类算法：DBSCAN
只要一个区域中的点的密度大于某个阈值，就把它加到与之相近的聚类中去。
对于一个类中的每个对象，在其给定半径的领域中包含的对象不能少于某一给定的最小数目；
概念：
设置半径阈值,数量阈值;
核心对象的-邻域至少包个对象；
从核心对象出发，对任何邻域内的点直接密度可达；
如果存在一个对象链，，，，，，对，，是从关于直接密度可达的，则对象是从对象相互密度可达的。
如果存在一个对象，使得对象和是从关于密度可达的，那么对象和是密度相连的。
一个基于密度的簇是基于密度可达性的最大的密度相连对象的集合 ;

连接性：密度相连；
最大性：由密度可达，

DBSCAN算法先任选数据集中的一个核心对象为"种子" ,再由此出发确定相应的聚类簇;
算法类似于BFS搜索，维护一个队列；

优点：

能克服基于距离的算法只能发现"类圆形"的聚类的缺点，可发现任意形状的聚类；
对噪声数据不敏感；

缺点：

计算复杂度大，需要建立空间索引来降低计算量；
数据维数的伸缩性较差；
对参数非常敏感；
如果数据库比较大的时候要进行大量的I/O 开销;
很难找到不同密度的簇;

基于网格的聚类：STING
基本思想：将对象空间量化为有限数目的单元，形成一个网格结构，所有的聚类都在这个网格结构中上进行。
其优点是处理速度很快，其处理时间独立于数据对象的数目，只与量化空间中每一维的单元数目有关。
在网格聚类方法中有利用存储在网格单元中的统计信息进行聚类的STING算法和在高维数据空间基于网格和密度的聚类方法等。
STING是一种基于网格的多分辨率聚类技术，它将空间区域划分为矩形单元。针对不同级别的分辨率，通常存在多个级别的矩形单元，这些单元形成了一个层次结构：高层的每个单元被划分为多个低一层的单元。高层单元的统计参数可以很容易的从底层单元的计算得到。这些参数包括属性无关的参数count、属性相关的参数m（平均值）、s(标准偏差)、min(最小值)、max(最大值)以及该单元中属性值遵循的分布类型。
STING算法采用了一种多分辨率的方法来较粗，则聚类质量会受到影响。进行聚类分析，该聚类算法的质量取决于网格结构最低层的粒度。如果粒度比较细，处理的代价会显著增加；
STING算法的主要优点是效率高，通过对数据集的一次扫描来计算单元的统计信息，因此产生聚类的时间复杂度是O(n)。在建立层次结构以后，查询的时间复杂度是O(g), g远小于n。STING算法采用网格结构，有利于并行处理和增量更新。
]]></content>
      <tags>
        <tag>papers</tag>
        <tag>Machine-Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Coloring</title>
    <url>/2025/07/05/Coloring/</url>
    <content><![CDATA[Vertex Coloring
为图的每个顶点分配某种颜色，称一种着色是正确的，如果没有两个相邻的顶点着色相同；
一个独立集(independent set)是指内部没有任意两个点相邻的点集；
因此，在一个正确的着色中，位于不同独立集的点集可以被不同颜色着色；
一个-点着色的无环图可以被划分为个独立集;
图的一个-点着色是用个颜色对其顶点进行着色；若图是一个-点可着色的，如果图有一个正确的-点着色方式；
图的色数(chromatic number)等于最小的使得是-点着色的整数；
称图是-色(k-chromatic)图，如果;
确定一个图是否是3-可着色的是一个NPC问题，对于平面图，计算机已经证明四色定理：对于任何平面图均有;
对于给定的图确定色数是一个NP问题，但是色数有一个平凡上界;
Theorem

值得一提的是，Petersen图的色数为3；
Theorem

Proof:以下贪心算法是一种 正确的着色方案，这说明我们找到了色数的一个上界；
假设第个颜色记作,列举图的顶点;

为分配颜色;
对于状态,假定已经着色，分配颜色,为相邻顶点尚未使用的颜色最小下标；

等号在奇圈和完全图上成立；
Five-color Theorem
简单平面图是5-可着色的；
proof：对归纳，若,结论平凡，假设成立，考虑度数最小的点，一定有,由归纳假设，对于除去点的图存在着色方案，若，则的邻居一定为留出一个颜色；

考虑,记邻居顺时针方向为,若这5个点只用了4个颜色，剩下的颜色留给即可；若这5个点颜色各不相同，假设染1色，染2色，将改染1色，染1色的邻居改染2色，依次类推；

若这样的操作不i能持续下去，一定出现如下情况的子图

由平面性，不会有这样的通路，对进行上述操作即可；

进一步，我们有四色定理(Four-color theorem, Appel and Haken):任意简单平面图都是4-可着色的，即;
经过对偶图变换可以得知，世界地图可以用4种颜色进行染色；

Brooks Theorem
对于非奇圈的非完全的简单连通图,有;
proof：若存在度数小于的顶点，我们需要精心安排顶点的顺序，使得每个顶点在染色时，排在它前面并与之相邻的顶点数不超过,以为根的图生成树的后序遍历序列满足条件，因为除外，其余顶点在这棵生成树的父亲一定位于这个点序列的后面；
假设图是正则的；进一步假设；
若有割点，取图的割点，以及两个连通分量,取,且均是的邻居；
对于的任意连通分量，可以对进行着色，对这样方案下每个的着色顺序进行置换，使得他们在的颜色一致；
进一步假设，即是2连通的，断言图存在三个顶点,使得连通，且

先将染成同色，对于,考虑令,贪心地为其他点染色后，最后染时，由于有两个邻点同色，因此一定留有一种颜色；
下证明断言：若是3连通的，因为是正则且不完全的，故选取距离为2的两点和公共邻点即可；
若不是3连通的，但是是2连通的，由于没有割点，每个叶块均有的相邻顶点，由于，因此可以选取两个不直接相邻的叶块中与的邻点；

Map Coloring
在地图着色问题中，不考虑地图之间的桥梁；

定义地图(map)为一个3连通的平面图；
称一个地图是-面可着色的，如果它的面可以被个颜色着色且有公共边相邻的面颜色不同；
Theorem
地图是2-面可着色当且仅当是欧拉图；
proof：对于每个顶点，一定有偶数个围绕它的面(两种颜色的面个数相同)，意味着其度为偶数，为欧拉图
如果为欧拉图，则选取任意一个面染为红色，对于其他面，到的曲线穿过偶数条边染为红色，奇数条边染为蓝色，这样的染法是良定义的，因为每个顶点有偶数度

Edge Coloring
图的一个-边着色是用个颜色对其边进行着色；
一个正确的边着色满足任意两个相关联的边颜色不同；
若图是一个-边可着色的，如果图有一个正确的-边着色方式；
不相关联的独立边集合称作一个匹配(matching)，更确切地说，在图中的一个匹配是一组互相没有公共顶点无环边集合，称顶点被匹配浸润的(saturated),若关联中的一条边，否则称为未浸润的(unsaturated);
一个正确的-边可着色可以认为对边集进行划分

其中是一个匹配，每个匹配分配相同的颜色；
边色数(edge chromatic number)定义为最小正整数使得为-边可着色的；
一个平凡下界为;
Theorem

对于奇数，任何匹配至多拥有条边，但是有条边，因此；
给出-边着色的构造：边界用种颜色染色，对角线的颜色和与之平行的边颜色相同；

对于偶数，我们给出-边着色的构造：
取出点,先为子图的用上述方案染色，每个顶点的关联边共种颜色，留下一个颜色与相连的边染色即可；
Theorem(Vizing)
对于有限图，两点间最大连边数为，则为-可染色的；
对于简单图来说，
Theorem(Konig)
对于二部图，
proof:对边数归纳，假设在较小的边数成立，考虑删除一条边，子图最大度不超过,对子图边染色，在子图中，,因此这样的边染色方案中，关联的边至少剩余一种颜色没有使用，设为，若,将染为该色即可；否则，考虑关联的染色的边,依次用色边增广它，得到增广路径不会经过点(因为没有奇圈)，反转增广路径的颜色后将染为色即为最终的染色方案；
Chromatic Polynomial
对于简单图，定义色数函数为将顶点用种颜色染色，相邻顶点不同色的方案数;
Theorem
对于简单图，有

proof:考虑删除一条边后的子图之间的关系，可以看作边顶点没有限制关系，可以看作边顶点必须同色；
显然是一个次多项式，满足如下性质

系数正负交替；
的系数是；
常数项为0；

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Graph-Theory</tag>
      </tags>
  </entry>
  <entry>
    <title>Convolution Neural Network</title>
    <url>/2025/06/21/Convolution-Neural-Network/</url>
    <content><![CDATA[Introduction
卷积神经网络是受生物学上感受野(receptive Field)的机制而提出的

在视觉神经系统中，一个神经元的感受野是指视网膜上的特定区域，只有这个区域内的刺激才能够激活该神经元;
感受野机制主要是指听觉、视觉等神经系统中一些 神经元的特性，即神经元只接受其所支配的刺激区域内的信号。

架构
卷积神经网络一般是由卷积层、池化层 和全连接层交叉堆叠而成的前馈神经网络。全连接层一般在卷积网络的最顶层。

卷积神经网络有三个结构上的特性：局部连接、权重共享以及 池化。这些特性使得卷积神经网络具有一定程度上的平移、缩放和旋转 不变性。和前馈神经网络相比，卷积神经网络的参数少。

卷积
一维卷积
给定一个输入信号序列和滤波器(filter)/卷积核(convolution kernel)，其卷积输出为


一维卷积常用于信号处理，用于计算信号的累计延迟；
滤波器可以看作信息的衰减率，输出结果为当前时刻产生的信息和以前的延迟信息的叠加；
不同的滤波器可以用来提取序列中的不同特征；定义

滑动步长(stride):卷积核在滑动时的时间间隔
零填充(Zero Padding);在输入向量两端进行补零


对于大小为的滤波器，根据输出长度的不同可以分为三类

窄卷积：步长为1，两端不补零,卷积输出长度为
宽卷积：步长，两端补零，卷积后输出长度
等宽卷积：步长，两端补零，卷积后输出长度

二维卷积
对于输入图像矩阵,卷积核矩阵,步幅为,卷积结果是一个阶为的方阵;
一般认为,卷积结果具体为


二维卷积有两种不同的方式：通常没有零填充的最优数量处于有效卷积和相同卷积中间的某个位置；

有效卷积：没有padding
相同卷积：输入和输出相同

即是卷积前后图像的宽度，是滤波器的宽度，是零填充的数量，是步长，是卷积前后后图像的高度;

Feature Map
一幅图像在经过卷积操作后得到结果称为特征映射（Feature Map）;
![Feature Map示意图](/assets/Machine-Learning/Feature Map示意图.png)
以下是一个图像中的二维卷积的例子：卷积神经网络是针对图像处理设计的特殊的网络结构，在图像处理中，卷积经常作为特征提取的办法，常用的均值滤波就是二维卷积，将当前位置的像素值设置为卷积核内所有像素的平均值；

卷积层
在FFN中，连接边的数量为前后两层神经元个数的乘积，当神经元数量巨大，权重矩阵训练效率较低；卷积运算具有特征抽取的能力，卷积层中每一个神经元都只和下一层某个局部窗口的神经元相连，因此连接边数降至为后一层神经元数量和卷积核大小的乘积；

一个常见的减少连接边的常见trick是权值共享，我们认为同一个卷积核能对应提取一个特征，卷积核对于第层的所有的神经元都是相同的。权重共享可以理解为一个卷积核只捕捉输入数据中的
一种特定的局部特征。因此，如果要提取多种特征就需要使用多个不同的卷积核。
这样的稀疏交互方式，即局部连接或者局部感受野的方式，既能进行特征提取，又加快了计算效率；但是卷积层并没有显著减少特征映射中的神经元个数；
池化层
池化层(Pooling Layer),也即子采样层(subsampling layer)，用于卷积层之后，降低特征维数，减少参数数量，从而避免过拟合；

对于池化层的输入图特征映射组为,对于其中每一个特征映射,将它们划分为多个区域(可以重叠也可以不重叠)，池化操作就是对每个区域进行下采样，作为这个区域的概括。
一般分为两种：


最大池化(max pooling):对于一个区域，选择该区域的最大活性值的神经元,主要用来抑制邻域值之间差别过大，造成的方差过大。对纹理的提取较好；



平均池化(mean pooling):是取区域内所有神经元活性值的平均值,能够抑制网络参数误差造成的估计均值偏移的现象。对背景的保留效果较好；




从定义方式我们可以看出来，池化操作可以更高地获取平移不变性，减少了神经元数量，并获得了更高的计算效率；
全连接
图像特征图的“分布式特征表示”映射到样本标记空间。在整个卷积神经网络中起到“分类器”的作用。最后一层的全连接层起到的作用就是输出结果;

通过Softmax函数将多个标量映射为一个概率分布，输出分类结果的置信度。
]]></content>
      <tags>
        <tag>papers</tag>
        <tag>Machine-Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Digraph</title>
    <url>/2025/07/05/Digraph/</url>
    <content><![CDATA[Conceptions
有向图(directed graph) 定义为非空有限顶点集和的有序对(箭头，arcs)形成的有限簇；
箭头的第一个顶点为尾(tail),第二个顶点为头(head)，箭头由尾指向头；
有向图消去方向后得到的无向图称作底图(underlying grapg)；
称为简单有向图(simple digraph)，如果 中所有箭头都不一样，且没有自环；
称两个有向图同构(isomorphic)，如果它们的底图同构且箭头保持相同的方向；
有向图的邻接矩阵定义为,为指向的箭头数；
关联矩阵定义为，如果是的尾,如果是的头；
有向图的迹是指箭头的有限序列；
称有向图为弱连通的，如果它不能表示为两个有向图的并，当且仅当其底图是连通的；
称有向图为强连通的，如果任何两个顶点.均有从到的有向路径；
有向图的强连通分量是其最大化的强连通子图；
称图为可定向的(orientable)如果图的每个边可以标定方向使得形成的有向图是强连通的；
称有向图是欧拉图，如果存在闭合迹包含中所有的箭头，这样的迹称作欧拉迹；
对于有向图的顶点,出度(out-degree)定义为以为尾的箭头数，入度(in-degree)定义为以为头的箭头数；
称顶点为有向图的源点(source)，如果;
称顶点为有向图的汇点(source)，如果;
称有向图是哈密顿的(Hamiltonian)，如果存在一个有向圈包括所有顶点；
称有向图是半哈密顿的(semi-Hamiltonian)，如果存在一个有向路径包括所有顶点；
Theorem(Robbin)
对于连通图，若是可定向的当且仅当是2-边连通的,即每条边至少被一个圈包含；
proof:必要性显然，充分性只需按照以下算法标方向即可：


选取任意一个圈,周期性地表明它的边的方向；


选取不在中但是和相关联的边；
不是桥，假设被包含在中，令，回到1；


Theorem(Handshaking dilemma)

Theorem
连通有向图是欧拉的当且仅当对于中任何顶点均有;
Theorem(Ghouila-Houri)
令有向图是具有个顶点的强连通图；如果,则是哈密顿的；
Tourament
竞赛图(tourament)定义为任何两个顶点都有箭头相连的有向图；
Theorem(Redei)
任何非哈密顿的竞赛图都是半哈密顿的；(竞赛图必有哈密顿路)
proof：对顶点数归纳，取,由归纳假设，取路径，若或,直接加在头尾即可；否则存在是最小的满足的下标，则哈密顿路为;
Theorem(Moon)
竞赛图都是哈密顿的当且仅当是强连通的；
proof:必要性显然，充分性归纳证明更强结论：对于任意，存在长度为的圈；若当前圈之外存在一个顶点对圈既有出边也有入边，找到插入的下标即可得到更长圈；

否则可以划分为对圈只有出边和点集和对圈只有入边的点集,到必存在一条入边，考虑去掉圈中一点加入该边即可得到更长圈；

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Graph-Theory</tag>
      </tags>
  </entry>
  <entry>
    <title>EGOEXO-GEN.md</title>
    <url>/2025/10/08/EGOEXO-GEN-md/</url>
    <content><![CDATA[EGOEXO-GEN: EGO-CENTRIC VIDEO PREDICTION BY  WATCHING EXO-CENTRIC VIDEOS
Abstract
以第一人称视角生成视频在 Augmented Reality(AR)和 Embodied Intelligence 领域具有广阔的应用前景。在这项工作中，我们探索了跨视图视频预测任务，其中给定 exo-centric 视频、相应 ego-centric 视频的第一帧和textual instructions，目标是生成 ego-centric 视频的未来帧。受 ego-centric 视频中的hand-object interactions(HOI) 代表当前演员的主要意图和动作这一概念的启发，我们提出了 EgoExo-Gen，它对 cross-view 视频预测的 hand-object dynamics进行了显式建模。EgoExoGen由两个阶段组成。首先，我们设计了一个 cross-view HOI mask预测模型，该模型通过对 spatiotemporal ego-exo correspondence 进行建模来预测未来 ego-frames 中的 HOI masks。接下来，我们采用 video diffusion model 来使用第一个ego-frame和 textual instructions 来预测未来的ego-frames，同时将 HOI masks 作为结构指导以提高预测质量。为了促进训练，我们开发了一个自动化 pipeline，通过利用 vision foundation models 为 ego- and exo-videos 生成 pseudo HOI masks。大量实验表明，与之前在EgoExo 4D 和 H2O benchmark datasets 上的视频预测模型相比，我们提出的EgoExo-Gen 实现了更好的预测性能，HOI masks 显著改善了ego-centric 视频中手和交互对象的生成。
Introduction
本文考虑了基于在同一环境中同时捕获的第三人称（exo-centric）视频来animating 一个 ego-centric frame 任务。如下图所示，给定 ego-centric 视频的第一帧、一个 textual instruction 和同步的 exo-centric 视频，目标是 ego-view 后续帧。

Exo-centric 的视角通常提供更广泛的环境背景和身体运动，但不太关注fine-grained 的行动。相比之下， ego-centric 的视角集中在相机佩戴者的手和交互对象上，这对于 manipulation 和 navigation 等任务至关重要。cross-view 视频预测中的挑战来自于这些 views 之间的显著的 perspective shift ，因为未来帧必须与第一帧的上下文环境和由 textual instruction 和 exo-centric视频显示的 actor’s motion 两者对齐。
将这两种观点结合起来提供了两个关键好处：

它允许 agents 从第三人称演示中构建一个鲁棒的 ego-centric 世界模型，使他们能够将更广泛的场景信息转化为第一人称视角；
它使  agents 能够通过将其 viewpoint 与人类用户对齐，think from the humans’ perspective，提高他们预测未来行动并做出更明智决策的能力。

这种能力在增强现实（AR）和机器人技术等实时应用中特别有价值，其中 agents 必须使其 actions 与人类或环境同步。通过学习将 exo-centric 视频转换为准确的 ego-centric 帧， agents 在参与动态的现实世界环境时可以变得更加适应。
视频预测模型的最近研究已经显示出巨大的进步。这些模型主要依赖于第一帧和 textual instructions 作为 diffusion 的输入，主要重点是 exo-centric 的视角生成视频。关于 ego-centric的视频预测，探索了文本指令的分解，但缺乏针对 ego-centric 视角的定制设计。在 cross-view video generation 的背景下，已经开发了专门的模型。例如，(Luo et al., 2024a;b)利用来自 ego-centric 视频的头部轨迹数据来生成 exo-centric 视频中的 optical flow 和 occlusion maps，而(Luo et al., 2024b)估计了 ego-centric的视图中的手部姿势，以指导 conditional ego-video generation。然而，这些方法依赖于 3D场景重建或精确的 human annotations，限制了它们在不同场景中的可扩展性和泛化能力。
在本文中，我们提出了 EgoExo-Gen，这是一种 cross-view video prediction model ，通过显式建模 hand-object dynamics 来生成 ego-centric视频未来帧。EgoExo-Gen采用两阶段方法：

它在 ego-centric 的视角中预测hand-object interaction (HOI) masks；
其次，它使用这些 masks 作为条件，驱动 diffusion model 来产生相应的 RGB 帧。

对于 cross-view HOI mask prediction model，它将 exo-centric 视频和 ego-centric video 视频的第一帧作为输入，并预测 HOI 从而形成 masks ego-centric 未来帧。为了处理 viewpoints 的巨大变化，我们设计了一个ego-exo memory attention module，该模块捕捉两个视角之间的 spatio-temporal correspondences ，使模型能够推断 HOI masks，即使当前ego-centric 帧是不可见的。然后将预测的 HOI masks 集成到 diffusion model 中，指导准确的ego-centric 未来帧的生成。为了确保可扩展的训练并最大限度地减少对 manual annotations 的依赖，我们还通过利用强大的视觉基础模型，为 ego-centric 和 exo-centric 视频开发全自动的 HOI mask annotation pipeline。这种方法的组合使 EgoExo-Gen 能够生成高质量的 ego-centric 视频，同时显着提高不同环境中的可扩展性和通用性。
我们对 cross-view video benchmark datasets 进行了广泛的实验，即 EgoExo 4D（Grauman等人，2024年）和H2O（Kwon等人，2021），包括丰富多样的 handobject interactions 和拍摄环境。实验结果表明 EgoExo-Gen 显着优于先前的视频预测模型并通过利用 hand and object dynamics 来提高预测视频的质量。此外，EgoExo-Gen在不可见的动作和环境中表现出强大的零镜头传输能力。
Methodology
Problem Formulation
本文考虑了一个具有挑战性的问题，即基于在同一时间和同一环境中捕获的 exocentric 视频，animating 一个ego-centric帧。具体来说，给定具有  帧的 exo-centric 视频，、ego-centric 第一帧和text instruction ，我们的目标是预测接下来的 ego-centric 视频。值得注意的是，以ego-centric 和 exo-centric视频的摄像机姿势和深度信息均不可用，以鼓励开发可以在不同摄像机和地点推广的方法。请注意，与 cross-view correspondence benchmark 和exo-to-ego image translation不同的是，我们考虑的问题仅假设在测试时以自我为中心的观点有一个开始帧可用，这使得这项任务显着更具挑战性。
Overview
我们提出了EgoExo-Gen，通过显式建模 hand-object dynamics ，能够根据其相应的exo-centric 视频来animating一个 ego-centric 视频帧。如下图所示，我们提出的模型包括：

cross-view mask预测网络 ，其估计ego-video 的spatio-temporal hand-object segmentation masks;
HOI已知下的 video diffusion model ,给定 hand-object masks, 用于估计RGB ego-frames ;
生成 ego-exo HOI segmentation masks 的全自动pipeline，用于训练所有的模型；

在推理时，整个过程可以公式化为：


cross-view mask prediction
本节详细介绍了 cross-view mask 预测模型 ，该模型将 hand-object masks 从 exo-centric 转换为 ego-centric 视角。具体而言，该模型将以下内容作为输入：

exo-centric 视频;
exo-centric 视频的逐帧 hand object masks , 包括背景、手部和对象;
ego-centric 视频的第一帧 。

期望的输出是以自回归方式生成的 ego-centric 视角中的对应的逐帧hand-object masks 。
在下面的部分中，我们只在训练时呈现整个 pipeline，而在推理过程中，我们只假设 ego-centric 视角中有一个起始帧可用，从而将 ego-centric 视频替换为ego-centric 视频的第一帧，以及后续以自我为中心的帧的所有 zero images。
Image and mask feature encoding
对于image encoder，我们采用共享的 ResNet，删除了最后一个卷积块。编image encoder 将 exo- and ego-frame 作为输入，并分别输出 exo- and ego-features:

mask encoder 将当前 exo-frame 和 exo-mask 的拼接作为输入，并使用另一个 ResNet 对它们进行编码。然后它通过 CBAM 块与 exo-image feature融合，并产生 exo-mask feature。

Ego-exo memory attention
该模块的核心是一个 memory bank ，它能够根据相应的 exo-centric 帧预测ego-centric 视频的 HOI mask features。
该模型以自回归方式操作，例如，当为第  个 ego-frame 生成时，

来自 exo-centric 视频的相应帧特征被视为 query, 历史 exo- and ego-frame features 被视为 keys;例如;
相应的 mask features 作为values，例如为早期的mask features


其中 为线性变换，[]操作表示顺着时间维度进行拼接操作；第 个 ego-frame 的 mask feature 可以通过 cross-attention 获得

softmax操作在时间维度上执行,  在训练时，由于 ego-centric 视频中的所有帧都是可见的，因此我们还通过利用 ego-visual features作为query来获得剩余记忆输出，即 。记忆注意力模块的最终输出是，其中  在训练阶段从  退火至 。我们观察到这种策略有助于早期阶段的模型训练，并最终学会在推理时预测ego-centric所有帧的 mask features。
Mask decoder
mask decoder 由 upsampling 块堆叠组成，每个 upsampling 块由两个convolution layers 组成，接着进行 bilinear upsampling operation。它接受来自 ego-exo memory attention 模块的 的输出，并将其与每个块的多尺度 ego-features 融合，类似于UNet。解码过程可以简化为：

其中  指的是来自缩小尺度  的 image encoder 的多尺度特征。
Memory store and update
如上所述，我们的 ego-exo memory bank分别存储过去空间图像和 mask features 的 keys和values信息。在时间处，我们将预测的 ego-mask 编码为 ego-mask feature

并将其与图像和 mask features 一起存储到 ego/exo memory bank中，即。在测试时，我们整合内存并丢弃过时的 features，同时始终保留接下来第一帧的可靠的 features，但我们并不强调这个过程是我们方法的贡献。
HOI-aware video diffusion model
HOI-aware video diffusion model 的目标是生成后续的 ego-video 帧 ，给定第一帧 、text instruction  和已预测的 ego-centric handobject masks 。
Base architecture
Following (Rombach et al., 2022b)，diffusion 和 denoising 过程是在 latent space中进行的。由以下部分组成

预训练的 VAE 编码器 和 解码器   ，用于对 ego-centric 视频进行逐帧编码/解码;
用于对 handobject masks 进行编码的mask encoder ;
denoising UNet ，参数为;

Following (Chen et al., 2023; Ren et al., 2024)，UNet 架构是基于预先训练的text-to-image 模型构建的。在每个 down/upsampling 块中，堆叠了 ResNet块、spatial self-attention 层和 cross-attention 层。附加了额外的 temporal attention层来建模cross-frame relationship。

U-Net 是一种卷积神经网络架构，名字来源于其独特的 U 形结构，是语义分割 任务的基准模型之一。
Encode / downsampling 块：捕获图像的上下文信息，每个模块包含：两个 3×3 卷积 + ReLU 激活函数，一个 2×2 最大池化；在特征图变化上，通道数加倍，空间尺寸减半

输入：572×572×1
经过编码器：64→128→256→512→1024

Decode/ upsampling 块：实现精确定位，每个模块包含：一个 2×2 转置卷积（上采样）与对应 downsampling 块 的特征图进行跳跃连接，两个 3×3 卷积 + ReLU；特征图变化上：通道数减半，空间尺寸加倍；
跳跃连接将编码器中的高分辨率、低层特征与解码器中的上采样特征相结合；用于解决梯度消失问题，保留空间细节信息，以及结合来自解码器的语义信息和来自编码器的位置信息；

First frame and text guidance
ego-video 的第一帧  被注入到 diffusion model 中以实现视觉上下文引导。形式上，该模型将以下三项的拼接作为输入：

损坏的有噪视频帧;
未损坏的视频的 VAE feature representation，其中第  至第  帧的 features 设置为零;
temporal mask  表示第一帧的可见性。

text instruction  通过 CLIP text encoder 进行 tokenised 和编码，然后通过cross-attention 注入到 UNet。
HOI mask guidance
为了将从 cross-view mask prediction model 获得的 hand-object masks 合并到video diffusion model 中，，我们通过单独的轻量级 mask encoder 并将 features 插入到 denoising UNet中。包含多个downsampling 块，每个 downsampling 块由 ResNet 块和 temporal attention 层组成。它将 HOI masks 作为输入并输出多尺度 spatio-temporal feature maps：

其中 mask feature ; 在每个 decoder 块中，通过逐元素相加将 mask features 与 latent features 融合，然后在线性投影后将其反馈到 temporal attention 层。HOI-aware video diffusion model的 训练目标表示为：

其中  是指 dissusion 的时间戳，以及 指代高斯噪声；
Data, Training and Inference Pipline
本节首先描述了自动生成 ego-centric和exo-centric 的 handobject masks的过程，该过程使我们能够超越对现有标记数据集的依赖，并扩展到更广泛的配对的ego and exo datasets。然后，我们为训练和推理过程列出outline。
Ego-Exo HOI mask construction
我们的注释管道如下图所示。
Ego-Exo mask annotation pipeline。我们首先使用hand-object detector/segmentor执行逐帧注释，并提示 Sam-2 跟踪视频中的 HOI masks。
对于 ego-centric 视频，我们首先使用 EgoHOS 用于手和交互对象的每帧分割。尽管单个帧的结果良好，但 EgoHOS 未能捕捉帧之间的 temporal dynamics 。为了解决这个问题，我们利用 EgoHOS 生成的初始 hand-object masks 作为Sam-2的 prompts，实现 object tracking across frames ，并确保整个视频的 mask 一致性。对于 exo-centric 视频，EgoHOS 被证明不足以进行分割。相反，我们使用100 DOH 用于 hands and interactive objects 的逐帧检测。此外，我们采用了人类基金会模型 Sapiens 细分关键地区，即左手和右手、前臂和上臂。对于 ego-centric 视频， bounding boxes 和 masks 充当Sam-2的 prompts，以确保一致的 cross-frame tracking。
Training stage
为了训练 cross-view mask prediction model，我们使用二元交叉熵损失和Dice Loss 的和。

Dice Loss 是一种用于衡量两个样本集合相似度的统计指标;

其中为预测的分割区域，为真实的分割区域;
在实际的神经网络训练中，我们需要处理概率输出而不是二值分割，定义 为第  个像素的预测概率（经过 sigmoid), 为第 个像素的真实标签（0 或 1）,用于防止除零错误的平滑项；

交叉熵损失会平等对待每个像素，但是如果 95% 是背景，5% 是目标，模型可能倾向于将所有像素预测为背景，依然获得 95% 的准确率
Dice Loss关注区域重叠度，即使背景占多数，如果目标区域预测错误，Dice Loss 会显著增大

随着训练的进行，我们逐渐 mask ego-frames，以鼓励模型在未观察到ego-frames时学习 cross-view correspondence。diffusion model 的训练过程分为两个阶段。

在第一阶段，我们使用 ego-centric 视频来训练 UNet backbone，使用第一帧和 textual instructions 作为条件，而不结合手-对象交互（HOI）。
在第二阶段，我们冻结 UNet backbone 并训练 mask encoder 和线性投影层。该阶段利用我们的自动数据 pipeline 生成的 ego hand-object masks，确保高质量的 mask 预测。

Inference stage
cross-view mask prediction model 将 exo-centric 视频、 exo-centric HOI masks和 ego-centric 视频的第一帧作为输入，并预测所有后续帧的ego-centric HOI masks。这些预测的 ego-centric HOI masks，以及ego-centric视频的第一帧，然后被输入到 diffusion model 中，以生成 ego-centric 未来帧。
Experiments
Dataset
在我们的实验中，我们选择Ego-Exo 4D数据集。Ego-Exo 4D是全球最大的多视图数据集，记录了1，286小时的视频。每个 ego-centric 视频至少有四个在同一环境中同时拍摄的 exo-centric 视频。我们选择属于烹饪场景的视频（在60个不同地点拍摄564小时），因为这些视频包含丰富的手与物体互动。训练集包含33，448个视频片段，平均持续时间为1秒。每个视频剪辑都与旁白配对（例如，C用右手将刀落在砧板上。）开始和结束时间戳。值得注意的是，Ego-Exo4D cross-view relation benchmark 包含特定对象的成对的ego-exo masks，然而，这些对象不保证是交互对象，并且 hand masks没有注释。相比之下，我们的自动注释过程包括手和交互式对象，提供更大的可扩展性。我们从验证集中抽取了1,000个视频片段，从中选择了500个视频片段，并使用 HOI masks 对其进行注释，以评估mask prediction model 的性能。训练和验证集有不同的takes，对模型对未见过的对象和位置的概括能力构成了挑战。为了评估该模型的零镜头传输能力，我们还采用了H2O（Kwon等人，2021年），一个专注于桌面活动的自我exo HOI数据集（例如，挤乳液，抓起喷雾剂）。H2O的验证集由122个带有动作标签的剪辑组成。
Implementation details
我们使用 Adam优化器训练 cross-view mask prediction model，epochs=30 batchsize=32。初始学习率设置为。我们为ego-centric和exo-centric的视频采样了个固定空间分辨率为480x480的帧。我们选择一个（四分之一）具有最高比例的exo-hand masks的exo-centric视频作为最佳视角，有效地最大限度地减少了遮挡问题。对于 video diffusion model，我们对两个阶段进行训练，epochs=10 batchsize=32，固定学习率为。我们使用 SEINE 初始化我们的模型, 在web-scale video-text pairs上进行预训练，并使用分辨率为256 x 256的个采样帧来训练模型。在推理过程中，我们采用 DDIM 采样器, 我们的实验中steps=100。
Evaluation metrics
Following（Grauman等人，2024），我们通过三个指标评估 cross-view mask prediction model：

Intersection over Union（IoU）：IoU评估地面实况掩码和预测之间的重叠;
Contour Accuracy（CA）： CA在应用平移以对齐它们的质心之后测量masks 的形状相似性;
Location Error（LE）：LE表示预测和地面实况掩码的质心之间的归一化距离。

关于视频预测模型的评估，我们采用SSIM、PSNR、LPIPS 和 FVD。
Quanlitative Comparision
Performance on Ego-Exo4D
我们将我们的方法与先前的视频预测模型进行比较，其中这些模型

第一帧作为条件：包括 SVD;
文本和第一帧作为条件：包括Seer，DynamiCrafter、SparseAlt，SEINE和ConstI 2 V。

我们在 EgoExo 4D 上对所有这些模型进行了微调，但SVD除外，我们发现其zero-shot性能更好。
如下表所示，微调的ConstitI 2 V和SEINE模型比视频预测模型实现了更高的准确性，尤其是分别在SSIM和LPIPS上。
Ego-Exo4D和零镜头转移到H2O的视频预测模型比较

EgoExo-Gen在所有指标上始终优于先前的方法，凸显了在视频预测模型中显式建模 hand-object dynamics 的好处。
Zero-shot transfer to H2O
我们评估模型对未见数据分布的概括能力，即 H2O，包含执行桌面活动的手与物体互动的同步以自我为中心和外在为中心的视频。与Ego-Exo 4D相比，拍摄地点、上下文环境、对象和动作类别的区别给模型移植带来了挑战。如上表右侧所示，大多数方法都能实现相对较高的FVD；我们的方法通过有效地建模手和交互对象的运动，超越了这些模型，即使在无需重新训练的情况下直接从Ego-Exo 4D转移到H2O时也是如此。
Ablation Studies and Discussions
Analysis on the HOI condition
我们在下表中比较了不同的 hand-object conditions。为了保证 mask 的质量，这里我们应用从未来视频帧提取的 hand-object masks，而不是cross-view mask 预测。

如第一行所示，没有mask conditions 的视频预测模型 baseline 仅达到0.518 SSIM和17.681 PSNR。
Random mask 不会比 baseline 有所改善，SSIM/PSNR更高，但LPIPS/FVD更低。
应用hand-only 或object-only masks 会比 baseline 模型产生显著的改进。
我们默认选择的hand-object masks 在所有指标上都达到了最佳效果，
区分左手和右手并不能进一步提高性能。

这些结果表明，双手和交互对象的细粒度控制对于ego-centric 视频预测至关重要。
不同手物条件下的比较。

Analysis on conditioning modalities
下表列出了应用不同模式作为视频预测任务的条件的比较结果。我们再次应用从未来视频中提取的 HOI masks 以保证 mask 的质量。

默认情况下，模型将第一个帧和 text instruction 作为输入作为条件，并预测后续帧（ID-3）。
放弃文本输入（ID-1）使预测的视频不再符合人类指令，导致可控性下降。
类似地，删除第一帧作为控制条件（ID-2）会将模型变成 Text-to-Video（T2V）模型。在这种情况下，模型无法在当前场景上下文中生成动作，因此性能显着下降（ID-1与ID-3）。
当结合第一帧和  HOI masks 时，该模型实现了优于基线的性能（ID-3与ID-4）。

这表明 structural control of the generation似乎比text instructions更有效，因为 hand-object movement可以作为推断当前动作语义的有价值的线索。相反，给定 textual instruction ，手和物体可能有多种实际互动和移动的方式。ID-5表明，将所有模式作为条件结合起来会产生最佳的预测性能。
作为视频预测条件的不同模式的比较。

Analysis on the cross-view mask prediction
我们研究了下表中的ego memory attention（作为query的 ego feature）和exo memory attention（作为query的exo feature）对cross-view mask prediction and video prediction 的影响。

第一行显示先验的性能，其中未来帧对cross-view mask prediction model可见。可以观察到分割和生成任务的高准确性，正如预期的那样。
如第二行所列，使用 ego-memory attention 只能产生较低的分割结果。尽管它对可见的第一帧进行了良好的分割，但它在后续帧中却遇到了困难，因为由于不可见性，它只能使用 zero-image features作为查询，因此很难有效地聚合历史信息。
相比之下，当仅使用exo-memory attention时，该模型可以对未观察到的帧做出比ego-memory attention更好的mask prediction，从而总体上更好的性能。

结合ego- and exo-memory attention协助早期阶段的模型训练，增强了在观察到和未观察到的帧中分割手和物体的预测能力，并随后改进了视频预测模型。
Analysis on exocentric video clues
EgoExo-Gen将cross-view video prediction任务分解为cross-view learning（通过cross-view mask prediction model）和视频预测（通过HOI-aware video diffusion model）。我们修改了我们的模型，通过用原始的exo-centric RGB frames或exo-centric hand-object masks替换以ego-centric hand-object mask condition，从而能够将 exo-centric 信息整合到单个模型中。如下表所示，两种方法都获得了次优性能，表明在单个 video diffusion model中进行分类学习exo-ego translation 和视频预测的困难。相比之下，ego-centric的视图中的hand-object movement提供了明确的像素对齐视觉线索，以改善视频预测。
外部中心信息融入的比较。

Analysis on data pipeline
为了验证我们的 cross-view mask 生成 pipeline 的效果，我们比较了仅在通过EgoHOS与EgoHOS+Sam-2生成的 HOI masks 上训练的视频预测模型。在这里，我们应用从未来帧提取的 HOI masks 作为直接比较的条件。EgoHOS执行每帧手部和交互对象分割，同时忽略随后帧之间的时间一致性。SAM 2通过在给定由EgoHOS生成的掩模提示的情况下在所有帧中跟踪手和对象来补偿时间一致性的损失。如下表所示，SAM-2 由于改善了hand and object masks 的质量而导致更好的生成性能。
注释pipline中HOI遮罩质量的比较。

Application to different diffusion models
为了证明我们方法的概括能力，我们将我们的 cross-view mask prediction model 与不同的视频扩散模型集成。默认情况下，我们采用 SEINE 作为我们的主要视频传播模型。此外，我们还对 ConistI2V 进行了实验作为替代扩散模型，并且训练和推理 pipline 保持不变。实验结果如下表所示，这表明，结合交叉视图屏蔽预测模型可以在SEINE和ConstI2V上获得性能提升。这验证了我们的方法在不同视频扩散模型中引入交叉视图信息方面的概括能力。
EgoExo-Gen对不同视频预测模型的推广能力。

Quanlitative Comparision and Limitation
我们在下图中显示了预测视频的可视化结果。
定性比较。EgoExo-Gen（w/o future）指的是我们使用预测的HOI mask作为条件的默认模型。EgoExo-Gen（w/ future）使用从可见的未来帧（中提取的HOI masks，充当Oracle。最后一行显示了手部运动复杂的失败案例。

我们的默认模型，即EgoExoGen（w/o future）预测具有合理手物体运动的视频，尽管需要轻微的手物体运动（例如，搅拌）。相比之下，ConistI 2 V可能会导致物体形状不稳定（例如，碗）或在第二种情况下几乎静态的视频。然而，我们发现 EgoExo-Gen 和 ConstI 2V 在涉及复杂手部运动的情况下都会失败，如最后一行所示。在第2列中，我们还展示了先验模型的结果，其中我们的HOI感知视频扩散模型采用使用EgoHOS和Sam-2从可见未来帧中提取的手对象面具。尽管存在上述挑战，EgoExo-Gen（w/ future)预测了接近地面真相的真实视频。
这表明 EgoExo-Gen 中的 HOI-aware video diffusion model 学习了对手和物体的良好控制性，而性能受到 sub-optimal mask预测能力的限制。提高未来不可见帧中predicted masks的质量（例如，第10帧）将是我们未来的工作。
在可见的第1帧以及不可见的第5帧和第10帧处，exo-centric的 hand-object masks和预测的 ego-centric masks的可视化。

Related Work
Egocentric-Exocentric video understanding and generation
超越 ego-only的Wang等人; Pei等人或 exo-only 的Wang等人视频分析、从以ego-centric 和 exo-centric 的联合角度理解视频涵盖了广泛的任务，例如action recognition，retrieval、cross-view relation，以及skill assessment。虽然大多数作品在视频层面上执行跨视图动作理解，但另一条研究路线专注于跨视图翻译/生成，这需要在不同视图之间建立时空关系。例如，Luo等人提出了通过从自我中心视图中挖掘轨迹信息来生成外心视图。Luo等人通过探索手部姿势作为图像扩散模型的显式指导，实现了exo-to-ego 图像生成。与先前的方法相比，我们设计了一种cross-view mask prediction model，以预测手和交互对象从exo-view到ego-view的spatio-temporal masks。
Diffusion models for video prediction
视频预测（又名 图像动画）旨在以第一帧作为条件来生成后续视频帧。受text-to-image（T2I）diffusion models 的启发和 text-to-video（T2V）diffusion models ，一系列作品将第一帧作为T2V模型的附加条件，实现可控视频预测。ConsistI 2 V在第一帧中进行时空关注，以保持空间和运动一致性。DynamiCrafter设计了dual-stream image injection paradigm来改进生成。与之前专注于在一般领域生成视频的方法相比，通过分解text instructions来预测现实世界的 ego-centric 视频 或专用适配器。我们的工作明确地建模了dynamics（即hands and interacting objects）在 ego-centric的视频预测中。
Hand-Object segmentation
对手与物体交互（HOI）的分析涵盖了广泛的研究方向。在这里，我们重点关注hand and interacting object segmentation（HOS），这是一项具有挑战性的任务，需要模型来分割开放世界的交互对象。Visor和EgoHOS提议以ego-centric 视图分割左手/右手和交互对象。尽管表现出色，但这些作品在 exo-centric的视图上通常失败。为了以第三人称视角解决HOS问题，HOISTformer设计了一款 maskformer-based的在 exo-centric dataset上训练的手对象分割模型。最近专门用于分割的视觉基础模型、SAM-2 能够在视觉提示的情况下分割和跟踪对象。Sapiens（擅长分割人体部位，包括手和手臂。我们的自动化管道是建立在这些作品的基础上的，可以在自我和外部视图中分割手和物体。
Conclusion
在本文中，我们提出 EgoExo-Gen 通过对视频中的 hand-object dynamics进行建模来解决 cross-view video prediction 任务。EgoExo-Gen结合了

一个 cross-view mask prediction model，该模型通过建模spatio-temporal ego-exo correspondence 来估计未观察到的 ego-frames 的 hand-object masks;
HOI-aware video diffusion model，该模型将结合预测的 HOI masks作为结构指导。

我们还设计了一个自动化的 HOI mask annotation pipeline，为ego- and exo-videos 生成 HOI mask，增强了EgoExo-Gen的可扩展性。实验证明，EgoExo-Gen在预测具有真实的hand-object movement的视频方面优于现有视频预测模型，揭示了其在AR/VR和 embodied AI 中的潜在应用。
]]></content>
  </entry>
  <entry>
    <title>Ensemble Learning</title>
    <url>/2025/07/02/Ensemble-Learning/</url>
    <content><![CDATA[idea
集成学习 (ensemble learning) 通过构建并结合多个学习器来完成学习任务。
下图展示了集成学习的一般结构：

先产生一组个体学习器 (individual learner)作为参与集成的学习器单元,不同预测模型在数据上具有不同表现
再用某种策略将它们结合

若集成中只包含同种类型的个体学习器，这样的集成是同质的(homogeneous)；同质集成中的个体学习器称为基学习器(base learner); 相应的学习算法称为基学习算法(base learning algorithm)；
集成也可以包含不同类型的个体学习器，即异质的 (heterogenous)或组件学习器；




特征
集成学习通过将多个学习器进行结合，通常可以获得比单一学习器显著优越的泛化性能。这对弱学习器(weak learner) 尤为明显。
弱学习器：预测结果比随机猜测略好的学习模型；
强学习器：预测结果明显比随机猜测好的学习模型；
实际中，成功的集成要求个体学习器通常应该好而不同，

准确性：个体学习器要有一定的准确性；
多样性：学习器间具有差异，预测模型犯的错误不相同，鼓励集成不同类型；


组合模型
实际操作一般有如下方式集成
平均：回归问题求平均值，分类分题进行投票
，

加权平均：训练集成模型时更新所有模型;
，

门控：训练集成模型时更新所有模型，比如自动驾驶中面对复杂的不同场景，切换不同的模型


树模型：用决策树作为集成模型，根据和函数的值进行结点拆分

策略
成功的集成学习西药一些多样性策略

包含不同类型的预测模型：比如识别pattern比较困难
改变训练集：数据过拟合
改变特征集：特征具有噪声
数据处理：避免学习到的集成模型过拟合

​
Bagging
Bagging策略
Bagging是一种并行学习策略，从原始样本集中生成不同的子集

给定包含 m个样本的数据集，先随机取出一个样本放入采样集，再把该样本放回初始数据集，使得下次采样时该样本仍有可能被选中；
经过 m 次随机采样，得到含 m 个样本的采样集；
初始训练集中有的样本在采样集多次出现，有的则从未出现；

这样可采样出 T 个含 m 个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器结合。这就是 Bagging 的基本流程。
核心问题为保证个体学习器采用不同的训练集，即子集生成问题

若子集与原始集合偏离过多，则基学习器经验风险过大；
若两个子集重叠样本过多，则基学习器过于相似；

Bootstrap策略
Bootstrap策略是一种有放回的均匀抽样


每个个体分类器的每次采样均从N个样本的原始数据抽取，从训练数据中有放回地采样生成一些数据，每个复制数据集大小和训练集相同


N无穷大时，样本未被抽到的概率为




复制数据集上的评估方差

模型误差

由于数据实例在自举采样数据集出现的概率约为0.632；直接在训练集上验证，大概率会过拟合；
因此提出留一自举法(leave-one-out bootstrap):构建自举复制集时不采样实例，然后利用这个实例评估模型

其中是那些没有包含实例的自举复制集的索引集合；如果为空集则忽略这些情况；
最后集成这些自举数据集上的模型，采用Bootstrap Aggregating(B-gag-ing)自举复制

对于有个训练样本的数据集
通过有放回的采样构造新的数据集
构造个自举采样集;
训练预测模型集合;
最终的预测结果为模型平均值


Pasting策略
Pasting策略时一种无放回的均匀抽样

对于每个个体分类器，已经抽出的样本不再出现
个体分类器的训练样本一般占总样本的60%到80%，，一般无重复

有效性分析
以下为两种场景的Bagging算法的分类效果



Bagging后的集成模型偏差和原始模型相同，但是降低了反差，对低偏差高反差的预测模型的提升效果显著；
对一系列服从同一分布的随机变量，方差为,两两关联性为,它们的均值变量方差为

随机森林
随机森林 (Random Forset，RF) 是 Bagging 的一个扩展。RF构建了一个解耦合(decorrelated)的树，然后对结果取平均。
RF 在以决策树为基学习器构建 Bagging 集成的基础上，在决策树的训练过程中引入随机属性选择。

传统决策树在选择划分属性时是在当前节点的属性集合 (假定有 d 个属性) 中选择一个最优属性；
在 RF 中， 对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含 k 个属性的子集，然后再从这个子集中选择一个最优属性用于划分；
参数 k 控制了随机性的引入程度。 一般取,甚至为1；

算法流程如下

假如有N个样本，则有放回的随机选择N个样本(自举采样：每次随机选择一个样本，然后返回继续选择)。这选择好了的N个样本用来训练一个决策树，作为决策树根节点处的样本。
当每个样本有M个属性时，在决策树的每个节点需要分裂时，随机从这M个属性中选取出m个属性，满足条件m &lt;&lt; M。然后从这m个属性中采用某种策略（比如说信息增益）来选择1个属性作为该节点的分裂属性。
决策树形成过程中每个节点都要按照步骤2来分裂（很容易理解，如果下一次该节点选出来的那一个属性是刚刚其父节点分裂时用过的属性，则该节点已经达到了叶子节点，无须继续分裂了）。一直到不能够再分裂为止。注意整个决策树形成过程中没有进行剪枝。
按照步骤1~3建立大量的决策树，这样就构成了随机森林了

假设集成结果为,可以做回归预测平均值，也可以分类进行多数投票；

Bagging仅仅是在有相同权重的自举采样集上对每个预测模型进行训练 ；
随机森林通过采样特征的方法尝试去解耦合自举训练预测模型（决策树）；
Boosting算法基于之前的预测模型有策略性地学习和结合接下来的预测模型；

Boosting
Boosting 是一族可将弱学习器提升为强学习器的算法：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本进行调整，使得先前基学习器做错的训练样本在后续受到更多的关注，然后基于调整后的样本训练下一个基学习器，如此重复进行，直至基学习器达到事先指定的值，最终将这 T 个基学习器进行加权结合。
比较常见的场景为：目前我们有一个打印字体的训练集，但是我们希望模型能识别手写字体，这时可能需要逐步提升模型，并保存中间结果，最后融合所有模型；
这类办法将模型看作如下的集成分类器

优化目标为所有学习器学习损失总和最小

这一般不是凸优化问题，可能有多个局部最优解，鲁棒性难以保证，参数数量多，梯度形势复杂，通常没有封闭解；梯度下降法的收敛速度难以保障，基分类器的泛化性能和“好而不同”的设计目标难以保障；
Boosting策略
串行训练个体学习器，新增加的个体学习器重点关注错分的样本，逐步提升集成学习系统的泛化性能,在学习目标中增加错分样本的权重,即重赋权(reweighting)

一类前向分步优化的思路是指每一步优化只新增一个学习器

新增基学习器训练中，已经集成的部分保持不变，优化;
从而转变成一种分布优化目标

这是一种类似greedy的策略，待优化的变量明显减少，但是无法保证解为全局最优；
Adaboost
Adaboost(adaptive boosting)自适应增强算法，关注前一个基本分类器分错的样本会得到加强，加权后的全体样本再次被用来训练下一 个基本分类器。同时，在每一轮中加入一个新的弱分类器，直到达到某个预 定的足够小的错误率或达到预先指定的最大迭代次数。
也就是说，后一个模型的训练总是在前一个模型上完成。流程如下



初始化训练数据的权值分布
如果有N个样本，则每一个训练样本最开始时都被赋予相同的权值：1/N


训练弱分类器
如果某个样本点已经被准确地分类，那么在构造下一个训练集中，它的权值就被降低
相反，如果某个样本点没有被准确地分类，那么它的权值就得到提高
权值更新过的样本集被用于训练下一个分类器，整个训练过程如此迭代地进行下去


将各个训练得到的弱分类器组合成强分类器
加大分类误差率小的弱分类器的权重，而降低分类误差率大的弱分类器的权重


示意图如下

采用面向二分类问题的加性模型假设,

在分布上任意采样，满足映射;目标优化为最小化指数损失函数


为什么选取这个函数？因为对于梯度为0处求得最优的,到达了贝叶斯最优错误率，说明这个函数是原来分类任务的一致的替代函数。

定义训练数据总量为,维度为,标签为二维的，真实的映射为;

对于时刻的样本分布(训练样本权重向量)

每个个体学习器在分布下的平均误差率为

对于这一类问题，其前向分布优化的过程如下：
将指数损失函数递归式Tylor展开得到

进一步近似得到

求解当前最优的基学习器为

注意到除以某个常数结果不变，记

递归表示如下

于是最优解（注意D下标变化）就是最小化错误分类

考虑前向分步最小化求解

令内式的梯度为0，求解

显然上述推导用到了太多的近似，并非一定是全局最优的，可以按照如下伪代码迭代
\usepackage&#123;algorithm, algpseudocode, amsmath&#125;\begin&#123;algorithm&#125;\caption&#123;AdaBoost Algorithm&#125;\label&#123;alg:adaboost&#125;\begin&#123;algorithmic&#125;[1]\Require Training Data $X = \&#123;\mathbf&#123;x&#125;_1, \dots, \mathbf&#123;x&#125;_N\&#125;$, Labels $Y = \&#123;y_1, \dots, y_N\&#125;$ where $y_i \in \&#123;-1, 1\&#125;$, Number of Iterations $T$.\Ensure A strong classifier $H(\mathbf&#123;x&#125;)$ represented by a list of base learners and their weights $\&#123; (h_t, \alpha_t) \&#125;_&#123;t=1&#125;^T$.\State Initialize sample weights $D_1$: $D_1(i) = \frac&#123;1&#125;&#123;N&#125;$ for $i = 1, \dots, N$.\State Initialize list of base learners and weights: $\text&#123;Learners&#125; = []$.\For &#123;$t = 1, \dots, T$&#125;    \State Train a base learner $h_t$ using a base learning algorithm $\Omega$ on data $(X, Y)$ with weights $D_t$.    \State Calculate the weighted error rate $\epsilon_t$ of $h_t$:    $\epsilon_t = \sum_&#123;i=1&#125;^N D_t(i) \cdot \mathbb&#123;I&#125;(h_t(\mathbf&#123;x&#125;_i) \neq y_i)$ \Comment&#123;$\mathbb&#123;I&#125;(\cdot)$ is the indicator function&#125;    \If &#123;$\epsilon_t &gt; 0.5$ or $\epsilon_t = 0$&#125;        \State Break loop or handle as edge case.    \EndIf    \State Calculate the weight $\alpha_t$ for base learner $h_t$:    $\alpha_t = \frac&#123;1&#125;&#123;2&#125; \ln\left(\frac&#123;1 - \epsilon_t&#125;&#123;\epsilon_t&#125;\right)$    \State Add $(h_t, \alpha_t)$ to $\text&#123;Learners&#125;$.    \State Update sample weights for the next iteration $D_&#123;t+1&#125;$:    \State Initialize normalization factor $Z_t = 0$.    \For &#123;$i = 1, \dots, N$&#125;        \State $D_&#123;t+1&#125;(i) = D_t(i) \exp(-\alpha_t \cdot y_i \cdot h_t(\mathbf&#123;x&#125;_i))$        \State $Z_t = Z_t + D_&#123;t+1&#125;(i)$    \EndFor    \For &#123;$i = 1, \dots, N$&#125;        \State $D_&#123;t+1&#125;(i) = \frac&#123;D_&#123;t+1&#125;(i)&#125;&#123;Z_t&#125;$ \Comment&#123;Normalize weights&#125;    \EndFor\EndFor\State \textbf&#123;Output:&#125; The strong classifier $H(\mathbf&#123;x&#125;)$. For a new sample $\mathbf&#123;x&#125;$, the prediction is given by:\State $H(\mathbf&#123;x&#125;) = \text&#123;sign&#125;\left(\sum_&#123;t=1&#125;^T \alpha_t h_t(\mathbf&#123;x&#125;)\right)$\end&#123;algorithmic&#125;\end&#123;algorithm&#125;

该算法对基学习器提出了一定要求，比如CART决策树，神经网络

比较容易将样本权重整合到基学习器的训练过程中
基学习器的表征和泛化能力便于用参数来调节
数据权重扰动对基学习器训练结果影响较大

GBDT算法
GBDT（Gradient Boosting Decision Tree）是一种迭代的决策树算法，该算法由多棵决策树组成，GBDT的核心在于累加所有树的结果作为最终结果，所以 GBDT 中的树都是回归树，不是分类树，它是属于Boosting 策略。GBDT是被公认的泛化能力较强的算法。
对于每一棵决策树的结果可以表示为叶子结点的加权结果

GBDT的预测结果为

前向分步表示为

分类问题损失函数一般选用指数损失函数，回归问题选用平方误差损失，这里就是平方误差；
显然，新到来的决策树就是对先前集成模型的残差拟合


一个更精细的模型算法流程如下：

]]></content>
      <tags>
        <tag>Machine-Learning</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>FLUX.1-Kontext:Flow Matching for In Context Image Generation and Editing in Latent Space</title>
    <url>/2025/09/27/FLUX-1-Kontext-Flow-Matching-for-In-Context-Image-Generation-and-Editing-in-Latent-Space/</url>
    <content><![CDATA[Abstract
我们展示了 FLUX.1 Kontext 的评估结果，这是一种统一图像生成和编辑的生成式流匹配模型。该模型通过结合文本和图像输入的语义上下文来生成新颖的输出视图。FLUX.1 Kontext 使用简单的序列级联方法，在单一统一架构内处理本地编辑和生成性上下文任务。与当前在多个回合中显示字符一致性和稳定性下降的编辑模型相比，我们观察到 FLUX.1 Kontext 改进了对象和字符的保存，导致迭代工作流程的鲁棒性更强。该模型通过当前最先进的系统实现了有竞争力的性能，同时提供了显着更快的生成时间，支持交互式应用程序和快速原型制作工作流程。为了验证这些改进，我们引入了 KontextBench ，这是一个综合基准测试，包含 1026 个图像提示对，涵盖五个任务类别：本地编辑、全局编辑、字符引用、样式引用和文本编辑。详细的评估表明，FLUX.1 Kontext 在 single-turn 质量和 multi-turn 一致性方面都表现出色，为统一图像处理模型树立了新标准。
Introduction
图像是现代传播的基础，也是社交媒体、电子商务、科学可视化、娱乐和模因等各个领域的基础。随着视觉内容的数量和速度的增加，对直观但忠实和准确的图像编辑的需求也在增加。用户期望工具能够保留精细细节、保持语义一致并更多的响应自然语言命令。大规模生成模型的出现改变了这种格局，实现了以前不切实际或不可能的纯文本驱动图像合成和修改。
传统的图像处理 pipelines 通过直接操纵像素值或通过在显式用户控制下应用几何和光学变换来工作。相比之下，generative processing 使用深度学习模型及其学习的 representations 来合成无缝适应新场景的内容。两种互补的能力是该范式的核心


Local editing：局部、有限的修改，以保持周围环境完整


例如，改变汽车的颜色，同时保留背景，或替换背景，同时将主题保持在前景。


LaMa 、Latent Diffusion inpainting、RePaint 、Stable Diffusion Inpainting variants 和 FLUX.1 Fill 3等生成性修复系统使此类上下文感知编辑变得即时;


除了修补之外，ControlNet 还支持面具引导的背景替换，而 DragGAN 提供交互式的基于点的几何操纵。




Generative editing：提取视觉概念（例如特定的人物或标志），然后在新环境中忠实再现，可能在新的视角下合成或在新的视觉环境中渲染。

与大型语言模型中的 in-context learning 类似，其中网络从提示中提供的示例中学习任务，而无需任何参数更新，生成器将其输出动态地适应条件上下文。
该属性可以实现生成图像和视频模型的个性化，而无需微调或 LoRA 训练。
此类免训练主题驱动图像合成的早期工作包括 IP-Adapter 或 retrieval-augmented diffusion variants。



最近的进展
DirectPix2Pix 和后续工作展示了 synthetic instruction-response pairs 对微调 diffusion mode（用于图像编辑）的前景，而个性化 text-to-image synthesis 的 learning-free 方法使 image modification 能够使用脱离现实的高性能图像生成模型。
后续的 instruction-driven editors （例如Emu Edit, OmniGen, HiDream-E1, ICEdit） 将这些想法扩展到细化的数据集和模型架构。Huang等人在特定任务上引入了针对 diffusion transformers 的上下文 LoRA，其中每个任务都需要训练专用的LoRA 权重。嵌入在 multimodal LLMs （例如，GPT-Image, Gemini Native Image Gen）中的 新型的 proprietary systems 进一步模糊了对话框和编辑之间的界限。
Midjourney 和 RunwayML 等生成性平台将这些进步集成到端到端创意工作流程中。
最近方法的缺点
就结果而言，目前的方法存在三大缺陷：

instruction-based 的方法在 synthetic pairs 上训练，继承了其 generation pipelines 的缺点，限制了可实现编辑的多样性和真实性;
在多次编辑中保持角色和对象的准确外观仍然是一个悬而未决的问题，阻碍了讲故事和品牌敏感应用程序;（人物一致性存在问题）
与 denoising-based 方法相比，除了质量较低之外，集成到大型多模式系统中的自回归编辑模型通常具有较长的运行时间，与交互式使用不兼容。

解决方案
我们引入了FLUX.1 Kontext，这是一种 flow-based 生成式图像处理模型，其质量相匹配或超过最先进的黑匣子系统，同时克服了上述限制。
FLUX.1 Kontext是一个简单的流匹配模型，仅使用 context 和 instruction tokens 的 concatenated sequence上的速度预测目标 进行训练。

Character consistency ：FLUX.1 Kontext 擅长 character preservation，包括多次迭代的edit turns。
Interactive speed ：FLUX.1 Kontext 速度快。文本到图像和图像到图像应用程序都能达到1024 x 1024（3-5秒）的图像合成速度。
Iterative application：快速推理和强大的一致性使用户能够通过多次连续编辑以最小的视觉漂移来细化图像。

FLUX.1
FLUX.1是一类 rectified flow transformer，使用 image autoencoder 的潜在空间训练。我们跟随 Rombach et al，从头开始训练具有对抗目标的 convolutional autoencoder。

通过扩大训练计算并使用16个潜在 channels，与相关模型相比，我们提高了重建能力;
此外，FLUX.1 是由 double stream blocks 和 single stream blocks 的 mixing 构建的。

double stream blocks 对图像和文本标记采用单独的权重；
mixing 是通过对 tokens 串流使用 attention operation 来完成的。


在将 tokens 串流传递通过 double stream blocks 后，我们将它们连接起来，并将38个 single stream blocks 应用于图像和文本标记。
最后，我们丢弃文本标记并解码图像标记。


为了提高 single stream blocks 的 GPU 利用率，我们利用了受 Dehghani 等人启发的融合feed-forward blocks

将 feed-forward blocks 中的调制参数数量减少2倍
将注意力输入和输出线性层与 MLP 的融合，从而产生更大的 matrix-vector multiplications，从而提高训练和推理效率。
我们利用 factorized 3D RoPE。每个 latent token 都由其时空坐标 ，， 来索引（对于单个图像输入，）。

FLUX.1 Kontext
我们的目标是学习一种可以根据 text prompt 和参考图像共同生成图像的模型。更正式地说，我们的目标是逼近条件分布


 是目标图像;
 是上下文图像（或上下文图像）;
 是自然语言指令;


与经典的文本到图像生成不同，这个目标需要学习图像本身之间的关系，由  介导，以便同一个网络可以

当  时执行图像驱动的编辑，
当  时从头开始创建新内容。

为此，令  是输出（目标）图像， 是可选的上下文图像， 是文本提示。我们对条件分布  建模，以便对于同一个网络当  执行 in-context and local edits ，以及当  时执行 free text-to-image generation。训练从 FLUX.1文本到图像的 checkpoint开始，我们收集并策划数百万个关系对  用于优化。实际上，我们不会在 pixel space 中对图像进行建模，而是将它们编码为 token sequence。
Token sequence construction
图像通过冻结的 FLUX autoencoder 编码成 latent tokens。然后，这些上下文图像 tokens  被append 到图像 token  ，并被馈送到模型的 visual stream 中。这种简单的 sequence concatenation

支持不同的输入/输出分辨率和宽高比
容易扩展到多个图像 ，，， 。

我们还测试了和的逐行级联，但在最初的实验中，我们发现这种设计选择的性能更差。
我们通过3D RoPE嵌入来编码位置信息，其中上下文  的 embeddings 接收所有上下文 token 的 constant offset 。我们将 offset 视为一个虚拟时间步，它将 context 和target blocks 干净地分开，同时保持其内部空间结构不变。具体来说，如果 token position 由元组 表示，那么我们为 target tokens 设置，，和为 context tokens 设置 ;
Rectified-flow objective
我们训练采用 rectified flow–matching loss

其中  是  和噪音之间的线性插值隐变量；

我们对 使用 logit normal shift schedule，其中我们根据训练期间数据的分辨率更改模式 。当对 text–image pairs() 进行采样时，我们忽略所有tokens ，以保留模型的文本到图像生成能力。
Adversarial Diffusion Distillation
通过优化 rectified flow–matching loss 获得的流匹配模型的采样通常涉及使用50-250个 guided network evaluations 来求解普通或随机方程。虽然通过这样的过程获得的样本对于 well-trained model  来说质量良好，但这也存在一些潜在的缺点：

这种多步采样速度慢，导致模型大规模服务成本高昂，并阻碍了低延迟、交互式应用程序。
此外，指导偶尔可能会引入视觉伪影，例如过饱和样本。

我们使用 latent adversarial diffusion distillation（LADD）来应对这两个挑战，减少采样步骤的数量，同时通过对抗训练提高样本质量。
Implementation details
从纯粹的文本到图像检查点开始，我们按照 rectified flow–matching loss 顺带地对 image-to-image 和 text-to-image 任务上的模型进行微调。虽然我们的公式自然涵盖了多个输入图像，但我们目前专注于单个背景图像进行条件反射。
FLUX.1 Kontext [pro]使用 flow objective 和LADD 进行训练。我们按照Meng等人中概述的技术，通过引导蒸馏到12B diffusion transformer 中来获得 FLUX.1 Kontext [dev]。为了优化 FLUX.1 Kontext [dev] 编辑任务的性能，我们只关注 image-to-image 训练，即不训练 FLUX.1 Kontext [dev] 的text-to-image 任务。
我们采用了安全训练的操作，包括 classifier-based filtering 和 adversarial training，以防止产生non-consensual intimate imagery（NCII）和 child sexual abuse material（CSAM）。
我们以混合精度使用FSDP 2，all-gather operations 采用 bfloat 16中执行，而 gradient reduce-scatter 使用 float 32以提高数值稳定性。我们使用 selective activation checkpointing 以减少VRAM 的最大使用量。为了提高吞吐量，我们使用Flash Attention 3 和各个Transformer块的区域编译。
Evaluations &amp; Applications
在本节中，我们将评估 FLUX.1 Kontext 的性能并展示其功能。我们首先介绍 KontextBench，这是一个 novel benchmark，其特点是现实世界的图像编辑挑战，这来自用户的众包。然后，我们提出了我们的主要评估：FLUX.1 Kontext 与最先进的 text-to-image 和 image-to-image 合成方法的系统比较，我们在不同的编辑任务中展示了具有竞争力的性能。最后，我们探讨了FLUX.1 Kontext的实际应用，包括迭代编辑工作流程，样式传输，视觉提示编辑和文本编辑。
KontextBench – Crowd-sourced Real-World Benchmark for In-Context Tasks
在捕捉现实世界的使用情况时，用于 editing models 的现有 benchmarks 通常受到限制。INSTPix 2 Pix 依赖于合成的 Stable Diffusion 样本和 GPT-generated 指令，从而产生固有的偏差。MagicBrush 虽然使用真实的 MS-COCO 图像，但在数据收集期间受到 DALLE-2 功能的限制。Emu-Edit 等其他基准使用具有不切实际分布的低分辨率图像，并且仅关注编辑任务，而 DreamBench 缺乏广泛的覆盖范围，Gedit-bridge 并不代表现代多模式模型的全部范围。Intelligence Bench仍然不可用，只有300个不确定任务覆盖的示例。
为了解决这些差距，我们从众包的现实世界用例中编篡了 KontextBench。该基准包括1026个独特的 image-prompt pairs，这些图像来自108个基本图像，包括个人照片、CC许可的艺术品、公共领域图像和人工智能生成的内容。它涵盖五项核心任务：local instruction editing（416）、global instruction editing（262）、text editing（92）、style reference（63）和character reference （193）。我们发现 benchmark的规模在可靠的人工评估和对现实世界应用程序的全面覆盖之间提供了良好的平衡。我们将发布此 benchmark，包括 FLUX.1 Kontext 的样本和所有报告的 baselines。
State-of-the-Art Comparison
FLUX.1 Kontext 旨在执行 text-to-image (T2I) 和image-to-image (I2I) 合成。我们根据这两个领域中最强大的专有和开放权重模型来评估我们的方法。我们评估FLOX.1 Kontext [pro]和[dev]。如上所述，对于[dev]来说，我们专门关注图像到图像的任务。此外，我们还引入了FLOX.1 Kontext [max]，它使用更多计算来提高生成性能。
Image-to-Image Results
对于图像编辑评估，我们评估多个编辑任务的性能：图像质量、本地编辑、字符参考（Cref）、风格参考（Sref）、文本编辑和计算效率。

Cref 可以在新颖的设置中一致地生成特定的字符或对象，而Sref则允许从参考图像转移风格，同时保持语义控制。

我们比较了不同的 API ，发现我们的模型提供了最快的延迟，在速度差异方面比相关模型表现高出一个数量级。在我们的人工评估中，我们发现 FLUX.1 Kontext [max]和[pro] 是本地和文本编辑类别以及一般 Cref 的最佳解决方案。我们还计算Cref的量化分数，为了评估输入和输出图像之间面部特征的变化，我们使用AuraFace 6来提取前后的面部嵌入，并编辑和比较两者。与我们的人类评估一致，FLOX.1 Kontext 优于所有其他模型。对于全局编辑和 Sref 来说，FLOX.1 Kontext分别仅次于gtt-Image-1和Gen-4 Reference。  总体而言，FLOX.1 Kontext提供了最先进的角色一致性和编辑功能，同时在速度上比GPT-Image-1等竞争模型要好一个数量级。
跨模型1024 x 1024生成的中位数推断延迟 秒 越低越好 FLOX.1 Kontext 在文本到图像和图像到图像任务方面都实现了有竞争力的速度

KontextBench上的图像到图像评估 我们显示了六个上下文图像生成任务的评估结果。FLOX.1 Kontext pro 在所有任务中始终名列前茅 在文本编辑和字符保留方面取得了最高分

Text-to-Image Results
当前的 T2I 基准主要关注一般偏好，通常会提出“which image do you prefer?”等问题。我们观察到，这种广泛的评估标准通常倾向于典型的“人工智能美学”，即过度饱和的色彩、过度关注中心主题、明显的散景效应以及向同质风格的趋同。我们将这种现象称为 bakeyness。
为了解决这一局限性，我们将T2 I评估分解为五个不同的维度：提示跟随、美观（“which image do you find more aesthetically pleasing”）、现实主义（“which image looks more real”）、印刷准确性和推理速度。我们评估了从学术基准（DrawBench，Participants）和真实用户查询中编译的1000个不同的测试提示。在下文中，我们将此基准称为 Internal-T2 I-Bench。此外，我们通过对GenAI工作台的额外评估来补充该基准。
在T2 I中，FLUX.1 Kontext在各个评估类别中表现出均衡的性能。尽管竞争模型在某些领域表现出色，但这往往以牺牲其他类别为代价。例如，Recraft提供了很强的美观质量，但及时的粘附性有限，而GPT-Image-1则显示出相反的整体性能模式。
FLUX.1 Kontext 与其前身 FLUX1.1 [pro] 相比，始终如一地提高了各个类别的性能。我们还观察到从FLUX.1 Kontext [pro]到FLUX.1 Kontext [max]的渐进收益。
Text-to-image evaluation on Internal-t2i-bench 我们报告多个质量维度的评估结果。FLOX.1 Kontext模型展示了美学、提示跟随、印刷和现实主义基准方面的竞争性能。

我们在下图中突出显示了样本。

Iterative Workflows
在多次编辑中保持角色和对象一致性对于品牌敏感和讲故事的应用程序至关重要。当前最先进的方法存在明显的视觉漂移：每次编辑，角色都会失去身份，对象都会失去定义性特征。在图12中，我们展示了由 FLUX.1 Kontext、Gen-4 和 GPT-Image-High 产生的编辑序列之间的字符身份漂移。我们还计算了输入和通过连续编辑生成的图像之间 AuraFace 嵌入的 cos 相似性，强调了FLUX.1 Kontext相对于竞争方法的较慢漂移。一致性至关重要：营销需要稳定的品牌特征，媒体制作需要资产连续性，电子商务必须保留产品细节。下图显示了由FLUX.1启用的应用Kontext的可靠的一致性。
迭代的产品风格编辑 从参考碗（a）开始，我们的模型首先在桌面工作室环境中生成一个与鲜花相匹配的花瓶（b），然后将花瓶的基本色更改为黑色，同时保留花卉图案、灯光和构图（c）

连续的面部表情编辑 从轮廓参考（a）开始，我们的模特首先将对象重新定位为相机（b），然后将她的表情改变为自发的笑声（c），同时保留背景、服装和灯光

Specialized Applications
FLUX.1 Kontext支持标准代以外的多个应用程序。风格引用（Sref）首先由Midjourney 普及，通常通过IP Adapters 实现，它可以从参考图像传输风格，同时保持语义控制。此外，该模型支持通过视觉线索进行直观编辑，响应红色椭圆等几何标记来指导有针对性的修改。它还提供复杂的文本编辑功能，包括徽标细化、拼写纠正和风格调整，同时保留周围环境。我们在图5中演示了风格参考，在图13中演示了基于视觉线索的编辑。
风格参考 给定输入图像，模型提取其艺术风格并应用它来生成多样化的新场景，同时保留原始的风格特征。

FLOX.1 Kontext能够利用边界框等视觉线索并在保持风格的同时编辑文本

Discussion
我们介绍了 FLUX.1 Kontext，这是一个流匹配模型，它将上下文图像生成和编辑结合在一个框架中。通过简单的序列拼接和训练配方，FLUX.1 Kontext实现了最先进的性能，同时解决了多轮编辑期间的字符漂移、推理速度慢和输出质量低等关键限制。我们的贡献包括处理多个处理任务的统一架构，跨迭代的卓越字符一致性，交互速度和KontextBench：具有1026个imagemprompt对的真实世界基准。我们的广泛评估表明，FLUX.1 Kontext可与专有系统相媲美，同时支持快速，多回合的创意工作流程。
局限性
FLUX.1 Kontext在其当前的实现中表现出一些局限性。过多的多圈编辑可能会引入视觉伪影，从而降低图像质量。该模型有时无法准确遵循说明，忽略了特定的提示要求。此外，蒸馏过程可能会引入影响输出保真度的视觉伪影。
编辑失败案例 顶行：身份退化的一个例子：虽然中心图像显示了良好的编辑，但保留正确的角色身份（使用稍微修改的提示）会导致严重的身份损失。中间行：场景修改而不是物体移动：模型添加牛奶泡沫而不是重新定位马克杯。底行：经过六次迭代编辑后，样本可能会表现出可见的伪影。

未来的工作
应重点关注扩展到多个图像输入、进一步扩展并减少推理延迟以解锁实时应用程序。我们方法的一个自然扩展是在视频领域进行编辑。最重要的是，减少多回合编辑期间的降级将实现无限流动的内容创建。FLUX.1 Kontext和KontextBench的发布为推动统一的图像生成和编辑提供了坚实的基础和全面的评估框架。
]]></content>
      <tags>
        <tag>papers</tag>
        <tag>Computer-Vision</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang中的并发机制</title>
    <url>/2025/07/05/Golang%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[Golang的并发处理优势
并发处理是Golang设计的核心目标之一，其通过一条简单的关键字go来启动协程goroutine,在广义上我们可以将协程理解为线程；
由于Golang轻量级的特性，在一个主程序中可是轻而易举地列举上千条协程，线程安全只需要由通道(chan)数据类型实现，而且先天支持多核CPU的调度；
多核CPU并发分担
所谓main()运行在程序的主线程中，当main()退出时，所有的goroutine都将退出，即便这些协程没有完成它的任务；
因此我们在接下来的示例程序中将引入100ms的睡眠无限循环防止程序提前退出，以便其他协程有机会运行，同时避免主协程无效忙等；
请注意，协程的执行是异步的，主协程不会等待协程，而是直接跳过协程，这就是在协程上打断点无效的原因；
在Goalng中查看实际硬件CPU数：
cpuCores := runtime.NumCPU()
将可用CPU核数设为n,对于n&lt;1,配置为默认的机器配置；
runtime.GOMAXPROCS(n)
测试起见我们将CPU数设为2,因为可能配置太高看不出来共享冲突；
共享冲突
执行以下代码：
package mainimport (	&quot;fmt&quot;	&quot;runtime&quot;)var valueG int = 0var stop1 bool = falsevar stop2 bool = falsefunc routine1(countA int, stopA *bool) &#123;	for i := 0; i &lt; countA; i++ &#123;		valueG = valueG + 2	&#125;	*stopA = true&#125;func main() &#123;	runtime.GOMAXPROCS(2)	go routine1(100000000, &amp;stop1)	go routine1(100000000, &amp;stop2)	for &#123;		if stop1 &amp;&amp; stop2 &#123;			break		&#125;	&#125;	fmt.Printf(&quot;valueG: %v\n&quot;, valueG)&#125;
执行结果如下：

很明显，临界资源的访问没有互斥机制，所以执行的结果也有不同；
我们加上控制机制来保证同一时刻只能由一个任务来访问该数据；
共享安全
共享安全：保证在多任务并发处理时共享数据不会因共享冲突而导致错误；
Golang就提供了这样的数据类型来保证共享安全机制：chan管道, 这是一个先入先出的队列
执行以下代码：
package mainimport (	&quot;fmt&quot;	&quot;runtime&quot;)var valueG chan intvar stop1 bool = falsevar stop2 bool = falsefunc routine1(countA int, stopA *bool) &#123;	for i := 0; i &lt; countA; i++ &#123;		tmpC := &lt;-valueG		valueG &lt;- (tmpC + 2)	&#125;	*stopA = true	 &#125;func main() &#123;	runtime.GOMAXPROCS(2)	valueG = make(chan int, 1)    defer close(valueG)    	go routine1(10000, &amp;stop1)	go routine1(10000, &amp;stop2)	valueG &lt;- 0	for &#123;		if stop1 &amp;&amp; stop2 &#123;			break		&#125;	&#125;	fmt.Printf(&quot;valueG: %v\n&quot;, &lt;-valueG)&#125;
执行结果如下，可以看到确实输出结果保持了一致：

注意：

理解-&gt;和&lt;-操作符是阻塞的：

当从通道接收数据时，如果通道中没有数据，接收操作会阻塞，直到有数据可接收；
当向通道发送数据时，如果通道没有接收方，发送操作会阻塞，直到有协程准备接收数据；
这种阻塞行为可以确保并发协程之间的通信是同步的，避免了数据的丢失或竞态条件



获取令牌的任务
对于一些任务，取到令牌的任务才能访问某些数据，访问完毕之后交回令牌供其他任务使用；
以下是示例代码：
package mainimport (	&quot;fmt&quot;	&quot;runtime&quot;)var valueG intvar stop1 bool = falsevar stop2 bool = falsevar token chan boolfunc routine1(countA int, stopA *bool) &#123;	for i := 0; i &lt; countA; i++ &#123;		&lt;-token  // 关键		valueG = valueG +2		token &lt;- false	&#125;	*stopA = true	 &#125;func main() &#123;	runtime.GOMAXPROCS(2)	token = make(chan bool, 1)	defer close(token)		go routine1(10000, &amp;stop1)	go routine1(10000, &amp;stop2)		token &lt;- false	for &#123;		if stop1 &amp;&amp; stop2 &#123;			break		&#125;	&#125;	fmt.Printf(&quot;valueG: %v\n&quot;, valueG)&#125;
在实际应用中，令牌的或许就像这个token一样，等待管道输入过后，任务完成后交回token给下一个任务使用；
多任务归并
并发编程中，主任务将任务拆分成子任务并等待所有子任务完成之后再进行下一步处理的过程称作多任务的归并；
这样做可以充分利用CPU性能，避免资源的过渡浪费；
观察以下代码：
package mainimport (	&quot;fmt&quot;	&quot;runtime&quot;)var goroutineCount = runtime.GOMAXPROCS(0) // 默认CPU核数var resultBuffer chan float64 func addRoutine(lenT int)&#123;	var sumT float64	for i := 0; i &lt; lenT; i++ &#123;        sumT += 1.0    &#125;    resultBuffer &lt;- sumT&#125;func addByGoroutine(countA int) float64 &#123;	sumT := 0.0	lenT := countA / goroutineCount	leftT := countA - lenT*goroutineCount	go addRoutine(lenT + leftT)	for i := 1; i &lt; goroutineCount; i++ &#123;		go addRoutine(lenT)	&#125;	for i := 0; i &lt; goroutineCount; i++ &#123;		sumT += &lt;-resultBuffer	&#125;	return sumT&#125;func main()&#123;	resultBuffer = make(chan float64, 1)	defer close(resultBuffer)	res := addByGoroutine(1000000)	fmt.Print(res)&#125;
超时终止机制
利用select监听多个通道，我们可以轻松实现超时终止机制：
select &#123;case tmpF = &lt;-resultBuffer1:	sumT1 += tmpF // 任务1case tmpC = &lt;-resultBuffer2:	sumT2 += tmpC // 任务2case &lt;-time.After(3 * time.Second):	timeoutFlag = true // 超时&#125;
注意：time.After将返回一个定时触发的chan类型值
我们可以如下自定义超时函数：
// 休眠指定的秒数后，向通道中写入一个数值表示超时（数值本身不重要）// chanA是只能写入的单向通道func realTimeout1(secondsA time.Duration, chanA chan&lt;- bool) &#123;	time.Sleep(secondsA * time.Second)	chanA &lt;- true&#125;// 仅用于新建一个通道后启动真正的超时routine，并将该通道返回让select等待通道中有值func timeout1(secondsA time.Duration) &lt;-chan bool &#123;	chan1 := make(chan bool, 1)	// 传入realTimeout1的chan1被强制转换为只写通道类型	go realTimeout1(secondsA, (chan&lt;- bool)(chan1))	return (&lt;-chan bool)(chan1) // 返回时将chan1强制转换为只读通道类型&#125;
sync实现并发处理
我们可以利用sync.WaitGroup来实现多任务的归并，初始化sync.WaitGroup,每进行完一个任务计数器减1；
观察如下代码，执行发现每次结果有所不同：
package mainimport (	&quot;fmt&quot;	&quot;sync&quot;)var groupG sync.WaitGroupvar times = 100000var valueG = 0func addRoutine(countA int) &#123;	defer groupG.Done()	for i := 0; i &lt; countA; i++ &#123;		valueG = valueG + 2	&#125;&#125;func minusRoutine(countA int) &#123;	defer groupG.Done()	for i := 0; i &lt; countA; i++ &#123;		valueG = valueG - 1	&#125;&#125;func main()&#123;	groupG.Add(2)	go addRoutine(times)	fmt.Printf(&quot;add value: %d\n&quot;, valueG)	go minusRoutine(times)	fmt.Printf(&quot;minus value: %d\n&quot;, valueG)	groupG.Wait()	fmt.Printf(&quot;Final value: %d\n&quot;, valueG)&#125;
这是因为触发了竞态条件：valueG = valueG + 2 和 valueG = valueG - 1 这些操作并不是原子操作，包含多个步骤：读取 valueG 的值，进行计算，然后将结果写回 valueG；
在并发环境中，这些步骤可能会被其他 Goroutine 打断，导致结果不一致；
正确的做法是为add和minus加锁：
package mainimport (	&quot;fmt&quot;	&quot;sync&quot;)var groupG sync.WaitGroupvar mutexG sync.Mutexvar times = 100000var valueG = 0func addRoutine(countA int) &#123;	defer groupG.Done()	for i := 0; i &lt; countA; i++ &#123;		mutexG.Lock()		valueG = valueG + 2		mutexG.Unlock()	&#125;&#125;func minusRoutine(countA int) &#123;	defer groupG.Done()	for i := 0; i &lt; countA; i++ &#123;		mutexG.Lock()		valueG = valueG - 1		mutexG.Unlock()	&#125;&#125;func main()&#123;	groupG.Add(2)	go addRoutine(times)	fmt.Printf(&quot;add value: %d\n&quot;, valueG)	go minusRoutine(times)	fmt.Printf(&quot;minus value: %d\n&quot;, valueG)	groupG.Wait()	fmt.Printf(&quot;Final value: %d\n&quot;, valueG)&#125;
协程和进程的区别

一个线程可以有多个协程。
大多数业务场景下，线程进程可以看做是同步机制，而协程则是异步。
线程是抢占式，而协程是非抢占式的，所以需要用户代码释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。
协程并不是取代线程，而且抽象于线程之上。线程是被分割的CPU资源, 协程是组织好的代码流程, 协程需要线程来承载运行。

]]></content>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title>Graph Introduction</title>
    <url>/2025/07/05/Graph-Introduction/</url>
    <content><![CDATA[Graph
对于三元组,满足：

顶点集有限；
边集是顶点无序对组成的(可重)集合，也即；

Simple Graph
当边集有重复元素，称相同的边为重边/平行边(multiple/parallel edges);
称点与边是关联的(indicent)，当且仅当,这样称是边​的一个端点(end)；
称点是相邻的(nerbor)，当且仅当边;
称边为自环(loop),当且仅当边的两个端点相同；
称图是简单的(simple),当且仅当边集既没有重边也没有自环；
Degree
称顶点的度(degree)为顶点关联的边数

自环在度中贡献2次；

称图的最大度；
最小度为;
称点为孤立点(isolated vertex)，当且仅当;
称点为悬垂点(pendent vertex),当且仅当
Handshaking Theorem(握手定理)
对任意图

推论：对于任意图，奇数度的顶点的个数为偶数；
Definitions
称图是图​的子图(subgragh)，如果

进一步，若图是图的生成子图(spanning subgragh)，如果

称两个图同构(isomorphism),记作,当且仅当存在映射

使得对于的任意两点,均有

彼此同构的图构成等价类；
如果图满足,它们的不交并(disjoin)表示为

其点集为,边集为;
无标号图计数问题：阶图同构图等价类个数；
有标号图计数问题：顶点固定的阶图同构图等价类个数；
称为简单图的补图(complement graph)，当且仅当其点集和边集满足


补关系是自反的；


称图为自补的(self-complement),当且仅当


;
是自补的；

Connectedness
称图为连通的(connected),如果该图无法被划分为两个图的不交并；否则为非连通的(disconnected)；

一个非连通图至少可以划分为两个连通分支
连通图仅有一个连通分支；

记图的连通分支数为
Representation
定义图的邻接矩阵(adjacency matrix)

关联矩阵(incident matrix)

Laplacian矩阵

将的特征值称为图的Laplace特征值，按非递增序排列如下：



图是连通的当且仅当;此时被称为Fiedler 值；


中连通分量的数量是的零空间的维度;


注意：

​是对称的方阵；
一般认为非简单图，自环,重边处值为2；

Examples
一般的图
称图为空图(empty graph), 当且仅当其边集为空,记作；
称图为完全图(complete graph),当且仅当其任意两个顶点均连边，记作;

完全图的边数为

称图是**正则的**(regular)，如果;

一般认为;
正则图也指代立方体图；

对于正则图来说，不能同时为奇数;

Petersen Graph
对于图,对于,记的全体二元子集为
，

性质：

3-正则的；
色数为3；
非平面的；

Platonic Graph(正多面体图)
Platonic图也称正多面体图；它们都是正则的；


Bipartite图（二部图）
称图为二部图(Bipartite)，如果其顶点和边集满足


可以划分为两个不相交的部集






对于完全二部图,其边集是所有之间的所有边；




特别的，我们称为爪，为星；
Hypercube(k-cube)
二进制定义(Binary Definition)
对于维度为的二进制序列;
立方体图,是指点集和边集满足如下条件：

也就是说，两点连边当且仅当仅有一个二进制位不同；
递归定义(Recursive structure)

;


其中两个图的Cartesian积  定义如下：


性质

是一个二部图

考虑每个点的按位异或，值为1的和值为0的分别为两个部集；、



是正则的；

独立集与Ramsey 问题
在图中，称点集为独立集，如果满足：

换言之，没有两个点在中相邻；
对于给定的,存在最小的正整数,使得对于任意阶的简单图，要么存在,要么存在阶的独立集，这个正整数称为Ramsey数；
如果我们将红蓝二染色，等价描述为必存在阶蓝色完全图或者阶的红色完全图；
Hadamand矩阵
Lemma

proof:由红蓝二染色的对称性易得；
Theorem

proof:
注意到以下反例，推知

只需证明：将二染色必存在红色或蓝色;
考察,有5条关联的边，由抽屉原理，必有3条边同色，不妨假设为红色,那么若存在红边，那么和该红边构成红色,否则构成蓝色;其余平凡；
Theorem(Erdös and Szekeres, 1935)
对于给定，存在上界，并且满足不等关系：

proof:只需证明阶完全图二染色必存在红色或蓝色;
选择,将划分为两个集合,满足：

若为蓝色，则;
若为红色，则;

显然,由抽屉原理，要么，要么;
由归纳假设，要么中存在红色或蓝色,要么中存在红色或蓝色，算上结论显然；
Corollary(Greenwood and Gleason, 1955)
当均为偶数时

proof:假设,考虑阶的完全图,显然为奇数，对,

以下三种情况必有其一成立：





由归纳假设，平凡，只需考虑:
现统计蓝色边数量，由的任意性和握手定理，

奇偶性矛盾!
Theorem

proof:一方面;
另一方面，下图说明

Theorem

proof:一方面;
另一方面,下图说明

Theorem

proof:由推论;
另一方面，下图说明

通过的二次剩余可以构造该图；
目前的Ramsey数的进展如下：

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Graph-Theory</tag>
      </tags>
  </entry>
  <entry>
    <title>IN-CONTEXT LORA FOR DIFFUSION TRANSFORMERS</title>
    <url>/2025/10/06/IN-CONTEXT-LORA-FOR-DIFFUSION-TRANSFORMERS/</url>
    <content><![CDATA[Abstract
最近的研究探索了使用 diffusion transformers（DiT）通过简单地在图像之间 concatenating attention tokens 来生成 task-agnostic 图像。然而，尽管有大量的计算资源，生成的图像的保真度仍然不理想。在这项研究中，我们通过假设 text-to-image 的 DiT 固有地拥有 in-context generation 的能力，只需最低限度的调整即可激活它们，从而重新评估和简化了这个框架。通过不同的任务实验，我们定性地证明了现有的 text-to-image DiT可以在无需任何调整的情况下有效地执行上下文生成。基于这一见解，我们提出了一个非常简单的pipeline 来利用 DiT 的上下文能力：

连接图像而不是 tokens;
执行多个图像的 joint captioning;
使用小数据集应用特定于任务的LoRA调整（例如，20 ~ 100个样本），而不是对大型数据集进行全参数调优。

我们将我们的模型命名为 In-Context LoRA（IC-LoRA）。这种方法不需要修改原始 DiT 模型，只需要更改训练数据。值得注意的是，我们的 pipeline 可以生成更好地遵守提示的高保真图像集。虽然在调优数据方面是特定于任务的，但我们的框架在架构和管道方面仍然保持 task-agnostic，这为社区提供了强大的工具，并为进一步研究产品级任务不可知生成系统提供了有价值的见解。我们在 GitHub上发布我们的代码、数据和模型。
Introduction
文本到图像模型的出现显着推进了视觉内容生成领域，使能够从文本描述创建高保真图像。现在，许多方法都提供了对各种图像属性的增强控制，允许在生成期间进行更细的调整。尽管取得了这些进展，适应文本到图像的模型，以广泛的生成任务，特别是那些需要连贯的图像集与复杂的内在关系，仍然是一个开放的挑战。在这项工作中，我们介绍了一个 task-agnostic 的框架，旨在适应文本到图像模型，以不同的生成任务，旨在提供一个通用的解决方案，多功能和可控的图像生成。

传统方法（任务特定）：要做图像分类，就训练一个分类网络（如ResNet）。要做目标检测，就训练一个检测网络（如Faster R-CNN）。要做语义分割，就训练一个分割网络（如U-Net）;每个模型都是“各自为政”，从零开始或在特定数据集上微调，学到的特征只擅长自己的任务。
任务无关的方法：先使用一种通用的、自监督的预训练方法（如MAE, SimCLR, DINO）在一个巨大的、无标签的图像库（如ImageNet）上训练一个模型。这个模型学习到的图像特征就是“任务无关”的。它不知道也不关心你将来要用它来分类、检测还是分割。它只是学会了如何很好地“理解”图像的内容和结构。当需要解决具体任务时，只需在这个通用的“任务无关”模型后面添加一个非常简单的任务特定头（比如一个分类层），然后用少量数据进行微调，甚至不微调（线性探测），就能取得非常好的效果。
任务无关的框架是一个系统或模型架构，它被设计成能够不经过核心结构修改，直接处理多种不同的视觉任务。这个框架的核心是一个共享的、任务无关的骨干网络，它负责从图像中提取通用的特征。然后，通过附加不同的、轻量级的“任务头”或使用不同的提示指令，来引导这个骨干网络解决不同的问题。

最近的工作，例如 Group Diffusion Transformers（GDT）框架，探索了将视觉生成任务重新定义为群体生成问题。在这种情况下，具有任意 intrinsic relationships 的一组图像在单个去噪扩散过程中同时生成，可选地以另一组图像为条件。GDT 的核心思想是将图像中的注意力标记连接起来，包括条件标记和要生成的标记，同时确保每个图像的标记只关注其相应的文本标记。这种方法允许模型以与任务无关的零触发方式适应多个任务，而无需任何微调或梯度更新。
然而，尽管 GDT 具有创新的架构，但其generation fidelity 相对较低，与原始预训练的文本到图像模型相比，通常表现不佳。这一限制促使人们重新审视将文本到图像模型适应复杂生成任务时所采用的基本假设和方法。
在这项工作中，我们做出了一个关键假设：text-to-image 模型固有地拥有in-context generation capabilities 。为了验证这一点，我们直接将现有的 text-to-image 模型应用于各种需要生成具有不同关系的图像集的任务。如图3所示；
FLUX文本到图像生成示例。使用 FLUX.1-dev 跨六个任务生成文本到图像的示例，突出显示了具有不同关系属性的多面板图像的创建。主要观察结果包括：（1）原始的文本到图像模型已经可以生成在身份、风格、照明和字体方面具有连贯一致性的多面板输出，尽管仍然存在一些小的缺陷。(2)FLUX.1-dev在解释描述多个面板的组合提示方面表现出强大的能力。

以 FLUX.1-dev 模型为例，我们观察到该模型已经可以执行不同的任务，尽管存在一些缺陷。它保持一致的属性，例如对象身份、风格、照明条件和调色板，同时修改姿势、3D方向和布局等其他方面。此外，该模型还展示了在单个合并提示内解释和遵循多个图像描述的能力。
这些令人惊讶的发现让我们得到了几个关键见解：

固有上下文学习：文本到图像模型已经具备上下文生成能力。通过适当触发和增强这种能力，我们可以利用它来执行复杂的生成任务。
无需架构修改的模型可重用性：由于 text-to-image 模型可以解释合并的captions，因此我们可以重用它们在上下文中生成，而无需对其架构进行任何更改。这涉及简单地更改输入数据，而不是修改模型本身。
最少数据和计算的效率：无需大型数据集或延长训练时间即可实现高质量的结果。小型、高质量的数据集加上最少的计算资源可能就足够了。

基于这些见解，我们设计了一个极其简单但有效的 pipeline，用于使 text-to-image 模型适应不同的任务。我们的方法在以下方面与 GDT 形成鲜明对比：

图像拼接：我们将一组图像拼接成单个大图像，而不是拼接注意力标记。该方法大致相当于 diffusion transformers（DiT）中的 token concatenation，忽略了 Variational Autoencoder（VAE）组件引入的差异。
prompts 拼接：我们将每个图像的 prompts 合并为一个长prompt，使模型能够同时处理和生成多个图像。这与 GDT 方法不同，在GDT方法中，每个图像的 tokens 都与其文本 tokens 交叉。
使用小数据集进行最小微调：我们没有对数十万个样本进行大规模训练，而是使用一小组仅 个图像集来微调模型的 Low-Rank Adaptation（LoRA）。这种方法显着减少了所需的计算资源，并在很大程度上保留了原始文本到图像模型的知识和上下文能力。

生成的模型非常简单，不需要修改原始的 text-to-image 模型。调整仅通过根据特定任务需求调整一小组调整数据来实现。为了支持image-conditional generation，我们采用了一种简单的技术：在连接的大图像中 mask 一个或多个图像，并 prompt 模型使用剩余图像修补它们。为此，我们直接利用SDEDit。
尽管它的简单性，我们发现，我们的方法可以适应各种各样的高质量的任务。虽然我们的方法需要特定于任务的调优数据，但整体框架和 pipeline 仍然与任务无关，允许在不修改原始模型架构的情况下适应各种任务。这种最低数据要求和广泛适用性的结合为生成社区，设计师和艺术家提供了强大的工具。我们承认，开发一个完全统一的发电系统仍然是一个开放的挑战，并将其作为未来的工作。为了便于进一步研究，我们在项目页面2发布了我们的数据、模型和训练配置。
Related Work
Task-Specific Image Generation
Text-to-image 模型在从复杂的文本提示生成高保真图像方面取得了显着的成功。然而，它们通常缺乏对生成图像的特定属性的细粒度可控性。为了解决这一限制，人们提出了许多工作来增强对布局等方面的控制和照明条件。有些方法甚至支持同时生成多个图像，类似于我们的方法。
尽管取得了这些进步，但这些模型通常采用特定于任务的架构和 pipelines，限制了它们的灵活性和通用性。每个架构都是针对单个任务量身定制的，并且为一项任务开发的功能不容易组合或扩展到任意新任务。这与自然语言处理的最近进展形成鲜明对比，其中模型被设计为在单个体系结构中执行多个任务，并且可以概括超出它们显式训练的任务。
Task-Agnostic Image Generation
为了克服任务特定模型的限制，最近的研究旨在创建任务不可知的框架，该框架支持单个架构内的多个可控图像生成任务。例如，Emu Edit 集成了广泛的图像编辑功能，而Emu 2，TransFusion ，和 OmniGen 在一个统一的模型中执行不同的任务，从 procedural drawing 到 subject-driven generation。Emu 3通过在一个框架下支持文本、图像和视频生成进一步扩展了这一功能。这些工作代表了统一或任务不可知的一代的实质性进展。
与这些模型相反，我们提出现有的 text-to-image 架构已经具备内在的上下文能力。这消除了开发新架构的需要，并以最少的额外数据和计算资源实现高质量生成。我们的方法不仅提高了效率，而且还在各种任务中提供卓越的发电质量。
Method
Problem Formulation
遵循 Group Diffusion Transformers 的方法[Huang等人，2024]，我们将大多数图像生成任务定义为产生一组 图像，条件是另一组图像和个文本提示。该形式化涵盖广泛的学术任务，例如图像翻译、风格转移、姿势转移和主题驱动生成，以及图画书创作、字体设计和转移、故事板生成等实际应用。条件图像和生成的图像之间的相关性通过每个图像提示隐式地维护。
我们的方法通过对整个图像集使用一个consolidated prompt 来稍微修改这个框架。此 prompt 通常从图像集的总体描述开始，然后是每个图像的单独提示。这种统一的 prompt 设计与现有的 text-to-image 模型更兼容，并允许整体描述自然地传达任务的意图，就像客户如何向艺术家传达设计要求一样。
Group Diffusion Transformers
我们从基本框架开始，Group Diffusion Transformers（GDT）。在GDT中，通过在每个 Transformer self-attention block 中的图像之间连接 attention tokens，在单个扩散过程中同时生成一组图像。这种方法使每个图像都能够“看到”集中的所有其他图像并与其交互。Text conditioning 是通过让每个图像注意其相应的 text embeddings 来引入的，使其能够访问其他图像的内容和相关的 text guidance。  GDT在数十万个图像集上训练，使其能够以零镜头方式在任务中进行概括。
In-Context LoRA
虽然 GDT 展示了零镜头任务适应性，但其生成质量不足，与text-to-image models模型的 baseline  相比，通常表现不佳。我们提出了一些改进措施来改进这个框架。
我们的出发点是假设基础的 text-to-image 模型固有地拥有一些针对不同任务的上下文生成能力，即使质量有所不同。下图中的结果支持了这一点，其中模型有效地生成跨不同任务的多个图像（有时有条件）。
FLUX文本到图像生成示例。使用 FLUX.1-dev 跨六个任务生成文本到图像的示例，突出显示了具有不同关系属性的多面板图像的创建。主要观察结果包括：（1）原始的文本到图像模型已经可以生成在身份、风格、照明和字体方面具有连贯一致性的多面板输出，尽管仍然存在一些小的缺陷。(2) FLUX.1-dev在解释描述多个面板的组合提示方面表现出强大的能力，详情请在附录A中。

基于这一见解，不需要对大型数据集进行广泛的训练;我们可以通过精心策划的高质量图像集激活模型的上下文能力。
另一个观察结果是，text-to-image 模型可以从包含多个面板描述的单个 prompt 生成连贯的 multi-panel 图像。
(a) Portrait Photography. This four-panel image captures a young boy’s adventure in the woods, expressing curiosity and wonder. [TOP-LEFT] He crouches beside a stream, peering intently at a group of frogs jumping along the rocks, his face full of excitement; [TOP-RIGHT] he climbs a low tree branch, arms stretched wide as he balances, a big grin on his face; [BOTTOM-LEFT] a close-up shows him kneeling in the dirt, inspecting a bright yellow mushroom with fascination; [BOTTOM-RIGHT] the boy runs through a clearing, his arms spread out like airplane wings, lost in the thrill of discovery.  (b) Product Design. The image showcases a modern and multifunctional baby walker designed for play and growth, featuring its versatility and attention to detail; [TOP-LEFT] the first panel highlights the walker’s sleek form with several interactive toys on the tray, focusing on its overall structure and functionality, [TOP-RIGHT] the second panel provides a side view emphasizing the built-in lighting around the play tray, illustrating both style and safety features, [BOTTOM-LEFT] the third panel displays a rear view of the walker showcasing the comfortable seat and adjustable design elements, underlining comfort and adaptability, [BOTTOM-RIGHT] while the final panel offers a close-up of the activity center with various colorful toys, capturing its playful appeal and engagement potential.  (c) Font Design. The four-panel image emphasizes the versatility of a minimalist sans-serif font across various elegant settings: [TOP-LEFT] displays the word “Essence” in muted beige, featured on a luxury perfume bottle with a marble backdrop; [TOP-RIGHT] shows the phrase “Pure Serenity” in soft white, set against an image of serene, rippling water; [BOTTOM-LEFT] showcases “Breathe Deep” in pale blue, printed on a calming lavender candle, evoking a spa-like atmosphere; [BOTTOM-RIGHT] features “Elegance Defined” in charcoal gray, embossed on a sleek hardcover notebook, emphasizing sophistication and style.  (d) Sandstorm Visual Effect. The two-panel image showcases a biker speeding through a desert landscape before and after a sandstorm effect, capturing a powerful transformation; [TOP] the first panel presents a biker riding along a dirt path, with the vast desert and blue sky stretching out behind them, conveying a sense of freedom and adventure, while [BOTTOM] the second panel introduces a violent sandstorm, with grains of sand swirling around the biker and partially obscuring the landscape, transforming the scene into a chaotic and thrilling visual spectacle.  (e) Visual Identity Design. This two-panel image captures the essence of a visual identity design and its adaptable application, showcasing both the original concept and its practical derivative use; [LEFT] the left panel presents a bright and engaging graphic featuring a stylized gray koala character triumphantly holding a large wedge of cheese on a vibrant yellow background, using bold black outlines to emphasize the simplicity and playfulness of the design, while [RIGHT] the right panel illustrates the design’s extension to everyday objects, where the same koala and cheese motif has been skillfully adapted onto a circular coaster with a softer yellow tone, accompanied by a matching mug bearing smaller graphics of the koala and cheese, both items resting elegantly on a minimalist white table, highlighting the versatility and cohesive appeal of the visual identity across different mediums. (f) Portrait Illustration. This two-panel image showcases a transformation from a photographic portrait to a playful illustration; [LEFT] the first panel displays a man in a navy suit, white shirt, and brown shoes, sitting on a wooden bench in an urban park, his hand resting casually on his lap; [RIGHT] the illustration panel transforms him into a cartoon-like character, with smooth lines and exaggerated features, including oversized shoes and a vibrant blue suit, set against a minimalist park backdrop, giving the scene a lively and humorous feel.
因此，我们可以通过使用统一的图像提示来简化架构，而不是要求每个图像专门关注其各自的文本标记。这使我们能够重复使用原始的 text-to-image架构，而无需进行任何结构上的修改。
我们最终的框架设计通过在训练期间将一组图像直接连接成一个大图像，同时生成一组图像，同时将它们的 captions 合并成一个合并的 prompt，并为每个面板提供总体描述和明确的指导。生成图像集后，我们将大图像拆分为各个面板。此外，由于 text-to-image 模型已经展示了上下文能力，因此我们不会对整个模型进行微调。相反，我们对一小群高质量数据应用Low-Rank Adaptation（LoRA）来触发和增强这些功能。

Low-Rank Adaptation(LoRA, 大模型的低秩自适应) 是一种用于高效微调大型预训练模型（如GPT、扩散模型、BERT等）的技术。

传统微调：好比为了给一件西装换个款式，你把整件衣服拆了，重新裁剪缝合所有布料。这需要很高的手艺（计算资源）和很长时间，而且容易把原来的好布料（预训练中获得的知识）弄坏。
LoRA微调：好比在这件西装的关键部位（比如肩部、腰部）用别针固定上几块小小的、新的布料。这些小块布料专门用于调整款式，非常轻便，而且随时可以取下，恢复西装原样。

LoRA基于以下假设：模型在适应新任务时，其权重变化具有“低秩”特性。这意味着不需要一个完整的、高维度的矩阵来表示所有的变化，而是可以用两个更小、更薄、可训练的矩阵的乘积作为旁路近似这个变化。在微调过程中，只更新A和B这两个小矩阵的参数，原始权重保持不变。矩阵A和B的秩非常小，这使得它们包含的参数数量极少

矩阵负责将输入数据降维;
矩阵负责将降维后的数据再升维回原始维度;
原始模型微调为;


为了支持对额外图像集的条件处理，我们使用 SDEDit（一种免训练方法）来基于 unmasked set 来修补一组图像，所有图像都连接在单个大图像中。

Stochastic Differential Editing(SDEdit, 随机微分编辑) 是一种Diffusion Model-based、train-free的图像生成与编辑方法。可以理解为一种模糊重绘技术：先给输入图像添加噪声，使其变模糊，然后利用 Diffusion Model，在降噪过程中重新绘制出一张既符合你输入的结构、又逼真自然的新图像。

Experiments
Implementation Details
我们在 FLUX.1-dev  text-to-image 模型上构建我们的方法，并专门针对我们的任务训练 In-Context LoRA。我们选择一系列实用的任务，包括storyboard generation、font design、portrait photography、visual identity design、home decoration、visual effects、portrait illustration和 PowerPoint template design等。对于每个任务，我们从互联网上收集 20 到 100 个高质量图像集。每一组都连接成一张合成图像，并使用 Multi-modal Large Language Models (MLLMs) 生成这些图像的字幕，首先是总体摘要，然后是每个图像的详细描述。训练在单个A100 GPU上进行，执行 5000 个步骤，批量大小为4，LoRA秩为 16。为了进行推断，我们采用了 20 个抽样步骤，指导标度为3.5，与 FLUX.1-dev 的蒸馏指导标度相匹配。对于图像条件生成，SDEDdit应用于旨在生成的 mask images，从而能够基于周围图像进行修补。
Results
我们提供定性结果，证明我们的模型在各种任务中的通用性和质量。鉴于任务的多样性，我们推迟对未来的工作采用统一的，定量的 benchmark 和评估。
Reference-Free Image-Set Generation
在此设置中，图像集仅根据文本提示生成，无需额外的图像输入。我们的方法在一系列图像集生成任务中实现了高质量的结果。
Reference-Based Image-Set Generation
在此设置中，使用 text prompt 和输入图像集 具有至少一个参考图像 生成图像集。SDEDdit用于 mask 某些图像，从而启用基于其余图像的修复。图像条件生成的结果如图13所示，常见的失败案例如图14所示。
图像条件生成。在多个任务中使用In-上下文LoRA以及免训练SDEDit的图像条件生成示例。在某些情况下，例如沙尘暴视觉效果的应用案例，输入和输出图像之间可能会出现不一致，包括汽车驾驶员身份和着装的变化。解决这些不一致之处留给未来的工作。

图像条件生成的失败案例。使用带SDEDit的In-Context LoRA的肖像身份传输失败的示例。我们观察到 In-Context LoRA 的 SDEDdit 往往不稳定，通常无法保留身份。这可能源于 SDEDdit对输入到输出映射的单向依赖性与 In-Context LoRA 训练的双向性质之间的差异。解决这个问题留给未来的工作。

尽管在多个任务中有效，但与文本条件生成相比，图像之间的视觉一致性有时较低。这种差异可能是由于SDEDit在掩蔽和未掩蔽图像之间的单向依赖性造成的，而纯文本生成允许图像之间的双向依赖性，从而实现条件和输出的相互调整。这表明了改进的潜力，例如结合可训练的修复方法，我们将其留给未来的探索。
Reproducing
克隆 ai-toolkit 仓库和 In-Context-LoRA 仓库;
git clone https://github.com/ostris/ai-toolkit.git /opt/liblibai-models/user-workspace2/model_zoogit clone https://github.com/ali-vilab/In-Context-LoRA.git /opt/liblibai-models/user-workspace2/model_zoo
创建虚拟环境
conda create -n aitk_xqy python=3.11conda activate aitk_xqypip3 install --no-cache-dir torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu126pip3 install -r requirements.txt
在命令行下登陆 Huggingface;
huggingface-cli login
移动配置文件
scp /opt/liblibai-models/user-workspace2/model_zoo/In-Context-LoRA/config/movie-shots.yml /opt/liblibai-models/user-workspace2/model_zoo/ai-toolkit/config/
执行训练
cd /opt/liblibai-models/user-workspace2/model_zoo/ai-toolkitpython run.py config/movie-shots.yml
可以看到加载了配置文件进行训练;
或者使用 UI 进行训练的配置，注意


在本地访问http://localhost:8675,在服务器上执行如下命令（这个命令是可以中断的，无需保持 UI 运行即可运行作业，它只需要启动/停止/监控作业。）
cd uinpm run build_and_start


修改配置文件，指定 FLUX 模型为本地已经下载好的模型，而不是从 Huggingface 拉取；
model:        name_or_path: &quot;/opt/liblibai-models/user-workspace2/model_zoo/FLUX.1-dev&quot;        is_flux: true        quantize: true


(opt) 开始训练前，在 Huggingface 上获取 Access Tokens；


训练的 UI 界面如下：

]]></content>
      <tags>
        <tag>papers</tag>
        <tag>Computer-Vision</tag>
      </tags>
  </entry>
  <entry>
    <title>Internet</title>
    <url>/2025/07/02/Internet/</url>
    <content><![CDATA[Internet
描述
计算机网络是两台以上具有独立操作系统的计算机通过介质连接成互相共享的软硬件资源的集合体；以下是其成分的描述：

主机(hosts)/端系统(end):运行着网络程序的设备；
通信链路(communication link)：通常包括双绞线，光纤，无线电频谱，卫星；
分组交换机(packet switch)：作用是转发分组/包


链路的传输速率就是常说的带宽，单位为bps；
端系统通过因特网服务供应商(ISP)接入因特网；一个分组从端系统到接收端系统，经理的一系列通信链路和交换机称为路由(route);

对于Internet往往难以给出其精确定义，可以理解为由网络构成的网络

松散分层
分为公共Internet和专用Internet；
由协议(protocol)控制发送和接受消息；协议运行在互联网上的许多部件上；

在服务层面描述Internet，它包括

通信基础设施：允许终端系统运行分布式应用程序(distributed application)，并交换数据；
Internet为这些分布式应用程序提供通信服务；


常见的分布式应用包括Web, email, games, e-commerce, database, VOIP, P2P file sharing；
服务一般分为面向无连接的(connectionless)，或者面向连接的(connection-oriented);这些服务在数据传递时间上是无保证的；

与因特网相连的端系统提供一个套接字接口(socket interface);这个接口规定了源端系统的应用程序请求Internet基础设施，向目的端系统特定程序交付数据的方式，是一套发送程序必须遵守的规则集合；
历史
第一阶段:20世纪60年代中期之前的以主机为中心的第一代计算机网络。
典型应用：是由一台计算机和全美范围内2000多个终端组成的飞机定票系统。终端是一台计算机的外部设备包括显示器和键盘，无CPU和内存。
其他常见产品：VAX 计算机。
这样的通信系统已具备了网络的雏形。
第二个阶段:20世纪60年代中期至70年代的以通信子网为中心的第二代计算机网络。
典型代表：是美国国防部高级研究计划署的计算机分组交换网ARPAnet，ARPAnet标志着计算机网络发展进入了一个新纪元，使计算机网络的概念发生了根本性的变化，它被认为是Internet的前身。
主机之间不是直接用线路相连，而是由接口报文处理机转接后互联的。IMP和它们之间互联的通信线路一起负责主机间的通信任务，构成了通信子网。通信子网互联的主机负责运行程序，提供资源共享，组成了资源子网。
第三个阶段：20世纪70年代末至90年代的具有统一的网络体系结构并遵循国际标准的开放式和标准化的网络，即体系结构标准化的第三代计算机网络。
产生了两种国际通用的最重要的体系结构，即TCP/IP体系结构和国际标准化组织的OSI体系结构（ISO OSI/RM）。
随着TCP/IP体系结构在网络中的广泛应用，标志Internet的诞生。
第四个阶段 :以下一代Internet为中心的新一代网络。
进入20世纪90年代以来，微电子技术、大规模继承电路技术、光通信技术和计算机技术不断发展，为网络技术的发展提供了有力支持。电信网络、闭路电视网（CATV）和计算机网络将三网合一。

Internet主干
如今的Internet由多层次的因特网服务提供商（ISP）组成，大致可以分为以下几层：

第一层ISP (Tier 1 ISP)：这些是全球性的ISP，它们互相连接形成Internet的核心骨干网。它们通常不向最终用户提供接入服务，而是通过**对等（peering）**协议与其他第一层ISP直接连接，并且通过IXP与其他ISP（如区域ISP）连接。
因特网交换点 (IXP - Internet Exchange Point)：IXP是多个ISP可以互相连接和交换流量的物理位置。它允许不同ISP之间的流量直接交换，而无需通过第三方ISP。
区域ISP (Regional ISP)：这些ISP覆盖的地理范围比第一层ISP小，它们通常从第一层ISP购买因特网接入服务，并通过IXP与第一层ISP和其他区域ISP连接。它们也向接入ISP或大型机构提供服务。
接入ISP (Access ISP)：这是最接近最终用户的ISP，它们直接向家庭、公司和机构提供因特网接入服务。接入ISP通常从区域ISP（或在某些情况下直接从第一层ISP）购买因特网接入服务。

此外，大型内容提供商（如Google）也拥有自己的私有网络，并通过IXP或直接连接到第一层ISP和区域ISP，以便高效地向最终用户交付内容。

一个分组的到达可能要穿越许多网络；

Protocol
基本概念
Internet上的协议(protocol)定义了两个或多个通信实体间所交换报文的格式和次序，以及在报文发送和/或接收或者其他事件方面所采取的响应。

语法：通信数据和控制信息的结构与格式；
语义：对具体事件应发出何种控制信息，完成何种动作以及做出何种应答；
同步：对事件实现顺序的详细说明；


为了完成同一项工作，这些通信实体必须运行相同的协议；
rules for 1. specific message sent + 2. specific actions taken when message received or other events

TCP协议和IP协议是Internet中最重要的两个协议，因特网上的主要协议统称为TCP/IP协议；
分层体系结构
网络被设计为分层的方式组织这些协议，每一层为顶上一层提供服务
Internet通常采用五层协议体系结构，由高到低依次为：



层次
英文名称
主要功能
数据单元
典型协议示例




应用层
Application Layer
支持网络应用
报文 (message)
HTTP, SMTP, FTP


传输层
Transport Layer
提供端到端的逻辑通信
报文段 (segment)
TCP, UDP


网络层
Network Layer
将分组从一台主机移动到另一台主机
数据报 (datagram)/分组 (packet)
IP, 路由选择协议


链路层
Link Layer
通过一条链路传输数据报
帧 (frame)
以太网, PPP, WiFi


物理层
Physical Layer
在物理媒介上传输比特
比特 (bit)
(取决于具体物理介质)



将各层的协议综合起来形成协议栈(protocol stack)
数据封装 (Encapsulation)：当应用层的报文通过协议栈向下传递时，每一层都会给报文添加首部信息（有时还有尾部信息），这个过程称为封装。每一层的数据单元都包含上一层的数据单元作为其载荷。

计算机网络标准化组织
常见的Internet标准由Internet Engineering Task Force(IETF)研发，其标准文档称为Request for Comment(RFC);这些文档定义了TCP，IP，HTTP，SMTP等协议；
ISO(International Organization for Standard )
​    成立于1947年,是世界上最大的国际标准化专门机构，是联合国甲级咨询机构。
​    它的成员是89个成员国的国家标准化组织。
​    美国在ISO中的代表是ANSI，大家所熟悉的ASCII和C语言的工业界标准，就是由ANSI所制定的。
​    ISO在网络领域的最突出贡献就是提出OSI参考模型，该模型是网络发展史上的一个重要里程碑。
IEEE**（Institute of Electrical and Electronic Engineers）**
电气和电子工程师协会IEEE是世界上最大的专业技术团体，由计算机和工程学专业人士组成。它创办了许多刊物，定期举行研讨会，还有一个专门负责制定标准的下属机构。IEEE在计算机网络界的最大贡献就是制定了802标准系列，802标准将局域网的各种技术进行了标准化。
网络边缘
网络中的主机运行网络应用程序处在网络的边缘，进一步根据职责划分为

客户端(client)：通常是个人PC,手机等；
服务端(server)：性能更为强大，用于存储和发布Web页面，视频，邮件等；这些都属于大型的数据中心；


C/S架构一般是指客户请求，并接收服务器提供的服务模型；端到端架构(P2P)是不采用专门服务器的服务模型；


接入网络
分类
接入网通常是指将端系统连接到边缘路由器(edge route)的网络,这是端系统到任何其他远程端系统的路由上的第一台路由器；

家庭接入：通过数字用户线(digital subscriber line, DSL)和电缆；
机构接入：我们传说中的校园网属于此类；这类局域网(local area network, LAN)连接端系统到路由器
无线接入：我们常说的5G固定式无线技术；一般是手机等通过无线的方式接入Internet，无限用户从一个接入点连接企业网，企业网再与有限Internet连接；

DSL
用户在使用DSL时，本地的电话公司CO就是它的ISP；每个用户的DSL调制调解器使用现有的电话线与CO的数字用户线接入复用器(DSLAM)交换数据；
电话线承载了不同形式的电话信号，它们采用不同频率编码，包括高速上行信道，中速上行信道，和普通的电话信道；
这种方法使得单根DSL看起来有三条单独的线路一样，称作频分复用技术；
DSL也定义了多个传输速率，这些上行速率和下行速率时不同的，因此这种接入是不对称的,不同的价格使用不同的速率;
cable
家庭电缆接入Internet需要特殊的调制调解器cable modem；混合光纤同轴电缆 (hybrid fiber coaxial cable, HFC)是常见的电缆；

非对称: 可达2Mbps 上行速率, 30Mbps下行速率
光纤/同轴电缆混网连接家庭住宅到ISP路由器，各住宅共享到路由器之间的广播信道
可以通过广电公司提供该网络接入服务部署:

在电缆的头端，电缆调制调节端接系统(CMTS)与DSLAM具有类似功能，将模型信号转换为数字信号的形式；
电缆接入Internet的一个重要特征是共享广播媒体；

广播式下行链路：头端（服务提供商）到所有家庭的下行链路是单条共享的物理线路（如同轴电缆）。头端发送的每个分组数据会广播到该链路连接的所有家庭，而非独立传输给单个用户。
上行链路：所有家庭向头端发送数据需共用同一条上行信道。


每个用户下载资源时要求共享下行链路的信道资源，这是一种分蛋糕的模式，用户越多，每户实际速率越低；而发送请求时要求竞争上行链路的信道资源，这是一种抢麦的模式，用户越多，信道拥塞越严重；因此需要一个分布式的多路访问控制协议；
fiber
光纤到户**(fiber to the home, FTTH)技术提供了一条CO直接到家庭的光线路径，速率约为千兆比特每秒的接入速率；我们仅讨论PON方案；
每个家庭拥有一个光纤网络端接器(optical network terminator, ONT)，由专门的光纤连接到近邻的分配器；分配器把多个家庭连接到一个共享的光纤，再连接到CO的光纤线路端接器(optical line terminator, OLT);

Ethernet
该部分仅简单介绍以太网(Ethernet)；大部分机构和校园使用局域网(LAN)都在普及和部署以太网，共享（共享式以太网）或独占（交换式以太网）链路连接端系统和边缘路由器；
物理介质
对于每个传输器-接收器对，比特通过传播电磁波或者光脉冲的方式跨越物理媒介(physical medium)进行发送；

导引型媒介：信号在固态介质中有向传播, 如：光纤、双绞线和同轴电缆等 ；
非导引型媒介：信号在大气空间或外太空空间自由传播, 如：无线电

双绞铜线
无屏蔽双绞线(unshielded twisted pair, UTP)常用于局域网中，速率约为10Mbps-10Gbps;是主流的高速LAN联网的方案；

同轴电缆
同轴电缆(coaxial cable)由同心的而不是并行的，彼此绝缘的两根铜导体，速率在100Mbps量级，能够用作导引型共享媒介，可以进行双向传输；

光纤
光纤(fiber)用于传到光脉冲，每个脉冲代表一个比特；

支持高速点对点传输：速率约在数百Gps
低误码率：难以被分光窃听，防止电磁干扰，中继到更远距离传输；

无线电
无线电信道的特征

使用电磁频谱承载信号
无需安装物理线路，可以穿墙，提供移动用户的连接和长距离承载信号
双向传输

传播环境的影响:

多路径衰落－干扰物表面反射
盲区衰落－障碍物绕/透
干扰－其他电磁信号

无线链路的类型可按距离分为几类：

地面微波：达 45 Mbps 信道
局域无线通道：WiFi 11Mbps, 54Mbps
广域无线通道：蜂窝局域网(cellular) GPRS, CDMA 3G: 数百 kbps 4G, ~约10 Mbps 5G, 约2 Gbps
卫星通信 高达数百Mbps 信道 (或多个更小的信道)250 msec毫秒端到端延迟
地球同步卫星(geostationary)与低轨道卫星(low earth orbiting) 铱星系统－66颗低空卫星

Network Core
网络核心是由Internet端系统分组交换机和链路组成的网状网络，在下图用粗线表示；

因此可以理解为相互连接的路由器；它们通过电路交换和分组交换传送数据，发送报文(message);
报文应该被设计成执行某种控制功能，也可以包含某种特定数据；
分组交换
分组交换发生在分组交换网中，数据被拆成离散的数据块通过网络来发送；
源端系统将长报文划分为小数据块，称作分组(packet);

每个分组共享网络资源,存在资源竞争，即资源需求总量大于可用资源总量；
每个分组使用链路全部带宽，分组的传输速率总是以链路最大传输速率通过链路；
资源按需求使用；

每个分组经过通信链路和分组交换机(packet switch)传送,包括

路由器(router)
链路层交换机(link-layer switch)

存储转发
多数分组交换机在链路的输入端采用 存储转发(store-and-forward transmission)机制；
交换机在开始向链路传输分组的第一个比特前，必须接收整个分组并缓存；可以理解为，如果忽略传播时延的话，链路上的传输时间为交换机缓存分组的时间；
一般来说，对于有条速率传输速率为的链路组成的路径，从源到目的发送个分组，端到端的转发时延为

排队时延和分组丢失
对某台分组交换机，每个与之相连的链路维护一个输出缓存(output buffer)，结构为队列，用于存储路由器准备转发那条链路的分组；

若到达的分组需要传输的链路忙碌，此分组必须在输出缓存中等待；
此时，分组承受了输出缓存带来的排队时延(queuing delay)；
排队时延是变化的，取决于网络的拥塞情况；

若缓存空间被其他分组完全充满，则新到来的分组将会出现分组丢失(packet loss)的情况；
转发表
每个端系统具有IP，当源主机向目的主机发送分组时，源在分组首部包含了目的主机的IP地址；
每台路由器将维护一个转发表(forwarding table)，用于将目的地址映射为输出链路；
转发表由特殊的路由选择协议(routing protocol)自动地设置这些转发表；这些路由选择协议可以决定从每台路由器到目的地的最短路径，并使用这些最短路径的结果配置转发表；

用逐段问路的司机的例子理解转发和路由选择；

统计复用
统计复用是根据各业务的统计特性,在保证业务质量的情况下,在各个业务之间动态分配带宽,以达到最佳的资源利用率；

分组之间到达没有固定顺序；
电路交换
电路交换(circuit switching)发生在电话网中，每次会话预留沿其路由所需的独占资源，包括缓存和链路传输速率等；

发送方发送信息前，网络必须建立发送方和接收方的连接，称之为电路(circuit);
当电路被创建时，预定了恒定的带宽,这条链接是双方专用的端到端连接(end-to-end connection)；


频分复用
频分复用(frequency division multiplexing, FDM)中，链路的频谱由跨越链路创建的所有连接共享，频段的宽度为带宽(band-width);
实现技术为频分多址(frequency division multiple access)，即将信道频带分割成若干更窄而不互相交的频带，并把每个子频带分给一个用户专用；

时分复用
时分复用(time-division multiplexing, TDM)中，时间被划分为固定时段的帧，每个帧被划分为固定数量的时隙，每个时隙专门为该链接单独使用；
时分多址(Time Division Multiple Access) 把信道帧划分为若干不相重叠的时隙，把每个时隙分配给一个用户。

比较两种交换技术



特性
分组交换 (Packet Switching)
电路交换 (Circuit Switching)




连接建立
无需预先建立专用连接
需要预先建立专用连接（电路）


资源利用
动态共享带宽，资源利用率高
专用带宽，资源利用率低（即使无数据传输）


数据传输
数据划分为分组，独立传输，按需分配资源
专用通道，恒定带宽，独占资源


时延
可能有排队时延和分组丢失，时延不固定
连接建立时延，传输时延固定，低延迟


可靠性
通过重传机制提高可靠性，但可能丢包或乱序
高可靠性，数据按序到达，不易丢失


拥塞处理
拥塞时可能丢包或增加时延
连接建立时可能被阻塞，一旦建立则无拥塞


应用场景
适用于数据通信（如互联网、电子邮件）
适用于实时通信（如传统电话语音通话）


计费方式
通常按数据量或连接时间计费
通常按连接时长计费


灵活性
高度灵活，分组可走不同路径
不灵活，路径固定


存储转发
采用存储转发机制
不采用存储转发机制


协议复杂性
协议相对复杂
协议相对简单




用是否接受预定的餐馆例子理解二者的区别

电信网络
电信网络的分类如图所示

Performance
时延
处理时延(process delay)包括检查分组首部，决定分组导向何处需要的时间，检查比特差错的时间等；
排队时延(queuing delay)是指，在队列中，分组在链路上等待传输的时间；

排队时延取决于事先代打正在排队等待向链路传输分组的数量；
若队列没有分组，排队时延为0；

定义分组到达队列的平均速率为，传输速率为，假定所有比特长度为，则比特到达的平均速率为,假定队列无限大，则流量强度定义为;
若流量强度大于1，则排队队列趋向于无限增加；
假设分组周期性到达，则传输的第个分组具有如下的排队时延；

但是分组的到达一般是随机的；

: 分组稀疏到达,无队列,平均排队延迟极小接近于0
: 输出队列平均位到达速率超过送走这些位的极限速率，输出队列持续增长，排队延迟趋于无穷大。


路由器输出链路入口点的缓冲区输出队列容量有限，当分组到达路由器输出队列发现缓冲区队列已满，路由器只好丢弃分组，丢失的分组可能被前路由节点、源节点重传，或不重传
传输时延(transmission delay)是由存储转发机制带来的，对于长度为的分组，链路的传输速率为,则传输时延为

传播时延(propagation delay)是指，一个比特从链路起点到路由器传播所用时间，具体来说，若链路长度为,链路物理媒介的传播速率为,则传播时延为


用公路段和收费站类比传播时延和传输时延产生的原因；

端到端的总时延为上述所有时延相加；在不同的场景，这些时延可能作用有所不同；假设总共源主机到目的主机有个路由器，则所有结点的延迟累加为端到端的总延迟

吞吐量
吞吐量 (throughput) 表示在单位时间内通过某个网络（或信道、接口）的数据量。

吞吐量更经常地用于对现实世界中的网络的一种测量，以便知道实际上到底有多少数据量能够通过网络。
吞吐量受网络的带宽或网络的额定速率的限制。

带宽
带宽(bandwidth) 本来是指信号具有的频带宽度，其单位是赫（或千赫、兆赫、吉赫等）。
在计算机网络中，带宽用来表示网络中某通道传送数据的能力。表示在单位时间内网络中的某信道所能通过的"最高数据率"。单位是bps；
在带宽的上述两种表述中，前者为频域称谓，而后者为时域称谓，其本质是相同的。
也就是说，一条通信链路的"带宽"越宽，其所能传输的"最高数据率"也越高。
瓶颈
假如接受比特的文件花费秒，则称文件传送的平均吞吐量(average throughput)为bps；相对应的瞬时吞吐量为主机在某一时刻接受文件的速率；
对于网络中的吞吐量受到最慢链路的制约，也就是瓶颈链路，其吞吐量为


]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Computer-Network</tag>
      </tags>
  </entry>
  <entry>
    <title>KD-Tree</title>
    <url>/2025/07/02/KD-Tree/</url>
    <content><![CDATA[数据结构
K-Dimensional Tree (KD-Tree) 是一种用于组织 k 维空间中的点的数据结构，主要用于快速进行范围搜索和最近邻搜索。它可以看作是二叉搜索树在多维空间上的扩展。其结构非常适合寻找最近邻居和碰撞检测.
KD-Tree 的核心思想是通过一系列与坐标轴平行的超平面，将 k 维空间递归地分割成更小的区域。每个区域对应于树的一个节点，存储该区域内的一个数据点。
KD-Tree 是一棵二叉树。

节点: 每个节点包含一个 k 维数据点、一个用于分割空间的维度 (split dimension) 和一个分割值 (split value)。
子节点 (Children): 节点的左子树包含该分割维度上值小于等于分割值的点，右子树包含值大于分割值的点。

构建 KD-Tree
构建 KD-Tree 是一个递归过程：

选择分割维度: 在当前节点的数据集中，选择一个维度用于分割。通常，这个维度是根据树的层级确定的，第0层从方差大的维度开始切分，然后循环选择其他维度；
选择分割值: 在选定的分割维度上，找到数据集的中位数作为分割值。将中位数点作为当前节点存储的点。
划分数据集: 根据分割值，将数据集中的点分成两部分：小于等于分割值的点构成左子集，大于分割值的点构成右子集。
递归构建子树：对左子集和右子集分别递归地构建左子树和右子树。

这个过程持续进行，直到数据集为空或只剩下一个点（作为叶子节点）。
复杂度: 构建一个平衡的 KD-Tree 的时间复杂度通常是 ,然而，在最坏情况下可能会退化。

范围搜索
查找落在指定多维区域（例如一个矩形或球体）内的所有数据点。

从根节点开始。
如果当前节点的分割超平面与查询区域相交，则需要同时搜索左右子树。
如果查询区域完全位于分割超平面的某一侧，则只需要搜索对应的一侧子树。
当到达叶子节点时，检查该点是否在查询区域内。
剪枝：如果在某个节点，发现以该节点分割值和维度确定的区域完全不在查询区域内，则可以剪掉整个子树。

最近邻搜索
输入：构造好的KDTree，目标样本;
输出：样本的最近邻；
过程：


从根节点开始，沿着查询点在每个分割维度上的值，从根结点出发，递归地向下访问𝑘𝑑树，维护当前最近邻点的样本值；

若目标点𝑥当前维的坐标小于切分点的坐 标，则移动到左子结点;
否则移动到右子 结点。直到子结点为叶结点为止。
将该叶子节点作为当前的最近邻点，并记录其距离。




回溯与剪枝 在递归返回的过程中，对于当前节点，检查是否有可能在另一个子树中找到更近的邻居。在回溯过程中，不断更新最近邻点和距离。


计算查询点到当前节点分割超平面的距离。


如果这个距离小于或等于当前找到的最近邻距离，则需要进入另一侧的子树进行搜索。



如果这个距离大于当前找到的最近邻距离，那么另一侧的子树中不可能存在更近的点，可以剪掉该子树，不需要进入搜索。





当回退到根结点时，搜索结束。


复杂度: 平均情况下，最近邻搜索的时间复杂度是。但在高维空间（k 很大）下，KD-Tree 的性能会急剧下降，搜索可能需要访问树的大部分节点，趋向于 (O(N));
特点

维度诅咒: 在高维空间下性能显著下降。对于高维数据，其他方法如 Ball Tree 或局部敏感哈希可能更有效。
树的平衡性: 随机插入和删除操作可能导致树失去平衡，影响搜索效率。虽然可以通过周期性地重建树来解决，但这会增加开销。
对数据分布敏感: 如果数据在某些维度上高度集中，树可能会变得不平衡。

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Data Structure</tag>
      </tags>
  </entry>
  <entry>
    <title>KNN</title>
    <url>/2025/07/02/KNN/</url>
    <content><![CDATA[KNN学习
idea
作为最简单的监督学习算法，可概括为"近朱者赤近墨者黑"。
作为典型的消极学习(lazy learning)，KNN在训练阶段仅仅是把样本保存起来，训练时间开销为零(没有显式的训练过程), 待收到测试样本后再进行处理；
KNN基于某种近邻索引方法找出训练样本集中与其最靠近的K个样本，然后进行结果预测；

对于分类问题使用“投票法”获得预测结果；
对于回归问题使用“平均法”获得预测结果。

1NN性能
当我们讨论1NN(最近邻分类器)在二分类问题的性能，结论是泛化错误率不超过贝叶斯最优分类器的错误率的两倍
时目标是找到最近邻的1个点，给定测试样本 ,最近邻训练样本为，标签集为,抽样的样本独立同分布

对任意测试样本，总能在任意近的范围的范围内找到一个训练样本
令表示Bayes最优分类器的结果,计算分类出错的概率


距离度量
根据距离函数计算待分类样本X和每个训练样本的距离（作为相似度），选择与待分类样本距离最小的K个样本作为X的K个最近邻，最后以X的K个最近邻中的大多数所属的类别作为X的类别。
流程


导入划分训练集和测试集

每条属性应该有若干属性和一个标签
由于KNN是懒惰学习，对于测试集的每一个样本，KNN通过样本的若干属性和训练集的样本的属性的距离



设置算法的K值，为超参数，需要人为设置，算法实现后可通过交叉验证的方式选取最好的


设置算法的距离指标


遍历所有的测试样本，对每一个样本进行预测



当前的样本为 sample，计算 sample与训练集中的样本(标签为 lb)的距离 d,
把所有距离-标签元组((d, lb))按照 d升序排序
投票：对前 K个元组，找到出现次数最多的标签，这个标签就是预测的结果(平局的情况：我们选择数据点中第一个出现的数据点的标签作为结果，这在python也是很好实现的。)



记录所有预测的标签，计算准确率


对所有的可能的​值，交叉验证


问题

K值设定：K值选择过小：得到的近邻数过少，会降低分类精度，同时会放大噪声的干扰，K值选择过大：k个近邻并不相似的数据亦被包含进来，造成噪声增加而导致分类效果的降低。
类别的判定方式：投票法没有考虑近邻的距离的远近，距离更近的近邻也许更应该决定最终的分类，所以加权投票法更恰当一些。
距离度量方式的选择：当变量越多（高维诅咒问题），欧式距离的区分能力越差。
性能问题 ：KNN是一种懒惰算法，构造模型很简单但在对测试样本分类地的系统开销大。

针对这些可能的问题，我们提出如下策略：采样训练样本量减少训练集的大小；或通过聚类，将聚类所产生的中心点作为新的训练样本。
特点


对值敏感：增大值，一般来说准确率先上升后下降


高维诅咒：在高维空间中近邻的点都变得差不多远，在高维情形下出现的数据样本稀疏


非参数化parameter-free：不对数据分布做出任何假设


简单，易于实现，内存消耗大，计算成本高，解释性差，预测慢


]]></content>
      <tags>
        <tag>Machine-Learning</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>LDA</title>
    <url>/2025/07/02/LDA/</url>
    <content><![CDATA[LDA技术
Idea
对于一类二分类问题，还可以采取线性判别分析(Liner Discriminant Analysis);
给定训练样例集，将样本投影到一条直线上，使得同类顶点尽可能接近，一类样本投影点尽可能远离；

同类点协方差尽可能小，异类中心距离尽可能大；

对新样本分类时，将其投影到该直线上，根据投影点的位置判定类别；因此LDA可以被视作监督降维技术；

二分类问题
对于二分类问题，假设两类样本的集合分别为  和 ，它们的均值向量分别为  和 。其协方差矩阵为;
在投影到  方向后，两类样本的均值分别为  和 ;投影后的协方差矩阵变为和;
定义类内散度矩阵

投影后样本的类内总散度为 。
定义类间散度矩阵

投影后两类样本的均值差的平方为

进一步定义全局散度矩阵为;
LDA的目标是最大化类间散度同时最小化类内散度，这可以表示为最大化以下目标函数 ：

这个目标函数就是广义瑞利商（Generalized Rayleigh Quotient）的形式。
转化为一个最优化问题，取分母为1，等价于

采用Lagrange乘子法，得到如下的广义特征值问题：

即最大化广义瑞利商的问题可以转化为求解一个广义特征值问题；
如果  是可逆的（通常情况下需要满足样本维度小于样本数量，并且各个特征之间不是完全线性相关的）

因此，最优的投影方向  对应于矩阵  的最大的非零特征值所对应的特征向量。对于二分类问题， 的秩最大为1，因此最多只有一个非零特征值。
对于不可逆的情况，考虑对作奇异值分解;
结果为

通常在计算时，为了数值稳定性，会先对数据进行白化处理。
对于不可逆的情况，考虑对作奇异值分解;
多分类问题
LDA可以自然地推广到多分类问题。假设有  个类别，类别  的样本集合为 ，均值向量为 。
LDA的目标是找到一个投影矩阵 ，将样本从原始  维空间投影到  维子空间中，使得投影后的样本具有最大的类间可分性和最小的类内方差。通常，投影后的维度  最大为 。
多分类类内散度矩阵：

这里， 是第  类样本的均值向量。
多分类类间散度矩阵：
假设总样本均值为 ，其中  是总样本数。第  类样本数为 。

多分类LDA的目标是找到一个投影矩阵 （其列向量是投影方向），使得投影后的类间散度尽可能大，类内散度尽可能小。这通常通过最大化以下目标函数来实现：

最大化这些目标函数等价于求解以下广义特征值问题：

最优的投影矩阵闭式解  由与最大的  个非零特征值  对应的特征向量  组成，即 
]]></content>
      <tags>
        <tag>Machine-Learning</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>Link</title>
    <url>/2025/07/02/Link/</url>
    <content><![CDATA[数据链路层
链路层要解决的问题是单段链路的数据传输，物理层解决的是数字信号与电气信号之间的相互转换。
在这一层中，我们把所有接入数据链路层的实体看作结点，包括主机，路由器，交换机和Wifi接入点；将相邻结点间的通信信道为链路；
数据通过给定链路时，传输结点需要将数据封装成帧(framing)，送入链路中，数据链路层提供的服务包括

成帧；
链路接入：介质访问控制(Medium Access Control, MAC)协议规定了帧在链路上传输的规则；
可靠交付：链路层上的可靠交付服务也是依靠确认和重传取得的；
差错检测和纠正：通常使用硬件实现；
流量控制：在邻接的发送节点和接收节点间的同步调节；
对半双工和全双工的实现：半双工是指一个结点不能同时同时传输和接收，全双工是指结点可以同时传输和接收；


注意：分组经过不同的链路可能采取不同的协议；每个链路协议提供不同的服务；链路层不一定要具有全部的这些功能服务。

适配器
一般链路层实在网络适配器(NIC)上实现的；不同的适配器对应不同的协议；部分链路层协议实在运行在软件上实现的，通常在软件和硬件交接的地方；

常见的适配器有Ethernet卡，PCMCIA卡， 802.11卡；


上图通信过程涉及链路层和物理层，其中

发送方封装分组成帧，增加检测位，可靠传输，流量控制；
接收方检测差错，可靠交付，流量控制，提取分组，并传给接收节点；

差错检测和纠错
差错检测和纠错的核心技术是冗余，通常会增加设计差错检测和纠错(error-detection and correction, EDC)比特；
接收方检测和纠错的能力称为前向纠错(forward error correction, FEC);常用于音频等设备；


注意，错误检测并非完全可靠；越大的EDC域能提供更大的纠错检错能力，但需要tradeoff；

一种比较简单的技术为奇偶校验(parity);

一维奇偶校验通过增加一位冗余，只有一半的概率检测到错误；
二维偶数奇偶校验能检测和纠正单个位的错误,检测任意组合的两个错误


另一种常见的技术为Internet校验和(checksum)，多见于传输层；
但是最广泛为基于循环冗余检测(cyclic redundancy check, CRC)的编码技术；

接收方和发送方协商一个生成多项式(generator)，长度为;
发送方在末尾添加冗余多项式,长度为;
每个CRC标准能够检测少于r+1位的突发错误和任意的奇数个比特错误；


这意味所有连续r比特或更少比特差错可以检测，长度大于r+1比特差错能以概率检测到；

的确定等价于


多路访问协议
网络链路分成两种具体类型

点对点链路(point-to-point link)：由链路一对发送方和接收方组成，包括点对点协议(point-to-point, PPP)，HDLC或者在以太网交换机和主机间的链路；
广播链路(broadcast link)：让多个发送和接收结点连接到相同的单一的共享的广播信道；比如传统以太网或者802.11局域网；

多路访问控制协议(multiple access protocol)提出了在共享广播信道中结点传输的规范；

当两个或多个结点同时传输时，我们认为信道发生了碰撞(collide);
某一时刻仅有一个结点发送数据才认为可以成功发送信息；
碰撞发生时，没有任何结点可以有效获得传输帧；

该协议内置一个分布式算法，决定各个节点如何共享信道；共享信道负责数据传输和算法的控制信息传输，理想的效果为：

当只有一个结点活跃时，活跃结点吞吐量为bps；
当存在个活跃节点时，每个结点吞吐量接近为bps;

有三类常见的实现方式

信道划分：把信道划分为小片；给节点分配专用的小片，
随机访问：不划分信道，允许冲突，能从冲突中恢复，对应一类随机访问协议；
轮流：通过集中调整共享访问避免冲突；是信号划分和随机访问的tradeoff；

信道划分协议
频分多路访问(frequency division multiple access, FDMA)

对应频分多路复用，信道被分成不同频段；
每个站点分配一个固定的频段，未被使用的频段空闲；

时分多路访问(time division multiple access, TDMA)

对应比如时分多路复用，轮流访问信道；
在每个循环中，每个站点得到一个固定长度的时隙，时隙长度通常为数据服务单元的发送时间，未被使用的时隙空闲

码分多路访问(Code Division Multiple Access, CDMA)

每个节点分配一个唯一的编码，每个节点用它唯一的编码来对它发送的数据进行编码；
允许多个节点“共存” ，信号可叠加，即可以同时传输数据而无冲突 ；

这些协议在即使在高负载情况下依旧能保证信道公平；但是在低负载下效率较低，后果是延迟访问，因为只存在一个活跃结点就只分配了的带宽；
随机访问协议
非时隙ALOHA是简单的协议，无需同步，帧一到达就立即传输；
假设在发送的帧和其他帧没有冲突，则概率为

这个概率过低了；
在时隙ALOHA中，假设所有帧大小相同，每个时间划分为传输一帧的时隙，每个结点必须在一个时隙开始才能传送，结点需要同步机制，每个结点知道从何时隙从何开始，也能检测到彼此的冲突；

当结点发送新帧时，需要等待下一个时隙传送；
若没有冲突，则可以在下一个时隙发送新帧；
若有冲突，则以概率重传该帧；


其优点为单个活跃结点可以持续满速率传送帧，且高度分散，只需要时隙的同步，简单；
其缺点为冲突可能浪费时隙，以及空间时隙什么也没做，只有在传输数据包时结点才能感受到冲突；
此方案的效率为

载波侦听多路访问(Carrier Sense Multiple Access, CSMA)是一类更礼让的协议
载波侦听(carrier sensing)指结点在传输前先听信道，若忙则延迟传送，若闲则传送整个帧；

仍然可能发生冲突，因为传播延迟导致两个结点没有侦听到其他节点的传送；

一类具有碰撞检测(collision detection)：当一个传输结点正在传输时同时侦听信道，若检测另一个结点正在传输干扰帧，则停止传输，随机等待一段时间；实现的协议是CSMA/CD;
等待的时间选择原则一般是二进制指数后退(binary exponential backoff)算法
这类协议在低负载情况下效率高，单个节点可以获得整个信道；但是高负载时，冲突开销大；
一般CSMA/CD协议用于以太网，而CSMA/CA协议用于无线网络；
轮流协议
轮流协议(taking-turns protocol)分为轮询协议(polling protocol)和令牌传递协议(token-passing protocol);

轮询协议要求指定主结点，主节点轮询其他结点，邀请它们从信道传输数据，虽然消除了碰撞和空时隙的问题，但是带来了轮询开销时延，而且一旦主结点失效，整个网络也失效了；
令牌传输协议设计了一个控制令牌，从一个结点传递到下一个结点，当且仅当当前令牌持有结点有帧发送时，才会持有令牌；同样也存在令牌开销，时延和令牌失效的风险；

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Computer-Network</tag>
      </tags>
  </entry>
  <entry>
    <title>Markov链</title>
    <url>/2025/07/05/Markov%E9%93%BE/</url>
    <content><![CDATA[Markov过程
对于为一随机过程，为其状态空间，若对参数集中的任意个时刻,任意的 有

即随机变量在已知 情况下，条件分布函数只与有关，则称随机过程为Markov过程.
这条性质也就是著名的Markov性，也就是无记忆性或无后效性；
若对于离散的状态集的随机过程也具有Markov性，那么就变成Markov链：
随机过程称为Markov链，若它只取有限或可列个值(若不另外说明，以非负整数集来表示),并且对任意的及 任 意 状 态  有

其中表示过程在时刻处于状态
转移概率（矩阵）
称Markov链中的条件概率为一步转移概率，简称转移概率，记为.它代表处于状态的过程下一步转移到状态的概率.
当Markov链的状态为有限时，称为有限链，否则称为无限链。但无论状态有限还是无限，我们都可以将排成一个矩阵的形式，令

称P为转移概率矩阵，简称转移矩阵.这显然是个随机矩阵，满足下面性质：

;
​

Mark
关于判定Markov链有一个小定理十分实用：
设随机过程 满足

, 其 中  ,且 取 值
在上。
为独立同分布随机变量，且与也相互独立；

则是Markov链，且一步转移概率为p_{ij}=P(f(i,\xi_1)=j)
Chapman-Kolmogorov方程，n步转移概率
称条件概率

为Markov链的步 转 移 概 率 , 相 应 地 称 为 步 转 移矩阵
为求n步转移概率，有如下C-K方程，表述如下：
对一切有






概率分布向量
记为时刻的 概 率 分 布 向 量 ,其中
称为Markov链的初始分布.
Property

 对任意的均成立。
一个Markov链的特性完全由一步转移矩阵P和初始分布向量决定；


吸收态，可达性和互通性，可约性
称状态 为 吸收态 , 如果 
若,则称状态为过渡态；
称状态可 达 状 态 ,若存在使得,记为.
若 同 时 有, 则 称 与互 通 , 记 为  ​;
任何两个互通的状态归为一类，若markov链只存在一类，那么称这是不可约的，否则是可约的；
Mark
互通是一种等价关系，满足自反性，对称性和传递性；
互通的状态形成等价类；
常返性
对于任何状态,以记从出发经步后首次到达的概率：

则为由出发，经有限步首次到达的概率。
定义平均回返时间


若,称为常返状态；

,则称​为正常返状态；
,则称为零常返状态；


若,则称为瞬过状态,

Property

若,则同为常返或非常返状态.因此常返性是一个类性质。.
若且为常返状态,则必为常返状态,且.

Mark
证明上述等价命题需要用到小引理：
对任意状态及1 有

周期性
若集合非空，则称该数集的最大公约数

为状态的周期 .
若,称为 周 期 的 ;
若,称为非周期的;
规定上述集合为空集时，称的周期为无穷大;
基本极限定理表述如下：
若状态是周期为的常返状态，则

当时，​
当是瞬过状态，,必有​;
若为瞬过(非常返)状态或零常返状态，则

Mark
若状态的周期为并不意味着​;
设为常返状态，则为零常返状态 ​;
设为常返状态,则​同为正常返状态或零常返状态.
遍历性
若为正常返状态，且是非周期的，则称为 遍 历 状 态.吸收态是遍历状态的一种特殊情况。
如果一个Markov链的所有状态都是遍历状态，则称其为遍历Markov链，简称遍历链。
Property


类性质：若状态属于同一类，则;


若Markov链为不可约，正常返，且非周期，则对任意有



有限状态的Markov链没有零常返状态；


有限状态的Markov链不可能全为瞬过状态；


不可约的有限Markov链状态都是正常返的；


若Markov链有一个零常返状态，那么必然有无限个零常返状态；


平稳分布，极限分布
一个定义在状态空间上的概率分布 称为Markov链的平稳分布，如有

即,有

若存在，,则称为Markov链的极限分布.
Property


对于不可约的遍历Markov链，极限分布存在：



对于不可约、非周期的Markov链，

若 它 是 遍 历 的 , 则 平 稳 分 布 为, ,并且是唯一的平稳分布；
若状态都是瞬过的或全为零常返的，则平稳分布不存在.



Mark
对于不可约的遍历Markov链，其极限分布等于平稳分布，而后者的求解只是一个线性齐次方程问题，因此这个定理给我们一个通过先求解平稳分布(极限分布)得到平均回返时间的一个办法.
连续时间的Markov链
随机过程的状态空间为离散空间，为方便书写设为 若对任意,以及任意的,有

则称为 连 续 时 间 Markov链 , 又 称 连 续 参 数Markov链.
我们默认我们讨论的Markov链是时齐的，也即 与无关。简记为称 ​​为相应的转移概率矩阵.
我们熟知的Poisson过程是连续时间Markov链.它的初始分布为.对,它的转移概率为

和离散版本的Markov链作对比不难得到如下性质：
Property

 是函数：




对于,在已知的条件下，“将来”与“过去”​独 立.





 有 C-K方程：



设时 刻 的 概 率 分 布 向 量 
则的概率分布为


连续时间Markov链的有限维分布由转移概率矩阵和初始分布完全决定：对,



对于,有



假定在时刻0过程刚刚到达 以记过程在离开之前在停留的时间，即在条件的条件下服从指数分布.


当时，它在状态停留的平均时间为0，即一旦进入马上离开，称这样的状态为瞬过状态.


当时，则称为 吸 收 态 , 即 一 旦 进 入 , 将 停 留 的 平 均时间为无限长。


当,称为 逗 留 态 , 这 时 过 程 停 留 在 状 态 ,若干时间后跳到别的状态，停留时间服从指数分布.




正则Markov链，转移速率(矩阵)
称一个连续时间Markov链是正则的，若以概率1在任意有限长的时间内转移的次数是有限的.从而可得连续性条件

以下我们总假定所考虑的Markov链都满足正则性条件.
定义状态转移速率：


对,极限q_i:=-q_{ii}=\lim_{t\to0}\frac{1-p_{ii}(t)}{t}\leq+\infty 存在，但可能是无限.
对,极限q_{ij}=\lim_{t\to0}\frac{p_{ij}(t)}{t}&lt;\infty 存在且有限.

设状态空间为,此时记

称为连续时间Markov链的Q-矩阵(转移速率矩阵).
当矩阵元素满足 时，称该矩阵为保守的.
类比Poisson过程，我们能得到如下性质：
Property
对于Markov链,. 用表示过程在状态的停留时间,则有:


.
当时,
在条件下,和独立.
当时,​.

Kolmogorov微分方程
对一切且为保守矩阵时，有

Kolmogorov向后方程：



Kolmogorov向前方程：


]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Random Process</tag>
      </tags>
  </entry>
  <entry>
    <title>Naive Bayes</title>
    <url>/2025/07/02/Naive-Bayes/</url>
    <content><![CDATA[Naive Bayes 分类器
贝叶斯分类算法是统计学的一种分类方法，它是一类利用概率统计知识进行分类的算法。在许多场合，朴素贝叶斯(Naïve Bayes，NB)分类算法可以与决策树和神经网络分类算法相媲美，该算法能运用到大型数据库中，而且方法简单、分类准确率高、速度快。
但由于对数据特征条件独立的强假设，所以如果数据集不符合这种假设，准确率可能会较低。
Bayes决策论
假设有种可能的类别标记，即
先验概率是根据以往经验和分析得到的概率，我们用来代表在没有训练 数据前假设拥有的初始概率;
后验概率是根据已经发生的事件来分析得到的概率。以代表假设成 立的情下观察到数据的概率，因为它反映了在看到训练数据后成立的置信度;
是将一个真实标记为的样本误分类为所产生的损失.
基于后验概率可获得将样本分类为所产生的期望损失;
即在样本上的"条件风险"(conditional risk)

我们的任务是寻找一个判定准则以最小化总体风险

对每个样本,若能最小化条件风险,则总体风险也将被最小化.

若目标是最小化分类器错误率，则误判损失表示为\left.\lambda_{ij}=\left{\begin{array}{ll}0,&amp;\mathrm{if~}i=j:;\1,&amp;\mathrm{otherwise},\end{array}\right.\right.
此时条件风险  ,
于是，最小化分类错误率的贝叶斯最优分类器为

即对每个样本,选择能使后验概率最大的类别标记(hard assignment)，这就是最小错误概率分类准则等价于最大后验概率分类准则；
属性条件独立假设
假设有维属性数目，

由极大似然估计可知，贝叶斯判定准则如下：

拉普拉斯修正
为了避免其他属性携带的信息被训练集中未出现的属性值"抹去"，
在估计概率值时通常要进行"平滑"(smoothing)
避免了因训练集样本不充分而导致概率估值为零的问题,
并且在训练集变大时，修正过程所引入的先验(prior)的影响也会逐渐变得可忽
略，使得估值渐趋向于实际概率值.
极大似然估计
Idea
贝叶斯学派认为参数是未观察 到的随机变量,其本身也可有分布,因此,可假定参数服从一个先验分布,然后 基于观测到的数据来计算参数的后验分布;
MLE 认为，我们已经观测到的数据是最可能出现的数据。因此，我们应该选择那些参数值，使得这些观测数据出现的概率（或概率密度）达到最大。
似然函数估计
对于给定的参数  和一组独立同分布观测数据 ，这些数据联合出现的概率是各个数据点概率的乘积：

我们将这个概率视为关于参数  的函数，称为**似然函数 **(Likelihood Function)

注意，这与概率密度函数不同，概率密度函数是将  作为变量， 作为常数；而似然函数是将  作为变量， 作为已知的观测数据。
为了简化计算，通常改写对数似然函数(Log-Likelihood Function)：

由于对数函数是单调递增的，最大化  与最大化  是等价的。
MLE 的目标就是找到使似然函数  达到最大值的参数 。即：

令偏导数等于零，解这个方程组以找到参数  的估计值。如果解析解难以获得，可以使用数值优化方法（如梯度下降）来最大化 。
EM算法
在无监督学习或者半监督学习中，数据没有标签，可以认为它们是未观测的隐变量(latent variable);
令为已观测的变量集，表示隐变量集，为模型参数，改用对作极大边际似然(marginal likelihood)估计

流程
EM 算法是一个两步迭代过程，直到参数收敛：
E 步 (Expectation Step):

模型参数是已知的,根据训练数据推断出最优隐变量的值。
利用当前的参数，计算每个数据点属于每个隐变量状态（或簇）的后验概率或称为"责任"。
本质上基于推断

M 步 (Maximization Step):

假设在 E 步计算出的隐变量的后验概率是已知的，基于这些后验概率（即隐变量的软分配），重新估计模型参数；
以最大化观测数据的完全数据对数似然的期望（这里的期望是在 E 步计算出的隐变量后验分布下计算的）。
基于和，对作MLE；

朴素贝叶斯分类器
朴素贝叶斯分类器(Naive Bayes Classifier)是一种基于贝叶斯定理和特征条件独立性假设的概率分类算法。它是一种简单但非常有效的分类方法，在许多实际应用中表现良好。
核心原理
朴素贝叶斯分类器基于贝叶斯决策论中的最大后验概率 (MAP) 原则。给定一个样本 ，我们希望预测它属于哪个类别  的概率最大，即找到：

根据贝叶斯定理，后验概率  可以写成：

先验概率已知，引入属性条件独立假设，只需最大化分子即可：

假设是训练集中第c类样本组成的集合，取值为的样本集合为可根据独立同分布样本估计

对于连续属性可假设为正态分布；
为了避免在估计条件概率时出现概率为零的情况（例如，某个特征值在训练集中某个类别下从未出现过），通常采用拉普拉斯修正进行"平滑"。这会在分子和分母中都加上一个小的常数（通常是 1），避免了概率估计为零对整个乘积造成影响。
参数估计
模型中的参数  和  需要从训练数据中估计。通常使用MLE来进行估计：

类别先验概率  估计为训练集中属于类别  的样本占总样本数的比例。
条件概率  估计为在属于类别  的样本中，特征  取值为  的样本占该类别样本总数的比例。

优点

简单高效： 算法逻辑简单，易于实现，计算速度快。
对小规模数据和高维数据有效： 在训练数据量不是非常大时也能表现良好。
对缺失数据不敏感，鲁棒性强： 可以相对容易地处理缺失数据（例如，在计算概率时忽略缺失的特征）。

缺点

特征条件独立性假设在实际中往往不成立，这可能会降低分类性能。当特征之间存在强相关性时，朴素贝叶斯的性能可能会受到影响，尤其在图像或语音等任务中精度不佳。
对连续型特征的处理需要进行离散化或假设特定的概率分布（如高斯分布）。
无法捕捉特征之间的交互作用： 不能建模特征之间的协同效应。
概率估计不总是可靠： 尤其是当某些组合在训练集中未出现时（可用拉普拉斯平滑缓解）

Bayesian Network
Idea
贝叶斯网(Bayesian Network)是一种概率图模型，它通过 (DAG)来描述一组随机变量之间的条件依赖关系。

图中的节点表示随机变量。
图中的有向边表示变量之间的直接依赖关系。如果从变量 A 指向变量 B 有一条边 ()，则表示在知道 A 的值后，B 的概率分布可能会发生变化，即 B 直接依赖于 A。

注意： 边表示因果或影响关系，但不一定是严格的因果关系。


在同父结构中,给定父结点的取值,则 X3 与 X4  条件独立.
在顺序结构中,给定 z 的值,则 u 与 z 条件独立 .
v 型结构,给定子结点 X4 的取值, Xl 与 X2 必不独立; 若X4的取值完全未知,则 V 型结构下 Xl 与 X2 却是相互独立的.(边际独立性)

条件概率分布
每个节点  都有一个与之关联的 CPD，它描述了在给定其所有父节点状态下的概率分布(Conditional Probability Distributions, CPDs)。

如果一个节点没有父节点，它只有一个先验概率分布。
对于节点  及其父节点集合 ，其 CPD 表示为 

贝叶斯网的关键在于，图的结构和 CPDs 可以用来唯一地确定所有变量的联合概率分布。对于贝叶斯网中的一组变量 ，它们的联合概率分布可以分解为每个变量在其父节点条件下的概率的乘积：

这个公式是根据**图的结构（独立性假设）**得出的。具体来说，每个变量在其父节点已知的情况下，条件独立于其非后代节点。
朴素贝叶斯是具有特定图结构（中心一个类别节点指向所有特征节点）和特定独立性假设（特征之间在类别条件下相互独立）的贝叶斯网。
推断与学习
贝叶斯网的主要任务包括：
推断 (Inference): 在已知部分变量的观测值（证据）下，计算其他未知变量的后验概率。
学习 (Learning):

结构学习 (Structure Learning): 从数据中学习变量之间的依赖关系，即学习图的结构。
参数学习 (Parameter Learning): 在图结构已知的情况下，从数据中估计每个节点的 CPDs。

]]></content>
      <tags>
        <tag>Machine-Learning</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>Network Flows</title>
    <url>/2025/07/05/Network-Flows/</url>
    <content><![CDATA[Matching
图中的极大匹配(maximal matching)是指不能添加更多的边的匹配；最大匹配(maximum matching)是指图中拥有最多边数的匹配；

显然每个最大匹配都是极大的，反之未必；

给定匹配，一个-交替路径是指一个交替选择中的边和不在中的边的路径；一个-增广路径是指其两个端点不被浸润的-交替路径；

给定-增广路径，我们可以替换中的边形成多一条的边的新的匹配;

对于定义在顶点集上的图,其对称差(symmetric difference)定义为顶点集为，边集中的边只属于和其中之一的图,通常具有异或(exclusive-or)性质；
对于两个匹配，;
对于二部图，一个完美匹配是指一个从到的一对一的对应关系使得每个具有对应关系的顶点都相邻；
结婚条件(Marriage condition)形象来说一组个女孩d至少总共认识个男孩；
Lemma
两个匹配的对称差的每个分量是偶圈或者路径；
proof：注意到;
Theorem(Berge)
图中的匹配是最大匹配当且仅当中没有增广路径；
proof: 充分性显然，下证必要性，若没有增广路径也不是最大匹配，取中的最大匹配，令，只包含偶圈和路径，注意到，必须包含一个分量是路径，其两个端点属于的边，这个路径就是的增广路径，矛盾；
Theorem(Hall)
对于二部图，存在到的完美匹配的充分必要条件是对任意子集，均有;
proof:这说明结婚条件是充分必要的；必要性显然，下证充分性
取中的最大匹配,没有浸润,我们说明存在子集使得;
取且未被浸润,取通过交替路径到达的所有点中在的部分为,在中的部分为,注意有;



断言:匹配和
每个在的顶点都可以通过中的一条边到达中顶点；没有增广路径因此中顶点都是浸润的，因此一个到达顶点的交替路径也通过的边到达，因此有


由于，于是必有，故



由此证明了充分性；
也可以用归纳法证明；也可以使用Menger定理证明；
Corollary
对于-正则的二部图有完美匹配；
proof:统计边数验证满足结婚条件；
Theorem(Konig)
二部图中最大匹配数等于最小点覆盖数；
proof:相互构造

Flow
称两条从到的路径是边不相交的(edge-disjoint)，如果它们没有公共边；
称两条从到的路径是点不相交的(vertex-disjoint)，如果它们没有公共点；
考虑图中不相邻的两个顶点，断集(vw-disconnected set)指图中的一个边集，每条从到的路径包括中的一条边；分离集(vw-seperated set)指图中的一个点集，每条从到的路径包括中的一条点;
一个网络(network)是一个带权有向图，每一条箭头分配一个容量；
一个流(flow)为每个箭头分配一个流量；
对于顶点，定义流出量为离开的箭头总流量，流进量为进入的箭头总流量；
称一个流是可行(feasible)，如果满足

流量约束：对于每个箭头，；
守恒约束：对于每个顶点，;

零流显然是可行，定义流的净流量/值为在汇点处

一个最大流是一个拥有最大净流量的可行流；
对于网络中的流，一个增广路径(f-augmenting path)是一个从源点到汇点的路径，在底图中的边满足如下性质：

若在上同向，则,定义;
若在上反向，则,定义;

称路径的容忍度(tolerance)为

一个增广路径对应一个大值流，这样的定义确保了容忍度为正；
一个s/t割(source/sink cut)由点集出发的到点集的箭头组成，构成点集的划分；
源/汇割的容量,是这些箭头的总容量；
一个最小割是指拥有最小总容量的割；

Theorem(Menger)
连通图中相异顶点之间的边不相交路径最大条数等于不连通集的最少边数；
proof:显然后者不超过前者，只需证明前者不超过后者即可；
对边数归纳，考虑非平凡情况，假设图中最小的不连通集的边满足

不是所有的边和相关联
不是所有的边和相关联

有两个分别包括顶点的不相交的子图;
定义为收缩中的每一条边形成的图，为类似收缩的每一条边形成的；由归纳假设，给出个边不相交的路径，所求的个边不相交路径显然就是给出的路径的并；
对于平凡情况，可以假设中每条边都在中，否则可以删去它使用归纳假设，考虑间的最短路，包括至多一条边在中；对采用归纳假设，至少有条边不相交路径，算上即可；
Theorem(Menger)
连通图中相异顶点之间的点不相交路径最大条数等于分离集的最少点数；
Corollary
对于图是-连通的当且仅当任意相异顶点之间有至少条边不相交的路径；
对于至少有个顶点的图，是-连通的当且仅当任意相异顶点间至少有个点不相交的路径；
值得一提的是，Menger定理对有向图也成立，因此一般表述成连通图中最大流等于最小割；手动添加两个顶点也可证明Hall定理；
Lemma
令是增广路径，具有容忍度，通过以下方式改变流

:在与同向的箭头上
:在与反向的箭头上

形成的新可行流，其值
Theorem(Max-flow Min-cut)
在任意网络中，最大流的值等于最小割的容量；
proof:容量为整数情形时可以看作Menger定理视作有向图中连接对应容量个箭头；
只需要找到一个流值等于一个割流量即可；
取为最大流，如下定义点集划分：点当且仅当存在路径使得或
由引理,源点,汇点;显然对每个,有,对于每个，我们有，否则应该属于;
因此有

是所求的最小割；
Algorithm(Ford-Fulkerson)

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Graph-Theory</tag>
      </tags>
  </entry>
  <entry>
    <title>Network</title>
    <url>/2025/07/02/Network/</url>
    <content><![CDATA[Network
设计
路由器的工作在分组从发送方主机传送到接收方主机 的过程的中间：

发送方将数据段封装成分组
接收方将分组解封装后将数据段递交给传输层
网络层协议存在于每台主机和路由器上，路由器检查所有经过它的IP分组的分组头


分层
网络层(network layer)通常被划分为两层：数据平面(data plane)和控制平面(control plane);这也是网络层的功能；

转发(forwarding)：数据平面从输入链路向输出链路转发数据报(datagrame)；时间通常很短；
路由选择(routing)：控制平面主要和网络范围相关，协调本地路由器的转发操作，通常需要设计选路算法，以确定分组从源端到目的端的路径范围处理过程；

路由器会维护一个转发表(forwarding table)，检查分组首部，索引转发表，找到对应的输出链路接口；

SDN
软件定义网络(software-defined networking, SDN)将控制平面的功能作为单独的服务；
传统的路由器通过人工操作的静态配置的办法，这样不需要任何路由选择协议，但是不是自动化的，对于网络拓扑结构的改变响应更慢；
控制平面的功能往往位于一台远程的控制器中，可能由ISP管理，路由器通过交换包含转发表等信息的报文与控制器通信，这样的网络是软件定义的；

服务
网络服务模型(network service model)定义了分组在发送和接收主机间的端到端传输特性，如确保交付，确保时延上界，有序分组，最小带宽，安全加密；
这样网络层的服务称作尽力而为服务(best-effort service)，网络层尽力完成这些服务特性，但是不给予任何保证；



特性
尽力而为服务




分组交付
不保证所传送的分组不丢失，当网络发生拥塞时网络中的结点可根据情况将一些分组丢弃


分组顺序
不保证按源主机发送分组的先后顺序


交付时限
不保证在时限内必须将分组交付给目的主机




换句话说，就是没有服务！但是通过传输层的设计，网络层的尽力而为的服务模型和适量带宽的供给被认为足够的好；




网络体系结构
服务模型
传输质量-带宽保证
传输质量-无丢包保证
传输质量-排序
传输质量-定时
拥塞指示




Internet
尽力而为
无
无
任何可能顺序
不维持
无


ATM
恒定比特率CBR
恒定速率
是
有序
维持
无拥塞


ATM
可用比特率ABR
保证最小速率
无
有序
不维持
提供拥塞指示



Data Plane
不同类型的网络具有不同类型的设计，区别如下表所示，这两种设计哲学分别对应了数据报网络和虚电路网络：



特性
Internet (数据报网络)
ATM (虚电路网络)




核心设计理念
数据在计算机中进行交换
由电话系统演变而来 (人类会话)


服务类型
弹性服务，没有严格的时间限制
严格的时间和可靠性要求，需要有保障的服务


终端系统
智能终端系统，具有适应性，性能控制，错误恢复
哑终端系统 (电话)


网络内部复杂性
网络内部简单，边缘复杂
网络内部复杂


链路类型
多种链路类型（卫星，以太网光纤，无线等），具有不同特性
-


统一服务
统一服务困难
-



网络层在数据平面上提供了两种基本的服务模型：数据报服务和虚电路服务。
虚电路
网络层为上层的主机提供的服务分类为

数据报服务：无连接的网络服务，网络随时接受主机发送的数据报，网络为每个分组独立地选择路由 ；
虚电路服务：面向连接的网络服务，源主机先向目的主机发出一个特定格式的控制信息分组，要求进行通信，同时寻找一条合适路由。若目的主机同意通信就发回响应，然后双方就建立了虚电路。

虚电路服务对通信的服务质量(Quality of Service)有较好的保证。 性能可靠，网络行为沿网络路径发生

数据传输前建立虚电路，传输完毕后拆除虚电路
每个分组携带 VC 标识(并非目的地址)
在源-目的路径上每个路由器要维护每个连结的状态信息
链路、路由器资源（带宽、缓冲区）可能分配给VC

一个虚电路VC的组成如下：

源和目的主机间的路径
VC号,沿着该路径中的每段链路一个号码
沿着该路径的每台路由器中的转发表项

VC号的更新：每台中间路由器用一个新的VC号取代原来的VC号.
新的VC 号从转发表中获得；
与传输层服务有相似之处，但也有很大不同：



特性
网络层
传输层




服务
主机到主机
端到端


服务选择
在同一时间仅提供数据报服务或虚电路服务中的一种
提供TCP和UDP


实现
在端系统及网络核心实现
在端系统中实现



路由器由转发表来维护连接状态信息；

信令协议
信令协议用来建立，维护和拆除虚电路，在ATM，帧中继(frame-relay),X.25等中有应用；

数据报网络
数据报网络不同于虚电路网络，在网络层没有呼叫建立；

路由器端到端的连接没有状态信息维护；
分组使用目的主机地址转发，同一源-目的主机对间的分组可能走不同的路径；

转发表维护如下：

路由器原理
回忆路由器的基本功能：路由选择和转发；在数据平面上设计的结构如下图，主要在硬件上实现转发功能；

输入端口(input port)：执行物理层的功能，和数据链路层的交互；
输出端口(output port)：将输入端口连接到输出端口的内部网络；
交换结构(switching fabric)：存储交换结构存储的分组


位于控制层面的路由选择处理器负责执行路由选择算法；
输入端口的内部执行分散式转发：根据分组中的目的地址, 在输入端口的缓存中查找转发表得出适当的输出端口；

交换结构可能具有如下类型的三种结构；

基于内存交换：较传统的方式为CPU控制交换完成，分布被拷贝到系统内存，速度受到内存带宽限制，因为分组需要经过两次总线；
基于总线交换：分组从输入端口缓存经过一根共享总线到达输出端口缓存，交换速率受总线带宽限制，但是对于接入和企业路由器来说速度足够了 ；
基于互联网格交换：克服总线带宽限制，一个纵横式交换机就是一个由2n条总线组成的互联网络,n个输入端口与n个输出端口连接，比较高级的设计为IP数据报分割成固定长度信元, 通过互连网络来交换信元.


输出端口在网络层执行的是缓存分组，当分组从交换结构到达的速率快于输出链路速率时,需要缓存；而调度的原则都是在等待传输的排队分组中进行选择；

queuing
输入端口排队：当交换速度比所有输入端口的综合速度慢；
输出端口排队：当分组从交换结构到达的速率快于输出链路速率时,需要缓存；

用通过入口进入匝道和从出口离开匝道类比路由器结构，堵车类比于路由器中的排队；

排队带来的直接影响就是延迟，甚至当排队队列缓冲区溢出，可能造成分组丢失；
线头阻塞(head-of-the line blocking, HOL blocking)是指，排在队列前面的分组阻止队列中其他的分组向前移动；

这里就是上面红色分组排队导致下面绿色分组等待；


当没有足够的缓存输入分组时，需要采取丢包的策略，有时需要向发送方告知拥塞（拥塞告知比特）对分组标记；这些策略统称为主动队列管理(active queue management, AQM)；包括RED，PIE，CoDel等；
当我们考虑缓存大小的问题时，我们需要trade-off，因为大缓存可以缓解丢包问题，但是可能加剧时延问题，即缓存膨胀(bufferbloat)；
还有一些排队规则问题，可以类比OS，比如FIFO，优先权，循环和加权公平下的保持工作排队，加权公平排队(WFQ)等等；以确保网络的中立性；

网际协议
数据报格式
IPv4数据报格式的关键字段如下：

版本：4比特。标识IP协议的版本，对于IPv4始终是4。用于确保不同IP版本设备间的兼容性。
首部长度：4比特。指示IP头部的长度，以32比特字（4字节）为单位。最小值为5（20字节），最大值为15（60字节），因为可选字段的存在导致头部长度可变。
区分服务：6比特。原为服务类型字段，用于指定差异化服务，例如实时数据流的优先级。
显式拥塞通知：2比特。允许端到端地通知网络拥塞，而无需丢弃数据包。当两端都支持且网络支持时有效。
总长度：16比特。定义整个IP数据包的长度（字节），包括头部和数据。最小20字节，最大65535字节。用于确定数据包的实际大小和数据负载的起始位置。
标识：16比特。当一个IP数据报被分片时，所有分片都带有相同的标识号，接收方用它来识别属于同一个原始数据报的分片，以便重组。
标志：3比特。包含三个标志：

保留位：1比特，必须为0。
不分片：1比特。如果设置为1，路由器将不会分片数据报。如果数据报太大而无法通过，则会被丢弃并向发送方发送错误信息。
更多分片：1比特。如果设置为1，表示后面还有更多分片。最后一个分片的MF位为0。


片偏移：13比特。指示当前分片在原始未分片IP数据报数据部分的相对位置。以8字节块为单位。第一个分片的偏移量为0。
生存时间：8比特。限制数据报在网络中传输的最大跳数（路由器数量）。每经过一个路由器，TTL值减1。当TTL达到0时，数据报被丢弃，并通常会向发送方发送ICMP超时消息，防止路由循环。
协议：8比特。标识IP数据报数据部分封装的上层协议类型（例如，6表示TCP，17表示UDP，1表示ICMP）。接收方根据此字段将数据递交给正确的上层协议。
首部校验和：16比特。用于检测IP头部在传输过程中是否损坏。只对IP头部进行校验。每经过一个路由器，TTL变化后需要重新计算校验和。
源IP地址：32比特。发送方的IPv4地址。
目的IP地址：32比特。接收方的IPv4地址。
选项：0-320比特，可变长度，并用0填充至32比特的倍数。不常用，包含如源路由、记录路由等信息。包含选项的数据包可能会被某些路由器视为危险并阻止。


IPv4 &amp; IPv6
每台主机和路由器都能发送数据报，因此IP要求每台主机和路由器接口都应该有一个IP地址；
接口是主机/路由器与物理链路之间的边界；从技术上来说，一个IP地址和一个接口相关联，在全球互联网中，IP应该是唯一的；
对于IPv4地址来说，具有如下特性

每个IP地址长度为32比特，等价于4字节；
按照点分十进制记法，每个字节按照十进制书写；
子网由一个路由器接口和下面连接的主机接口构成；
子网被分配一个掩码(mask)，指示IP左侧多少比特定义了子网的址；任何连到该子网的主机必须具有相同的掩码；因此子网代表这个网络的最高公共前缀；
一个最佳实践是一个组织内部的IP地址共享前缀，因为这可以减少路由器中转发表的长度；


两种推荐方法使得 IPv4 和 IPv6 路由器的网络工作
双栈的设计是，一些路由器具有双重栈 (v6, v4) 能够在两种格式中转换双栈节点具有三种工作模式：

只运行IPv6协议，表现为IPv6节点；
只运行IPv4协议，表现为IPv4节点；
双栈模式，同时打开IPv6和IPv4协议。

隧道的设计是分组在穿过IPv4路由器时，IPv6分组作为 IPv4分组的负载

CIDR
无类别域际路由选择(Classless InterDomain Routing, CIDR) 是IP地址分配和路由选择的一种方法，这是一种分类编制的技术，旨在更有效地利用IP地址并减缓IPv4地址耗尽的速度，同时降低路由表的增长速度。

CIDR放弃了传统的A、B、C类网络划分概念，允许在IP地址的任意比特边界上进行地址分配和路由。
IP地址被分为两部分：最高有效位组成的网络前缀（标识网络或子网）和最低有效位组成的主机标识符（指定网络中特定主机的接口）。

CIDR表示法：采用"斜线记法" (a.b.c.d/n)，其中 a.b.c.d 是IP地址，n 表示网络前缀的位数（从左到右连续的1比特数）。
子网掩码 (255.255.255.0) 编码了与IPv4地址或网络关联的前缀长度，与CIDR记法功能相同，但在CIDR中，前缀位始终是连续的。
这样做的好处是可以实现层次寻址和路由聚合,即超网，提高了IP地址的有效利用率，也就缓解了IPv4消耗过快的问题；
DHCP
一个组织获得了地址分配后，它可以为本组织内所有主机和路由器分配IP地址；也可以采取静态分配的办法，但是主流是动态主机配置协议(dynamic host configuration protocol, DHCP)；
主机每次和网络连接时，都会被分配一个临时的IP地址，每次连接该网络时可能是不同的；
网络连接时，通常是连接WIFI时，主机会获得以下信息

临时IP地址
子网掩码
默认网关：指第一跳路由器地址
本地DNS服务器地址
IP地址租用期

这是一类即插即用的协议或者零配置协议；也是一类客户-服务器协议，网络中新到达的主机向服务器请求以上信息，每个子网都具有一台DHCP服务器或者一个DHCP代理（通常是路由器）；
sequenceDiagram    客户端-&gt;&gt;DHCP服务器: DHCP Discover（广播）    DHCP服务器-&gt;&gt;客户端: DHCP Offer（单播）    客户端-&gt;&gt;DHCP服务器: DHCP Request（广播）    DHCP服务器-&gt;&gt;客户端: DHCP Ack（单播）
用户从Discover报文开始，到ACK报文结束，便完成了一次交互；



报文类型
方向
作用




DHCP Discover
客户端→服务器
寻找可用DHCP服务器


DHCP Offer
服务器→客户端
提供IP配置提案


DHCP Request
客户端→服务器
确认接受配置


DHCP Ack/Nak
服务器→客户端
最终确认/拒绝分配



NAT
网络地址转换(Network Address Translation, NAT)是一种在IP数据报头部中修改网络地址信息的技术，允许一个私有IP网络连接到互联网。

通过将多个内部私有IP地址映射到一个或少量公共IP地址，实现IP地址的复用，缓解IPv4地址耗尽问题；
此外，NAT也提供了安全功能，通过隐藏内部网络的拓扑结构和IP地址，增加了一层对外网络的匿名性。
NAT还为网络构建带来了灵活性，当更换ISP时无需更换内部网络映射；

工作原理：

NAT通常运行在连接内部私有网络和外部公共互联网的路由器或防火墙上。
当内部主机发送数据包到外部网络时，NAT设备会将数据包的源IP地址和源端口号、转换为一个公共IP地址和新的端口号。
NAT设备维护一个转换表（NAT table），记录私有地址与公共地址之间的映射关系。
当外部网络的数据包返回时，NAT设备根据转换表将目的公共IP地址和端口号转换回内部私有IP地址和原始端口号，然后转发给相应的内部主机。


RFC 1918中规定了以下私有IP地址范围，这些地址在公共互联网上是不可路由的：

10.0.0.0 到 10.255.255.255 (A类私有网络)
172.16.0.0 到 172.31.255.255 (B类私有网络)
192.168.0.0 到 192.168.255.255 (C类私有网络)

NAT类型：

静态NAT (Static NAT)：将一个私有IP地址一对一地永久映射到一个公共IP地址。常用于需要从外部网络访问的内部服务器；
动态NAT (Dynamic NAT)：从一个公共IP地址池中动态地选择一个未使用的公共IP地址，将其映射到内部私有IP地址。映射关系在会话结束后释放。
端口地址转换 (Port Address Translation, PAT)，也称为NAT过载 (NAT Overload)：允许多个内部私有IP地址共享一个公共IP地址。通过为每个连接分配不同的端口号来区分不同的内部主机。这是最常用的NAT类型，因为它极大地节省了公共IP地址。

但是这是一项有争议的技术

引入延迟：数据包在NAT设备进行地址转换会增加传输延迟。
破坏端到端连接性：NAT使得外部主机难以主动发起与内部主机的连接，这给P2P应用、VPN协议等带来挑战。
应用层协议问题：某些应用层协议（如FTP、SIP）在数据载荷中嵌入IP地址信息，NAT设备可能需要应用层网关（ALG）来检查和修改这些载荷，增加了复杂性。
跟踪和调试困难：由于地址被转换，网络管理员在故障排除和流量监控时可能会遇到困难。

ICMP
因特网控制报文协议(Internet Control Message Protocol, ICMP) 主要用于IP网络上发送控制消息和错误报告。

它作为IP协议的辅助协议，弥补了IP协议无连接、不可靠的特性，但并不使IP本身变得可靠。
当数据包在网络传输过程中遇到问题（如目标不可达、传输时间超时、参数问题等）时，路由器或目标主机通过ICMP消息向源主机报告。

工作流程如下：

源端发送一系列的IP分组给目的端，当第n个分组到达第n个路由器时路由器丢弃该分组并给源端发送一个ICMP报文(type 11, code 0)这个报文包含了路由器的名称和IP地址;
当源端收到ICMP报文时，计算传输往返时间RTT，对每个TTL作三次，作为停止发送的根据；
IP报文最终到达目的端，目的端返回回应应答的 ICMP 报文 (type 0, code 0)，源端收到此报文，停止发送；

Control Plane
控制平面主要和路由器的选路算法有关；选路算法的任务是发现端到端的最小路径；
从算法考察网络信息来看，可分类为

集中式路由选择(centralized routing)算法：拥有全局完整的网络信息计算端到端的最短路径；又被称为链路状态(link state)算法;
分散式路由选择(decentralized routing)算法：路由器以迭代的分布式的方式计算出最短路径，每个结点仅有直连链路（邻居）的结点信息，典型的算法为距离矢量(distance vector)算法;

从算法的变化性来看

静态路由选择算法：路由随时间变化缓慢，通常人为调整；
动态路由选择算法：随着网络流量的负载或者拓扑结构发生变化而改变路由选择；通常周期性更新且直接响应链路开销；

从拥塞水平来看

负载敏感(load-sensitive)算法：链路开销动态变化，以反映链路的拥塞水平，分组倾向于绕开该拥塞链路，比如ARPAnet算法；
负载迟钝(load-insensitive)算法：链路开销不变化，大多数算法都是此类，比如RIP，OSPF，BGP；

LS算法
Dijkstra算法是一种著名的单源最短路径算法，用于在具有非负边权的图中查找从一个源节点到所有其他节点的最短路径。
核心思想：采用贪心策略。算法维护一个已确定最短路径的顶点集合 S 和一个存储从源点到未访问顶点当前最短距离的优先队列。每次从优先队列中选择距离源点最近的未访问顶点，并将其加入 S，然后更新其邻居的距离。

Dijkstra算法不能处理含有负权边的图。因为其贪心选择的特性，一旦一个节点的距离被确定，就不会再改变，而负权边可能会导致已确定的最短路径并非真正的最短路径。

工作原理：

初始化：将源节点的距离设为0，其他所有节点的距离设为无穷大。创建一个优先队列，包含所有顶点及其当前距离。
迭代：在每一步中，从优先队列中取出当前距离最小的未访问顶点 u。
标记：将 u 标记为已访问。一旦一个顶点被标记为已访问，其最短路径距离就被确定。
松弛：对于 u 的每个邻居 v，如果通过 u 到 v 的路径（即 dist[u] + weight(u, v)）比当前 v 的距离 dist[v] 更短，则更新 dist[v]，并在优先队列中更新 v 的优先级。
重复：重复步骤2-4，直到所有顶点都被访问或优先队列为空。

时间复杂度：
使用邻接表和二叉堆实现时，时间复杂度为 或，对于稀疏图效率更高；对于稠密图，的实现可能更优。
Internet中的OSPF协议，采用链路状态广播(link state broadcast)的方式，使得所有结点都就有网络的视图；
在真实的网络环境中，假设链路开销是链路上的流量之类非对称量，每次LS算法运行，可能产生震荡；这是一种自同步现象，可以通过每台路由器引入随机链路通告时间解决；
DV算法
距离矢量算法(Distance Vector Algorithm, DV) 是一种迭代的、异步的、分布式的路由选择算法。每个路由器维护一张距离矢量表，其中包含它到网络中所有其他目的地的"距离"估计值。这些估计值会周期性地与邻居路由器交换。

迭代性：算法通过重复计算和信息交换逐步收敛到最终的最短路径。
异步性：路由器之间不需要同步计算或消息交换，它们可以独立地执行计算并发送更新。
分布式：每个路由器仅与直接相连的邻居交换信息，并基于这些信息以及自身的链路开销进行计算，不需要拥有整个网络的全局拓扑信息。

Bellman-Ford方程：DV算法的核心是Bellman-Ford方程（也称为Bellman-Ford原理），用于计算从节点 x 到节点 y 的最低开销路径的开销值：

这个方程决定了路由表的表项，选择能够提供最小开销的邻居 v* 作为下一跳：

工作原理：

初始化：每个路由器知道到达其直接相连邻居的链路开销。对于所有其他目的地址，距离被初始化为无穷大。
信息交换：每个路由器周期性地将其完整的距离矢量发送给所有直接相连的邻居。
更新：当路由器 x 收到来自邻居 v 的距离矢量时，它使用Bellman-Ford方程更新自己到每个目的地的距离估计。如果通过邻居 v 到某个目的地的路径开销更小，则更新该目的地的距离和下一跳。
收敛：这个过程持续进行，直到网络中的所有路由表都收敛，即所有路由器都找到了到所有目的地的最短路径，并且不再有距离矢量更新发生。


当链路的开销变化，结点探测到后，将更新路由信息，重新计算距离向量，若其DV发生变化，则通知邻居；

好消息传得快，但是坏消息传得慢，存在计数无穷大问题：当某个目的地变得不可达时，路由器之间可能互相"学习"到错误的、逐渐增大的距离，直到达到最大跳数（无穷大），这个过程非常缓慢，且期间会形成路由环路。
收敛速度慢：特别是在网络拓扑发生变化（如链路故障）时，DV算法可能需要较长时间才能收敛到新的最短路径。
路由环路：在收敛过程中，可能会出现临时的路由环路，导致数据包在环路中无限循环或直到TTL耗尽才被丢弃。

为解决上述问题，引入了一些优化措施：

水平分割：路由器不会将从某个邻居学习到的路由信息再通告回那个邻居。这有助于防止两跳路由环路。
毒性反转：如果路由器 A 知道通过邻居 B 可以到达目的地 X，那么当 A 向 B 发送路由更新时，它会将自己到 X 的距离设置为无穷大。这比水平分割更强，能更快地消除一些环路。
最大跳数限制：设定一个最大跳数，任何超过此跳数的路径都被视为不可达；

比较LS算法和DV算法



特性
LS算法
DV算法




报文复杂性
具有n个节点，E个链路情况，每次发送个报文
只是在邻居间交换信息


收敛速度
算法，要求发送个消息，可能导致振荡
收敛时间变化，可能产生循环路由，存在计数到无穷大问题


健壮性
节点会广播错误的链路开销；每个节点只计算自己的转发表（提供了一定程度的健壮性）
DV节点会通告错误的路径开销；每个节点的转发表可被其他节点使用，错误会扩散到整个网络



层次选路
在实践中，路由表不可能存储所有结点，否则路由表的信息交换过于巨大；
区域的路由器组成的自治系统AS

同一个AS下运行相同的路由协议
不同的AS下可以运行不同的路由选择协议
每个AS应该选出一个网关路由器，运行域间路由协议，和其他网关路由器交互；


OSPF协议
开放最短路优先(Open Shortest Path First, OSPF)是在AS内部实现的LS协议

采用洪泛链路状态信息和Dijkstra算法，每个路由器都广播OSPF通告，OSPF通告里为每个邻居路由器设一个表项；
每台路由器有自治系统完整的拓扑图，分发LS 分组


注意OSPF信息通过IP直接传输；

优点包括

安全：所有的OSPF间的消息交换需要鉴别；
允许多条相同开销的路径；
综合支持单播和广播；
支持单个AS的层次结构；

BGP
我们还需要设计一个域间自治系统选择协议，所有的AS运行相同的AS间路由选择协议，即边界网关协议(Border Gateway Protocol, BGP);
这是一个基于路径矢量(Path Vector)路由协议，不使用传统的距离或开销度量，而是基于路径属性和策略进行路由决策。
基本特征：

域间路由：BGP的主要作用是在不同的AS之间提供通信，实现全球互联网的互联互通。
策略驱动：BGP支持丰富的路由策略，允许管理员根据业务需求、成本、安全等因素控制流量的进出。
基于TCP：BGP使用TCP作为其传输协议（端口179），提供可靠的连接和消息交换。
路径信息：BGP通告中不仅包含可达的目的地和下一跳，还包含完整的AS路径信息，用于防止路由环路和支持策略决策。
增量更新：BGP建立邻居关系后，初始会交换完整的路由表，之后只发送增量更新，以节省带宽。

BGP的功能：

初始对等体建立和认证：BGP对等体（路由器）之间建立TCP连接，并交换消息以确认连接参数和进行认证。
交换可达性信息：发送网络可达性信息，包括目的网络和到达这些网络的路径属性。
连接验证：持续验证对等体和它们之间的网络连接是否正常运行（通过Keepalive消息）。

BGP的类型：

外部BGP (eBGP)：用于不同AS内的路由器之间交换路由信息。eBGP对等体通常直接相连。
内部BGP (iBGP)：用于同一个AS内的路由器之间交换路由信息。iBGP对等体之间不需要直接相连，但通常需要全互联（Full Mesh）或使用路由反射器/联盟来简化配置。

BGP的关键元素（路径属性）：
BGP路由决策过程是基于一系列路径属性的，这些属性帮助路由器选择到达目的地的"最佳"路径。当存在多条路径时，BGP会按照一个预定义的顺序比较这些属性：

Weight (权重)：Cisco私有属性，本地有效，不传递给BGP邻居。值越高越优先，用于影响出站流量。
Local Preference (本地优先级)：在AS内部有效，传递给iBGP对等体。值越高越优先，用于影响AS的出站流量。
Locally Originated (本地发起)：如果路由是由本地路由器发起（例如通过network命令），则优先。
AS-Path (AS路径)：表示数据包到达目的网络需要经过的AS序列。路径越短越优先。用于防止路由环路，也可通过"AS Path Prepend"影响入站流量。
Origin Code (起源代码)：表示路由信息的来源。优先级顺序：IGP (i) &gt; EGP (e) &gt; Incomplete (?)。
Multi-Exit Discriminator (MED)：也称为度量，用于影响流量进入AS的决策。值越低越优先，通常用于在多个入口点时指导外部AS选择最佳入口。
BGP Route Type (BGP路由类型)：eBGP路由通常优先于iBGP路由。
Age (路由年龄)：在某些情况下，更老的路由（更稳定）可能被优先选择。
Router ID (路由器ID)：当其他属性都相同时，选择BGP路由器ID最低的路由。
Peer IP Address (对等体IP地址)：最后，如果所有属性都相同，选择BGP对等体IP地址最低的路由。

BGP路由信息管理功能：

路由存储：每个BGP路由器存储到达其他网络的信息。
路由更新：使用特殊技术确定何时以及如何使用从对等体收到的信息来正确更新路由。
路由选择：每个BGP路由器使用其路由数据库中的信息来选择到达互联网上每个网络的最佳路由。
路由通告：每个BGP发言者定期告知其对等体有关各种网络及其可达性的信息。

RIP
**RIP **(Routing Information Protocol)作为互联网中最早也是最广泛使用的距离矢量路由协议之一，使用跳数作为度量标准，最大跳数为15。
在RIP协议中，每30s，RIP通告就会通过响应报文在邻居间交换；每个报文包含了多达25个AS内的目的子网列表，以及发送方到每个子网的距离；
若180秒后没有收到通告，则认为邻居死机或链路中断。以下是恢复机制

通过故障邻居的路由失败，新的公告发送给其他邻居；
邻居然后再发送新的公告 (如果转发表发生变化)；
链路故障信息快速传播到整个网络；

毒性逆转用于防止乒乓循环 ；
注意，RIP协议中有一个应用route-d管理RIP转发表，通告是通过UDP报文周期性重复发送的；
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Computer-Network</tag>
      </tags>
  </entry>
  <entry>
    <title>PCA</title>
    <url>/2025/07/02/PCA/</url>
    <content><![CDATA[维度灾难
在一维的时候，数据点是非常稠密的，而随着维数的增加（如2维， 3维），整个数据点的空间就形成非常庞大的空间（由 3 个，变 成9个，再变成27个），相应地，数据分布就变得相当稀疏了。

我们需要对原始高维空间转换为一个低维的子空间(subspace)，即降维；数据样本虽然是高维的，但与学习任务密切相关的也许仅是某个低维分布， 即高维空间中的一个低维嵌入(embedding)；

PCA
主成分分析(Principal Component Analysis, PCA)作为一种典型的降维方法，旨在寻找一个超平面，满足如下性质

最近重构性：样本点到超平面距离足够近
最大可分性：样本点在这个超平面上的投影尽可能分开

以下证明这两种性质等价；
假定对维空间的样本进行中心化；
投影变换的新坐标系为, 这些为标准的正交基,维度为；

新坐标系下，样本点变换为，反过来的坐标变换为;注意到


一种解释是最大可分性，我们的目标是投影在超平面上的点方差最大化，即

等价与最大化

另一种解释是最小重构性,期待最小化

计算重构前后的样本点集在低维空间的距离总和，目标使之最小

由Lagrange乘子法知，PCA的解析解为：将协方差矩阵特征值分解后的top d'个特征值对应的特征向量

算法流程对应如下

t-SNE
idea
t-SNE是一种降维技术，用于在二维或三维的低维空间中表示高维数据集，从而使其可视化；

为高维样本构建一个概率分布；为低维嵌入中的点定义概率分布；
分布中相似的样本对应高概率值，不相似的样本对应极小概率值。
KL散度用来最小化两个分布之间距离；


换而言之，t-SNE希望将一个高维数据集将其简化为一个保留了大量原始信息的低维图；
通过保留局部邻域而不是全局距离来实现这一点。具体来说，t-SNE 关注的是：在高维空间中非常相似（距离很近）的点，在低维空间中也应该映射得很近；在高维空间中不太相似（距离较远）的点，在低维空间中也应该映射得较远。

流程
首先，计算高维空间中任意两个数据点  和  之间的相似度。常用的方法是计算它们之间的欧几里得距离 。
将距离转换为条件概率 ，表示  认为  是其邻居的可能性。这个概率通常基于高斯分布（正态分布）来计算：

其中  是以  为中心的高斯分布的方差，即通过用户指定的困惑度(Perplexity)参数来确定。困惑度可以被理解为每个点周围的有效邻居数量。
为了得到一个对称的联合概率分布 P，t-SNE 使用

(这里的  是数据点总数，分母是为了归一化)。这个  表示  和  在高维空间中是邻居的联合概率。对于相距较远的点， 的值会非常接近于零。
类似地，在低维嵌入空间中，我们为对应的映射点  和  计算它们之间的相似度 。与高维空间不同，低维空间使用自由度为1的T分布来计算概率。低维空间中的联合概率  定义为：

这里分母是为了归一化，确保所有  的和为 1。
t-SNE 的目标是调整低维空间中的点  的位置，使得低维概率分布  尽可能地接近高维概率分布 。t-SNE 使用梯度下降等优化方法来迭代调整低维点  的位置，以最小化 KL 散度。损失函数的梯度为：

局限性

计算成本高，不适合用于非常大的数据集。
结果可能受到参数（如困惑度）选择的影响，不同的参数可能产生稍微不同的可视化结果。
主要用于可视化，不适合直接用于后续的机器学习任务（因为没有一个明确的映射函数可以用于新数据）。
运行结果随机性：由于优化过程是非凸的，每次运行可能会产生略有不同的布局。

]]></content>
      <tags>
        <tag>Machine-Learning</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>Path and Cycle</title>
    <url>/2025/07/05/Path-and-Cycle/</url>
    <content><![CDATA[Walk/Trail/Path/Circle
在图中，途径(Walk)是指如下形式的 边序列


边的数量是迹的长度
简单图可以表示为
起始点initial vertex：
终点final vertex：
内部点internal ertex：

特别地，我们称边集相异的途径称为 迹(trail)
我们称顶点集相异的迹称为路(path)

所有的点为,可能存在
记作

对于顶点和终点相同的路称作圈(circle);

所有的点为,
记作
长度为3的圈记作三角形(triangle)

Theorem
对于顶点集为和邻接矩阵,邻接矩阵的幂

表示间长度为的迹的数目；
proof :归纳法
Theorem
对于所有点度数至少为2的图，必定包含一个圈;
proof:考虑最长路；
Lemma
对于简单图,,那么包含一条长度至少为的路；
连通图
称图是连通的(connected)，当且仅当对于点集中任意点对,存在到的路；
连通分量的数目记作;
Theorem
对于具有个顶点的简单图 ,其有个连通分量，边的数目满足以下不等式约束：

proof: 下界显然，上界只需注意以下引理

Corollary
任意具有个顶点的简单图，若其边数大于, 则一定是连通的；
proof：这意味着连通分量个数小于2；
Distance
对于图上两点

距离：从到的最短路的长度；
离心距:对于点,遍历可能的顶点,使得最大化的距离值；
图的直径:使得最大化的离心率值；
图的半径:使得最小化的离心率值；
图的围长:图的最短圈的长度；
图的周长:图的最长圈的长度；

Theorem(Konig)
图是二部图当且仅当图中不含有奇圈；
proof: 反证法；
Edge-Connectivity
断集(disconnecting set)是指对于连通图上的一组边，满足其消失导致图变得不连通；
对于，,如果两个点集之间的边，其顶点各在不同的两个点集之中，记作;
边割(edge cut)就是指这样一种;这样的边割定义蕴含着某种对称差性质，记作;
称图的最小非空边割为键(bond)；
若一个边割只包含一条边，我们称这条边为割边(cut edge)/桥(bridge)；

对于连通图，其边连通性（edge connectivity）定义为最小边割的大小，也就是我们使图不连通所需要删除的最少边数，记作;
换句话说，若,称是边连通的，但不是边连通的；
note:边连通性描述了图到底有多么连通的性质，删除多少条边才能使得图变得不连通，暗示着图两点之间的独立路径数；
Lemma
对于图上的顶点子集，满足

proof:统计贡献；
Corollary
图是偶图(每个顶点的度为偶数)，当且仅当对于任意的非空顶点子集, 为偶图；
proof：充分性显然，必要性只需要取一个顶点构成的点集即可；
Lemma
对于图,其点集的子集，有

proof:如下图

Theorem
对于连通图，一个边割是键当且仅当恰好有两个个连通分量；一个边集是边割的充分必要条件是是若干键的不相交并；
proof：利用键的最小性即可；
Lemma
对于图，一条边是桥当且仅当不在图的圈中；
proof：反证法；
Vertex-Connectivity
对于连通图，称一组顶点为点割(vertex cut)，如果删除这组顶点会导致图不连通；若点割只包含一个顶点，则称这个点为割点（cut vertex）;
类似定义点连通性为点割的最小大小，记作，也就是使得图不连通的最少删除点数
若，称作图是点连通的，但不是点连通的；
Theorem
对于简单图,有;
proof：考虑度最小的点，尝试删除与其关联的边，有;
取一组最小的边割,完全图的情况平凡，考虑非完全图，取出；
构造

这是一组点割，容易观察到;

2-连通图
称两条路内部不相交(internally disjoint),如果他们没有共同的内部顶点；
2-连通图意味着它既是2-边连通的，也是2-点连通的；
Theorem
对一个至少有3个顶点的图，若是2-连通的，当且仅当对于每一个点对,均存在两条内部不相交的路将他们相连；
proof:充分性：删去一条边/点仍有另一条路径将之连通；
必要性：对距离归纳，相邻情况平凡；考虑最短路径前面一个点，构造不相交路径，删去该点仍然存在一条路径将之连通，如下图，选择最后一次与先前构造的两条路径交汇的顶点即可；

Theorem(Menger,vertex version)
拥有至少条路经的图是-点连通的当且仅当对于每一个点对存在条内部无公共点的路径；
Theorem(Menger,edge version)
图是-边连通的当且仅当对于每一个点对存在条内部无公共边的路径；
Eulerian Graph
欧拉迹(Eulerian trail)定义为包含图中所有边的迹；若这个迹闭合，称为欧拉圈（Eulerian circuit）；
若图包含一个欧拉圈，称该图为欧拉图(Eulerian graph)；若图不包含欧拉圈，但是包括一个欧拉迹，称该图为半欧拉图(semi Eulerian graph)；
Lemma
若图是图，每个顶点的度至少为2，那么图包含圈；
proof:对于非简单图，结论平凡，对于简单图，考虑最长路即可；
Theorem
若连通图是欧拉图当且仅当每个顶点的度数为偶数；
proof：配对；
Theorem
若连通图是半欧拉图，当且仅当恰好存在两个顶点的度数为奇数；
proof：除开迹首尾两个顶点外配对，迹首尾两个顶点为奇点；
Fleury Algorithm
构造欧拉圈可按照如下算法：

从一个顶点开始，选择与之关联的，未被遍历的一条边；
若选择的边是桥，改选其他边，若没有别的选择，就选择桥；选择这条边的另一个顶点为;
将这条边加入迹中，擦除这条边
若产生了新的孤立点，同时擦除这个孤立点；
将更新为，选择下一条边；

Hamilton Graph
一个哈密顿圈是指一个遍历图中所有顶点的圈；
一个图为哈密顿图当且仅当图包含一个哈密顿圈；

对于，是哈密顿图
当且仅当时，是哈密顿圈
Peterson图不是哈密顿图

由此定义图的哈密顿闭包:通过在不相邻的点对上增加边，达到不存在不相邻的点对使得的状态，也就是无法继续加边；这样的加边是顺序无关的；

Theorem
若均是哈密顿图，那么是哈密顿图;
proof:对于为偶数，构造如下：

对于为奇数，构造如下：

Theorem
对于哈密顿图，取顶点集的非空真子集，有

proof:取的哈密顿圈，至多个分量；意味着至多个分量；
Theorem(Erdos)
对于具有个顶点的简单图，若，则图是哈密顿圈；
proof：反证法，增加边使得成为没有哈密顿圈的最大图，取图中的最长路;由假设
注意到
Ｓ

则存在哈密顿圈;
注：可进一步加强为对任意不相邻的点对成立，这说明在简单图上哈密顿闭包是良定义的；
Lemma(Bondy)
对于简单图，是哈密顿图当且仅当的闭包是哈密顿图；
Theorem(Chvatal)
对于简单图的度序列为，，，则图G是哈密顿图;
Theorem（Chvatal-Erdos）
若，则是哈密顿图，除非
Claw-free Graph
称图是**无爪的(**claw-free)，当且仅当其不含
在无爪图中，任何顶点的邻居的生成子图只有两种类型，从而将顶点分为两类：

Type1:连通图
Type2:仅有两个连通分量，并且分量都是完全图；

对于Type1的顶点，定义操作：在邻居中添加原本没有的边；只要邻居不构成团，操作就可以进行；
定义Ryjáček闭包：对于无爪图,反复应用上述操作使得每一个Type1顶点邻居都能导出团，增边结束后生成图；
Theorem
是哈密顿的当且仅当是哈密顿的；
Theorem
设是2-连通图，顶点数,和是的不同点。若

则具有哈密顿圈。
Shortest Path Problem
Gravity法
Making a model of the map by knotting together pieces  of string whose lengths are proportional a length of the roads. To find the  shortest length, take hold of the knots corresponding to A to L–and pull tight !
Dijkstra算法
The idea is to move across the graph from left to right, associating with each vertex X a number l(X) indicating the shortest distance from A to X. This means that, when we reach a vertex such as Kin the figure, then l(K) is either l(H) + 6 or l(I) + 2, whichever is smaller.
Chinese Postmen Problem
邮递员希望投递信件，尽可能短的总距离并回到他的起点。显然，他必须至少穿过路线中的每条道路一次。

在一个具有非负权的带权连通图中，找出一条总权重最小的环游，这种环游称为最优环游。
若为欧拉图，任意欧拉圈都是最优环游；
考虑为非欧拉图，其必然包含偶数个奇度顶点；并且， 对于任意一个环游必定通过某些边不止一次，选取重复边按相同权值加入图中，问题等价描述为一个最优化问题：
添加重复边求一个欧拉赋权母图，最小化

同时找到的欧拉圈；
Theorem
上述欧拉赋权母图拥有最小权值的欧拉圈当且仅当

的每一条边至多被添加一次
对于的每一个圈,均有

Ttravelling Saleman Problem
一位旅行推销员希望参观一些城镇，然后返回他的家。鉴于城镇之间的距离，他应该如何规划路线，以便他只访问每个城镇一次，并最大限度地减少总旅行距离？
该问题可形式化描述为最小化带权完全图的哈密顿圈权值，称问题的解为TSP环游；
这是一个NP-hard问题；
Aheuristicapproach:2-edge-exchange: 如果一个可以通过删除两条边并添加两条边从另一个获得，则两个TPS路径称为2-相邻；

通过上述边的对换， 我们可以迭代地挖掘出最优路径；
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Graph-Theory</tag>
      </tags>
  </entry>
  <entry>
    <title>Perceptron</title>
    <url>/2025/07/02/Perceptron/</url>
    <content><![CDATA[Perceptron
线性可分
对于二分类问题，给定一个数据集

其中，。
如果存在一个超平面：能够将数据集中的正例和负例完全分开，即对于所有的正例有，对于所有的负例有，则称该数据集是线性可分的。

神经元
感知机(perceptron)是一种线性分类器，是最简单的ANN，只有一个神经元；
每个神经元作为独立的处理单元，模拟生物神经元行为的机器，有与生物神经元相对应的部件，如权重（突触）、偏置（阈值）及激活函数（细胞体），输出为+1或-1

对每个输入信号进行加权处理（确定其强度）；
确定所有输入信号的组合效果（求和）；
确定其输出（转移特性，即激励特性）。

感知机模型的假设空间是定义在特征空间中的所有线性分类器，形式化表示如下


学习算法
感知机学习的目标是求得一个能够将训练集正实例点和负实例点完全正确分开的分离超平面。
感知机是一种错误驱动的在线学习算法

初始化权重向量;
每次分错一个样本时，即，使用该样本更新权重;

换而言之，感知机的损失函数如下，每次按梯度更新，学习率为1；定义全体误分类的点集为;


对于线性可分的数据集，感知机学习算法收敛，即经过有限次迭代可以得到一个将训练数据集样本完全正确划分的分离超平面和感知机模型。其迭代收敛性有如下Novikoff定理保证：
假设训练集线性可分，则存在满足的超平面能将数据集完全分开，且,对于所有训练样本有

感知机在数据集上的误分类次数存在上限

局限性
下图展示了感知机的参数学习更新过程。红色实心点为正例， 蓝色空心点为负例。黑色箭头表示当前的权重向量，红色虚线箭头表示权重的更新方向。
假设训练数据集线性可分，感知机学习的目标是求得一个能够将训练集正实例点和负实例点完全正确分开的分离超平面。

输入为的单层单个神经元（输入层不计入层数），采用阶跃激活函数，可以解决线性可分问题

可以看到，单层感知机只能处理线性问题，无法解决异或问题，这是一类典型的线性不可分问题；
对偶形式
将参数反过来表示数据集的示例线组合，按照先前的学习方式

最后学习的参数具有如下形式

表示第i个实例点由于误分而进行更新的次数。实例点i更新次数越多，意味着它距离分离超平面越近，也就越难正确分类。换句话说，这样的实例对学习结果影响最大。
对偶形式中训练实例仅以内积的形式出现。为了方便，可以预先将训练集中实例间的内积计算出来并以矩阵的形式存储，这个矩阵就是所谓的Gram矩阵。

]]></content>
      <tags>
        <tag>Machine-Learning</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>Planarity</title>
    <url>/2025/07/05/Planarity/</url>
    <content><![CDATA[Planarity
一个平面图(planar)被定义为：在平面上绘制没有交叉的图；
若图不能在平面上绘制或表示，称为非平面图；
若两个图可以在同一个图的边插入一个2度的新顶点来获得，则这两个图是同胚的(homeomorphic);

称图紧缩于(contractible to)或， 如果我们将的边收缩能够得到，或;
Theorem(Kazimierz Kuratowski)
是非平面的；进一步地，如果一个图是平面图，当且仅当其没有子图和或同胚；
Corollary
一个图是平面的当且仅当它不包含可紧缩到或的子图;
proof:考虑命题反面

Crossing
图的交叉数定义为将绘制在平面上是发生的最小交叉数；
显然;

图的厚度定义为将分解成若干个平面图的并的最小数量；
Theorem
对于简单图,顶点数,边数; 则厚度存在下界

proof:只需证;
Bound
定义一个平面图的区域的边界度(bound degree)为 为遍历区域的边界记录的图的边数；
假设平面图将平面划分为个区域，称为平面图的面数；
Theorem
假设平面图的面最小边界度为,则

对于不少于3个顶点的简单平面图，则

对于一般的平面图，自然有

对于二部平面图，有

Theorem(Euler)
若图是一个具有个顶点，条边和个面的连通平面图，则满足一下公式：

proof:若图有圈，删除一条圈中的边导致和均减少1，且不丢失连通性；重复上述操作划归为树的情况，即
note:由此可证明不是连通图；
Corollary
是平面图当且仅当;是平面图当且仅当;
Corollary
对于平面图，有

Polyhedra
一个多面体(polyhedron)定义为一个实体，它被有限个面包围，每一个面都是多边形；
一个多面体是凸的，若连接两个顶点的险段都完全包含在多面体内；
多面体可以用一个平面图表示；
一个多面体是正则的(regular)，若存在整数,每个顶点均有个面在此相遇，而且每个面的边界上均有条边；

Theorem
假定正多面体的顶点度为，每个面度为，则仅有如下取值：

proof:注意到

导出

Fullerene
一个烯(fullerene)的特征如下：

由五边形和六边形构成；
每个顶点处有3个面相遇；

可以确定，总共12个五边形；
proof:注意到

Genus
定义一个表面的亏格数(genus)，如果其拓扑同构于有个柄(handle)或者交叉帽(cross-caps)一个球体(sphere);

这里给出结论，和是亏格数为1的图(toroidal graphs)；

Theorem
图的亏格数不超过其交叉数;
Theorem
对于可定向的连通图，亏格数为,顶点数为,边数为，面数为,满足

Theorem
对于不少于4个顶点的可定向的连通图，边数为,顶点数为，其亏格数满足

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Graph-Theory</tag>
      </tags>
  </entry>
  <entry>
    <title>Poisson过程</title>
    <url>/2025/07/05/Poisson%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[Poisson过程
计数过程
随机过程 称为计数过程，如果表示从时刻0到某一特定事件发生的次数，它具备以下两个特点：

且取值为整数；
时， 且 表示时间内事件发生的次数。

Poisson过程
计数过程称为参数为的Poisson过程，如果





过程有独立增量；


对 任 意 的 ,



等价定义如下：





过程有平稳独立增量；


存在,当时



当0时，



计算机如何模拟Poisson过程？下面是一个基于样本路径的性质的又一等价定义：

每次时间发生的间隔相互独立；
服从参数为​的指数分布；

这告诉只需要产生足够多的同指数分布的随机数，依次相加得到时间发生的时刻，分段就得到了Poisson过程的一条样本路径.
Mark


参数​​​被称作Poisson过程的速率(强度)；


常见模型有：普通的排队系统，简单的保险公司索赔


第一定义推导第二定义显然，下面是一种由第二定义推导第一定义的办法：
对于任意给定的,构造.有以下断言：


几乎就是:


越来越像Poisson分布：



独立同分布那么由于因此
\lim_{n\to \infty}P(X_n=k)=\frac{(\lambda t)^k}{k!}e^{-\lambda t}



Poisson过程的样本路径
,表示第次事件发生的时刻，规定
,表示第次与第​次事件发生的时间间隔.

Property

服从参数为的指数分布,且相互独立.
服从参数为和的分布;

事件发生时刻的条件分布
在已 知的条件下，事件发生的个时刻的联合概率密度是

Mark

如果知道事件只在内发生一次，那么发生的时刻服从均匀分布；
在已知内发生了次事件的前提下，各次事件发生的时刻 (不排序)可看做相互独立的随机变量，且都服从​上的均匀分布.

非齐次Poisson过程
当Poisson过程的强度λ不再是常数，而是一个时变参数时，Poisson过程被推广为非齐次Poisson过程。
计数过程称做强度函数为的非齐次泊松过程，如果


过程有独立增量；

​

等价定义如下：





过程有独立增量；


是参数为​ 的泊松分布.


Mark
泊松过程与非齐次泊松过程之间转换关系:
设是一个强度函数为的非齐次Poisson过程.对任意令,则 是一个强度为 1的泊松过程.
复合Poisson过程
随机过程被称为复合泊松过程，如果对于,可以表示为

其中是一个Poisson过程， 是一族独立同分布的随机变量，并且与​也是独立的.
Mark


常见应用：保险公司的索赔金额，顾客成批到达的排队系统


设 是 一 复 合 泊 松 过 程 , 泊 松 过程的强度为,则


有独立增量；


若,则E[X(t)]=\lambda tE(Y_1),\quad D[X(t)]=\lambda tE(Y_1^2).


特征函数​




条件Poisson过程
Poisson过程描述的是一个有着“风险”参数λ的个体发生某一事件的频率。如果我们考虑一个总体，其中的个体存在差异，比如发生事故的倾向性因人而异，这时泊松过程的强度参数本身是一个随机变量.
设随机变量 如果在的条件下，计数过程是参数为的泊松过程，则称​为条件泊松过程.
设的分布是, 由 全 概 率 公 式 可 知 , 随 机 选 择 一 个 个 体 在长度为的时间区间内发生次事件的概率为

Property
设是条件泊松过程，且, 则




]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Random Process</tag>
      </tags>
  </entry>
  <entry>
    <title>Recurrent Neural Network</title>
    <url>/2025/07/02/Recurrent-Neural-Network/</url>
    <content><![CDATA[RNN介绍
时序任务
对于一些任务需要能够更好的处理序列的信息，这些任务的特征是前面的输入和后面的输入是有关系的。比如，当理解一句话意思时，孤立的 理解这句话的每个词是不够的，需要处理这些词连接起来的整个序列；当处理视频的时候，不能只单独的去分析每一帧，而要分析这些帧连接起来 的整个序列；
循环神经网络(Recurrent Neural Network，RNN)具有记忆能力；循环神经网络全部或者部分神经元可以接受来自其它神经元或自身信号的神经网络结构，其拓扑结构可以是网状的，也可以是具有一定层级的，反馈神经网络通常被视为一个动态系统，主要关心其随时间变化的动态过程;
基本架构
RNN主要模拟的是人脑的记忆，来进行一个反馈的过程；RNN至少包含一个反馈链接的神经网络结构，特别适合处理时序数据，其基本结构如下所示：


输入层向量;
输入层到隐藏层的权重矩阵
隐藏层向量:不仅和当前输入的有关，还取决于上一次隐藏层的值；
隐藏层到输出层的权重矩阵;
输出层向量;
上一次隐藏层的向量被权重矩阵作用后，被作为这一次隐藏层的输入；

按时间顺序展开如下

可以抽象如下：

显然，某一时刻的输出值，收到前面历次输入值的影响；
一类带延迟/偏置的RNN常表示如下：

场景
神经网络模型通过训练“学”到的东西蕴含在“权值”中。基础的 神经网络只在层与层之间建立权连接，而RNN最大的不同之处在 于隐藏层内的神经元也建立了权连接。
RNN在不同的场景下，可能表现为不同的结构；
比如在文本分类中，输入数据为单词的序列，输出为该文本的类别

图片到文字描述的任务下，RNN表现如下：

输入和输出序列长度相同，比如为视频帧打标签

经典的编码器解码器架构，用于处理翻译问题

随时间反向传播
BPTT算法(Back-Propagation Through Time)可以用于RNN的训练，和BP算法类似，BPTT需要沿着徐娅优化的参数的负梯度方向寻找更优的点直到收敛；
将RNN沿时间轴展开如下：

观察

BPTT算法是针对循环曾的训练算法。基本原理和BP算法是一样的,

前向计算每个神经元的输出值
反向计算每个神经元的误差项,它是误差函数对神经元的加权输入的偏导数；
计算每个权重的梯度；
随机梯度下降更新权重；

长程依赖
RNN 的长处之一是它可以利用先前的信息到当前的任务上，尤其当相关的信息和 预测的词之间的间隔较小时效果明显。 然而在间隔不断增大时，RNN会丧失学习到连接如此远的信息的能力。
考察RNN权重矩阵的最终梯度为各个时刻的梯度之和

在一般的训练中，从时刻开始，梯度已经几乎减少到了。即从此时刻 开始再往之前走，得到的梯度（几乎为零）就不会对最终的梯度值有任何贡献。这就是原始RNN无法处理长距离依赖的原因。
]]></content>
      <tags>
        <tag>Machine-Learning</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>SVM</title>
    <url>/2025/07/02/SVM/</url>
    <content><![CDATA[支持向量机
Idea
支持向量机(Support Vector Machine)是Vapnik等于1995年首先提出的，它在解决小样本、非线性及高维模式识别中表现出许多特有的优势，并能够推广应用到函数拟合等其他机器学习问题中。
SVM是建立在统计学习理论的VC 维理论和结构风险最小原理基础上的，根据有限的样本信息在模型的复杂性和学习能力之间寻求最佳折衷，以期获得最好的推广(泛化)能力。
对比感知机和SVM，感知机利用误分类样本最少的策略，求得分离超平面，不过这时的解有无穷多个； 线性可分支持向量机利用间隔最大化求最优分离超平面（解是唯一的）。

基本概念
在二分类的样本集中，SVM希望找到一个超平面将不同样本分开，同时希望两边的数据离超平面有尽量大的间隔，以期获得高分类的容忍度；
超平面方程和上下的边界方程如下，对为法向量,为位移项；

假设能将训练样本正确分类，必有：

因此分类预测函数为

在上下边界上使得方程等号成立的点就是支持向量，即每类中距离决策面最近的样本点，上下边界之间的间隔(Margin)如下：


可以看到

在决定分离超平面时，只有支持向量起作用，而其他实例点并不起作用；
移动支持向量将改变所求的解，即改变分离超平面；
移动间隔边界以外的实例点，甚至去掉这些点，解是不会改变的；

Hard Margin SVM
对于线性可分的数据，我们寻求一个最大间隔分离超平面。这个问题可以表示为以下优化问题：
最大化间隔等价于如下最优化问题(primal form)：

这是一个有  个约束条件的凸二次规划问题，解存在且唯一。该形式求解算法的复杂度与样本维度有关；
我们通常将其转化为对偶问题(dual form)。引入拉格朗日乘子 ，构建拉格朗日函数：

根据对偶原理，原始问题的对偶问题可以通过先对拉格朗日函数关于原始变量  求偏导并令其等于零，然后对拉格朗日乘子  求最大化得到。
对  关于  和  求偏导：


将这些关系代回拉格朗日函数，消去  和 ，可以得到只关于  的对偶函数，并对其进行最大化，从而得到对偶问题，满足KKT约束条件，特别地，第三个条件被称为互补松弛性；

这意味着对于最优解 ：

如果 ，由互补松驰性可知， ，样本  位于最大间隔边界，这就是支持向量；
如果 ，即样本  在间隔边界之外，则对应的  ；

从  可以看出，只有当  时，对应的样本  才会对最优的  产生贡献。因此，最终的决策边界只由支持向量决定。
这个问题有许多技巧处理，比如SMO算法，求解算法的复杂度与样本数量（等于拉格朗日算子的数量）有关；
获得对偶问题的解后，存在下标使得,并按照上式获得primal form问题的解

Soft Margin SVM
硬间隔SVM要求所有样本都必须严格满足约束 ，即将所有样本正确且以至少为1的函数间隔分开。
然而，在实际应用中，数据往往不是完全线性可分的，或者包含一些噪声和异常点。对于近似线性可分的数据，即数据集中存在一些异常值，将其去除后，剩下的样本组成的集合是线性可分的。硬间隔SVM在这种情况下无法找到解。为了解决这个问题，引入了软间隔(Soft Margin)的概念。
软间隔SVM允许部分样本违反硬间隔约束，但通过引入惩罚项来控制违反的程度和数量。这通过引入松弛变量（Slack Variables）  来实现，每个样本  对应一个松弛变量。
约束条件放宽为：;
同时，为了惩罚违反约束的样本，将松弛变量的和加入到目标函数中，得到软间隔SVM的原始优化问题：

其中， 是一个惩罚项。C大表示对误分类样本的惩罚大；C小对误分类样本的惩罚小。如果C无穷大，则接近于硬间隔。

构建拉格朗日函数：

求偏导获得



通过将将解约束回代，等价于求解如下优化问题

这个优化问题相比于原始问题，具有如下优秀性质；

C只出现在约束条件中， 从目标函数中消失。
μ是拉格朗日乘子，在对偶问题中消失。
目标函数同硬间隔SVM一样

与硬间隔SVM不同，软间隔SVM的支持向量不仅包括恰好位于间隔边界上的点，还包括位于间隔内部（但分类正确）以及被错误分类的点。这些点对确定最终的分类超平面起着关键作用。
具体来说，根据松弛变量  的值，软支持向量可以分为几类：


位于间隔边界上：对应  且  的样本点。



位于间隔内部但分类正确：违反不等式约束的样本，对应  且  的样本点。



被错误分类：对应  且  的样本点（）；




梯度下降
在 硬间隔SVM 中，损失函数本身的目标是最小化权重，从而实现最大间隔，同时惩罚误分类样本（即没有满足约束条件的样本）。硬间隔的损失函数，包括两部分

正则化项：用于控制间隔大小；
约束损失：每个样本应用约束条件，如果该条件没有满足，则需要加入相应的损失；

定义如下合页损失(Hinge Loss)

因此梯度下降的更新规则为,对于每个不满足约束的样本

通过梯度下降法，我们可以逐步更新 SVM 的模型参数 和，使得损失函数逐渐收敛，最终获得一个可以有效分类的模型;
非线性SVM Kernel
对于原始特征空间中线性不可分的数据，SVM通过将样本映射到更高维的特征空间，使得样本在该高维空间中线性可分。这个过程通过核技巧（Kernel Trick）实现。
分类器在高维特征空间中的形式为：

其中  是将样本  映射到高维特征空间的映射函数。
将  代入决策函数，可以得到：

注意到在对偶问题和最终的决策函数中，样本的特征向量总是以内积的形式出现（在映射后的空间中是  或 ）。核函数（Kernel Function）  可以直接计算出在高维空间中的内积，而无需显式地进行映射 。
因此，通过引入核函数，软间隔SVM的对偶问题可以写为：

最终的分类决策函数为：

其中只有对偶变量  的样本（支持向量）对决策函数有贡献。
常见核函数举例：

线性核： (对应原始空间的线性分类)
多项式核：(处理一类比线性数据复杂，但是有规则线性边界的数据)
径向基函数核(RBF)：(处理非线性数据的首选)
Sigmoid核：

SVM多分类器
一种是直接法，直接在目标函数上进行修改，将多个分类面的参数求解合并到一个最优化问题中，通过求解该最优化问题“一次性”实现多类分类。但其计算复杂度比较高，实现起来比较困难，只适合用于小型问题中；
另一种是间接法，主要是通过组合多个二分类器来实现多分类器的构造，常见的方法有one-against-one 和 one-against-all两种。
one-against-one多分类是指，在任意两类样本之间设计一个SVM，因此 n 个类别的样本就需要设计n(n-1)/2 个 SVM分类器。 当对一个未知样本进行分类时，最后得票最多的类别即为该未知样本的类别。
one-against-all多分类是指，训练时依次把某个类别的样本归为一类,其他剩余的样本归为另一类，这样n 个类别的样本就构造出n个 SVM 分类器。
支持向量回归
支持向量回归(SVR)是指，对所有的样本点，容忍回归模型与真实值 之间存在最大偏差 ，即以 f (x)为 中心，构建一个宽度为 2ε 的隔离带。

若训练样本落入此间隔带，则认 为是被预测正确的。较小的 ϵ 值会使 SVR 模型更加复杂，因为允许的误差范围更小，对误差更敏感；
将SVR形式化为
𝓁
其中，为正则化常数，SVR损失函数选取为不敏感函数；落入中间间隔带的样本不计算损失，以提高模型的稀疏性；
𝓁
优点

处理小样本：由于决策边界只由支持向量决定，SVM在小样本数据集上也能表现良好。
处理非线性和高维识别：通过核技巧可以有效处理原始空间中非线性可分的数据，并且在高维空间中进行运算而避免"维度灾难"。
泛化能力强：SVM建立在结构风险最小化原则上，通过最大化间隔来提高模型的泛化能力。
凸优化问题：硬间隔和软间隔SVM的原始问题及对偶问题都是凸优化问题，可以保证找到全局最优解。

]]></content>
      <tags>
        <tag>Machine-Learning</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>Taylor多项式实验和Fourier多项式实验</title>
    <url>/2025/07/05/Taylor%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%AE%9E%E9%AA%8C%E5%92%8CFourier%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%AE%9E%E9%AA%8C/</url>
    <content><![CDATA[Background
和动画实验一样，这次也是用matlab和python共同实现，完成对Taylor中值定理，Euler公式，Fourier公式的验证；
这次我们需要的python库：sympy，这个库能让我们像matlab一样完成符号运算;
Content
Taylor公式
先给出Taylor中值定理：
若在的临域具有直到阶导数，则当在内，可以表示为关于的次多项式与一个余项之和：

在之间
在matlab中利用taylor函数可以直接求出对应展开阶数的P(x)，taylor函数的接口如下：
T = taylor(f,var,a)
f是即将展开的函数；
var指定要展开的自变量；
a指定拓展点，也就是说T展开应该是关于(x-a)的多项式；
T = taylor(___,Name,Value)
Name和Value是在此之上的选项，例如，可以指定泰勒级数的扩展点、截断顺序或顺序模式扩张。
'ExpansionPoint',x0,指定拓展点为x0
order,n指定展开阶数
下面是对的展开实验代码
matlab：
syms xfx = sin(x); x0 = 0; %展开点n=[11 14 17];for i=1:length(n) %展开阶数: n-1阶hx(i) = taylor(fx,x,&#x27;order&#x27;,n(i),&#x27;ExpansionPoint&#x27;,x0)    endxp = linspace(-6,6,400); %创建节点数组y  = subs(fx, x, xp);   %通过subs替换符号计算函数值y1 = subs(hx(1), x, xp); y4 = subs(hx(2), x, xp);y6 = subs(hx(3), x, xp);h=plot(xp,y,&#x27;r&#x27;,xp,y1,&#x27;k&#x27;,xp,y4,&#x27;b&#x27;,xp,y6,&#x27;c&#x27;,&#x27;linewidth&#x27;,2)legend(h,&#x27;source&#x27;,&#x27;n=11&#x27;,&#x27;n=14&#x27;,&#x27;n=17&#x27;)set(gca,&#x27;fontsize&#x27;,16)
通过matlab拟合出来的图像是这样的：

python：
这里需要注意的小点是：利用sympy中的series方法得到的talor展开是带的符号式，记得需要用removeO方法去掉，同时将sympy的公式用lambdify转化成numpy的公式才能对linspace计算函数值；
在sympy中series方法的接口如下：
expr.series() 方法来对表达式进行级数展开。下面是一些参数：
x: 展开的变量。
x0: （可选）展开点，默认为，也就是在  处展开。
n: （可选）展开式的阶数，就是说要展开到的几次方。
dir: （可选）展开方向，+ 表示正方向，- 表示负方向（对劳伦展开有用）。
import numpy as np import sympyimport matplotlib.pyplot as plt x = sympy.Symbol(&#x27;x&#x27;)y = sympy.sin(x)n = [11, 14, 17]val = []cor = [&#x27;r&#x27;, &#x27;k&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]xp = np.linspace(-6, 6, 400)funco = sympy.lambdify(x, y, &#x27;numpy&#x27;)yo = funco(xp)val.append(yo)for i in range(len(n)):    fi = y.series(x, 0, n[i]).removeO()    funci = sympy.lambdify(x, fi, &#x27;numpy&#x27;)    yi = funci(xp)    val.append(yi)fig = plt.figure()ax = fig.add_subplot(1, 1, 1)for i in range(len(val)):    ax.plot(xp, val[i], color = cor[i])plt.show()
最后拟合出来的效果是这样的：

Euler公式
有了Taylor展开的基础后，我们顺便验证Euler公式：​,使用numpy中的复数，对中一系列点，计算两边值是否相等即可；
import numpy as np from numpy import cos,sin,pi,eimport sympy xp = np.linspace(-np.pi, np.pi, 100)lrh = e**(1j*xp)rlh = cos(xp)+1j*sin(xp)if sum(lrh == rlh)==len(xp):    z = sympy.Symbol(&#x27;z&#x27;, real = True)    print(sympy.expand(sympy.E**(sympy.I*z), complex = True))
展开的结果确实是
I*sin(z) + cos(z)
注意Euler公式有一个常见的变形：

Fourier变换相关
和Fourier变换有许多知识点，比如作者还打算复习之前学过的快速Fourier变换算法，这是一个十分优秀高效的算法，不过在这里只介绍Fourier变换的强大之处，也就是几乎对各种各样的函数的拟合；
注意之前的Taylor展开对函数的拟合其实并不是那么好，基本只能在展开点附近才有比较好的效果，并且Taylor展开本身对函数要求也很高：要求函数在该点具有足够高阶的导数，我们知道许多函数的性质都不是这么好；
先来复习一下Frourier变换


连续函数的正交：
若定义在函数满足则称两函数在正交;

如果把函数理解成一系列很密集的散点，那么这些散点构成的向量就满足向量正交的概念，不过在函数取密集的散点向量，不一定是正交的，因为函数描述的是连续的性质，不过我们在工程中经常采用这种近似



关键的积分关系：








​



是一串两两正交的函数列


根据工程实践猜想傅里叶级数公式：
若周期信号周期为,角频率为,满足Dirichlet条件：

一个周期内只有有限个第一类间断点
一个周期内只有有限个极值点

则可以展开成下列级数：

根据上述「关键的积分关系」待定系数求得：
直流分量：
傅里叶系数：​


Fourier级数指数形式：




​	
​	其中​


将周期信号​推广成有限时间的非周期信号,也即时域从周期转化为非周期时，频域从离散的转化为连续的：原始的Fourier变换（FT）




离散时间无限频谱内的Fourier变换（DTFT）
将连续信号采样，采样时间点间隔为,冲击序列为,取样信号为,其频谱密度为



离散傅里叶变换（DFT）：
对于数组,定义由离散傅里叶变换得到,

可待定系数证明由离散傅里叶逆变换得到,

由于暂时没看懂其中的物理意义所以留个坑，貌似这样的式子都是天才一眼看出来的🤣,同时给FFT埋个坑



经过简单的对Fourier变换的复习之后，我们来看看我们的任务：
给以为周期的周期函数在区间定义如下,验证傅里叶级数对其近似效果：

先看matlab代码
T=2*pi;fx=@(x) (mod(x+pi,T)&lt;pi).*(T-mod(x,T)).^2;test=4;xp=linspace(-2*pi,2*pi,1000);N=[2,4,8,16];col=[&#x27;red&#x27;,&#x27;cyan&#x27;,&#x27;blue&#x27;,&#x27;yellow&#x27;];idx=2;yp=fx(xp);plot(xp,yp,&#x27;color&#x27;,&#x27;red&#x27;,&#x27;LineWidth&#x27;,2,&#x27;DisplayName&#x27;,&#x27;OriginSignal&#x27;)hold onyp_test=[];for i=1:test    n=N(i);    [fs,an,bn]=FourierSeries(fx,x,n);    yp_t=subs(fs,x,xp);    yp_t=double(yp_t);    yp_test=[yp_test;[yp_t]];endplot(xp,yp_test(1,:),&#x27;color&#x27;,&#x27;green&#x27;,&#x27;LineWidth&#x27;,2,&#x27;DisplayName&#x27;,&#x27;n=2&#x27;);hold on;plot(xp,yp_test(2,:),&#x27;color&#x27;,&#x27;cyan&#x27;,&#x27;LineWidth&#x27;,2,&#x27;DisplayName&#x27;,&#x27;n=4&#x27;);hold onplot(xp,yp_test(3,:),&#x27;color&#x27;,&#x27;yellow&#x27;,&#x27;LineWidth&#x27;,2,&#x27;DisplayName&#x27;,&#x27;n=8&#x27;);hold on;plot(xp,yp_test(4,:),&#x27;color&#x27;,&#x27;blue&#x27;,&#x27;LineWidth&#x27;,2,&#x27;DisplayName&#x27;,&#x27;n=16&#x27;);hold on;legend(&#x27;show&#x27;,&#x27;location&#x27;, &#x27;northeast&#x27;);hold off function [fs,an,bn]=FourierSeries(fx,x,n,l,r)%fx为周期信号%x为自变量%n为展开阶数%[l,r]为周期区间%an，bn为余弦项系数，正弦项系数%fs为展开表达式if nargin==3    l=-pi;    r=pi;endT=r-l;w=2*pi/T;%fx=subs(fx,x,x+l+T/2);fx=@(x)fx(x+l+T/2);an=integral(fx,-T/2,T/2)/T;bn=[];fs=an;for k=1:n    ak=integral(@(x) fx(x).*cos(k*w*x),-T/2,T/2)*2/T;    bk=integral(@(x) fx(x).*sin(k*w*x),-T/2,T/2)*2/T;    an=[an,ak];    bn=[bn,bk];    fs=fs+ak*cos(k*w*x)+bk*sin(k*w*x);endfs=subs(fs,x,x-l-T/2);end
最后拟合出来的效果是这样的，可以看到随着展开阶数增大，拟合效果越来越好，但也可以看到吉布斯现象也越来越显著；

用python也可以做到同样的效果，很遗憾python库里也没有直接计算傅里叶级数的函数；
import numpy as npimport matplotlib.pyplot as pltfrom scipy.integrate import quad# Define the original signal function fxT = 2 * np.pidef fx(x):    return (np.mod(x + np.pi, T) &lt; np.pi) * (T - np.mod(x, T)) ** 2# Fourier series calculationdef fourier_series(fx, x, n, l=-np.pi, r=np.pi):    T = r - l    w = 2 * np.pi / T    fs = 0    an = []  # Cosine coefficients    bn = []  # Sine coefficients    # Calculate a0 coefficient    a0, _ = quad(lambda x: fx(x), -T/2, T/2)    an.append(a0 / T)    fs += an[0] / 2    # Calculate remaining an and bn coefficients    for k in range(1, n + 1):        ak, _ = quad(lambda x: fx(x) * np.cos(k * w * x), -T/2, T/2)        bk, _ = quad(lambda x: fx(x) * np.sin(k * w * x), -T/2, T/2)        an.append(ak * 2 / T)        bn.append(bk * 2 / T)        fs += an[k] * np.cos(k * w * x) + bn[k] * np.sin(k * w * x)    return fs, an, bn# Define the range of x and the number of Fourier series termstest = 4xp = np.linspace(-2*np.pi, 2*np.pi, 1000)N = [2, 4, 8, 16]colors = [&#x27;green&#x27;, &#x27;cyan&#x27;, &#x27;yellow&#x27;, &#x27;blue&#x27;]# Plot the original signalyp = fx(xp)plt.plot(xp, yp, color=&#x27;red&#x27;, linewidth=2, label=&#x27;OriginSignal&#x27;)# Plot the Fourier approximationsfor idx, n in enumerate(N):    fs, _, _ = fourier_series(fx, xp, n)    plt.plot(xp, fs, color=colors[idx], linewidth=2, label=f&#x27;n=&#123;n&#125;&#x27;)# Show the legend and plotplt.legend(loc=&#x27;northeast&#x27;)plt.show()
]]></content>
  </entry>
  <entry>
    <title>Transformer</title>
    <url>/2025/06/19/Transformer/</url>
    <content><![CDATA[Transformer介绍
Seq2Seq任务
对于一类Seq2Seq任务，输入和输出都是序列的任务，输出的长度不确定时采用的模型，常见于机器翻译中；

针对一类序列模型和 transduction-problem(语言处理，机器翻译等)，Google提出一种简单的网络架构Transformer

只基于注意力机制(attention mechanisms) 构建输入输出的全局依赖
完全舍弃RNN和CNN的transduction model
允许并行化提高计算效率，减少串行计算(现有模型运算次数和输入输出所在位置距离有关)，引入多头注意力机制(Multi-Head Attention)

Tokenization
观察到长句子总是由单词组成的，我们把语句中有意义的词块组成为token，这些token一般需要训练形成token表，最终设计的效果是意思相近的token具有接近的embedding；

embedding是一种嵌入技术，可以直接理解为词向量

对于一个句子或一篇文章，每个位置的重要性和信息都不同；比如在标题和摘要部分的重要性显著高于其他部分；
每个位置拥有一个独特的position_embedding，好的向量可以训练得到；
这些token embedding在训练的过程中，没有考虑上下文的关系；但是在实际运用过程中，同样的单词或token在不同语境下可能有不同含义；
架构
大多数的 transduction model 都具有encoder-decoder结构

Encoder会构建一个输出序列到连续的中间表示序列的映射
在某一时刻，对于给定的,Decoder 将产生输出序列
Transformer通过逐步堆叠自注意力层，将Encoder和Decoder全连接


Encoder
Encoder模块堆叠个相同的layer.每个layer有两个sublayer.

子层1:Multi-Head Attenion；
子层2:feed-forward network.

在进入下一个子层前，使用残差连接(residual connection)和层正则化(layer normalization)
处理后，加上原来的输入，换言之，每个子层的输出为

所有的子层输出维度为，这样做有利于残差连接；
Decoder
Decoder模块同样堆叠个相同的layer.每个layer有3个sublayer.

子层0: Mask Multi-Head Attention
子层1:Multi-Head Attenion；
子层2:feed-forward network.

类似于Encoder，每个子层的输出都嵌套了残差连接和层正则化运算；
在进入多头注意力层之前，需要添加一个掩码层，这样做是因为考虑到输出的embedding 偏离了一个位置，确保位置i上的预测只依赖于该位置之前的已知输出；
Position-wise FFN
在encoder和decoder后独立添加了相同的全连接的前馈神经网络，包含了两层线性变换和一个ReLU激活层,FFN输入输出层维度为，内部层维度为;

Embedding
类似于其他序列模型，使用Embedding将输入和输出token转化为维度的向量，并使用线性变换和softmax激活函数来预测下一个token的可能性；
在两个embedding层和pre-softmax层中间使用同一个权重矩阵，在embedding层，使用一个扩大了  的权重矩阵；
Position Encoding
由于放弃了RNN，所有必须在每个token注入位置信息，Transformer在encoder和decoder堆的底部采用position encoding层，维度都是使得它们可以相加；
Transformer选择了如下的位置编码的方式,这是基于模型可以容易地学习其他位置的信息；

这个函数有个独特的性质，可以表示为的线性表示；
Attention
Attention函数可以被描述为关于query,key,value向量的函数；Attention的输出是一类对value的加权平均，权重通过query相关的key的匹配程度计算；

记为key向量的维度，为value的维度，下式描述了左边的缩放点积注意力机制

加性注意力机制和点性注意力机制是流行的注意力计算方式；

点性注意力机制：计算更快，效率更高，因为矩阵乘法已经被高度优化了，被transformer借鉴
加性注意力机制：复杂度相近，计算单隐藏层的前馈网络

Transformer采用多头注意力机制(Multi-Head Attention)，将query，key，value划分为个线性部分，维度为，每个部分的计算是并行的；最后将计算结果拼接(concat)；

其中

本文取;
Transformer在三个地方采用注意力机制

encoder-decoder attention层中，query来自前一个decoder，而key和value来自encoder的输出，这使得decoder的每个位置都有来自先前序列的贡献，这是典型的encoder-decoder机制；
encoder包含一个自注意力层，key, value,query都来自上一个encoder的输出，encoder每个位置都可以处理编码器上一层的所有位置；
decoder包含的自注意力层也可以实现decoder每个位置都参与对当前位置之前的所有位置，为了防止信息向左流动，以保持auto-regressive属性，通过在缩放点注意力层，设置掩码()屏蔽来自softmax输入中非法连接；

这种自注意力机制有三个方面的优势

总计算复杂度降低
可并行化计算
解决在transduction tasks中长程依赖(long-range dependency)的挑战，输入输出序列的位置组合路径越短，长程依赖越容易学习

Other Tricks

翻译任务表现：在WMT2014英德翻译达到28.4 BLEU，英法翻译41.0 BLEU，训练耗时仅为3.5天（8 GPU），成本低于主流模型5-20倍
训练优化：采用Adam优化器（, ）、标签平滑（）和动态学习率调整;
位置编码对比：学习式嵌入与正弦编码效果相当，但后者支持更长序列外推
多头注意力有效性：8个头时性能最优，过多或过少均导致质量下降

]]></content>
      <tags>
        <tag>papers</tag>
        <tag>Machine-Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Tree</title>
    <url>/2025/07/05/Tree/</url>
    <content><![CDATA[树&amp;森林
若一个连通图没有圈，称这个图为树(Tree);
若一个图没有圈，称这个图为森林(forest);
Theorem
若树至少有个点，那么至少包含2个叶子结点；
proof:取最长路的两个端点；
Theorem
对于含有个结点的简单图，以下命题等价：

是一棵树；
有条边且没有圈；
有条边且连通；
连通，且每条边都是桥；
中任意两个点有且仅有一条路径；
没有圈，但是任意添加一条边恰好形成一个圈；

proof:
:归纳，删去叶子
:归纳，每个连通分量无圈，说明分量是树，统计边发现只有一个连通 分量；
:只需证个点的连通图至少有条边，归纳，删叶子即可；
:由连通性至少有一条，若存在两条，则这两条路径上的边不是桥，矛盾；
:若有圈则任意两点至少两条路径，矛盾；加一条边至少形成一个圈，若多余1个，说明原图有圈，矛盾；
:反证，若不连通，每个分量是树，在分量之间添加一条边无法形成圈，矛盾；
Corollary
若图是一个森林,则
Spanning Tree
图的生成子树(spanning tree)是指图的一个生成子图，这个子图是树；
对于连通图,一定包含一个生成子树；定义陪树(cotree)为中去除得到的图；
对于一个具有个顶点，条边，个连通分量的图,通过删除图中任意一条边，直到没有圈剩下，得到的图是图的一个生成森林；

圈阶:在这个过程删除的边数
键阶:最小边割的边数;

对与连通图和其生成子树，
定义子树的键基本集(bond fundamental set)：删去子树将图划分为两个顶点集，连接的所有边构成图的键，通过这种方式获得的键的全体构成基本集；
类似定义子树的圈基本集(cycle fundamental set)
Theorem
对于图的任意生成子树,有

图的任意键和至少有一条公共边；
图的任意圈和的陪树至少有一条公共边；

proof:取是图的键，删去将图分成两部分，一定有边连接这两部分，这条边一定属于键；若圈和陪树没有公共边，那么圈一定包含在中，矛盾；
Prufer序列
给定由个数构成的集合，记是定义在上的一棵树；
定义的Prufer编码,是长度为的序列，显然；
编码算法如下：

维护的叶子集合;
在第步，找到中标号最小的叶子, 令是叶子的父亲；
更新；若因为删去成为叶子，
直到只剩下一条边，停止；

解码算法如下：

维护未加标记点集和未使用的编码点集,初始化，初始化图为个孤立点
准备第步，取出,此时,中至少有2个点不会出现在中，即;
取为中标号最小的顶点，添加到，标记，(即从位开始，指针右移)；
重复2，3一共次，剩下两个未标记的顶点，连边并加入;

举例：以下树的Prufer编码为[6,5,6,5,1],发现编码删边的顺序和解码加边的顺序相同；

Theorem(Caylay)
对于个顶点，一共有个不同的标号树；
proof:只需要证明树作Prufer编码和解码，依然得到树,完成双射，归纳即可（删去第一个叶子后采用归纳假设）；
Corollary
有个生成子树；
矩阵树
定义连通图，定义其生成子树的数量为;记其Laplacian矩阵为；
对于图和其中一条边，定义其缩边为合并的两个顶点为一个顶点，原来和两个顶点关联的边都和新顶点相关联；
Theorem
若且不是自环，则

为此只需证明的生成树和中包含的生成树之间可建立双射即可；

Theorem
假设是从中删除行列得到的矩阵，则生成树的数目等于的任何余子式的值；

proof:为此只需证明的情况
树中的最优化问题
The Connector Problem
将建立连接多个城镇的铁路网。考虑到在城镇和之间建造直接连接的成本，设计这样的网络以最大限度地降低建设总成本;
这个问题可进一步形式化描述如下：
给定一个连通加权图，如果的边权之和不超过的任何其他生成树之和，则生成树称为最小权重生成树,现需要找到图的最小生成子树权和；
Kruskal算法
Kruskal算法用于解决一类稀疏带权图的最小生成树问题,这是一类基于添加当前最优边的贪心策略；

初始化，,对边权值排序；
若下一条权值最小的边将的两个分量连接起来，则，否则丢弃它；
迭代总共步加边操作，此时变得连通；


Kruskal算法最优性证明：
假设Kruskal生成树，其一定不包含圈，否则一定存在某次加边操作，没有连接两个分量而是在某一个分量内部连接；
假设最小代价树，边排序后，考虑它们不相同的第一条边;将产生圈，取,那么是比更小代价的生成树，矛盾；
数据结构实现：
顺序迭代边可采用优先队列（堆）；
为每个顶点记录包含的连通分量标号，初始为其序号；
对于选用某条边时，应该有，否则被弃用；
添加边后，应该更新;
时间复杂度应为;
或是维护边的并查集
Prim算法
Prim算法用于一类稠密带权图的最小生成树问题，这时一类逐步归并顶点的策略；

任意选择树的根节点，初始化已包含顶点集,树;
选择连接和中的边权值最小者,更新;
重复添加顶点，直到;

Prim算法最优性证明：
假设Prim生成树，其一定不包含圈，因为每次加边操作都是在不相交的集合中选择的；
假设最小代价树，边排序后，考虑它们不相同的第一条边;取,由的最小性，，由算法最小性;
数据结构实现：
存取图使用邻接表,采用斐波那契堆优化，可达到;
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Graph-Theory</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown 写作规范</title>
    <url>/2025/06/22/markdown-%E5%86%99%E4%BD%9C%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[这是一个一级标题
本主题按照本人使用的 Typora 编辑器风格定制，旨在打造一款轻量级的TeX样式。
本主题改编自 Typo。
这是一个二级标题
如果你使用本主题，作者建议按照如下规则组织你的写作：

中英文混杂时，应该确保中间有空格，不直接连接。如果有连接的必要，使用   语法。

这是一个三级标题


本主题的数学公式采用内联公式使用$ symbol $， 块内公式使用&lt;br&gt;$$&lt;br&gt; formular &lt;br&gt;$$&lt;br&gt;的格式，即内联公式和前后的字符应该有一个空格，块内公式的标志应该另起一行；


不建议在无序列表中嵌套两次以上


]]></content>
      <tags>
        <tag>Musings</tag>
      </tags>
  </entry>
  <entry>
    <title>下推自动机</title>
    <url>/2025/06/20/%E4%B8%8B%E6%8E%A8%E8%87%AA%E5%8A%A8%E6%9C%BA/</url>
    <content><![CDATA[下推自动机
下推自动机(Pushdown Automaton, PDA)是一种带有栈存储器组件的有限自动机；
它比有限自动机更强大，因为栈提供了无限存储能力；
构造PDA可识别一类CFL，CFG和PDA对CFL的表达上是等价的；二者可以互相转化；
形式定义
一个PDA可由六元组定义

其中：

有限状态集: 全体状态构成的集合
输入字母表: 所有可能的输入字母；
栈字母表: 所有可能进栈的输入字母；
转移函数
初始状态: 状态机的初始状态；
终态集: 为状态机最终接受的状态；

工作原理

PDA假设从初始状态开始，开始符为, 栈底符，输入指针指向输入串的第一个符号；
任意时刻，假设下推栈的栈顶符号,当前的输入符号为，PDA可以：

读取输入符号
查看栈顶符号
改变状态
修改栈（压入或弹出符号）



转移函数
称自动机接受单词流 若存在状态序列和字符串序列,满足

接受一个单词流意味着序列中每个状态转移都是合法的；
转移函数的形式为：

对于一个自动机内部的合法的状态转移(transition)，可被描述为根据当前状态读取(read)输入后，决定弹出(pop)栈的元素，并选择进栈(push-in)的元素，进入下一个状态的过程，简记为a,b-&gt;t;

当前状态
输入符号a（可以是）
栈顶符号b
新状态
要压入栈的符号串c

PDA有两种接受方式：

终态接受：当输入串读完且PDA处于终态时接受
空栈接受：当输入串读完且栈为空时接受

确定性PDA
如果PDA的转移函数满足：

对于每个状态、输入符号和栈顶符号，最多有一个转移
对于每个状态和栈顶符号，如果有转移，则不能有其他转移

则称该PDA为确定性的(DPDA)。
示例
识别语言的PDA：

状态集：
输入字母表：
栈字母表：
初始状态：
初始栈符号：
终态集：

转移函数：







]]></content>
      <tags>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>二元关系</title>
    <url>/2025/07/05/%E4%BA%8C%E5%85%83%E5%85%B3%E7%B3%BB/</url>
    <content><![CDATA[集合定义
序偶(ordered pair)：两个元素按照一定的次序组成的二元组；



重有序组：个元素按照一定的次序组成的元组
笛卡尔积(Cartesian product):对于集合，笛卡尔积为如下集合


不满足交换律：，但是
;
;


关系(relation):对于非空集合, 称是从到的二元关系，如果是的一个子集；

空关系：;
恒等关系：
全关系：
对有关系：
所有可能的关系有个

元关系：的任意子集；
对于间的二元关系;
若且

定义如下概念：

前域
后域
定义域
值域
域

关系图和关系矩阵
关系可以用关系图表示

若关系定义在不同的集合：用带箭头的二部图表示，由前域指向后域；
若关系定义在某一个集合：用可能有向图表示，可能有自环和重边；；

称为关系的关系矩阵(邻接矩阵)，如果

显然这是一个Bool矩阵，对于是的Bool矩阵：


并



交



布尔积



关系表
在关系代数理论中，关系可以用二维表表示；
对于关系,第个属性代表,每一个行/表项为中的元素；
复合运算
对于非空集合，：,称一个从到的关系是复合关系，如果










逆运算
对于非空集合，,的逆关系是指









逆关系的关系矩阵等于原关系的关系矩阵转置；
幂运算
对非空集合,定义关系的次幂如下：

；
;


注意到，幂集随着增加呈现递减趋势，得出如下定理：

proof:只需证明,注意到定义缩减没必要的复合运算即可；
性质
对于定义在一个集合上的关系，我们考察其自反性，反自反性，对称性，反对称性和传递性；
如果对，都有,那么称在 上是自反的，关系图上表现为每个结点有自环，关系矩阵上表现为主对角线上全部为1；

是自反的

如果对，都有，那么称称在 上是反自反的；关系图上表现为每个结点都没有自环，关系矩阵上表现为主对角线上全部为0；

是反自反的

如果对，都有,那么称在 上是对称的;关系图上表现为任意两个结点要么没有边，要么有两条反向边，关系矩阵上表现为对称矩阵；

是对称的

如果对，都有,那么称在 上是反对称的;关系图上表现为任意两个结点至多一条边，关系矩阵上表现为矩阵自交为0；

是反对称的

设是非空集合上的关系．对，如果＜＞＜＞，那么＜＞，则称关系是传递的;关系图上表现为每个结点有自环，关系矩阵上表现为必有；

是传递的

对于定义在集合上的二元关系,考察其保守性：逆运算和交运算保守性好，并，差和复合运算的保守性差；

若具有自反性，则具有自反性；
若具有反自反性，则具有自反性；
若具有对称性，则具有自反性；
若具有反对称性，则具有自反性；
若具有传递性，则具有传递性；

关系闭包
在给定关系添加尽可能少的元素，使关系满足特殊性质，这个过程称为关系闭包；
形式化说，对于定义在非空集合上的关系，若存在定义在上的另一个关系,使得,且满足

是自反的/对称的/传递的
对于任何自反的/对称的/传递的关系,若,必有;

称为的自反闭包(reflexive closure)/对称闭包(symmetric closure)/传递闭包(transitive closure),记作;
闭包运算算法：

等价关系
称定义在非空集合上的关系为等价关系，若具有自反性，对称性和传递性；
给定非空集合,称集合构成集合的一个划分(partition),称作划分的类(class),若





利用等价关系可以将集合划分成互不相交的子集,也即等价类；
对于定义在集合上的等价关系,对,称集合

是生成的关于的等价类(equivalence)，为该类的代表元(generator);
简单来说，在等价关系中，所有与有关系的元素处于同一个等价类中，不难观察以下结论成立

对
对, 若，则;若,则;
;

进一步定义集合关于等价关系的商集

商集算法如下：

若非空，选取,计算并加入到中；
若，更新,回到1；

显然商集是对的等价划分，由划分也可以生成一种等价关系，如下：
定集合的一个划分，，则由该划分确定的关系

是上的等价关系,称该关系为由划分所导出的等价关系;
序关系
称定义在集合上的关系为拟序关系，如果是反自反的，反对称的和传递的，记作小于;
序偶称为拟序集，改记为,其逆关系大于为也是拟序关系；
称定义在集合上的关系为偏序关系，如果是自反的，反对称的和传递的，记作小于等于;
序偶称为偏序集，改记为,其逆关系大于等于为也是偏序关系；
规定偏序关系对应的哈斯图(Hasse diagram)如下：

用小圆圈或点表示中的元素，省掉关系图中所有的自环;
对于，，若且，则将画在的下方，可省掉关系图中所有边的箭头;
对于，，若且，且与之间不存在，使得，，则与之 间用一条线相连，否则无线相连;


是偏序集，是的任何一个子集，若存在元素，使得

对，都有，则称为的最大元;
对，都有，则称为的最小元;
对，满足 ，则称为的极大元;
对，满足，则称为的极小元.

若存在元素，使得

对，都有，则称为的上界（upper bound）;
对，都有，则称为的下界（lower bound）;
设元素是的一个上界，对的任何一个上界，若均有，则称为的上确界.记为 ;
设元素是的一个下界，对的任何一个下界，若均有，则称为的下确界.记为 ;

进一步有以下结论：
是偏序集，是的任何一个子集

若最大元存在，则同时是极大元，上界，上确界；若中的一个上界，则是的最大元；
若最小元存在，则同时是极小元，下界，下确界；若中的一个下界，则是的最小元；

对于有限子集,最大元/最小元若存在，则一定唯一，且是唯一极大元/极小元；若上确界/下确界存在，则上确界/下确界唯一；
对偏序关系来说，若，总有或其一成立，则为全序关系/线序(linear order)；
为全序集，其哈斯图表现为一条线；
对偏序关系来说，若中任意非空子集均有最小元，则为良序关系(well order)；
为良序集，良序关系一定是偏序关系，反之则不然，良序关系一定是全序关系，反之则不然；
函数
称关系为集合到集合的函数/映射(function/mapping)，记作,若对于每个,存在唯一的, 使得;

定义域;
值域;
改记为,自变量为，函数值为;

即任意可能的输入集合对应输出集合；
称是从到的单射(injection),若对于,均有;
称是从到的满射(surjection)，若,即对,；
称是从到的双射(bijection)，若既是单射又是满射；
当双射定义在上时，称是集合上的变换(transform)；
若函数,称是上的恒等函数;
若函数,称是上的常值函数；
若定义为全集的一个子集，则子集的特征函数定义为

若变换定义在有限集合上，则称为上的置换/排列(permutation),称作置换的阶(order),通常如下表示：

不同置换个数为个；
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Discrete-Mathematics</tag>
      </tags>
  </entry>
  <entry>
    <title>信息检索概述</title>
    <url>/2025/07/02/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[什么是信息检索

给定用户需求返回满足该需求信息的一门学科。通常涉及信息的获取、存储、组织和访问。
从大规模非结构化数据（通常是文本）的集合（通常保存在计算机上）中找出满足用户信息需求的资料（通常是文档）的过程。
通常需要定义并计算某种匹配“相似度”的学科。
应用：搜索系统，推荐系统

分类


第一类是广义的，把“信息检索”当作“信息存储与检索”的简称，信息存储是指将有用信息按照一定的方式组织和存放起来，信息检索是指查找或提取所需信息。本课程介绍广义的信息检索。
第二类是狭义的，是指按照一定的方式从现有的信息集合或数据库中，找出并提取所需要的信息。


按对象性质划分：
文献检索：对象是文献。
数值检索：对象是以数字形式表示的具体数值。
事实检索：对象是某一特定的客观事实。


按计算机检索技术划分
脱机检索：计算机检索的最早技术。
联机检索：功能较强、数据库质量较好。
光盘检索：分光盘单机系统和联机系统。
网络检索：基于搜索引擎技术，是信息检索的主要途径。


原理
核心问题
如何计算查询式与文档的相似度？

逻辑结构
两大基本功能：存储，检索
按功能分解子系统：采选子系统、词语子系统、标引子系统、查询子系统、匹配子系统、交互子系统。


采选子系统：从外部的各种信息源向系统进行输入操作；
标引子系统：使用系统规定的规范化词语，对输入的信息中具有检索价值的特征进行表示和描述；
词语子系统：对采用规范化词语的系统在标引和查询时所使用的词语进行规范化的控制和处理；
匹配子系统：完成对用户询问与数据库的匹配过程，并与词语子系统共同实现对信息检索系统的存储与检索两大基本功能的协同和沟通。
查询子系统：使用系统规定的规范化词语描述用户的检索询问，包括对用户询问进行概念分析和概念转换两个过程，也包括按照系统的既定规则指定检索策略和构建检索式。
交互子系统：保证系统与用户之间能够进行良好的沟通。一方面，要全面、准确地反映用户的真实需求，形成明确的检索目标；另一方面，把与用户查询全部或部分匹配的检索结果及时地反馈给用户。

研究内容

信息检索理论研究：主要集中在四个方面：检索模型、标引理论、信息组织理论、相关性理论。
信息检索方法研究：检索方法是指查找信息时所采用的具体方法，例如，布尔检索法、截词检索法、加权检索法。
信息检索技术研究：检索技术是实现信息检索有效性的手段和保障。
信息检索语言研究：检索语言是信息检索系统不可缺少的工具，是用户与系统交流、互动、沟通的媒介。
信息检索系统研究：主要包括信息检索系统的结构、功能、类型、分析、开发、运行、维护、管理及评价。
信息检索服务研究：通常包括用户及其需求的类型以及用户认知、心理行为等特征的调查、分析、研究，各种服务方式和模式的开发及对其实际效果和用户满意度的评价，用户认知和行为模型的建立等。
信息检索评价研究：
通常包括检索性能评价、检索效益评价、检索评价方法与步骤、检索评价指标体系以及评价实例研究等。

]]></content>
      <tags>
        <tag>Information-Retrieval</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>常见分布的数字特征</title>
    <url>/2025/07/05/%E5%B8%B8%E8%A7%81%E5%88%86%E5%B8%83%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/</url>
    <content><![CDATA[退化分布(单点分布)
若随机变量只取常数,即

则并不随机，但我们把它看作随机变量的退化情况更为方便，因此称之为退化分布，又称单点分布.
离散均匀分布
若随机变量的分布律为

则称之为离散均匀分布，记作​.
Property

特征函数


Bernoulli分 布
若 随 机 变 量的分布律为

则称之为离散均匀分布，记作Ber.
设事件出现的概率为,则为一次伯努利试验中​出现的次数.
Property

特征函数


二项分布
若随机变量​的分布律为

则称之为以和为参数的二项分布，记作.
设事件在每次试验中出现的概率均为,且每次实验相互独立，则为重伯努利试验中事件​出现的次数.
Property

特征函数


几何分布
若随机变量的分布律为

则称之为几何分布，记作Geom.
在伯努利试验中， 设事件在每次试验中出现的概率均为,则为事件首次出现时的总试验次数;
Property

特征函数


Poisson分 布
若 随 机 变 量 的分布律为

其中,则称服从Poisson分布，记为Poi​
Property


特征函数



数学期望



方差



负二项分布
对于任意实数,若随机变量的分布律为

则称之为负二项分布，记作​。
Property

特征函数


在伯努利试验中，设事件在每次试验中出现的概率均为,则为直到事件成功次时，试验的总失败次数。
负二项分布通常用于替换Poisson分布。同Poisson分布一样，它也在非负整数上取值，但因为它包含两个参数，相比Poisson 分布其变化更灵活。Poisson分布的方差和均值相等，但负二项分布的方差大于均值.
Property

特征函数


连续均匀分布
如果的概率密度为
若其他
其中,则称之为区间上的(连续)均匀分布，记为​
Property

特征函数


正态分布
如果的概率密度为

则称之为参数为和的正态分布，也称为高斯分布，记为​
Property


若随机变量X服从正态分布,其中,的​阶原点矩
当为奇数时当为偶数时
 
    证明
    $E(X^k)=(k-1)E(X^{k-2}),E(X)=0$



特征函数



指数分布
如果的概率密度为

则称之为指数分布，记为Exp​
Property


特征函数



分布函数



数学期望



方差



卡方分布
如果的概率密度为

为正整数，则称之为自由度为的卡方分布，记为​
Property


特征函数



数学期望

方差



Γ 分 布
若的概率密度为

, , 则称服从形状参数,反尺度参数的分布，记为.






如果,对任意的


如果Exp,则


如果,则 


如果相互独立同分布且服从参数为的指数分布，则


分布函数



特征函数



多维正态分布
设,是阶正定对称矩阵,并且其行列式为.如果的联合概率密度为

则称之为维正态分布,记为
Property


特征函数



若,则X的任一线性函数 服从维正态分布


若,则  


设,并且与相互独立，则

其中均值,协方差矩阵


服从维正态分布当且仅当其任意非零线性组合

服从正态分布,其中不全为零.


特别的，对二位联合正态分布，其联合概率密度为

其中相关系数


]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Random Process</tag>
      </tags>
  </entry>
  <entry>
    <title>信息检索模型</title>
    <url>/2025/07/02/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[形式特征
检索策略=文档表示+查询表示+匹配函数

文档表示：反映文档在系统中的存储形式描述，可用一组关键词或标引词表示；
查询表示：反映对用户信息需求的描述；
匹配函数：用于将经过处理的文档表示和查询表示放入系统中进行匹配，以过滤输出结果；

这样的模型主要从两个方面抽象出信息检索的方法：

如何表示文档，检索式
确定和计算 文档和检索式的关系

信息检索的任务就是建立文档，查询和它们的匹配函数之间的数学模型；
一般地，我们将信息检索用如下四元组表示：


是文档集中的一组文档逻辑视图（表示），称为文档的表示；
是一组用户信息需求的逻辑视图（表示），这种视图（表示）称为查询；
是一种机制，用于构建文档表示、查询及它们之间关系的模型；
，是排序函数，该函数输出一个与查询文档表示有关的实数，这样就在文档之间根据定义了一个顺序。


分类

经典模型：

布尔模型:模糊集合模型，拓展布尔模型，粗糙集模型...
向量模型:广义向量模型，潜语义标引模型，神经网络模型...
概率模型:概率粗糙集模型，推理网络型，信任度网络模型...


结构化模型

非重叠化链表模型
邻近节点模型
扁平浏览模型
结构导向模型
超文本模型



经典模型
标引词：每篇文档都可以用一组有代表性的关键词来表示，属于文档中的词语；
对于经典模型一般都有如下的数学表示：

系统中的所有标引词集合为;
文档用表示,所有文档集合；
权值用于衡量二元组标引词的重要性,通常认为是独立的；
文档也可以用一个标引词向量表示
函数用于返回文档中标引词的权，

布尔模型
概念
BM假定标引词要么在文档中出现，要么不出现，权值是二值数据，也即;
对于查询是一个常规的布尔表达式,由连接词非，或，与连接多个标引词组成；

查询的析取范式为
的任意合取分量为

文档和查询的相似度可以定义为

优点

查询简单，易于理解，易于实现
经过某种训练的用户可以容易地写出布尔表达式
可以通过扩展来包含排序的功能

缺点

布尔逻辑式的构造不易全面反映用户的需求
不适合普通用户
检索结果不能按照用户定义的重要性排序输出
不支持部分匹配，构建不当，检索结果过多或者过少

优化

半结构化检索：仅在标题，摘要等检索项目
检索对半结构化的语义位置起作用,比如说标引词出现在标题一定比出现在正文要重要
增加proximity操作符，指定项的距离

向量模型
概念
VSM对检出文档按相似度降序排列的方式，实现文档和查询的部分匹配
模型的构建由四部分组成：

文档向量的构造
查询向量的构造
查询与文档的匹配函数选择
相似度阈值的选择

在VSM中标引词在文档的权重是非二值的,对于所有的特征项，文档和查询可以表征为如下的向量

可抽象为如下过程：

二者的相似性一般用内积或余弦相似度衡量,夹角越小说明相似度越高；

根据计算的相似度，可以对检索结果进行排序，进一步作相关检索

排序后的结果与设定的相似度阈值比较
大于阈值说明文档和查询相关，保留查询结果；
小于阈值说明不相关，过滤此页；

TFIDF函数
从文档，查询到向量的映射需要计算特征项权重，TFIDF函数用于解决这一问题，通过词语加权和聚类实现；
将文档看作对象集,用户查询看作的模糊描述，这样信息检索被描述称一个聚类问题；这样的问题有两个重要特征

Intra-clustering:描述内部聚类的相似度
Inter-clustering:描述交叉聚类的相异度

一个好的聚类算法应该使二者达到平衡；
TF(Term Frequency)因子：

用文档中的词语的初始频率衡量
用于度量标引词描述文档内容好坏的程度；

IDF(Inverse Document Frequency)因子：

用文档中的词语的逆频率衡量
该因子说明许多文档出现的词语对于区分相关文档和不相关文档是没有作用的；

对于一个信息检索系统：

文档总数为;
包含标引词的文档数目为;
标引词在文档的被提及的次数(初始频率)为;
所有词语的最大初始频率值为

定义在文档中，标引词的标准化频率为


如果词语不出现在文档中，则
对于查询，类似定义

定义词语的逆文档频率为

著名的词语加权方案为

对于查询词语的权值，可以用如下方法：

优点

标引词加权改进了检索效果
部分匹配策略可以检索出与查询条件相近的文档
可以根据文档与查询之间的相似度对文档进行排序

缺点


没考虑特征项出现在文档的位置

特征项在文档中不同位置应该代表不同权重
这样的计算方式甚至可能导致出现标题的词语的权重比摘要、正文更低，与我们的经验相违；



没考虑关键词的长度

关键词长度越长，在文档中出现的概率越小，但是较长的关键词比较短的包含了更多的信息；
关键词出现在较短的文档的权重理应要高
如果同一特征项在不同文档出现次数不同，在出现频率较高的文档中权重应该较高，而不是统一的1；



没考虑标引词之间的相关性

在VSM中，标引词被认为相互独立



对于动态变化的文档集，查询性能降低

没增加一个文档需要重新计算向量



概率模型
对文档与查询相匹配的概率进行估计，估计值作为衡量文档相关性的尺度。
概率排序原理：给定一个用户查询，如果搜索系统能够在搜索结果排序时按照文档和用户需求的相关性由高到低排序，那么这个搜索系统的准确性是最优的。
对于给定的用户查询,按照查询将文档聚类为2类：；

对于任意的文档,根据Bayes公式，与其相关/不相关的概率表示如下：

二元独立模型
标引词独立性假设：任意一个标引词的出现不会影响到其他标引词的出现，他们相互独立
二元属性取值：对于任意的文档可表示为元随机变量,若在中出现，值为1,否则为0；

预先使用一定数量带有相关性标记的文档，用最大似然估计法确定


一般难以预先给出带有标记的文档集，可以利用反馈技术获取标记文档：先再用其他检索技术标记；
定义文档和检索排序函数

取对数重新表示

这种假设往往不符合实际情况，因为标引词往往具有相关性；
双Poisson分布概率模型
文档的单词可分为两类：

内容词：与表达文档的主题有关
功能词：只完成语法功能

其中内容词概率分布波动情况近似泊松分布：用表示某个功能词在文档中出现的频率

Harter假设

根据一个内容词可以将文档从主题上分为两类，同时该内容词在两类文档中的出现频率也会很不相同
一类文档的主题与该内容词相关，那么该内容词在其中的出现频率应该比较高，其波动特征可以用一个泊松分布表示；
而另一类文档的主题与内容词不相关，所以内容词在其中的出现频率应该比较低，其波动特征也可以用一个泊松分布表示。

一个内容词在文档中的出现频率可以表示为两个泊松分布的加权组合：

其中，分别为内容词在两类文档中出现频率的均值，表示了任意一个文档属于第一类的概率;
只要将所有的标引词看作是内容词，则它们也满足2-Poisson模型，则就形成了双Poisson模型。与二元独立模型相比，2-Poisson模型的不同在于不承认标引词独立性假设，其余都相同。
优点

利用概率论原理，通过赋予索引词某种概率值来表示这些词 在相关文档集合和非相关文档集合中出现的概率，然后计算某一 给定文档与某一给定用户提问相关的概率并做出决策
具有内在的相关反馈机制，将文档根据它们的相关概率按 递减顺序排列

缺点

最初需要把文档分成相关的集合和不相关的集合
这种方法并不考虑标引词在文档中出现的频率，即所有的权值都是二值的
假设标引词相互独立，然而如同VSM一样，这并不能明确 标引词的独立性在实际情况中是否为一个不利的假设

集合理论模型
模糊集合模型
模糊集合理论
模糊集合理论主要研究边界不明确的集合的表示。

把隶属函数和集合中的元素结合在一起。
该函数的取值在区间[0,1]上，0对应于不隶属于该集合，1表示完全隶属于该集合，隶属值在0和1之间表示集合中的边际元素。

将每一个查询语词定义成一个模糊集合，论域的一个模糊子集可以用隶属函数来描述，为的每个元素分配一个数值，该数值在区间上。
检索时通过匹配运算，计算每篇文档在查询中的标引词所定义的模糊集合中的隶属度，并根据隶属度大小对文档排序。
标引词关联矩阵
叙词表可以通过定义一个词-词关联矩阵来构建，这个矩阵的行和列分别对应于文档集合中的标引词。
在矩阵中，语词和之间的标准化关联因子可以定义为：

表示包含语词的文档的数目，表示包含语词的文档的数目，表示同时包含语词、​的文档的数目。
对于标引词,对文档的隶属度定义如下：

只要文档中至少有一个标引词与密切相关，则接近1，且标引词是文档的一个很好的模糊索引；
只要文档中所有标引词与不是密切相关，则接近0，且标引词不是文档的一个很好的模糊索引；
和布尔模型一样，模糊集合模型也会将查询转换为析取范式

计算文档与查询相关的过程类似于采用经典布尔模型进行比较的过程。
其区别在于：此处的集合是松散的集合而不是布尔集合。

优点

模糊集合模型与经典布尔模型关系密切，它基本保留了布尔检索功能，但是更为灵活，避免了布尔检索的二值相关性测度局限性。
模糊集合模型支持对命中文档按相关性大小排序。

缺点

模糊集合模型仅局限于小规模的文档集合，相关实试验结果的可比性差。
它的研究工作主要集中于模糊学领域的文档中，在信息检索领域的研究并不广泛

拓展布尔模型
用部分匹配和语词加权功能来扩展布尔模型，可以使布尔查询表达式与向量模型的特征结合在一起。


文档,其中第个标引词的权值为​


对于检索式,其中第个标引词的权值为​



定义文本和查询的相似度为

粗糙集模型
在粗糙集理论中，

一个等价关系将一个非空集合划分成互不相连的等价类，根据这个关系等价类中的对象是不可区分的。
全集和等价关系一同定义了一个近似空间，等价类和空集被称为这个近似空间的基本集或原子集。这样一个近似空间可以用来描述全集的任意子集
不需要先验知识，就可以从数据中获取潜在依赖规律

设是划分非空全集的一个等价关系


近似空间为;


一个划分被定义为 ，这里是的一个等价类


对于的任意一个子集,定义下近似集，上近似集



上近似集和下近似集近似描述了近似空间中的子集，粗糙集就可以用这两个近似集来描述;
边界定义为在上近似集中，但不在下近似集中的元素集合；
利用粗糙集将词汇建模：

该模型是将给定范围的单词（单个词汇和段落）当作全集，表示等价关系定义为字眼的相似关系
对产生一个划分，这样一个类中的字眼彼此都是同义的，用向量来表示文本和查询
文本和查询是全集的子集，分别求出它们在近似空间中的上、下近似集;
下近似集中的属性确定地描述了子集，而上近似集中的属性可能地描述了子集;
这些确定性和可能性当然很大程度上是由近似空间决定的，因此，下近似集自动向核心描述靠近，而上近似集在词汇空间允许的范围内扩大了描述。;

文本和查询的相似度计算：
定义全集的两个中心和拓扑意义上的边界差后

计算

保持为中心，如果上式为0，表示不匹配，上式为1，表示和的最大匹配；
优点：

无须提供问题所需处理数据集合之外的任何先验信息，粗糙集理论对不确定性的描述相对客观；
只处理离散性属性，连续属性的离散化使得粗糙集理论对离散和连续属性都能够处理，扩大了该理论的应用范围。

缺点：

存在局限性，不能使用用权值描述的文本和查询
不能利用除了同义词之外的字眼关系。

代数模型
广义向量空间模型
对于经典模型认为标引词相互独立，可以理解为标引词向量两两正交，​；在实践中，我们并不能将标引词向量当作向量空间的正交基；
最小项: 布尔代数，，，上由产生的形如

的布尔表达式称为由产生的最小项
其中,定义;最小项不能进一步简化，因此布尔代数的基本元素可用如下向量唯一确定：

对于每一个标引词，可以表示称基本元素的析取式；
定义标引词的向量

定义文档和查询为

可以用余弦相似度计算，最后文档按照相似度大小降序输出；
潜语义标引模型
基本思想：

将标引词之间、文档之间的依赖关系以及标引词与文档之间的语义关联都考虑在内，将文档向量和提问向量映射到与语义概念相关联的较低维空间中，从而把文档的标引词空间向量转化为语义概念空间。
在降维的语义概念空间中，计算文档向量和提问向量的相似度，然后根据所得的相似度把排列结果返回给用户。

关键词-文档矩阵
设表示具有个标引词，个文档的检索系统的关键词-文档矩阵，则

矩阵的每一个元素为关键词-文档的权值;权值的确定可以用TFIDF确定；
现对作奇异值分解（SVD），假设的秩;
可分解为三个矩阵的乘积：

矩阵的含义如下：

 :是由词-词关联矩阵导出的正交特征向量矩阵,称为的左奇异矩阵；
 :是由词-词关联矩阵导出的正交特征向量矩阵,称为的右奇异矩阵；
 :由奇异值组成的对角矩阵；

现在潜语义模型需要选取合适的值，保留前个最大的奇异值和相应的正交单位化的奇异向量，得到某种近似意义上的矩阵：

秩近似矩阵将文档的关键词向量空间转化为语义概念空间，且语义概念空间的维度;
因而，次要的术语区别就被忽略了，有相似用法的关键词，其向量也就相似，用法不同的关键词，对应的向量也就不相似，从而降低了同义词、多义词的影响，减少了冗余。
的选择是折中的;

首先，必须足够大，能包括所有的实数结构；
其次，又必须足够小，以便能忽略掉一些错误和不重要的描述细节。

对于两篇文档，现已进入维度为的降维空间

文档的相似度可以用列向量的内积表示；
标引词和文档相似度为;
为了对与用户提问相关的文档进行排序，我们通常把用户提问向量作为初识词-文档矩阵的一个伪文档向量;
计算文档向量与提问向量的相似度，并根据相似度的计算结果，把文档排列起来返回给用户。
优点：

选取合适的折中值降低了空间的维度，消除了标引词表示的描述的噪音
克服了多义词和同义词对检索的影响，提高了检索的精度；

神经网络模型
将检索模型看作一个神经网络如下图：

传播过程

由第一层的查询语词结点分别向对应的第二层文档语词结点发出信号；
文档语词结点又产生信息并向第三层的相关文档结点传送；
文档节点在收到文档词语节点发送的信号后，产生新的信号并返回到文档词语结点；
过程3将重复进行，直到信号不断衰减而终止。

分配查询语词结点的初始最大活跃值，也就是网络结点上的权值，可以用查询向量的2范数进行规范化

一旦信号到达文档语词结点，这些结点就直接向文档结点发出新的信号，这些信号已用规范化的文档语词结点的权值来衰减，同样规范化。
对到达文档结点的信号进行求和，在信号传播的第一个阶段之后，与文档相关联的文档结点的活跃值表示为

一般采用反向传播算法（BP）网络，或者或者遗传算法；
遗传算法：
模拟生物进化机制和遗传学原理，利用简单的编码和繁殖机制实现优胜劣汰的进化过程；
迭代一个大小为的群体，建立算子进行遗传和进化的操作，将适应度高的个体遗传到下一代

选择算子
交叉算子
变异算子

这种设计是基于自然选择的自适应算法，适合动态环境的应用，某种程度上提取用户兴趣模型也是一个优化问题；
遗传算法描述如下：

**初始化：**设置最大进化代数；随机生成个个体作为初识群体。
**个体评价：**计算群体中各个个体的适应度。
**选择运算：**将选择算子作用于群体。
**交叉运算：**将交叉算子作用于运算。
**变异运算：**将变异算子作用于群体。群体经过选择、交叉、变异运算之后得到下一代群体。
**终止条件判断：**若，则：,转到(2)，若,则以进化过程所得到的具有最大适应度的个体作为最优解输出，终止计算。

由于遗传算法存在某种随机性，因此发现用户没能正确表达的兴趣需求成为可能；
用户兴趣模型：定义一组含有权重的关键字描述用户的兴趣

对于一个描述关键字频率的文档向量；
向量的相似度仍然可以用余弦相似度描述
，
采用表示用户对文档的评分，则提取用户兴趣模型可看作使得

最小的优化问题；
针对于个体的变异算子有两种：

权值变异，即只改变个体中对应单词的权值；
单词变异，即个体中的单词和相应权值都改变。

两个个体通过杂交算子产生两个后代，杂交算子为：

随机从两个个体中选择两个基因点；
从这个基因点开始交换两者后面的基因，从而产生两个新的个体

算法中的个体基因必须唯一，也就是说在同一个体中每个基因单词都必须在个体中唯一，无论是杂交还是变异，都不能违背这一点。
拓展概率模型
概率粗糙集模型
概率粗糙集模型将条件概率关系和粗糙集理论结合，表示对象间的关联；
通过条件概率关系与模糊条件关系均用来表示对象间相似关系，而模糊条件概率关系代表了更一般化的情形。
对于非空有限论域,定义一个条件概率相似关系是指一个映射

对于是关于关于属性的模糊集，其关于的隶属函数为
一个模糊条件概率关系是指一个映射

对于,支持的对象集和被支持的对象集，也就是其被支持集和支持集分别定义为

由于条件概率关系满足自反性，因此

构成论域的一个覆盖；
对于论域的任意有限子集，可以定义其上下近似集

对于文档集,其标引词空间
同样将文档表示为向量;不同的是当分量的值定义在时，这就是文档的模糊标引词空间表示；
考虑定义在上的论域,定义论域的标引词对应的基本元素（等价类）为和标引词关于文档的隶属度;
我们需要寻找一个合适的分类粒度,用描述,定义标引词和文档的模糊条件概率关系和上下近似集，用于在标引词空间挖掘概念形成类空间

越大则分类粒度越小；
越小则分类粒度越大；

我们需要对文档作出模糊表示，这表明要构造文档论域上的一个模糊集；
先定义标引词关于模糊集的上下近似隶属度为

以文档论域为基础根据形成标引词概念空间，计算文档对象的近似集，再根据近似集隶属度定义计算每一标引词关于文档对象近似集的隶属度，从而得到文档近似集的模糊表示。
对于查询的上下近似集和隶属度，和文档类似；
查询和文档的上下近似关系采用Jaccard 相似度的计算方式，相加得到贴近度公式；

实现了查询和文档的上下近似集模糊表示后，可采用贴近度公式计算文档和文档间，文档和查询间的语义贴近度，最终排序输出；
推理网模型
将推理网模型分为两个部分

文档网络
检索网络


满足如下关系

网络中所有节点属于;
文档节点对应文档集合中的一个实际文档，其取值表示该文档是否被观察到。
表示节点对应文档的索引项，其取值表示某一文档是否包含该索引项。
每个文档节点与表示节点用有向边连接，强度用表示节点的条件概率表来表示。
检索网络以用户的检索需求是否被满足作为构成网络的因果关系，因此与文档网络的方向相反。
节点表示用户的信息检索需求，节点代表各种不同的检索方案，其取值表示该检索是否被满足。
不同节点的组合用于表示检索方案的不同表示方案，每种表示方案通过一批不同的表示节点来表示，每个节点的取值表示该节点是否被观察到。

将文档网络与检索网络结合在一起的是两者的表示节点各自构成的空间。这两个空间可以根据实际的应用背景，建立起多种映射关系;
这样信息检索过程转化为一个基于证据的推理过程；


指定文档变量的值为1，计算检索节点的后验概率后，换下一个文档；



根据后验概率对文档和相关度进行排序；


合并节点,用向量表示，计算相关度排序，将视作条件独立，变量值确定时，子节点相互独立

指定各项的不同取值，可以模拟多种检索模型。理论上来说可以综合多种检索模型的优点；
信度网模型
定义样本空间为文档集合中所有文档组成的索引项;定义概念为集合的一个子集;
用随机变量表示这些概念之间的关系

对于索引项，若其被一个概念包含值设为1，否则设为0；
每一个文档/查询可以看作样本空间的概念；

定义概念(全集为)对样本空间的覆盖度为其分布

定义检索和文档的相关程度为其覆盖度

选定一些基本概念

变量间的概率依赖关系构成Bayes网络；
结构化模型
非重叠链表模型
文档的整个文本划分成若干个非重叠的文本区域，并用链表连接起来。
由于将文本分为非重叠区域的方法有多种，所以会产生多种链表。

特点

各链表彼此独立，并且具有不同的数据结构。
同一链表中的文本区域没有重叠，不同链表中的文本区域可能重叠。
每个链表都对应一个独立的倒排文档，每个结构单元作为索引中的一项。与每个项相关的是一个文本区域的链表，表示文本区域在哪些文档中出现。
链表可与倒排文档合并，以表示文本中的单词。

由于文本区域是非重叠的，所以可以被提交的查询类型很简单：

选择一个包含给定单词的区域（不包含其他区域）；
选择一个不包含任何区域B的区域A（B属于一个不同于链表A的链表）；
选择一个不被包含于任何其他区域的区域。

邻近节点模型
模型允许在相同文档的文本上定义独立分层（非扁平的）索引结构。每个索引都有严格的层次结构，即由章、节、段、页、行所组成，这些结构单元通常称之为结点

每个节点指明了结构化单元（如章、节）在文本中的位置；

每个结点都与一个文本区域相关。
两个不同的层次结构可能会涉及到重叠的文本区域。
对于涉及不同层次结构的用户查询而言，所汇集的结果只能由来自其中一个层次结构的所有结点形成。

对于查询语言，可以为字符串检索的正则表达式，这个模型是表达和高效中的一个折中；
扁平浏览模型
当用户的兴趣不在于提交查询，而是浏览文档中感兴趣的内容时，可以称为用户是在对文档空间进行浏览而不是检索。
扁平浏览模型的思想是假设用户浏览一个扁平组织结构的文档空间。
扁平浏览模型的一个缺陷是：在给定的页面和屏幕上，可能没有关于用户所处上下文情况的任何提示。
结构导向模型
为了对浏览的任务提供更好的支持，文档可以被组织成为像目录那样的结构。
目录是类的层次结构，将文档按照相关主题来分类和组织。用户可以根据目录执行一个具有结构导向的浏览。
除了用于浏览任务导向的结构外，界面也可以提供一些其他的工具如历史地图，用来指明最近访问过的类，这对于浏览结构庞大的文档集是很有用的。
在检索时，通过表明事件发生来表示出这种结构（如采用内容表格的方法），这使我们能在全部文档上下文中看到事件的发生，而不是文本的某一页——以至于不清楚我们处在文档的哪个位置。
超文本模型
超文本：是一个允许以非顺序的方式在计算机屏幕上浏览文本的高层交互式导航结构。
它由结点和链所组成，结点之间的关系用链表示，结点和链构成一个有向图结构。
对于超文本来说，每个结点都与一个文本区域相关，这个区域可能是书中的章，或文章中的节，或是一个Web页面。
超文本的导航过程可以被理解为遍历一个有向图的过程。图中被链接的结点表示文本结点之间具有某种语义关联。
缺点：

当超文本很大时，用户可能会失去超文本组织结构的路线，其结果，用户进行错误的导航决策，并偏离他的主目标（一般只是查找超文本上少量的信息），这种情况称之为用户在网络空间中的迷航。
当用户浏览一个超文本时，会局限于由超文本设计者所构建的信息流。
在超文本导航中，用户可能发现很难确定自己的方位，即使在前面讨论的导航工具如超文本地图存在的情况下，这种困难也依旧存在，原因可能是由于复杂的超文本组织具有太多允许用户前进和后退的链接。

超文本结构的定义应该是在域建模(domain modeling)阶段，即在需求分析阶段之后完成的。
超文本为形成万维网(World Wide Web)的HTML（超文本标记语言）和HTTP（超文本传输协议）的构想和设计奠定了基础。
]]></content>
      <tags>
        <tag>Information-Retrieval</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>应用随机过程中的例子</title>
    <url>/2025/07/05/%E5%BA%94%E7%94%A8%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E4%BE%8B%E5%AD%90/</url>
    <content><![CDATA[平稳白噪声序列
设为一列两两互不相关的随机变量序列，满足,且
当当


白噪声序列为平稳的.
这是因为协方差函数 只与有关


滑动平均序列
设为 一 列 互 不 相 关 的 且 有 相 同 均 值 和方差的平稳白噪声序列。
设为任意个实数。如下滑动平均序列具有平稳性：

对于均值,保持不变：

协方差

滑动平均序列均值具有遍历性,这是因为是固定的数，

Fix-Neyman(1951)疾病、死亡模型
考虑一个包含两个健康状态以及两个死亡状态
(即由不同原因引起的死亡)的模型。若个体病愈，则认为它处于状态,若它患病，则它处于,个体可以从进入和, 易见这是一个马氏链的模型，转移矩阵为

离散排队系统
考虑顾客到达一服务台排队等待服务的情况。若服务台前至少有一顾客等待，则在一单位时间周期内，服务员完成一个顾客的服务后，该顾客立即离去；若服务台前没有顾客，则服务员空闲。在一个服务周期内，顾客可以到达，设第个周期到达的顾客数是一个取值为非负整数的随机变量，且相互独立
同分布。
设为第个周期开始时服务台前的等待服务的顾客数，验
证是链并写出转移概率。
M/G/1排队系统
在排队系统中，表示顾客到达服务台的时间间隔，假设为独立同分布，概率密度为 若服务员空闲，则顾客立刻就能得到服务，否则就需要等待排队。表示每位顾客的服务时间，假设为独立同指数分布(参数为λ),且与顾客到达过程相互独立。数字1表示只有1名服务员。
设表示第位顾客到达服务台时系统内的顾客数(包括该顾
客)、验证是链并写出转移概率。
(s, S)备货策略
设某商店使用备货策略，每天早上检查某商品的剩余量，
设为,定购额为
若若
设定货和进货不需要时间，每天的需求量独立同分布
且.设为第天结束时的存货量，
验证是链并写出转移概率。
分支过程
考虑一个能产生同类后代的个体组成的群体.每一个体生命结束时以概率产生了个新的后代，与别的个体产生的后代个数相互独立.
初始的个体数以表示，称为第零代的总数；第零代的后代构成第一代，其总数记为,第一代的每个个体以同样的分布产生第二代，.一般地，以记第代的总数.
此Markov链 称 为 分 支 过 程 .
现在假设群体是从单个祖先开始的，即,则 有

其中表示第代的第个成员的后代的个数。


第代的平均个体数

其中表示每个个体的后代个数的均值，从而可以看出，若，则平均个体数单调下降趋于0.若时，各代平均个体数相同.当​时，平均个体数按指数阶上升至无穷.
直觉上看家族消亡和有关.


考虑群体最终会消亡的概率, 设, 则
由的表达式 知它是直线和曲线交点的横坐标，显然(1,1)是一个交点.


当时，是 一 条 直 线 ,方程只有唯一解,家族必定消亡,此时



当时，由于

可见是 单 调 增 加 的 凸 函 数 .


, 方 程 只 有 唯 一 的解​
此时而 ,从而


存在一个使得 ,断言，必定取值为,为 此 只 需 证 明 是方程的最小解.
数学归纳法，\pi=\sum_{j=0}^\infty\pi^jp_j\geq\pi^0p_0=p_0=P{X_1=0}
假设 ,则

从而对一切,
群体最终灭绝,故这就证明了在这种情况下取值应为
容易看出.此时,因此等价关系成立






在实际应用中，考虑一个群体的真实增长时，分支过程的假定在群体达到无限之前就不成立了(比如独立同分布性).但另一方面，利用分支过程研究消亡现象是有意义的，因为一般灭绝常常发生在过程的早期.


人口结构变化的Markov链模型
考虑社会的教育水平与文化程度的发展变化，可以建立如下模型：
将全国所有16岁以上的人口分为文盲、初中、高中(含中专)、大学(含大专)、中级技术人才、高级技术人才、特级专家等7类，结构的变化为升级、退化(如，初中文化者会重新变为文盲)、进入 (年龄达到16岁或移民进入)迁出(死亡或移民国外).
用表示在年各等级的人数;
为 全 社 会 16岁 以 上 人 口 总 数  (简 称 为 总 人 数 );
以记每年从级转为级的人数在级人数中的百分比，则

是一个准转移矩阵(每行所有元素之和
再考虑进入与迁出，记为每年从级迁出占级总人数的比例,为每年进入级的人数占总进入人数的比例，则

记为总进入人数，为总迁出人数，则

令M(t)=N(t+1)-N(t)=R(t)-W(t).
设总人数以常数百分比增长(可以为负增长),即

于是

记,上式可改写为

由,可故写为

这是由于

特别地,当;
记
其中

则上式变为

这是一个以为转移阵的Markov链，在时刻分布满足的方程.
我们希望人口维持在比较合理的稳定水平,文盲不太多，专家也不太多，并且从现在的出发，通过控制人口进入各级的比例来尽快地达到这个稳定水平.为此我们讨论一下在不同的r下全部可能的稳定结构.由于

即

其 中

当数时\mathbf{r=aI-Q+(w_j\delta_{ij})^{-1}}即
因 为 要 求 . 从而,这 样 对 于

找出使其满足

从而对于此是一个稳定的结构.
Yule 过程
设群体中各个生物体的繁殖是相互独立，强度为的Poisson过程，并且群体中没有死亡，此过程称为Yule过程，也叫纯生过程;
设在时刻0群体中有1个个体，则群体将有的个体数是 ;
以记群体数目从增加到所需的时间，由Yule过程定义，当群体数目为时，这个个体是以相互独立的Poisson过程来产生后代的;
由Poisson过程的可加性知，这相当于一个强度为的Poisson过程；由Poisson过程的平稳独立增量性，易知与状态的转移是独立的 ,并且是相互独立且服从参数为的指数分布;
这就说明了Yule过程是一个连续时间Markov链。
生灭过程
设马尔可夫链,状态空间,若转移概率矩阵满足：当充分小时，

则称该过程为生灭过程.
根据生灭过程的定义，当充分小时，状态的转移只有三种可能： 这个特性是许多生物群体，例子裂变,信号计数等的共同特点，因而可以作为这一类为物理自然现象的数学模型。
生灭过程的矩阵是保守的：

若为生灭过程，则满足Kolmogorov微分方程


向后方程



向前方程



设是Markov链到达状态后，离开该状态前的停留时间.
对于生灭过程，服从参数为的指数分布，并且其在## 各个状态的停留时间相互独立. 定义,

是Markov链的第次转移时刻.
设 , 则​是 离 散 时 间 Markov链，其一步转移概率矩阵K：

其中

生灭过程描述的情况如下：已知时刻时有个生物时，再等待后，以概率增加一个生物，或者以概率减少一个生物. 这里Ехр
M/M/S排队系统
顾客的来到是参数为λ的Poisson过程。服务员数为个，每个顾客接受服务的时间服从参数为的指数分布。遵循先来先服务、 服务员没有|空闲就排队的原则，以记时刻系统中的总人数， 则是一个生灭过程(来到看作出生，离去看作死亡)。若以分别记系统中有个顾客时的来到率和离去率。则来到率是恒定参数为的Poisson过程;离去过程的参数会发生变化：

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Random Process</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐系统</title>
    <url>/2025/07/02/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[概念
推荐系统的任务：联系用户和物品，解决信息过载的问题；

好友（社会化推荐）
用户的历史兴趣记录（协同过滤推荐）
用户的注册信息

为什么推荐系统收到欢迎：

用户：可以帮助用户发现喜欢的新事物
商家：提高用户信任度和粘性，增加营收

信息过滤技术比较

搜索引擎满足用户有目的地主动查找需求；
推荐系统能够在用户没有明确目的时帮助发现感兴趣的新内容；




搜索引擎
推荐系统




由用户主导，包括输入查询词和选择结果，结果不好用户会修改查询再次搜索。
由系统主导，系统引导用户发现需要的信息。高质量的推荐系统会使用户对该系统产生依赖。


需要用户提供明确的需求，注重结果之间的排序。
不需要用户提供明确的需求，通过分析用户的历史行为对用户的兴趣建模，从而主动给用户推荐可能满足他们兴趣和需求的信息。



评测方法
一个推荐算法最终上线，必须完成

离线实验：在离线指标上优于现有算法
用户调查：确定用户满意度较优
在线AB测试：确定在关心的指标上较优

离线实验
步骤

通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集；
将数据集按照一定的规则分成训练集和测试集；
在训练集上训练用户兴趣模型，在测试集上进行预测；
通过事先定义的离线指标评测算法在测试集上的预测结果。

优点

实验都是在数据集上完成的，不需要一个实际的系统来供它实验
不需要用户参与实验，成本低
速度快，可以测试大量算法

缺点：

无法计算商业上关心的指标
离线实验的指标和商业指标存在差距

用户调查
步骤

用户调查需要一些真实的用户，让他们在需要测试的推荐系统上完成一些任务。
在他们完成任务时，需要观察和记录用户的行为，并让他们回答一些问题。
最后，我们通过分析他们的行为和答案，了解测试系统的性能。

优点：

可以获得用户的主观感受指标，出错后容易弥补

缺点：

招募测试用户代价较大
无法组织大规模的测试用户，统计意义不足

在线实验
在完成离线实验和用户调查之后，可以将系统上线做AB测试，将它和旧算法进行比较。
AB测试通过一定的规则将用户随机分成几组，对不同组的用户采用不同的算法，然后通过统计不同组的评测指标，比较不同算法的好坏。

多个方案并行测试；
每个方案采用不同的推荐算法；
以某种规则优胜劣汰。

优点：

可以公平获得不同算法实际在线的性能指标，包括商业上关注的指标；

缺点：

周期长，必须进行长期的实验才能得到可靠的结果
设计比较复杂

评测指标

用户满意度：描述用户对推荐结果对的满意程度，是最重要的指标，问卷调查/监测用户线上行为数据
预测准确度：描述推荐系统预测用户行为的能力。对用户，推荐的物品集合为,在测试集上喜欢物品的集合，可用计算
覆盖率：描述推荐系统对长尾物品的发掘能力。一般通过所有推荐物品占总物品的比例来计算。比例越大，则覆盖率越大。
多样性：描述推荐系统中推荐结果能否覆盖用户不同的兴趣领域。一般用不相似度描述；
新颖性：如果用户没有听说过推荐列表中的大部分物品，则说明该推荐系统的新颖性较好，需要做用户调查；
惊喜度：如果推荐结果和用户的历史兴趣不相似，但让用户很满意，则可以说这是一个让用户惊喜的推荐。可以用历史兴趣和用户满意度来衡量；
信任度：描述用户对推荐系统的信任程度。只能问卷调查了解；
实时性：时效性强的物品在进行推荐时必须考虑推荐系统处理物品冷启动的能力，可以采用人工推荐。
健壮性：衡量推荐系统抗作弊能力；
商业目标：平均一个用户是否能为公司带来盈利；

模块

用户
对象：单用户建模/群组建模
功能：能获取、表示、存储和修改用户兴趣爱好，能够进行推理对用户进行分类和识别，帮助系统更好地理解用户特征和类别，理解用户的需求和任务，从而更好地实现用户所需要的功能

推荐对象
基于内容的方法：从对象本身抽取信息来表示对象，常见TF-IDF方法和加权关键词矢量。
基于分类的方法：将推荐对象放入不同类，这样可以把同类文档推荐给该类文档感兴趣的用户了。分类常用算法Naive-Bayes,KNN,SVM;
潜在问题：

文本等对象特征提取技术相对比较成熟，但是网络上广泛存在的多媒体数据等的提取技术不够成熟，自动化的特征提取方法需要结合多媒体内容分析领域的相关技术。
推荐系统推荐给用户的对象首先不能与用户看过的对象重复，其次也不能与用户刚刚看过的太相似或是不相关，这就是所谓的模型过拟合问题。
推荐系统中出现新的对象时，新对象必须等待一段时间才会有用户查看并进行评价，在此之前推荐系统无法对此对象进行分析和推荐，这就是冷启动问题。

推荐算法
推荐算法很大程度上决定了推荐系统类型和性能的优劣；
基于内容推荐
物品的特征表示
为每个物品抽取出一些特征来表示此物品

结构化特征：属性意义比较明确，取值限定在某个范围，一般可以直接使用，如年龄、性别等。
非结构化特征：属性意义不明确，取值也没有什么限制，往往要先把它转化为结构化数据后才能在模型里使用。
文章特征表示：
相似度计算：

用户特征学习
利用一个用户过去喜欢（及不喜欢）的物品的特征数据，来学习出此用户的喜好特征。
生成推荐列表
通过比较上一步得到的用户喜好特征与候选物品的特征，为此用户推荐一组相关性最大的物品；
协同过滤推荐
用户行为数据



特征
显性反馈行为
隐形反馈行为




定义
用户明确表示对物品的喜好，如评分
不能明确反应用户喜好，如浏览记录


用户兴趣
明确
不明确


数量
较少
庞大


存储
数据库
分布式文件


实时读取
实时
有延迟


正负反馈
都有
只有正反馈



基于邻域的方法
基于用户（人以群分）


特点：社会化，着重于反应和用户相似度相似的小群体热点；


思路：

找到目标用户兴趣相似的用户集合
找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户；



余弦相似度计算:定义用户对所有物品的评价向量



皮尔逊相关系数：对于用户可能对某些物品的打分缺省的情况，定义如下



预测分值:记邻居集中对物品有过评分记录的用户集为;



生成推荐列表：按照预测的评分进行降序排序
基于物品（物以类聚）


特点：更个性化，着重于维护用户的历史兴趣，反映了用户兴趣的历史传承。


思路：

计算物品间的相似度。
根据物品的相似度和用户的历史行为生成推荐列表。



物品相似度计算：
用表示喜欢物品的人数；
两个物品相似度越高，说明两个物品被很多人共同喜欢，但是要惩罚热门物品以挖掘长尾信息；



预测分数：
用表示用户已评分过的物品集合,以此预测那些未评分的物品的分数



生成推荐列表：按照预测的评分降序排序


基于模型的方法/隐语义模型（不考）
对于海量的物品，让用户子集给音乐分类并给出子集的偏好不现实，我们需要对用户行为数据分析获得评分矩阵;
在实际应用中，评分矩阵可能相当稀疏，传统的矩阵分解代价太大;
我们需要从评分矩阵中抽取一组潜在的（隐藏的）因子，并通过这些因子向量描述用户和物品；
SVD将评价矩阵分解为3个低秩的矩阵，这3个矩阵的乘积能对原始矩阵进行某种程度的复原，从而可以评估出缺失值。
假设有个用户，个物品，设定个潜在因子

用户-潜在因子矩阵:表示不同用户对于不同因子的偏好程度
物品-潜在因子矩阵:每种物品含有各种因子的成分

则用户对物品的评分为

这样作近似


随机初始化,划分训练集,测试集
误差函数,损失函数，正则项, 目标函数为;

引入正则化项的目的是防止过拟合；
引入损失函数的目的用户对物品的真实喜爱程度与推算喜爱程度的均方根误差
测试集的评估也是MSE指标；
在深度学习中一般采用随机梯度下降(SGD)学习

估计出得分矩阵后，将用户已经使用的物品剔除，选择分数最高的物品推荐给用户；
缺点：

难以做到实时推荐，隐语义模型的训练需要在用户行为记录上反复迭代才能获得比较好的性能
模型的每次训练都很耗时，一般在实际应用中只能每天训练一次，并且计算出所有用户的推荐结果。

冷启动问题
使用协同过滤推荐算法时，新用户或新物品刚加入系统时、系统刚上线时，会因为行为数据的匮乏导致冷启动问题。
用户冷启动

利用用户注册信息：尽管是粗粒度的非个性化推荐，但是知道一些基本信息已经可以大大提高精度了；

人口统计学信息：年龄，性别，职业，民族，居住地
用户兴趣的描述：许多网站会在用户注册时让用户勾选部分感兴趣的标签
从其他网站导入的用户站外行为数据


选择合适的物品启动用户兴趣：

热门：要让用户对一个物品进行反馈的前提是用户知道这个物品是什么东西。
区分度强：启动用户兴趣的物品不能是老少皆宜的，这样的物品对用户的兴趣没有区分性。
多样性好：用户兴趣的可能性很多，我们需要提供具有很高覆盖率的启动物品集合，这些物品能覆盖大部分主流的用户兴趣。



物品冷启动
网站中时时刻刻都有新加入的物品，而且每个物品必须能够在第一时间展现给用户，否则经过一段时间后，物品的价值就大大降低了。

利用物品内容信息的表示

物品的内容可以通过向量空间模型表示
不过在绝大多数应用中，向量空间模型对于文本的分类、聚类、相似度计算已经可以给出令人满意的结果。



系统冷启动
系统冷启动的解决办法：专家标注
很多系统在建立的时候，既没有用户的行为数据，也没有充足的物品内容信息来计算物品相似度。这种情况下，很多系统都利用专家进行标注。
个性化推荐的挑战
数据稀疏
现在待处理的推荐系统规模越来越大，用户和商品数目动辄上亿，两个用户之间选择的重叠非常少，淘宝网的数据稀疏度在百万分之一以下。
数据非常稀疏导致绝大部分基于关联分析的算法效果都不好。这个问题本质上是无法完全克服的。
多样性与精确性的两难困境
如果要给用户推荐他喜欢的商品，最“保险”的方式就是给他特别流行的商品，因为这些商品有更大的可能性被喜欢。

盲目崇拜精确性指标可能会导致用户的视野变得越来越狭窄，难以激发用户新的购物需求。
推荐多样的商品与推荐的精确性之间存在矛盾，因为前者风险很大。

一种可行之策是直接对推荐列表进行处理，从而提升其多样性。
一些心怀不轨的用户通过提供一些虚假恶意的行为，故意增加或者压制某些商品被推荐的可能性，需要推荐系统提升鲁棒性；
譬如通过分析对比真实用户和疑似恶意用户之间打分行为模式的差异，提前对恶意行为进行判断，从而阻止其进入系统或赋予疑似恶意用户比较低的影响力。
]]></content>
      <tags>
        <tag>Information-Retrieval</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统绪论</title>
    <url>/2025/07/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F0-%E7%BB%AA%E8%AE%BA/</url>
    <content><![CDATA[操作系统
操作系统：控制应用程序执行的程序，是应用程序和硬件之间的接口；
本课程默认单核单CPU；
操作系统是一组控制和管理计算机硬件和软件资源，合理地对各类作业进行调度，以及方便用户使用的 **程序的集合 **；

内存管理；
处理机管理；
作业管理；
I/O设备管理；
文件管理；

操作系统的设计目标

便利性：使计算机易于使用；
有效性：允许以更有效的方式使用计算机资源；
扩展能力：不妨碍服务的情况下，有效的开发测试和引进新功能；

操作系统的位置
作为用户/计算机接口

操作系统的服务

程序开发：提供一系列工具和服务（如编辑器和调试器）
程序运行：为用户处理调度问题，如加载到内存、初始化I/O 设备等
I/O 设备访问：提供统一接口，隐藏具体的 I/O 操作指令
文件访问控制：屏蔽存储介质细节
系统访问：提供接口，防止未授权访问行为
错误检测和响应：软、硬件错误
日志：收集资源的利用率信息、监控性能特性

操作系统：资源管理者

资源管理者：控制数据的移动，存储和管理；
控制机制的特殊性：os同为一种程序，但是会转交控制权，必须依赖处理器才能恢复控制；

操作系统的发展过程
硬件升级+新设备出现+错误修复
串行处理

无操作系统；
操控控制台（显示灯，触发器，输入设备，打印机…）运行程序；
程序通过输入设备载入计算机；
用户按顺序访问计算机；
调度慢，启动时间长；

简单批处理

采用监控程序：对一批作业自动处理，内存中只能存在一道作业，作业自动续接，内存保护，定时器防止作业独占系统，拥有特权指令，允许中断；
处理器常处于空闲状态（I/O设备速度比处理器慢许多）；
拥有内核模式和用户模式

多批道处理系统

内存存放多个作业；
多个作业并发运行（并发：在某一时间切片内有多个作业运行，但某一时刻只有一个作业），可以显著提高系统资源的利用率；
作业调度系统负责作业的调度；
硬件支持：I/O中断，直接存储器访问；
多道性，调度性，无序性，无交互能力；

分时系统

采用多道程序处理多个作业，多个用户共享处理器，多个用户通过不同的终端同时访问系统；
多路性，独立性，及时性，交互性；

实时系统
系统能够（及时 即时 ）响应外部事件请求 在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地运行。

软实时系统：各个任务运行得越快越好，并不要求限定某一任务必须在多长时间内完成。
硬实时系统：各任务不仅要执行无误而且要做到准时。
实时性、可靠性、多路性、独立性、交互性；

操作系统的主要功能
进程
进程：一个正在 执行 的程序，计算机中正在 运行 的程序的一个实例，可分配给处理器并由处理器 执行 的一个实体；

一段可执行的程序
程序所需要的相关数据（变量、工作空间、缓冲区等）
程序的执行上下文（进程状态）：操作系统用来 管理和控制进程所需的所有数据

设计协调不同活动的系统软件非常困难，为了解决上述问题，需要一种系统级的方法来监控和控制处理器上各种程序的执行;
以下是可能出现的问题：

不正确 的同步
失败的互斥
不确定的程序操作
死锁

下图是一种典型的进程实现方法：

内存管理
操作系统进行存储管理的任务如下：

进程隔离：每个进程拥有独立的地址空间，互不干扰；
自动分配和管理：动态分配，对程序员透明；
支持模块化：动态加载，销毁程序员定义的模块；
保护和访问控制：一个程序的存储空间不能被其他程序任意访问；
永久存储：关机后依然存储信息；

操作系统的存储管理由 文件系统和 虚拟内存 实现；
文件系统
文件是一个有名称的对象，是访问控制和保护的基本单元；
文件系统实现了长期存储；
虚拟内存
内存：一系列长度固定的帧组成，每个帧的大小与页面大小相同。对需要执行的程序，它的所有或部分页面必须在内存中；
磁盘：辅存（磁盘）可以容纳很多长度固定的页。用户程序由很多页组成，所有程序和操作系统的页都以文件的形式保存在磁盘上。

程序以 逻辑方式 访问存储器；
多作业同驻留内存；
每个作业部分驻留（主要）；
换入，换出机制；

虚拟内存寻址如下：

信息保护和安全
操作系统的典型安全问题：

可用性：保护系统不被中断运行
保密性：保证用户不能读取未授权访问的数据
数据完整性：保护数据不被未授权修改
可靠性：涉及用户身份的正确认证和消息或数据的合法性

调度和资源管理
操作系统的一个关键任务是管理各种可用资源（如内存空间、I/O设备和处理器等），并调度各种活动进程使用这些资源

公平性：所有参与竞争某一特定资源的进程都能几乎相等且公平地访问资源
有差别的响应性：区分进程类型且可动态调整
有效性：最大化吞吐量（并发）和最小化响应时间，需要找到平衡点以折中处理矛盾需求

操作系统的目标和功能


处理机管理
处理机管理的主要任务是对处理机进行分配，并对其运行进行有
效的控制和管理；
在多道程序环境下，处理机的分配和运行都是以进程为基本单位，因而对处理机的管理可归结为对进程的管理；

进程控制：为作业创建进程，撤销已结束的进程，以及控制进程在运行过程中的状态转换；
进程同步：对诸进程的运行进行协调，包括进程互斥与进程同步
进程通信：实现相互合作进程之间的信息交换，包括直接通信与间接通信；
调度：按照一定的算法对作业与进程进行调度。



存储器管理
存储器管理的主要任务是为多道程序的运行提供良好的环境，方
便用户使用存储器，提高存储器的利用率，以及从逻辑上来扩充
内存。

内存分配：为每道作业分配内存空间，使它们“各得其所”，提高存储器利用率，减少不可用的内存空间。
内存保护：确保每道用户程序都在自己的内存空间中运行，互不干扰；
地址映射：将地址空间中的逻辑地址转换为内存空间中对应的物理地址；
内存扩充：借助虚拟技术，从逻辑上扩充内存容量；



设备管理
设备管理的主要任务，是完成用户提出的I/O请求，为用户分配
I/O设备；提高CPU和I/O设备利用率；提高I/O速度以及方便用户
使用I/O设备；

缓冲管理：管理好各种类型的缓冲区，以缓和CPU与I/O速度不匹配的矛盾，提高CPU和I/O设备的利用率。
设备分配：为用户分配其所需的设备。
设备处理又称设备驱动程序，实现CPU与设备控制器之间的通信。



文件管理
文件管理的主要任务，是完成实现文件的虚拟存取和高速存取，
方便用户访问文件、保存文件并维护其内容的完整性。

文件存储空间的管理：为每个文件分配必要的外存空间，提高外存的利用率，并能有助于提高文件系统的运行速度。
目录管理：为每个文件建立其目录项，并对众多的目录项加以有效的组织，以实现方便的按名存取。
文件的读/写管理和保护



命令接口
为了方便用户对计算机系统的使用与编程，操作系统向用户提供
了用户与操作系统的接口，简称用户接口

命令接口：

用户利用这些操作命令来组织和控制作业的执行
按作业控制方式的不同，可以将命令接口分为联机命令
接口和脱机命令接口


程序接口

程序接口由一组系统调用命令组成
这组系统调用命令向系统提出各种服务请求，如使用各种外部设备，进行有关磁盘文件的操作，申请分配和收
回内存以及其他各种控制要求。





操作系统的基本特征


并发性

在多道程序环境下，同一时刻只能有一条指令执行；
但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的；
可以让CPU、I/O设备并行工作，提高资源利用率；



共享性

系统中的资源可供内存中多个并发执行的进程共同使用
临界资源：在一段时间内，只允许一个进程访问，必须互斥访问共享，比如打印机
非临界资源：在一段时间内，允许多个进程访问，允许同时访问共享，比如磁盘



虚拟性

通过某种技术把一个物理实体变为若干个逻辑上的对应物
时分复用：虚拟处理机，虚拟设备
空分复用：虚拟磁盘，虚拟内存



异步性

多道程序环境下，程序执行过程是异步的，这意味着何时执行，执行顺序，完成运行时间都将带来不确定性
不确定性不是指程序的执行结果



操作系统的体系结构

无结构

存在于早期的操作系统，侧重于功能实现和效率提高；
难以调试与维护，扩展性差；


模块化结构

按功能划分若干个模块，模块之间通过接口交互；
衡量标准：内聚性，耦合度；
OS设计正确性高，易于理解和维护；
接口间调用关系变得复杂可能导致耦合度降低，模块之间存在复杂的依赖关系


分层式结构

按功能图的调用顺序等原则划分为若干层；每层只能使用其下层提供的服务；每层对其上层隐藏其下层的存在；
易于保证系统的正确性，易于维护理解和维护，易于扩充；


微内核结构

机制，策略分离：基于优先级的进程调度中，选择进程，为之分配处理机，属于机制；为每个进程设置优先级属于策略；
微内核基本功能：进程管理，低级存储器管理，中断和陷入处理；
优点：提高了可扩展性，可靠性，可移植性，提供了分布式系统的支持；
缺点：运行效率有所降低，因为消息传递机制和模式切换会带来开销；



]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>System</tag>
      </tags>
  </entry>
  <entry>
    <title>搜索引擎</title>
    <url>/2025/07/02/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/</url>
    <content><![CDATA[技术架构
网络爬虫：搜索引擎的信息源来自于互联网网页，通过网络爬虫将整个互联网获取到本地。
网页去重：互联网页面中有相当大比例的内容是完全相同或者近似重复的，网页去重模块会对此做出检测，并去除重复内容。
倒排索引：网页内容通过倒排索引这种高效查询数据结构来保存，网页之间的链接关系也会保存。
链接分析：链接关系在网页相关性排序阶段是可利用的，通过链接分析可以判断页面的相对重要性，对于为用户提供准确的搜索结果帮助很大。
云存储与云计算平台：网页数量非常多，搜索引擎不仅需要保存网页原始信息，还需要保存一些中间结果，单台或少量机器是不现实的。优秀的云存储和云计算平台已经称为大型商业搜索引擎的核心竞争力。
查询分析：当搜索引擎接收到用户的查询词后，首先需要对查询词进行分析，推导用户的真正搜索意图。
Cache系统：搜索引擎的缓存系统存储了不同的查询意图对应的搜索结果，如果能够在缓存系统中找到满足用户需求的信息，则可以直接将搜索结果返回给用户。
网页排序：根据用户的查询实时实时计算哪些网页满足用户信息需求，并排序输出作为搜索结果。网页排序最重要的两个参考因素：内容相似性因素、网页重要性因素。
反作弊：作弊将网页的搜索排名提高到与其网页质量不相称的位置，这会严重影响用户的搜索体验。自动发现作弊网页并对其处罚，是搜索引擎非常重要的一部分。

网络爬虫
网络爬虫是通过网页的链接地址来寻找网页，从网站某一个页面开始，读取网页的内容，找到在网页中的其他链接地址，然后通过这些链接地址寻找下一个网页，如此循环下去，直到把这个网站所有网页抓取完为止。

作用：为搜索引擎抓取大量数据；
对象：整个互联网上的网页；

工作原理
基本过程：

为爬虫输送表示起始位置的URL列表；
从种子列表出发，不断爬行发现新的URL
根据某种抓取策略爬行发现新的URL，如此重复


类型：

批量性爬虫：有明确的抓取范围和目标，当爬虫达到这个抓取目标之后，即停止抓取过程。
增量型爬虫：会保持持续不断的抓取，对于抓取到的网页，定期更新
垂直型爬虫：关注特定主题内容或者特定行业的网页

抓取策略
深度优先
依据深度优先的原则，先下载当前网页所链接的URL，追加到待抓取URL队列末尾。

宽度优先
将新下载的网页包含的链接直接追加到待抓取URL队列末尾。

Partial PageRank

对于已经下载的网页，加上待抓取URL队列中的URL一起，形成网页集合
在此集合内进行PageRank计算，将待抓取URL队列里的网页按照PageRank得分降序排列
形成的序列就是爬虫接下来应该依次抓取的URL列表。
一个性能折衷方案是每新下载个网页时，将所有网页重新计算非完全PageRank，对产生的新网页赋临时Pagerank值，若值比较大则优先下载；


OPIC策略(Online Page Importance Computation)
每个互联网页面都给予相同的现金，每当下载了某个页面P之后，P将自己拥有的现金平均分配给P所包含的链接页面，把自己的现金清空。
对于待抓取的URL队列中的网页，则根据手头拥有的现金金额进行排序，优先下载现金最充裕的网页。

不同于Pagerank的迭代计算，OPIC是在线策略，适合实时计算，
PageRank需要考虑无连接关系的网页远程跳转的过程，OPIC没有这一计算因子

大站优先策略(Lager Sites First)
以网站为单位来衡量网页重要性，对于待抓取的URL队列中的网页，如果哪个网站等待下载的页面最多，则优先下载这些链接
网页更新策略
互联网的内容具有动态性，网页更新策略的任务就是决定何时重新抓取已经下载过的网页，使得本地下载的网页和互联网的原始网页内容保持一致；
历史参考策略
假设：过去频繁更新的网页，那么将来也会频繁更新。该策略通过参考其历史更新情况来预估某个网页何时进行更新。
利用泊松过程对网站的变化建模，通过历史的变动情况，利用模型进行预测网页内容何时发生变化；
用户体验策略
更新网页取决于网页的内容变化带来的搜索质量变化；
影响越大的网页，则越快更新；
用户体验策略保存网页的多个历史版本，并根据过去每次内容变化对搜索资料的影响，得出一个平均值，以此作为判断爬虫更新该网页时机的参考依据，影响越大的网页则优先调度进行更新。
聚类抽样策略
具有相似属性的网页，其更新周期也是类似的，只需计算某个类别的更新周期；
对同一类别的网页进行采样，以被采样的网页更新周期作为其他网页的更新周期；
无需保留网页的历史信息。对于新网页也只需要找到其聚类就能进行更新；

与网页更新周期相关的属性有两大类：

静态：页面内容，链接深度，PageRank；
动态：图片数量的变化情况，入链出链的变化情况；

分布式爬虫
分布式技术将抓取任务分布到不同的节点以提高抓取的性能和可拓展性；
层级划分：分布式数据中心，分布式抓取服务器。分布式爬虫程序；

主从式分布爬虫
不同服务器承担不同的角色分工。

URL服务器维护待抓取URL队列，获得待抓取网页的URL，分配给不同的抓取服务器，分配使得各抓取服务器负载均衡。
抓取服务器之间没有通信联系，每个抓取服务器只和URL服务器进行消息传递。


URL服务器承担很多管理任务，同时，待抓取队列数量巨大，因此，URL服务器容易成为整个系统的瓶颈。
对等式分布爬虫
在对等式分布爬虫体系中，服务器之间不存在分工差异，每台服务器承担相同的功能，各自负担一部分URL的抓取工作。
该架构中没有URL服务器，则需要服务器自己判断某个URL是否需要自己抓取，或者将读取到的URL传递给其他服务器。
许多对等式分布爬虫通过哈希取模的方法进行任务的分工；

暗网抓取
暗网：目前搜索引擎按常规方式很难抓取到的互联网页面
典型的暗网是垂直领域的网站，通常是网站提供组合查询界面，用户输入查询才能获取数据的页面；
难点：模拟人的行为，填写内容并提交表单，获取数据；
技术：组合查询问题，文本框填写问题；
组合查询问题
查询模板：如果在向搜索引擎提交查询的时候，部分属性被赋予值，其他属性不赋值，则这几个赋值的属性称为查询模板。
对于固定的查询模板，如果给模板内的每个属性都赋值，形成不同的查询组合，提交给搜索引擎，获得的返回结果，如果内容相差甚大，则这个查询模板是富含信息的查询模板。
对于一个固定的垂直搜索来说，其查询模板组合起来有很多，抓取的任务是找到富含信息的查询模板。
ISIT算法：减少提交的查询模板数量

先从1维开始，判断是否是富含信息模板，如果是的话，将该1维模板拓展到2维，再次依次考察对应的二维模板；
如此类推，逐渐增加维数，直到再也找不到富含信息模板为止。

文本框填写问题
对于输入中的文本框，需要爬虫自动生成查询。

可以通过人工观察对网站进行定位，提供一个初始种子查询关键词表，以此作为爬虫工作的基础条件。
通过人工启发结合递归迭代的方式，尽可能覆盖数据库里的记录。

网络协议

URL规范：统一资源定位符,&lt;协议&gt;://&lt;主机&gt;:&lt;端口&gt;/&lt;路径&gt;;
HTTP协议:超文本传输协议,定义了浏览器怎样向万维网服务器请求万维网文档，以及服务器怎样把文档传送给浏览器。
Robots协议:是Web站点和搜索引擎爬虫交互的一种方式，robots.txt是存放在站点根目录下的一个纯文本文件。该文件可以指定搜索引擎爬虫只抓取指定的内容，或者禁止搜索引擎爬虫抓取网站的部分或全部内容。

索引技术
基础
搜索引擎索引是实现单词-文档矩阵的具体的数据结构；



术语
概念




文档
以文本形式存在的存储对象


文档集合
由若干文档构成的集合


文档编号
作为文档的唯一标识


单词编号
作为单词的唯一标识


倒排索引
实现单词—文档矩阵的一种具体存储形式


单词词典
文档集合中出现过的所有单词构成的字符串集合


倒排列表
记载出现过某个单词的所有文档的文档列表、以及单词在该文档中出现的位置信息


倒排文档
顺序存储倒排列表的文件




单词词典
单词词典：用来维护文档集合中出现过的所有单词相关信息，记载某个单词对应的倒排列表在倒排文件中的位置信息；
哈希+链表
主体部分是哈希表，每个哈希表项保存一个指针，指针指向冲突链表，在冲突链表里，相同哈希值的单词形成链表结构。

冲突链表：两个不同单词获得相同的哈希值，这在哈希方法里称为一次冲突，可将相同哈希值的单词存储在链表里，以供后续查找。
建立词典：

对于某个文档出现的单词T，利用Hash函数获取其哈希值；
根据哈希值对应的哈希表项读取并保存其中的指针，找到对应的冲突链表；
若冲突链表中已经存在单词T，则说明该单词之前解析的文档中已经出现过；若未发现该单词，则将其加入冲突链表中。

响应用户请求：

先计算请求的哈希值
定位对应的哈希槽中，获取冲突链表
将查询和链表中的每一个单词进行比较；

树形词典结构
利用B树可以进行高效的查找，前提是字典项具有顺序；

倒排列表
一个倒排索引项描述一个单词和文档相关的信息,形成列表结构，也就是倒排列表；

每一个文档维护一个文档编号DocID
单词在在这个文档出现的次数TF
单词在文档出现的位置...


在实际实现中，并不存储实际的文档编号，二十存储文档编号差值(D-Gap)

相邻两个倒排索引项文档编号的插值
文档编号一般是大数值，这样的作法可以增加数据的压缩率；
文档通常递增，因此通常为大于0的整数；

倒排文档
倒排文档的组成：

关键字（作者，主题词，分类号）
目长：含有关键字记录的条数
记录号集合：所有和该关键字有关的记录号；

倒排文档建立在顺排文档的基础上，它是从主文档中提取可检索字段内容，也有采取自动从标题、文摘或全文中提取关键词，利用所得到的这些属性词来建立倒排文档。
索引建立
两遍遍历文档法
在内存里完成索引的创建过程的，需要对文档进行两遍扫描。

第一次遍历：获得统计信息，根据统计信息分配内存，建立好单词的倒排列表在内存的位置；
第二遍文档遍历：建立每个单词的倒排列表信息；

一个空间上的优化是：始终在内存中分配固定大小的空间，用来存放词典信息和索引的中间结果，当分配的空间消耗完时，把中间结果写进磁盘，清空内存里中间结果所占空间，以用做下一轮存放索引中间结果的存储区。

排序法
排序法是指对中间结果在内存中排序；
基本步骤：

读入一个文档后，给文档进行编号，赋予唯一的文档ID，并对文档内容解析；
对于文档中出现的单词，通过查词典将单词转换为对应的单词ID，如果词典中没有这个单词，说明是第一次检测到，则赋予单词唯一的单词ID并插入词典中。
对该文档内每个单词建立一个（单词ID，文档ID，单词频率）三元组，这个三元组就是单词对应文档的倒排列表项，将这个三元组追加进入中间结果存储区末尾。
对文档内的所有单词都经过如此处理，形成三元组序列的形式，处理完成以后，开始依次序处理下一文档，如此循环。
当分配的内存空间被占满时，对三元组中间结果进行排序。排序的原则：

主键是单词ID，即首先要按照单词ID由小到大排序；
次键是文档ID，即在相同单词ID的情况下，按照文档ID由小到大排序。


然后将排好序的三元组写入临时文件中，空出内存来进行后续文档的处理。


注意，在建立索引的过程中，词典一直存储在内存中，每次清空内存只是将中间结果写入磁盘；
最终的文档处理完毕后，需要对中间结果进行合并，由于每个中间结果都是有序的

在合并中间结果的过程中，系统为每个中间结果文件在内存中开辟一个数据缓冲区，用来存放文件的部分数据。
将不同缓冲区中包含的同一个单词ID的三元组进行合并。
如果某个单词ID的所有三元组全部合并完成，说明这个单词的倒排列表已经构建完成，则将其写入最终索引中，同时将各个缓冲区中对应这个单词ID的三元组内容清空，这样缓冲区就可以继续从中间结果文件中读入后续的三元组来进行下一个单词的三元组合并。


归并法
分两个阶段进行

在内存中维护中间结果，当内存占满后，将内存数据写入磁盘临时文件
对临时文件进行归并，形成最终索引，

需要在内存建立索引结构，描述目前处理的文档子集；
在将中间结果写入磁盘临时文件时，将整个内存的倒排索引写入临时文件。依次将单词和对应的倒排列表写入磁盘文件，随后彻底清空所占内存。
动态索引
组成：

倒排索引：在磁盘中已经存在的索引；
临时索引：在内存中实时建立的倒排索引
已删除文档列表：用来存储已被删除的文档的相应的文档ID，形成一个文档ID列表。

动态索引的处理办法：

当系统发现有新文档进入时，立即将其加入到临时索引结构中。
当文档被删除时，则将其加入删除文档队列。
当文档被更改时，则将原始文档放入已删除队列，解析更改后的文档内容，并将其加入临时索引中。


对于查询请求，如何形成准确的搜索结果？

同时从倒排索引和临时索引中读取对应的倒排列表；
找到的文档集合进行合并；
在文档删除列表过滤；

索引更新
完全重建策略
当新增文档达到一定数量，将新增文档和原先的老文档进行合并，然后利用建立静态索引的方式，对所有文档重新建立索引。
新索引建立完成后，老的索引被遗弃释放，之后对用户查询的相应完全由新的索引来负责。

由于重建索引需要较长的时间，在进行索引重建过程中，内存中仍然需要维护老的索引来应对用户的查询请求。只有当新索引建立完成后，才能释放旧的索引，将用户查询请求切换到新索引上。
再合并策略Re-Merge
当新增文档进入搜索系统时，搜索系统在内存维护临时倒排索引来记录信息，当新增文档达到一定数量，或者指定大小的内存被消耗完，则把临时索引和老文档的倒排索引进行合并，以生成新的索引。
步骤如下：

当新增文档进入系统，解析文档，之后更新内存中的临时索引，文档中出现的每个单词，在其倒排列表末尾追加倒排列表项，这个临时索引可称为增量索引。
增量索引将指定的内存消耗光后，此时需要进行一次索引合并，即将增量索引和旧文档的倒排列表索引进行合并。
在合并过程中，需要一次遍历增量索引和老索引单词词典中包含的单词及其对应的倒排列表，可以用两个指针分别指向两套索引中的目前需要合并的单词：

如果这个单词在词典序中小于老索引的单词指针指向的单词，说明这个单词在旧索引中未出现过，则直接将这个单词对应的倒排列表写入新索引的倒排文件中，同时增量索引单词指针后移指向下一个单词。
如果两个单词指针指向的单词相同，说明这个单词同时在增量索引和旧索引中同时出现，则将老索引中这个单词的倒排列表写入新索引的倒排列表，然后把增量索引中这个单词的倒排列表追加到其后，这样就完成了这个单词所有倒排列表的合并。
如果某个单词仅在老索引中出现过，即发现老索引的单词指针指向的单词，其词典序小于增量索引单词指针指向的单词，则直接将老索引中对应的倒排列表写入新索引倒排文件中。新索引的单词指针后移指向下一个单词，继续合并。




由于在磁盘的老索引(倒排文档对应的倒排列表，保存为文件)是顺序的，增量索引在遍历词典的时候也按照字典顺序由低到高排列，可以只对倒排文件进行一遍扫描，顺序读取，减少了IO开销(文件操作中比较耗时的磁盘寻道时间)，提高合并效率。

这个再合并策略类似于归并排序；

优点：老的倒排索引是顺序结构，遍历时可以顺序读取文件内容，减少磁盘寻道时间，高效更新。
缺点：需要生成新的倒排索引文件，但是老索引很多单词的倒排列表其实没发生什么变化，也需要从老索引中读取出来并写入新索引文件中，这一操作非常耗时，带来大量的IO开销；

原地更新策略In-Place
在索引合并时，并不生成新的索引文件，而是直接在老的索引文件里进行追加操作，将增量索引里单词的倒排列表项追加到老索引相应位置的末尾。即只更新增量索引里出现的单词相关信息，其他单词相关信息不做变动。

策略步骤如下：

老索引中每个单词的倒排列表末尾都预留出空余磁盘空间，以作为信息追加的存储区域。
在对新增索引进行合并时，按照词典序，依次遍历新增索引中包含的单词，并对新增倒排列表的大小和老索引中相应预留空间大小进行比较：

如果预留空间足够大，则将新增列表追加到老索引后面即可；
如果预留空间不足以容纳新增倒排列表，则在磁盘中找到一块完整的连续存储区，这个存储区足以容纳这个单词的倒排列表，然后，将老索引中的倒排列表读出并写入新的磁盘位置，并将增量索引对应的倒排列表追加到其后。



缺点：
对于倒排文件中的相邻索引单词，其倒排列表顺序一般是按照相邻单词的词典序存储的，但是由于原地更新策略对单词的倒排列表做数据迁移，某些单词及其对应倒排列表会从老索引中移出

这样就破坏了这种单词连续性，导致在进行索引合并时不能进行顺序读取，必须维护一个单词到其倒排文件相应位置的映射表
一方面降低了磁盘读取速度，另外一方面需要大量的内存来存储这种映射信息。

混合策略
混合策略的出发点是能够结合不同索引更新策略的长处，将不同的索引更新策略混合，以形成更高效的方法。
常用的混合策略是根据单词的倒排列表长度进行区分：

对于经常在不同的文档中出现的单词，其对应的倒排列表较长，称为长倒排列表单词，采取原地更新策略；
对于少见的一些单词，其倒排列表较短，称为短倒排列表单词，则采取再合并策略。

查询处理
一次一文档(Doc at a time)
以倒排列表中包含的文档为单位，每次将其中某个文档与查询的最终相似性得分计算完毕，然后开始计算另外一个文档的最终得分，直到所有的文档的得分都计算完毕为止。
步骤

找到和查询相关的所有文档；
按照文档顺序，计算每个文档和用户查询的相似性得分

对每个查询单词，若文档包含单词，计算文档和单词的相似性得分
将查询出现的单词对应的得分，累加得到最终相似性得分；


根据文档得分进行大小排序，输出得分Top K作为搜索结果输出，即可完成一次用户查询的响应。


一次一单词(Term at a Time)
将某个单词对应的倒排列表中的每个文档ID，都计算一个部分相似性得分，在计算完毕某个单词倒排列表中包含的所有文档之后，接着计算下一个单词的倒排列表中包含的文档。若发现某个文档ID已经有了得分，则在原先得分上进行累加。
步骤

找到和查询相关的所有文档；
按照查询单词顺序， 计算每个文档和用户查询的相似性得分

对每个文档，若文档包含单词，计算文档和单词的相似性得分
将文档的所有部分得分累加得到最终相似性得分；


根据文档得分进行大小排序，输出得分Top K作为搜索结果输出，即可完成一次用户查询的响应。


跳跃指针(Skip Pointer)
对于某些搜索引擎，认为文档必须包含所有的查询词，才认为文档是相关的；
文档ID是以文档编号差值（D-Gap）形式存储，且这个差值是以压缩后的方式编码的；
note: 若倒排列表直接包含文档ID，而不是差分，只需要通过归并排序能获得倒排列表集合的交集；
跳跃指针基本思想：将一个倒排列表数据化整为零，切分为若干个固定大小的数据块，一个数据块为一组，对于每个数据块，增加元信息来记录关于这个块的一些信息。

设置数据块大小，将一个倒排列表分成若干块
每个块前加入管理信息&lt;idx, Pos j&gt;表示第j个块的首个文档ID为idx

在一个具有跳跃指针的倒排列表中查找某个文档(已知文档ID)：

先根据跳跃指针，确定文档在哪一个块中；
连续顺序解压，恢复该块中所有的文档ID，进行比较；

数据块的大小一般设置为,其中倒排列表长度为,效果比较好

数据块越小，则使用跳跃指针向后进行跳跃的可能性越大，其缺点是增加了比较操作的次数；
数据块越大，则可以有效减少指针比较次数，其缺点是使用跳跃指针向后跳跃的可能性越小。

获得查询词的对应的倒排列表交集：反复在两个倒排列表中查找某个文档是否存在，将同时存在两个倒排列表中的文档ID作为计算结果。
跳跃指针的优点

相对不包含跳跃指针的索引来说，只需对其中一个数据块进行解压缩和文档编号查找即可获得结果，不用将所有索引数据都进行解压缩和比较操作。这明显加快了查找速度，并节省内存空间。

索引压缩
索引压缩则可以利用数据压缩算法，有效减少数据量，并且可以减少磁盘读/写数据量，加快用户查询的响应速度。
倒排索引包含两个部分：单词词典、单词对应的倒排列表。
词典压缩
词典组织方式，一般存储单词+DF+指向倒排列表的指针

哈希加链表
B树形词典结构

结构优化

将单词连续存储在某个内存区域，原来存储单词内容的部分由指向这个存储区对应单词起始位置的指针代替；
单词结尾可以采用下一个单词的指针所指向位置判断。


进一步的优化技术：

将连续词典分块，动态调整分块大小，以获取最优压缩效果；
原来每个词典项需保留一个指向连续词典区的指针，分块之后，每个块中的词典项共享同一个指针。
每个分块内包含多个单词，则为每个单词增加单词长度信息，以在提取单词时对块内不同单词予以区分。

倒排列表压缩
采用二进制编码：由二进制数字0和1表示实际数据，不同的比特宽度代表了不同的数字表示范围。
倒排列表压缩算法举例：


Elias Gamma算法:利用分解函数将待压缩的数字分解为两个因子，然后分别用一元编码和二进制编码来表达这两个因子。
将分解数字表示为,因子用一元编码表示，因子采用长度为的二进制编码表示


Elias Delta算法：利用了两次Elias Gamma算法，将待压缩的数字分解为3个因子，之后利用一元编码和二进制编码来进行数值压缩。
将分解数字表示为,因子用Elias Gamma算法继续分解为个因子，因子采用长度为的二进制编码表示


PForDelta算法：PForDelta算法是目前解压速度最快的一种倒排文件压缩算法，其主要思想是尽可能一次性压缩和解压多个数值。设定连续压缩个数值，取一定比例作为异常大数；
压缩的数据分为3部分：异常数据存储区、常规数据存储区、异常链表头。
压缩过程

确定小数的最大者，进而确定比例宽度；
对原始数据循环遍历，处理异常大数。遇到大数则逆序放置到静态数据尾端，并将异常大数转换为链表结构。
将小数一次性快速压缩，存入常规数据存储区，压缩按照先前得到的比例宽度

解压过程
一次性将常规存储区的数据进行解压，根据异常链表头、依次顺序读出异常大数的位置，结合尾部存储的异常大数恢复原始数值序列。



文本处理
一般来说，名词是最能表达文档内容的。因此，对文档进行预处理是必要的。
文本处理过程：

文本的词法分析：主要是对文本中的数字、连接符、标点符号和字符的大小写进行处理；
无用词汇的删除：主要是过滤掉那些对于信息获取过程来说区分能力低的词汇；
词干提取：主要是去除词缀（前缀和后缀），这样可以允许所获取的文档包含一些查询词条的变换形式；
索引词条/词干的选择：在选择时，通常按照单词的习惯用法，实际上名词往往要比形容词、副词和动词包含更多的语义；
构造词条的分类结构：例如词典或者结构抽取，利用它可以进行查询的扩展。

词法分析
将字符串（文档中的文本）转换成词条的过程，这些词条可能被用来作为索引词条。因此词法分析的主要目的是识别文本中的词条。

英文：在对英文进行分词的过程中，除了空格分隔符，还需要处理：数字、连字符、标点符号和字母的大小写。
数字：数字一般不适合用作索引词条，因为对于数字来说，如果不参考上下文，它就没有明确的含义。
连字符：对于连字符的处理，目前常用的是方法是，首先采用一定的规则选出那些对词义有影响的连字符号，然后将其他的连字符都过滤掉。
标点符号：在词法分析过程中，标点符号将被全部去除。但是，对于那些成为单词中一部分的标点符号来说，一般不可以去除。
字母的大小写：可以将文本中的所有词条都转换成大写或者小写。但是在某些特殊情况下，也需要对大小写进行区分。

中文分词技术
对于中文来说，词与词之间没有分隔符，且存在许多歧义现象；

单字切分：是指按照中文一个字、一个字地进行分词。按此方式切分出来的词进入索引，称为字索引。
二分法：是指每两个字进行一次切分。
词库分词：是指用一个已经建立好的词的集合去匹配目标，当遇上集合中已经存在的词时，就将之切分出来。

系统评价：


用户相应度：主要指用户对这项技术的满意度。


兼容性：要求能在不同的系统中都可以毫无障碍地使用，而且能给各行各业都带来方便。


准确率：是分词系统性能的核心指标，系统的准确率越高越好，应尽可能接近100%。
切分结果中正确分词数切分结果中所有分词数


运行效率：在分词系统中分词的工作消耗的时间应尽量少，使用户没有等待的感觉。


适用性：好的分词系统具有良好的适用性，可以方便地集成在各种各样的汉语信息处理系统中。


通用性：中文分词系统必须具有很好的通用性。应能适应不同地区的不同用字、用词，不同的语言风格，不同的专用名构成方式等；支持不同的应用目标，包括语音合成、校对、翻译等；支持不同领域的应用，包括社会科学、新闻、办公等。


中文分词算法：基于字符串匹配的分词方法、基于理解的分词方法、基于统计的分词方法。
中文分词难题：

歧义识别：歧义是指同样的一句话，可能有两种或者更多的切分方法。
新词识别：在字典中都没有收录过，但又确实能称为词的那些词。

基于字符串匹配的分词
机械分词方法，它是按照一定的策略将待分析的汉字串与一个“充分大的”机器词典中的词条进行配，若在词典中找到某个字符串，则匹配成功（识别出一个词）。
最大匹配法（Forward Maximum Matching method, FMM）:FMM算法是正向最大匹配算法，它是基于字符串匹配的一种分词方法。
算法思想：选取包含6~8个汉字的符号串作为最大符号串，把最大符号串与词典中的单词条目相匹配，如果不能匹配，就削掉一个汉字继续匹配，直到在词典中找到相应的单词为止。匹配的方向是从左向右。
**逆向最大匹配法（Backward Maximum Matching method，BMM）：基于字符串匹配的一种分词方法，基本算法和正向最大匹配法相似，只是匹配的方向是从右到左，该算法比FMM的精确度高一些。
双向匹配法（Bi-direction Matching method，BM）：将FMM法和BMM法结合起来的算法称为双向匹配法，这种算法通过比较两者的切分结果，来决定正确的切分，而且可以识别出分词中的交叉歧义。
最少匹配算法（Fewest Words Matching，FWM）：FWM实现的分词结果中含词数最少，它和在有向图中搜索最短路径很相似。控制首先要对所选的语料进行分段，然后逐段计算最短路径，得到若干个分词结果，最后进行统计排歧，确定最理想的分词结果。
网格分词算法：基于统计性的一种分词算法，它的算法思想是：首先构造候选词网格，利用词典匹配，列举输入句子所有可能的切分词语，并且以词网格形式保存；然后计算词网格中的每一条路径的权值，权值通过计算图中每一结点得一元统计概率和结点之间的二元统计概率的相关信息；最后根据搜索算法在图中找到一条权值最大的路径，作为最后的分词结果。
基于理解的分词方法
基于理解的分词方法是通过让计算机模拟人对句子的理解，达到识别词的效果。
基本思想：在分词的同时进行句法、语义分析，利用句法信息和语义信息来处理歧义现象。
通常包括三个部分：分词子系统、句法语义子系统、总控部分。在总控部分的协调下，分词子系统可以获得有关词、句子等的句法和语义信息来对分词歧义进行判断，即它模拟了人对句子的理解过程。
基于统计的分词技术
从形式上看，词是稳定的字的组合，因此在上下文中，相邻的字同时出现的次数越多，就越有可能构成一个词。因此字与字相邻共现的频率或概率能够较好的反映成词的可信度。可以对语料中相邻共现的各个字的组合的频度进行统计，计算它们的互现信息。
基本思想：定义两个字的互现信息，计算两个汉字X、Y的相邻共现概率。互现信息体现了汉字之间结合关系的紧密程度。当紧密程度高于某一个阈值时，便可认为此字组可能构成了一个词。这种方法只需对语料中的字组频度进行统计，不需要切分词典。
无用词汇删除
在信息库的文档中太频繁出现的单词将不会成为具有良好区分能力的词汇。
实际上，如果一个单词出现在信息库中80％的文档中，该单词对于信息获取过程来说没用，这些词统称为无用词汇。在选择索引词条的时候，这些词条常常被过滤掉。
一般来说，冠词、介词、连词都可以算作无用词汇。
删除无用词汇对于信息获取来说具有重要意义，它可以大大缩小索引空间的大小，而且空间的缩小一般可以在40％左右。
信息获取系统通常会设置一个无用词汇列表。删除无用词汇将影响系统的查全率，因此，一些搜索引擎采用了全文索引，对无用词汇也会建立索引。
英文词干提取
用户输入词汇是信息库中某个相关文档中词汇的一种变形，词汇的变形可以是该词的复数、动名词或过去分词形式等。在这种情况下，则可以将文档中的词汇用它们的词干来代替。
词干：是单词的一部分，是去除词的前缀和后缀后剩下的部分。
波特算法基本思想：对文本中单词的后缀应用一系列的规则，是目前公认最好的算法。该算法使用了560个后缀，上千条规则。
索引词选择
一些名词常常是两个或者三个同时出现，可以将这些词汇作为一个整体建立索引。在实际操作中，可以先设置一个阈值，计算文本中词汇之间的距离，如果该距离小于阈值，则将这些词汇放在一起构成名词词组。
搜索排序
搜索结果排序是搜索引擎最核心的构成部分，很大程度上决定了搜索引擎的质量好坏与用户接受与否。
相关计算框架
搜索引擎的核心是判断哪些文档和用户需求相关，并按照相关程度排序输出。相关度计算是将用户查询和文档内容进行匹配的过程，而检索模型是用来计算内容相关度的理论基础。
机器学习排序
利用机器学习技术对搜索结果进行排序，是非常热门的一个研究领域。
基本思路：提供训练数据，机器自动学习获得排序公式（传统检索模型由人工拟合排序公式）。

人工标注训练数据：对于某个查询Q，人工标出哪些文档是和这个查询相关的，并标出相关程度，或者利用用户点击记录来模拟这种人工打分机制。
文档特征抽取：每个文档是由若干特征构成的，通过特征抽取算法抽取文档特征，常用特征有文档长度、网页PageRank值、网页入链数量等。
学习分类函数：通过多个训练实例，采用机器学习技术对系统进行训练，生成分类函数。
在实际搜索系统中采用机器学习模型：利用生成的分类函数对与查询相关的网页进行排序。

机器学习排序可分为三类方法：单文档方法（Pointwise Approach）、文档对方法（Pairwise Approach）、文档列表方法（Listwise Approach）。
检索质量评价
混淆矩阵如下：




相关文献
不相关文献
总计




被检出文献
A
C
A+C


未检出文献
B
D
B+D


总计
A+B
C+D
A+B+C+D



查全率：衡量系统在实施某一作业时检出相关文献能力的一种测度指标，是对检索遗漏程度的度量。

查准率：衡量系统在实施某一检索作业时检索精度的一个测度指标，是对检索噪音程度的度量。

链接分析
搜索引擎在查找能够满足用户请求的网页时，主要考虑两方面的因素：一方面是用户发出的查询与网页内容的内容相似性得分，即网页和查询的相关性，另一方面是通过链接分析方法计算获得的得分，即网页的重要性。
PageRank算法
取万维网链接结构图，的规模为;
对于中的每一个节点，设是其PageRank值，而向量为G对应的PageRank结果向量,分量和为1,预先设定参数;
Simplified Version
初始化向量;
每一步迭代，向量获得更新如下：

算法充分迭代，直到向量收敛；
Standard Version
初始化向量;
遍历每一个结点:


若,则遍历的出度顶点,更新



若,则对所有顶点更新：



遍历完成后，更新向量;算法充分迭代，直到向量收敛；
HITS算法
HITS是Hyperlink-Induced Topic Search（基于超链接推演的主题搜索算法）的简称，其核心思想是对网页两个方面的权威程度进行评价，一个是内容权威度（Authority Value），即网页本身内容的受欢迎程度，另一个是链接权威度（Hub Value），即网页链接到其他受欢迎资源的程度。
对用户输入的查询的主题而言，首先是通过文本搜索过程与此查询主题内容相关的网页集合，并适当扩展该网页集合，以包括尽可能多的结果候选网页，同时使结果集合网页间的链接结构关系更加完整；
随后则是通过一个“迭代-收敛”的过程计算网页集合中每个页面对应的链接权威度与内容权威度数值，算法最后输出的是分别按照链接权威度与内容权威度排序的结果列表，用户可以根据需求的不同，选择其中的结果页面进行浏览。
记为网络信息检索结果集合，找到和有关链接的网页形成结构图
对于图中每一个结点，维护为其链接权威度和内容权威度；
初始化;
每一步迭代，进行I操作和O操作，对每一个结点


I操作：



O操作：



规范化处理：每个分量除以某数，使得



算法充分迭代直到收敛，或者到达迭代次数上限；
P的内容权威度与链向P网页的链接权威度相关（O操作）。链向P的网页的链接权威度越高，说明P的内容权威度越高。
链接权威度与内容权威度之间具有相互增强的关系。
缺点：

计算效率较低：HITS是与查询相关的算法，所以必须在接收到用户查询后实时进行计算，而其本身需要进行很多轮迭代计算才能获得最终结果，导致计算效率变低。
主题漂移问题：如果在扩展网页集合里包含部分与查询主题无关的页面，而且这些页面之间有较多的相互链接指向，那么使用HITS算法很可能会给予这些无关网页很高的排名，导致搜索结果发生主题漂移，这种现象称为紧密链接社区现象。
易被作弊者操纵结果：HITS算法从机制上很容易被作弊者操纵，比如作弊者可以建立一个网页，页面内容增加很多指向高质量网页或者著名网站的网址，这就是一个很好地Hub页面，之后再将这个网页链接指向作弊网页，于是可以提升作弊网页的内容权威度。
结构不稳定：如果在原有的扩展网页集合内，添加删除个别网页或者改变少数链接关系，则HITS算法的排名结果会有非常大的改变。

比较



HITS
PageRank




与用户输入的查询请求密切相关
与查询请求无关


必须在接收到用户查询后进行实时计算，计算效率较低
在爬虫抓取完成后离线计算，在线直接使用计算结果，计算效率高


计算对象数量较少，只需计算扩展集合内网页之间的链接关系
全局性算法，需要对所有页面节点进行处理


适合部署在客户端
适合部署在服务器端


更易受到链接作弊的影响
从链接反作弊的角度来说机制更优


结构不稳定
后者计算时的远程跳转，表现更稳定



网页去重
搜索引擎是在网络爬虫阶段进行近似重复检测（网页去重）的。

框架

特征提取：对于给定文档，首先需要进行特征抽取，从文档中抽取出一系列能够表征文档主体内容的特征集合。
文档指纹生成：在将文档转换为特征集合后，对信息进一步压缩，采用信息指纹相关算法，将特征集合压缩为新的数据集合。
相似性计算：通过相似性计算来判断哪些网页是近似重复页面。

Shingling算法
Shingling算法以Shingles作为文档的特征。
Shingles，即将文档中出现的连续单词作为一个整体，对这个单词片段进行哈希计算，形成一个数值，每个单词片段对应的哈希值称为一个Shingle。文档的特征集是由多个Shingle构成的。
以一个固定大小的移动窗口从文档第一个单词（单字）开始依次移动，每次向后移动一个单词（单字），直到文本末尾。
步骤：

从文档中抽取出能代表文档内容的特征
根据两个文档对应的特征集合的重叠程度来判断是否近似重复；

用Jaccard相似性计算文档特征集的重合程度：
对于特征集合,Jaccard相似性计算为

Shingling算法在运用过程中，计算效率不高，如果网页数量大，运行时间会过长。
原因在于把一个文档转换为以Shingles表示的特征集合形式后，这个文档对应的特征集合很大。
SuperShingle Trick
对于不同的网页，将其转换为固定大小的特征集合，这个特征集合的大小远小于原始Shingling算法转换后特征集合的大小，以此方法来提高运算效率。
一个改进的Shingleing算法步骤如下：

将文档转换为由shingles构成的特征集合；
通过引入m个不同的哈希函数，将文档映射为固定大小，形成哈希函数簇；
对于某个特定的哈希函数F，对每个shingle都计算出一个对应的哈希数值，取最小的那个哈希值作为代表；
m个哈希函数便获得了m个哈希值，如此便将文档的特征集合转换为了固定大小m。


在SuperShingle Trick中，取​,对84个数值进一步压缩，以14个连续数值作为一块，即分为6块，在采用另一个哈希函数对每一块的14个数值进行哈希计算，进一步将文档转换为6个哈希值；若任意两个文档有两个以上的哈希值是相同的，即可认为是近似重复文档；
SimHash算法
实践表明，SimHash是目前最优秀的去重算法之一,属于局部敏感哈希算法(Locality-Sensitive Hashing)的一种；

文档指纹计算：将一篇文本文档转换为固定大小的二进制数值，以此作为文档的信息指纹；
文档指纹计算：将一篇文本文档转换为固定大小的二进制数值，以此作为文档的信息指纹；

文档指纹计算是指：通过适当的抽取方法，从文档中抽取一批能表征文档的特征，获得文档的特征及其权值w，利用一个哈希函数将每个特征映射成固定长度的二进制表示，利用权值改写特征的二进制向量，将权重融入向量中，形成一个实数向量。对每个特征向量完成改写之后，累加所有实数向量，获得一个文档整体的实数向量。累加规则，即将对应位置的数值相加即可，最后将得到的实数向量重新妆化成二进制向量。
这里二进制向量和实数向量转换规则是

若二进制的某个比特位是数值1，则实数向量中对应位置改写为w；反之，若实数向量位对应大于0，则二进制向量的比特位为1；
若二进制的某个比特位是数值0，则实数向量中对应位置改写为-w，即权值的负数；反之，若实数向量位对应小于等于0，则二进制向量的比特位为0；


在实践中一般文档转换为64比特的二进制数值，内容相似性通过海明距离的大小衡量；
对于64位二进制数来说，判断两个文档是否近似重复的标准是：海明距离是否小于等于3，若两个文档的二进制数值小于等于3位不同，则判定为近似重复文档。
对于动态出现新网页，找出其近似重复的内容，可采用以下分组算法，将索引网页根据文档指纹进行分组，新网页只在部分分组内进行匹配，以减少新文档和索引网页的比较次数。

对64位长度的二进制数值进行分块，没16位为一块，则每个二进制数值被划分为4块，分别以A、B、C、D命名。
对于海量的索引网页，依据分块进行聚类：对于A块来说，根据该块内16位二进制聚类，若16位二进制都相同，则将这些网页看作一个聚类，依据此规则，可将索引网页分为若干组数据。对B、C、D按照相同方法聚类。
对于新抓取的网页，同样将64比特二进制数据分为4块：Q1、Q2、Q3、Q4。
在索引网页的分组中，找到对应A块16位和Q1完全相同的分组，然后与分组内的网页一一匹配，查找哪些网页是近似重复的。对Q2、Q3、Q4作同样处理。

将新网页与分组内的索引网页一一匹配：若两者二进制数值的海明距离小于等于3，则判定为近似重复文档。

网页反作弊
作弊方法
内容作弊
内容作弊是指通过精心更改或者调控网页内容，使得网页在搜索引擎中获得与其网页不相称的高排名。
搜索引擎排名包含了内容相似性和链接重要性计算，内容作弊针对的是内容相似性计算部分。
内容作弊方式：关键词重复、无关查询词作弊、图片alt标签文本作弊、网页标题作弊、网页重要标签作弊、网页元信息作弊。
链接作弊
链接作弊是指网站拥有者通过操纵页面之间的链接关系，或者操纵页面之间的链接锚文字，以此来增加链接排序因子的得分，影响结果排名。
链接作弊方式：链接农场、Google轰炸、交换友情链接、购买链接、购买过期域名、“门页”作弊
页面隐藏作弊
页面隐藏作弊是指通过一些手段欺骗搜索引擎爬虫，使得搜索引擎抓取的页面内容和用户点击查看到的页面内容不同，从而影响搜索引擎的搜索结果。
页面隐藏作弊方式：IP地址隐形作弊、HTTP请求隐形作弊、网页重定向、页面内容隐藏。
Web2.0作弊
Web2.0作弊是指通过以用户为中心的一些应用产品来作弊。
Web2.0作弊方式：博客作弊、点评作弊、标签作弊、SNS作弊、微博作弊。
反作弊技术
信任传播模型
在海量的网页数据中，通过一定的技术手段或者人工半人工手段，从中筛选出部分完全值得信任的页面，也就是一定不会作弊的页面（可理解为白名单）；
算法以这些白名单内的页面作为出发点，赋予白名单内的页面节点较高的信任度分值，其他页面是否作弊，根据其和白名单内节点的链接关系来确定。
白名单内节点通过链接关系将信任度分值向外扩散传播，如果某个节点最后得到的信任度分值高于一定阈值，则认为没有问题，而低于这一阈值的网页则被认为是作弊网页。

不信任传播模型
从技术框架上来讲，不信任传播模型和信任传播模型是相似的，两者区别在于：初始的页面子集不是值得信任的页面节点，而是确认存在作弊行为的页面集合，即不值得信任的页面集合（可理解为黑名单）。
赋予黑名单内节点不信任分值，通过链接关系将这种不信任关系传播出去，如果最后页面节点的不信任分值大于设定的阈值，则会被认为是作弊网页。

异常发现模型
异常发现模型基本假设：作弊网页必然存在有异于正常网页的特征，这种特征有可能是内容方面的，也有可能是链接关系方面的。
该模型具有两种子模型：一种是直接从作弊网页包含的独特特征来构建算法；另一种是将不正常的网页视为作弊网页。
反内容作弊
针对内容作弊，通常采用一些启发规则或者内容统计分析地方式进行识别。
对于重复出现关键词这种作弊方式，可以判断文本内一定大小的窗口中是否连续出现同一关键词，如果是，则消除重复出现的内容。
对于标题关键词作弊，可以判断标题词在文本正文出现的比例和权重，如果达到一定条件，则判断为标题关键词作弊。
反链接作弊
通用链接反作弊方法，是指这种反作弊方法不需要针对某种具体的作弊方式来做特征分析，并根据分析结果构建有针对性的算法。
例如TrustRank算法属于信任传播模型中的反链接作弊技术：采取信任分值均分策略：即将网页获得的信任分值按照出链个数平均分配，如果一个网页有K个出链，则每个出链分配得到1/K的信任分值，并将这个分值传递给出链指向的页面。
BadRank属于不信任传播模型的反链接作弊技术：首先构建作弊网页集合，之后利用链接关系来将不信任分值传递到其他网页，和TrustRank计算类似；
SpamRank算法是一种符合异常发现模型的反作弊方法。计算思路：

计算网页的PageRank值；
计算出网页的支持页面；
判断支持页面的PageRank分布是否违反Power-Law统计分布，若违反则作为作弊页面处理。

反隐藏作弊
常见的隐藏作弊方式有页面隐藏、网页重定向。
识别页面隐藏：对网页进行两次抓取，第一次是正常的搜索引擎爬虫抓取，第二次以模拟人工访问页面的方式抓取，如果两次抓取到的内容差异较大，则认为是作弊页面。
识别网页重定向：收集一批作弊页面，据其进行扩展，检测到经常与这些作弊页面链接一起出现的链接，则扩充进可疑页面集合。依次访问这些页面，若某个页面被诸多可疑链接重定向指向，或者重定向到作弊网页的可疑链接，均被认为作弊网页。
]]></content>
      <tags>
        <tag>Information-Retrieval</tag>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>进程</title>
    <url>/2025/07/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F1-%E8%BF%9B%E7%A8%8B/</url>
    <content><![CDATA[什么是进程
程序的顺序执行与并发执行
顺序执行：若干程序和程序段必须严格按照某种先后顺序执行

顺序性：操作严格按照程序规定的顺序执行；
封闭性：程序运行时占用全机资源；
可再现性：只要程序的执行环境和初始资源的条件相同，结果就相同；

并发执行：多个时间在同一个时间间隔内发生；

应用级并发：事务处理系统，数据库管理系统
系统级并发：操作系统；
间断性：由于资源的共享和相互合作，程序体现执行-暂停-执行的现象
失去封闭性：程序在并发执行时，是多个程序共享系统的资源，资源的状态有多个程序来改变；
不可再现性：程序在并发执行时，由于失去了封闭性，多次重复可以得到不同的结果；


进程
引入进程的目的：为了 控制 多道程序能够 正确的并发 执行
定义：(程序代码program code + 数据集set of data + 进程控制块PCB，process control block)

一个正在执行的程序；
一个正在计算机上执行的程序实例；
一个能够被调度到处理器上执行的实体；
由一串指令的执行、当前状态和一组正在使用的系统资源表征的活动单元；

进程的物理存在：进程映像

Process Image=PCB+program+data+stack；
进程映像取决于文件格式；

系统中同时存在的诸进程相互独立，也相互关联，这取决于设计模式；
可以说，并发基于进程；
进程控制块
进程执行的任意时刻可以由 进程控制块 表征，组成如下：

标识符
状态
优先级
程序计数器
内存指针
I/O状态信息
记账信息......

注意，PCB常驻内存，PCB是进程存在的唯一标志；
进程的特征

动态性：最基本特征，是计算机的执行的程序实例，存在生命周期；
并发性：多个进程实体存在于内存中也能在一段时间内同时运行，可以说进程的设计就是为了操作系统的并发；
独立性：进程实体是独立运行的基本单位，也是系统独立获得资源和调度的基本单位，各个进程的地址空间相互独立除非进程间相互通信；
异步性：各个进程按照独立的，不可预知的速度向前推进；

注意：进程和程序之间不存在一一对应的关系；
进程带来的挑战

空间开销：为进程建立数据结构PCB
时间开销：管理和协调，跟踪，填写和更新相关的数据结构，切换进程，保护现场
控制复杂性：协调多个进程对资源的竞争和共享，预防解决多个进程因为资源竞争问题带来的故障

进程状态模型
由于进程具有动态性，执行间断性和多种状态的特征，需要建立进程状态的自动机描述；
进程轨迹trace ：进程执行的指令序列，描述单个进程的行为；
调度器dispatcher：调度多个进程的执行；
以下是 轮转（round-robin） 的例子：通过指定一个时间片，处理器决定是否切换进程;


两状态模型
进程处于两种状态之一：

运行态：进程队列的头部进程被系统调度执行；
非运行态：进程创建后，以非运行态进入进程队列中；

进程队列：存放指向特定进程的指针；

三状态模型
进程处于三种基本状态之一：

就绪ready：

进程已经获得除开CPU外的所有必要资源后，只需获得CPU立即执行进程


执行running：

进程获得CPU，程序正在执行；


阻塞waiting：

正在执行的进程因为其他事件的等待无法继续执行；
进程放弃处理机而处于暂停状态；



对于一些嵌入式的操作系统，三状态模型足以描述：

注意：

状态转换并非都可逆
一个进程在任何一个指定的时刻必须而且只能处于一
种状态
时间片完也不是执行-就绪的唯一原因，可能是高优先级抢占控制权
在单处理机系统中，只有一个进程处于执行状态

五状态自动机
进程新增两个状态后真正称为自动机模型：

新建New：

进程刚刚创建，OS完成了进程创建的必要工作(构造了进程标识符，创建了进程管理的表格)
OS未将进程加入可执行进程组，进程自身未进入主存，进程尚未被同意执行，进程的程序也没有分配空间而保存在辅存；
进程创建原因：新的批处理作业，交互登陆，提供服务，现有进程派生


终止Exit

进程不再具有执行资格；
表格和其他信息暂时保留，OS从可执行进程组释放；
原因：正常完成，超时，无可用内存，各种错误...




注意：

加载/接纳：OS做好接纳进程的准备后，将一个进程从新建态转换成就绪态；
就绪-退出，阻塞-退出：某些系统中，父进程可以在任何时候终止一个子进程，这样的转换可能存在；

排队模型实现：维护就绪队列和阻塞队列

进入OS的每个进程放在就绪队列中，OS选择进程运行时在就绪队列中选择一个；
运行的程序被移除处理器后，要么终止，要么进入就绪队列或阻塞队列
某事件发生导致阻塞队列中的相应进程进入就绪队列中；

具体实现：
多阻塞队列可以避免对很长的队列进行扫描；

七状态自动机
交换技术swapping和挂起suspend
进程竞争内存资源：内存紧张，或者所有进程因为某事件等待，但是无就绪进程，处理机实际空闲
解决方案：扩充内存，swapping

将内存中处于阻塞、就绪、甚至是执行状态的进程swapping-out进外存(磁盘)
不再参与CPU的竞争，我们把这种静止状态称为挂起状态；
在磁盘中维护一个挂起队列，建立虚存；
当存在已具备运行条件的进程或进程所需要的数据和程序，Swapping-in到内存。

进程挂起的原因：

进程全部阻塞，处理机空闲
交换，如系统负荷过重，内存空间紧张
操作系统的需要，操作系统可能需要挂起后台进程或一些服务进程，或某些可能导致系统故障的进程。
终端用户的请求,如调试
父进程请求

被挂起进程的特征

不能立即执行
挂起条件独立于阻塞条件
使之挂起的进程：自身、OS、父进程
激活挂起进程的进程：实施挂起操作的进程

当被挂起的进程返回内存时，OS不一定执行的准备，进一步划分：

就绪挂起：进程在外存，只要调入内存并获得CPU即可执行
阻塞挂起：进程在外存，并等待某事件


注意：

加载：新建进程后，进程要么加入就绪队列，要么进入就绪挂起队列，视当时的资源而定；

创建进程的just-in-time原理：尽可能推迟创建进程以减小系统的开销；


运行-就绪挂起：一般来说，运行进程的分配时间到期后就会转换成就绪态，但是某个具有高优先级的进程位于阻塞/挂起队列不被阻塞时，OS会抢占这个进程

进程描述
进程的执行必须由操作系统分配资源，操作系统是资源的管理者：采用表格记载资源的信息，进而实现资源的管理，维护和更新；

内存表
I/O表
文件表
进程表


进程控制块
包括信息主要有三类：

进程标识信息；唯一标识一个进程

内部标识符：操作系统为每个进程赋予的一个唯一整数，便于系统控制
父进程标识符
用户标识符


处理机状态信息：主要是上下文，由处理器的各种寄存器中的内容组成的

通用寄存器
控制和状态寄存器
栈指针


进程控制信息：与进程调度和进程切换有关的信息

进程状态
进程优先级
时间记账
阻塞原因
链接指针
进程间通信
程序和数据地址
资源所有权和使用情况



进程的组织方式
索引
系统为所有进程的状态建立几张索引表；

链接


单一队列：所有PCB块连接成一个队列



多级队列：相同状态的PCB块连接成一个队列



内核
内核是操作系统的核心，是包含重要系统功能的部分，常住内存以提高操作系统的系统功能；
不同操作系统对内核的设计(功能范围的设定)不同；


资源管理


进程管理：进程的创建和终止，调度，分配，切换，同步和进程间通信，管理PCB


存储管理：为进程分配地址空间，交换，页和段管理


I/O管理：缓冲区管理，为进程分配I/O通道




支撑功能

中断：操作系统的一切重要活动最终依赖于中断
时钟
记账



执行模式

大多数处理器至少支持两种模式：内核模式，用户模式
某些指令只能在特权模式运行，部分内存只能在特权模式下访问
采用两种模式可以保护操作系统和重要的系统操作表不受程序干扰
查看运行模式：程序状态字寄存器PSWR下指示执行模式的位

模式切换：

原因：系统调用或中断，中断发生时，将程序计数器设置为中断程序处理的开始地址，切换成内核模式使得中断程序可以执行某些特权指令
中断不一定引发进程切换，也不一定造成模式切换，模式切换和进程切换无决定关系

进程控制
进程控制包括以下事件：

进程的穿件与撤销
进程的阻塞和唤醒
挂起和激活
进程切换

实现方式：原语Primitive

原语用于完成一定功能的过程，定义了原子操作
其执行过程不允许被中断；

create原语：创建进程

为新进程分配唯一一个进程标识符
为进程分配空间
初始化进程控制块（标识信息，处理机状态信息，调度信息）
建立连接，插入就绪（就绪/挂起）队列
建立扩充其他相关的数据结构

后面两步是方便操作系统管理进程的必要步骤；
进程终止原语

根据标识符找到其PCB，读出进程的状态
对于执行状态的进程，终止它，调度下一个进程就绪进程的执行
若进程存在子进程，不同的操作系统有不同的处理方式，挂在其他结点或者终止它
将进程的全部资源归还（父进程或者OS）
被终止进程的PCB从队列中移除，等待其他程序搜集信息

进程阻塞

对于执行状态的进程发生阻塞时，使用Block（）原语将自己阻塞
将PCB的状态由执行到阻塞将PCB加入阻塞队列
将处理剂分配给下一个就绪进程并切换

进程唤醒

被阻塞进程期待的事件出现时，有关进程调用唤醒原语wakeup（），等待该事件的进程唤醒
唤醒进程原语执行：将被阻塞进程从队列移出，将PCB中现行状态由阻塞改为就绪，插入到就绪队列中

进程挂起
出现引起进程挂起的事件时，系统将利用挂起原语suspend（）将指定挂起；

检查被挂起的状态
插入相应队列

进程激活

发生激活进程的事件时，将在外存上处于挂起的进程换入内存

利用激活原语active（）将指定进程从外存调入内存：检查进程状态，插入相应队列



进程切换
进程切换：调度另一个就绪进程占用处理器
进程上下文：进程执行的现场
发生原因：

时钟中断
IO中断
内存失效
陷阱
系统调用

步骤：

保存处理器上下文，包括程序计数器和其他寄存器
更新运行进程的PCB
将PCB移动到相应队列
选择另一个进程执行
更新另一个PCB
恢复被选择的上下文

线程
线程是进程的一个实体，是独立调度和分派的基本单位；
进程是系统进行资源分配和调度的独立单位；
线程是进程的一个实体，是对调度和分配的基本单位；

进程是系统中拥有资源的单位，比如进程映像的地址空间，全局变量，打开文件，IO设备
线程，拥有少量的私有资源（线程控制块，栈…）
同一进程哪的线程共享全部资源
同一进程的线程切换不会引发进程切换
不同进程中线程切换将引起进程切换
同一进程的多个线程也存在并发，提高系统资源的使用和系统吞吐量
线程间通信比进程间通信快很多
线程的系统开销小于进程，同一进程的多个线程同步和通信更容易

状态

就绪状态
执行状态
阻塞状态

一般不具有挂起状态，一个进程可以创建和撤销多个线程,同一个进程的多个线程可以并发执行
基本操作

派生spawn：
阻塞block
解除阻塞ubblock
结束finish

分类

用户级线程
内核级线程
混合线程

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>System</tag>
      </tags>
  </entry>
  <entry>
    <title>调度</title>
    <url>/2025/07/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F2-%E8%B0%83%E5%BA%A6/</url>
    <content><![CDATA[进程调度
如果存在多个进程竞争CPU，那么需要选择下一个要运行的进程；

调度程序
调度算法

目标：满足系统目标（响应时间，吞吐量，处理器效率）的方式，将进程分配称一个或多个处理器上执行；
调度层次类型：长程/中程/短程……
长程调度
决定外存上后备队列中哪个作业进入内存处理
考虑两个问题：

何时创建进程

取决于多道程序的并发度；
处理器的空闲时间超过某个阈值，也可能启动长程调度；


选择哪些作业进行调度

取决于调度算法



中程调度
属于对换功能的一部分，用以提高内存的利用率和系统的吞吐量；

内存紧张时，选择一个进程换出到外存
内存充裕时，从外存选择一个挂起的进程调度到内存
只有支持进程挂起的操作系统支持中程调度

短程调度
决定就绪队列中哪个进程应该获得处理器；

运行频率最高；
现代操作系统几乎都设计了短程调度功能；
引发原因：时钟中断，io中断，操作系统调度，信号；

调度规则
周转时间
构成：作业提交给系统，到作业完成的时间间隔

驻外存等待调度时间
驻内存等待调度时间
执行时间
阻塞时间

平均周转时间

带权周转时间

平均带权周转时间

响应时间
从用户提交请求开始， 到系统首次产生响应的时间；

输入传送时间
处理时间
响应传送时间

截止时间

某任务必须开始执行的最迟时间；
必须完成的最迟时间；

系统吞吐量
在单位时间内系统完成的作业数；
需求

面向用户

响应时间快：使绝大多数用户的请求能在能够接受响应的时间完成，常用于评价分时系统
平均周转时间短：常用语评价批处理系统
截止时间：常用语评价实时系统


面向系统：

系统吞吐量大：评价批处理系统
处理器利用率高：评价大型用户系统
公平性
资源平衡使用
优先权高进程优先调度



决策模式

抢占（剥夺）方式：中断当前进程，让优先级较高的进程执行
非抢占（非剥夺）方式：执行进程只有在执行完毕时才会释放处理机的进程，不适合即时性较高的场景

调度算法
系统的资源 分配策略 规定的资源分配算法，以针对不同的系统目标；
常见的调度算法：

先来先服务
时间片轮转
短作业优先
剩余时间最短
最高响应比优先
反馈

先来先服务FCFS
选择最先进入就绪队列的进程投入执行，进程按照请求CPU的顺序使用CPU
评价：

属于非抢占调度方式
有利于CPU繁忙的进程，不利于IO繁忙的进程
不利于直接用于分时系统
平均周转时间长
对于长进程有利，不利于短进程
简单，但是相对公平

时间片轮转RR
CPU被每个进程分配自己的时间片，在时间片结束时进程还在运行，则抢占其CPU分配个下一个进程；
被剥夺CPU的进程插入到队列末尾等待下一次的调度；
如果该进程在时间片内注射或结束，则立即切换CPU；
评价：

属于抢占式调度
常用语分时系统和事务处理系统
时间片设置和系统性能，响应时间密切相关（时间片短导致调度程序和中断次数多，时间片长引起短交互请求的响应时间变长）
时间片的大小的确定要考虑最大最大用户数量，响应时间，系统效率

虚拟轮转法VRR
增加一个基于FCFS的辅助队列，接受I/O阻塞完成的进程，调度优先于主就绪队列，但是占用处理机时间小于主就绪队列的时间片
评价：

VRR相较RR公平
常用语分时系统，事务处理系统

短进程优先SPN/SJN
进程的执行时间预知，选择短进程优先调度
评价：

SPN属于非抢占式调度算法
对长作业不利，可能导致饥饿
有利于短进程，减小了平均周转时间
缺少剥夺机制，不适用分时系统或事务
算法不一定准确，不一定真正做到短作业优先

剩余时间最短者优先SRT
调度程序总是选择预期时间最短的进程
当新进程加入就绪队列，若它比当前运行进程更短的剩余时间，就会发生抢占
在SPN上增加了剥夺机制；
评价：

不像FCFS偏爱长进程，也不像RR产生额外的中断，减小了开销
在周转时间方面，SRT性能比SPN更好，短作业可以立即被选择执行
需要预估服务时间，可能存在进程饥饿，必须记录进程的已服务时间

最高响应比优先HRRN
当前进程执行完毕/需要阻塞时，选择就绪队列中响应比最该的进程投入执行；

评价：

HRRN本质上是动态优先权调度算法
结合了FCFS和SPN，既照顾了短进程，又考虑了到达的先后次序，不会使长进程长期得不到服务
每次调度前需要计算响应比，既增大了开销又难以准确计算

反馈调度法FB
采用多级队列区别对待，惩罚长进程；

准备多个独立的，优先级不同的就绪队列
优先级高的队列被优先调度
进程执行过程可能 被降级，整个生命周期内可能位于不同的队列；

以基于时间片轮转的FB算法为例：

设置多个就绪队列，其优先级不同

优先级约到的队列，进程执行的时间片越小


新进程进入，首先放入第一个队列的队尾，FCFS原则排队
若进程在规定时间片完成，则退出

队列调度的进程允许执行的时间，才会被抢占
若时间片完则被抢占被抢占的进程降级到下一个优先队列


到末尾队列不再降级
当且仅当上一个队列空闲，下一个队列的进程才被调度

评价：

FB算法具有较好的性能，平衡了各类需求
有利于终端作业用户，这类通常为短作业，一般能在第一队列规定的时间片做完
对于长批处理作业，也能在前几个队列规定时间片完，但是不断有长进程到来时，可能存在饥饿

实时系统和实时调度
实时系统
系统能及时响应外部事件的请求，规定时间内完成对该事件的处理，控制所有的实时任务协调运行
实时操作系统的特点

可确定性：任务按照固定的预先确定的时间间隔进行
可响应性：关注系统知道中断后为中断提供服务时间
用户控制：用户能区分软实时和硬实时任务，控制任务优先级
可靠性：实时控制，响应事件，保障性能
失效弱化：不能满足所有任务的实时性时，优先满足重要的，优先级高的任务期限，减少系统故障
调度方式
基于时间片的轮转抢占式

进程按照时间片轮转方式执行，到达进程放在就绪队列末尾
时间片完进行调度，响应时间为秒级，广泛用于分时系统和一般实时处理系统


基于优先级的非抢占式

进程按照优先级，非抢占的方式，新来的进程在就绪队列的头部
当前进程阻塞或完成时，立即调度新来的进程
响应时间为数百毫秒到数秒，用于多道批处理系统和不太严格的实时系统


基于优先级的抢占点抢占调度

进程按照优先级，抢占方式执行
下一个剥夺点到来时，立即占用CPU
响应时间为数十毫秒，用于一般实时系统


立即抢占式调度

按照优先级，抢占方式
响应时间在微妙级，用于苛刻的实时系统



实时任务
具有及时性，常常被重复执行，往往预先设定的特定进程，在实时系统中称为任务

开始截止时间：该时间之前任务必须执行
完成截止时间：该时间之前任务必须结束
分类：
按截止时间划分：硬实时任务，软实时任务
按周期性划分：周期性实时任务，非周期性实时任务

实时调度
静态表驱动调度
用于调度周期性实时任务
按照任务周期到达的时间，执行时间，完成截止时间以及任务的优先级，制定调度表，调度实时任务
比如：最早截止时间优先(EDF)调度算法
任何任务调度申请改动都会引起调度表的修改，带来不灵活性；
静态优先级抢占调度
多用于非实时多道程序系统
优先级确定方法很多
实时系统一般对任务的限定时间赋予优先级；
比如：速度单调算法(RMS)为实时任务赋予静态优先级

任务速率：任务周期以赫兹为单位
优先级确定：任务周期越短，优先级越高；优先级函数时任务速度的单调递增的函数
系统按任务优先级的高低工作进行调度；

基于动态规划的调度
实时任务到达以后，系统为新到达的任务和正在执行的任务动态创建调度表
在当前执行进程不会错过截止时间的条件下，如果也能使新到达任务在截止时间完成下，则立即调度执行新任务；
动态尽力调度法
广泛用于非周期性实时任务调度
当任务到达时，系统根据属性赋予优先级，优先级高的先调度；
比如EDF算法总是尽力尽早调度紧迫任务；
缺点：当任务完成或者截止时间到达时，很难知道该任务是否满足其约束时间；
限期调度
对具有完成期限的周期性实时任务
这类任务往往周期性可预测的；
一般采用最早截止时间优先调度算法EDF；
对具有开始期限的非周期性实时任务
这类任务往往是非周期的不可预测的；
预先知道任务的截止时间可采用允许CPU空闲的EDF调度算法；

优先调度截止时间最早的合格任务，并运行完毕
合格任务可以是还未就绪，但是事先知道开始截止时间的任务
CPU利用率不高，但是系统的任务都能按要求完成

实时系统处理能力限制
假定系统中有个周期性硬实时任务，处理时间分别为，周期为,则在单处理机的情况下，满足如下限制

CPU利用率=任务执行时间/任务周期；
各个任务的处理器利用率总和不超过1；
优先级反转
一个高优先级任务简介被一个低优先级任务所抢占，使得两个任务的相对优先级被倒置；
系统不希望这种调度任务状态，但是可发生于任何基于优先级的可抢占的调度方案；
解决方案：优先级继承，优先级较低的任务继承任何与其共享同一资源的优先级较高的任务的优先级
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>System</tag>
      </tags>
  </entry>
  <entry>
    <title>并发</title>
    <url>/2025/07/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F3-%E5%B9%B6%E5%8F%91%E6%80%A7/</url>
    <content><![CDATA[概念
原子操作：一个函数或者动作，由一个或多个指令序列实现，

对外不可见，没有其他进程可以看到其中间状态或者中断这个操作
保证指令序列要么都执行，要么都不执行
保证了并发进程的隔离

同步：为了完成任务而建立的多个进程，这些进程为了需要在某些位置上协调工作而等待，传递信息而产生的制约关系

空闲让进：没有进程处于临界区时，可以允许一个请求进入临界区
忙则等待：已有进程进入临界区时，其他试图进入临界区的进程必须等待
有限等待：对要求访问临界资源的进程，保证要在有限时间内进入临界区
让权等待：当进程不能进入临界区时，应该释放处理机

互斥：当一个进程在临界区访问共享资源时，其他进程不能进入临界区访问共享资源
临界区：进程将访问共享资源的一段代码


一个进程在临界区运行时，另一个进程无法进入临界区


一次只有一个程序在临界区


死锁：多个进程相互等待导致都不能执行
活锁：进程为像一个其他进程的变化，持续改变自己的状态，但不做有用的工作
竞争：多个进程读写一个共享变量，该变量的最终指依赖它们的相对调度
饥饿：进程已经完全具备了了执行条件，但是得不到CPU资源
进程并发面临问题

忙等：没有执行有用的事情但是一直占用处理机，违背了让权等待的原则；
永久阻塞：需要得到临界资源的进程永远得不到资源，违背了有限等待的原则；
死锁：每个进程误以为对方进入了临界区，使自己处于阻塞
互斥礼让：代表进入临界资源区的标志为不断的重置和检查，重置序列无限延伸，任何进程不能进入自己的临界区

硬件方法实现互斥和同步
中断屏蔽

利用开关中断指令实现，类似于原语
即先关中断，关中断后即不允许当前进程被中断，也必然不会发生进程切换，然后进入临界区，直到当前进程访问完临界区，再执行开中断指令，才有可能有别的进程上处理机访问临界区。
简单高效，但是不适合多处理机，只适用于操作系统内核进程，不适合用户进程

TestAndSet，Swap(TS指令/TSL指令/Swap指令)

TSL指令是用硬件实现的，执行的过程不允许被中断，只能一气呵成。相比软件实现方法，TSL 指令把“上锁”和“检查”操作用硬件的方式变成了一气呵成的原子操作。
实现简单，无需像软件实现方法那样严格检查是否会有逻辑漏洞
适用于多处理机环境
不满足“让权等待”原则，暂时无法进入临界区的进程会占用CPU并循环执行TSL指令，从而导致“忙等”

整形信号量
将可用的资源数定义为一个整型量，初始化后可通过两个原子操作访问

wait(S):P操作,while(S&lt;=0);S—-;
signal(S):V操作,`S++
整形信号量不遵循让权等待原则；

记录型信号量
由两部分构成：

代表资源数目的整型变量Value
表示所有等待进程的进程链表L

typedef struct Semaphore &#123;	int Value;	List_of_Process L;&#125;;void Wait(Semaphore s)&#123;    s.Value --;    if(s.Value &lt; 0)&#123;    	L.push(now_process);        block(now_process);    &#125;&#125;void Signal(Semaphore s)&#123;    s.Value ++;    if(s.Value &lt;= 0 ) &#123;        next_process = L.top();        wakeup(next_process);    &#125;&#125;
当Value初值为1，表示只允许一个进程访问临界资源，转化为互斥信号量（二元信号量）；
简单说明互斥锁和二元信号量的区别：

为互斥量加锁和解锁的进程只能是同一进程；
可能有某个进程对二元信号量加锁，另一个进程为其解锁；

一般来说，对于多个进程互斥访问临界资源的情况，每个进程应该都要设计代表访问临界资源的锁；
Semaphore mutex(1);void Process1&#123;	// 申请访问其他资源		P(mutex); // 申请进入临界区	// Critical Section 临界区代码	V(mutex); // 释放临界区资源		// 释放已申请的其余资源&#125;
进一步还可以利用信号量设计进程间的前趋关系；
AND信号量
将进程在整个运行过程中需要的所有资源，一次性全部地分配给进程，待进程使用完后再一起释放。只要尚有一个资源未能分配给进程，其它所有可能为之分配的资源，也不分配给他。
对临界资源的分配采用原子操作的方式；
信号量集
对每一类资源，设定一个下限值和需求单位值；
Swait(S1, t1, d1, …, Sn, tn, dn) 	if ( S1≥t1 and … and Sn≥tn ) 	for  ( i=1;i&lt;=n; i++) 		Si =Si-di; 	else

Swait(S, d, d) 此时在信号量集中只有一个信号量，  但允许它每次申请d个资源，当现有资源数少于d时，不予分配;
Swait(S, 1, 1)此时的信号量集已退化为一般的记录型信号量(＞时)或互斥信号量(时);
Swait(S, 1, 0)这是一种很特殊且很有用的信号量 操作。当时，允许多个进程进入某特定区；当变为0后， 将阻止任何进程进入特定区。换言之，它相当于一个可控开关。

管程Monitor
管程是由一个或多个过程，一个初始化序列和局部数据组成的软件模块

局部变量数据只能被管程的过程访问，外部过程无法访问
一个进程通过调用管程的一个过程进入管程，设计一个入口，进入管程之前先进入管程的待进入队列中；
只能有一个进程在管程中执行，其他调用管程的进程将被阻塞；


管程通过条件变量支持同步,其原子操作和普通的信号量不同；

cwait(c): 调用进程的执行 在条件c阻塞，管程可以被另一个进程使用；
csignal(c)：恢复在cwait(c)之后因为某些条件被阻塞的进程；

在一个进程在管程中时，因为某种原因，这个进程发送cwait(x)将自己暂时阻塞在条件x上，此时加入条件x的条件队列，之后这个进程等待条件x的改变，以重新进入管程的待进入队列中，若进程发现条件x真的发生了改变，则发送csignal(x)通知相应的条件队列条件已经改变；
Producer-Consumer Problem
描述

有一个或多个生产者生产某种资源，放入缓冲池
有一个消费者从缓冲池读取资源，每次读取一项
任何时候仅有一个生产者/消费者可以访问缓冲池，
缓冲池已满时，生产者不再往其中添加资源；
缓冲池为空时，消费者不会从中移走资源；

信号量实现

利用互斥信号量mutex实现对缓冲池的互斥使用
利用信号量empty full表示缓冲池中空区和满区的数量；


size_t n;Semaphore mutex(1);Semaphore full(0), empty(n);Item Buffer[n];int in=0;int out=0;void append(Item v)&#123;	Buffer[in] = v;    in = (in+1)%n;&#125;Item take()&#123;    v = Buffer[out];    out = (out+1)%n;    return v;&#125;void Producer()&#123;    while(true) &#123;        v = produce();                P(empty);        P(mutex);        append(v);        V(mutex);        V(empty);    &#125;&#125;void Consumer()&#123;    while(true)&#123;        P(full);        P(mutex);        v = take();        V(mutex);        V(full);                comsume(v);    &#125;&#125;
对于一系列P操作和V操作，也可以用AND信号量实现，不过注意，对P操作的顺序不能颠倒，否则将可能导致死锁；
Reader-Writer Problem
描述

多个进程对同一个文件进行读写
不能同时写文件
不能同时读和写文件
可以同时读文件

信号量实现

设置写锁Wmutex,由于最多有一个进程在写，因此这应该是一个互斥信号量
设置读锁Rmutex，用于记录目前在读文件的进程数ReaderCnt，这些进程应该互斥地修改它；

Semaphore Rmutex(1)Semaphore Wmutex(1);int ReaderCnt = 0;void Reader(file) &#123;	P(Rmutex);    if(ReaderCnt == 0) P(Wmutex); 	ReaderCnt ++;    V(Rmutex);        open(file);    read(file);    close(file);        P(Rmutex);    ReaderCnt --;    if(ReaderCnt == 0) V(Wmutex);    V(Rmutex);&#125;void Writer(file) &#123;    P(Wmutex);        open(file);    write(file);    close(file);        V(Wmutex);&#125;
死锁
哲学家进餐问题

5个哲学家坐在圆桌，他们中间穿插5只筷子
哲学家进餐必须同时具备左边和右边的筷子
一只筷子在同一时刻只能由一位哲学家使用，
哲学家在进餐完毕后必须将筷子放回原处，然后思考哲学问题；

一般我们将5只筷子设置为5个信号量，哲学家进餐前默认先拿起左边的筷子，再拿起右边的筷子后，进餐，完毕后先放下右手的筷子，再放下左手的筷子，然后思考或等待下一次进餐；
注意：
假如五位哲学家同时饥饿而都拿起的左边的筷子，就会使代表筷子的5个信号量同时置0，这时他们试图拿起右边的筷子时，都因为相互等待二陷入死锁；
可以进行如下的改进策略：

限制并发量：至多允许4个哲学家同时进餐
解除环路等待：指定一位哲学家必须先拿起右边的筷子
恢复策略：死锁发生时，指定一位哲学家放下自己的筷子；
检测策略：哲学家进餐前，同时申请两只筷子；
管程优化：每次只有一个进程进入管程

产生原因

竞争资源：资源包括可剥夺资源和非剥夺性资源，一般是竞争非剥夺性资源，竞争临时性资源引起；
进程间推进顺序不当；

充分必要条件

互斥条件：至少有一个资源是非剥夺性的
请求并保持条件：进程因请求新的资源而保持对已有资源的占有
不可剥夺条件：已获得的资源在未使用完之前，不能被其他进程抢占
环路等待条件：存在一组进程，使得每个进程都在等待其他进程所持有的资源

注意，前三者是死锁发生的必要条件，而非充分的；
预防死锁
预防死锁发生的可能（一般不会禁止互斥条件，如果操作系统实现了互斥的话）

预防请求并保持条件

进程在执行前，一次申请完执行过程中可能用到的所有资源；


预防不可剥夺条件

进程已占用一些资源，但后续资源得不到满足，必须释放已经占用的资源；
高优先级进程申请被低优先级进程占用的资源，系统将后者资源抢占，分配给前者；


预防环路等待条件

将资源进行排序（定义资源的线性顺序），若进程获得资源，后续资源序号只能都大于或都小于;



注意，预防死锁可能会导致资源的低效使用和低效的进程执行
避免死锁
死锁避免允许三个必要条件的发生，但是明智的选择确保不会到达死锁点，因此允许了更多的进程并发；
安全状态
系统能找到进程的执行序列，为每个进程分配所需资源，直到每个进程的最大需求 ，使得每个进程都可以顺利完成

允许进程动态地申请资源
分配之前检查会不会导致系统进入不安全的状态

考虑一个有个进程，个不同类型资源的系统，定义
struct state &#123;	int resource[m]; 		// 系统中每种资源的总量，向量R    int avalaible[m];		// 未分配给进程的每种资源的总量,向量V    int claim[n][m];		// 进程i对资源j的最大需求,矩阵C    int allocation[n][m];	// 	系统为进程i分配资源j的数量,矩阵A&#125;
不难看出以下关系成立：

对于每类资源，要么可用，要么已被分配：
任何进程对任何资源的请求不能超过这个系统中的资源总量：
任何进程得到的资源数不会超过最开始声明得到此资源的最大数量：
启动新进程的充分必要条件：

安全性检查算法
系统如果要将资源分配给进程,必须满足：

那么只需要以此找到满足上述约束关系的进程，执行完成后释放，找到下一个满足的进程；
安全性检查算法描述如下：


设置工作向量work[m]:表示系统可提供给进程继续运行所需的各类资源的数目； finish[n]：表示系统是否有足够的资源分配给进程，使之运行完成；


初始化work := available finish := false


从满足finish[i]=false的进程集合找到满足上述约束条件的进程i

若能找到，执行4
若不能找到，执行5



进程i得到资源执行后，释放其资源，应该执行
work[j] += allocation[i][j]finish[j] = true
后，返回2


若所有进程的finish值均为true，则说明系统安全，否则系统处于不安全状态；


银行家算法
某一时刻收到进程i的对系统资源的请求向量request_i；
按照以下步骤对系统资源状态进行检查：


检查request_i[j]&lt;=claim[i][j]-allocation[i][j]

真，则进行2；
否则认为系统出错，资源数不满足其先决条件；



检查request_i[j]&lt;=available[j]

真，则进行3；
否则认为尚无足够的资源，进程i必须等待；



系统尝试为进程i分配资源，状态修改如下：
available[j] -= request_i[j];allocation[i][j] += request_i[j];


系统执行安全性检查算法

若通过检查，则正式分配资源给进程i
否则恢复原来的资源状态，宣布让进程i等待；



检测和解除死锁
额外定义请求矩阵Q[n][m]，表示进程i请求资源j的数量；
维护一个标记表L,最初所有进程都是未标记的；
检测死锁按照以下步骤进行：

标记allocation矩阵中一行全为0的进程；
初始化临时向量w := available
尝试查找下标i，使进程i当前未被标记，且其请求小于w;

若查找失败，终止算法


进程i加入标记表L,更新w[k] += allocation[i][k]
当且仅当算法结束时存在未被标记的进程时，意味着死锁存在于这些进程之中

解除死锁的思路比较简单，以下是常见的设计：

撤销所有死锁的进程：这是操作系统最常用的办法；
死锁进程回滚到某些检查点，重新启动
连续撤销死锁进程直到死锁不存在
连续抢占资源直到不存在死锁

进程间通信
对于PV操作可以用于进程的同步和互斥，属于低级进程通信，对网络进程通信和数据交换量较大的单机进程通信不适用；
进程间通信可以利用共享存储器/消息传递/管道实现；
共享存储器

基于共享数据结构的通信方式：公用某一个数据结实现信息交换
基于共享存储器的通信方式：划分一块存储空间作为公用

消息传递

直接消息传递：多个进程利用系统调用相互发送消息；

利用send，receive原语
可能产生安全问题：消息丢失，对象假冒，消息篡改
一般通信有三种情况：阻塞send+阻塞receiver，无阻塞send+阻塞receiver，无阻塞send+无阻塞receiver


简介消息传递：不直接发送消息给接收者，而是发到某个共享空间

接受者和发送者的关系不确定：一对一，多对多，一对多，多对一
需要解决共享空间的所有权问题



管道
在UNIX中，一般采用半双工的方式工作；
利用pipe函数创建管道
# include &lt;unistd.h&gt;int pipe(int fd[2]);
fd[1]的输出fd[0]的输入；创建成功返回0，失败返回-1；
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>System</tag>
      </tags>
  </entry>
  <entry>
    <title>存储管理</title>
    <url>/2025/07/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F4-%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[目的
为多道程序的运行提供良好的环境

方便用户使用存储器
提高存储器的利用率
逻辑上扩充存储器容量

基本功能

存储分配和回收
地址变换
存储保护
存储共享
存储器扩充

编译原理基础
源代码转化成进程的三个步骤

编译compile：由编译程序将用户源代码编译成若干个目标模块
链接linking：由链接程序将编译后形成的一组目标模块，以及所需要的苦函数链接在一起
装入loading：由装入程序将装入模块装入到物理内存中

地址和空间
名空间：高级语言常常用符号名来访问某一个单元，将程序中由符号名组成的程序空间称作符号名空间
逻辑空间：源程序经过编译后形成目标程序，这个程序按照0为基址为顺序进行编址，原先用符号名访问的单元用单元号代替，这样目标程序占据一定的地址空间叫做逻辑地址空间
逻辑地址：在逻辑空间中每条指令的地址和指令要访问的操作数地址统称为逻辑地址
内存地址：内存中每个存储单元都有一个编号，称作内存地址
物理空间：所有内存地址构成的集合称为内存空间/物理空间,可进行一维线性地编号
地址映射Mapping：将逻辑地址转换为运行时由机器寻址的物理地址

链接
源程序经过编译后得到一组目标模块，再利用链接程序将这组目标模块链接形成装入模块

静态链接：程序运行前，将各个目标模块和他们所需的库函数，链接成一个完整的装配模块之后不再拆开

相对地址的修改：每个其实模块用到相对地址，起始地址为0，链接成一个装入模块时要修改成模块的相对地址
变换外部引用地址：外部调用符号也相应地变换相对地址
缺点：不利于代码共享，不利于模块的独立升级，也可能链接不会执行的模块浪费存储空间和处理机时间


装入时动态链接：装入一个目标模块时，若发生一个外部模块调用时间，将引起装入程序去找出相应的外部模块，装入内存并修改模块的相对地址

优点：利于模块的独立升级和模块的共享
缺点：可能链接不会执行的模块，装入后不能移动位置


运行时动态链接：对某些目标模块的链接，是在程序执行中需要该目标模块时 ，由操作系统去找到该模块并将之装入内存，随后把它链接到调用者模块上

优点：凡在执行过程中未被用到的目标模块，都不会被调入内存和 被链接到装入模块上，这样不仅可加快程序的装入过程，而且可 节省大量的内存空间。



装入
将可装入模块装入内存
地址重定位：将可执行文件的逻辑地址转化为内存物理地址的过程

绝对装入方式

在编译时就知道程序将驻留在内存中的具体位置，编译 程序产生绝对地址的目标代码
优点：实现简单，无须进行逻辑地址到物理地址的变换
缺点：程序每次必须装入同一内存区，程序员必须事先了解内存的使用情况，根据内存情况确定 程序的逻辑地址，不适于多道程序系统


可重定位（静态重定位）方式

编译时采用相对地址，即编译器假设是装入到从零开始的 内存位置
优点：易实现，无需硬件支持
缺点：程序重定位后就不能移动，因而不能重新分配内存，不利于内存的有效利用，程序在存储空间中只能连续分配，不能分布在内存的不同 区域，难于共享


运行时重定位（动态重定位）装入方式

程序的地址转换不是在装入时进行，而是在程序运行时动态 进行，需要硬件支持，即重定位寄存器，用于保存 程序在内存中的起始地址，是实现装入的主流方式
优点：程序不必连续存放在内存中，可分散存储，可移动；便于共享；对于存储器紧缩、解决碎片问题极其有利
缺点：需要硬件支持，实现存储管理的软件算法比较复杂；同一地址，可能多次转换。



需求
在单道程序设计中，内存的使用目的：

供操作系统使用：驻留监控程序，内核
供当前正在执行的程序使用

在多道程序设计中，必须作进一步细分，由于处理器长期空闲，因此必须有效分配内存来保证适当数量的就绪进程可以占用这些可用的处理器时间；
内存管理的功能需求

重定位：进程在内存中进出，放置于不同位置的能力
保护：保护进程的程序和数据不被未授权的进程访问和修改
共享：不损害基本保护的前提下，必须对内存的共享区域进行受控访问
逻辑组织：利于系统和硬件能有效地处理某种某块形式组织的用户程序和数据
物理组织：计算机存储器的两级划分（内存和外存）的移动信息应该由系统负责；

内存分配（内存分区）
内存分配包括以下：

连续分配：单一连续分配，涉及分区管理，内存扩充（覆盖和对换）
离散分配：涉及对分页式，段式和段页式存储管理
虚拟存储器：涉及请求分页存储，请求分段和段页式虚拟存储

连续分配方式
连续分配
原理：内存划分为系统区和用户区，整个用户区分配一个进程
适用场合：最简单，适合当用户和单任务OS
优点：易于管理
缺点：造成空间的浪费
分区管理
原理：将内存分为一些大小相等或不等的分区，每个应用进程个占用若干个分区，操作系统占用一个分区
特点：适用于多道程序系统和分时系统
内部碎片：占用分区之内未被利用的空间
外部碎片：占用分区之间难以利用的空闲分区
固定分区
原理：将内存划分为大小相等或不等的分区，在每个分区只装入一道程序，分区的划分有OS决定，一旦划分结束，总分区个数保持不变
特点

适用于多道程序系统和分时系统
支持多个进程并发执行

问题

程序可能太大装不到一个分区
内存利用率可能很低，程序小可能也要占用一个分区，形成内部碎片现象；

划分方法：分区大小相同/分区多种大小
分区描述表：通常将分区按大小排队，标明起始地址和分配状态，建立分区描述表
分配算法

对于分区大小相同：使用哪个分区都没关系
对于分区大小不同：最佳匹配（为空闲分区选择最佳任务/根据任务选择最佳空闲分区），或者最坏匹配

存储保护：防止某个作业破坏系统或者其他作业，通常采用界限寄存器实现，每个寄存器都对应两个代表上下限的寄存器用于越界保护；
优点

比单一连续分配方法，提高内存的利用率
可以支持多道程序，无外部碎片
实现简单

缺点

分区数目在系统生成时确定，限制系统中活跃进程的数目；
小作业的内部碎片可能比较大；
作业必须要预先估计自己要占用多大空间；

动态分区
根据进程的实际需要，动态地分配内存空间，因此动态分区的长度和数量是可变的；
使用动态分区的方式，需要维护：

空闲分区表：记录每个空闲分区的情况；
空闲分区链：通过指针的迭代拼接称双向链；

分配算法

首次匹配算法First Fit

要求空闲分区链以地址地震的次序链接，在分配内存时，从链首开始顺序查找，知道一个大小满足要求的空闲分区为止；
为大作业分配大的内存空间创造了条件
低地址空间不断被划分，留下难以利用的小空闲分区，增加查找查找开销


循环匹配算法Next Fit

为空闲分区构成循环链表，采用循环查找方式，设置一个开始查寻指针，用于指示下一次起始查询的空闲分区
使得内存空闲分布更均匀，减小查找开销
缺乏大的空闲分区
空闲分区应该按照地址顺序排列


最佳匹配算法Best Fit

每次分配内存时，总是能把满足要求又是最小的空闲分区分配给作业
产生的外部碎片小
碎片太小往往难以利用，造成浪费
按容量从小到大排列


最坏适应算法Worst Fit

每次满足要求又是最大的空闲分区给作业
留下的空闲分区很大方便下一次利用
不利于大作业
按容量从大到小排列



分区管理

分配：按照算法选择空闲分区，并在空闲分区表删除，添加新产生的空闲分区
回收：当进程运行完毕释放内存时，需合并相邻的空闲分区，形成大的分区
紧凑和动态重定位：将内存中的所有作业进行移动，使它们全都 相邻接，这样，可把原来分散的多个小分区合成一个大分区

存储保护：上、下界寄存器方法/基址、限长寄存器方法2
优点

支持多道程序
管理方案简单，不需要更多的软硬件开销
实现存储保护的手段比较简单

缺点

主存利用不够充分
无法实现多进程共享存储器的信息（不是分段内存分配都无法实现）
无法实现主村的逻辑扩充，进程的地址空间受物理内存的限制

伙伴系统
伙伴系统是固定分区和动态分区的折中方案；
设计可用的内存块大小为字节，整个分配空间被视为的块；
对于进程申请的空间，可以用以下的递归算法找到大小为的块；

查找大小为的空闲分区，若找到则分配；
若未找到大小为2i的空闲分区，则查找大小为的空闲分区 ；

若找到，则将该空闲分区划分为相等的两个分区（一对伙伴），其 中的一个用于分配，另一个分区加入大小为的空闲分区链中；


以此类推

内存扩充
内存扩充：借助大容量辅存在逻辑上实现内存扩充，来解决内存容量不足的问题；
覆盖和交换：需要在较小可用内存运行较大的程序，在任何时候，只在内存中保留所需的指令和数据，当需要时，在从外存中写回内存
覆盖overlay
基本思想:一个程序的几个代码段或数据段，按照时间先后来占用公共的内存空间。
实现：

将程序的必要部分代码和数据常驻内存；
可选部分在其他程序模块中实现，平时存放在外存中（覆盖文件），需要用到时才装入到内存；
不存在调用关系的模块不必同时装入到内存，可相互覆盖

交换swapping
基本思想：把内存中展示不能运行的进程或者暂时不使用的程序和数据换出到外存上，以腾出足够的内存空间
粒度：

进程交换：解决内存紧张问题，进一步提高内存利用率
页面交换，分段交换：可以支持虚拟存储系统

管理：

外存：对换区比文件区侧重于对换速度
对换区一般采用连续分配

优点：

换入和换出操作由内存管理模块，与程序结构无关

离散分配方式
解决问题
一个进程的分配的内存由多个离散的空间组成

固定分区存在内存碎片
动态分区存在外部碎片
可重定位动态分区的系统开销大

基本单位
分页式存储管理

页面：程序地址空间被划分为若干固定大小的片段
页框：物理内存被划分成相同大小的块

分段存储管理

以段为基本分配单位的存储管理方式

段页式存储管理

段内分页

分页式存储管理
存储管理系统负责用户空间，物理空间的划分编号；
以下是程序空间到物理空间的映射，程序的每一个页分散到物理空间的页；而从每一页看地址都是连续的；

逻辑地址结构转换物理地址
假设对于32位的机器，页面大小为，给定逻辑地址空间的地址为

页号：12-31位
页内偏移量：0-11位

对于16位的机器而言，页号占6位，页内偏移量占10位；
页表则维护每个页面对应的页框信息，即页号和段号的映射

存储在内存
PCB保存页表的起始地址
快表：对页表的使用频度高表项用高速缓存器存储

优点：

存在页内碎片，但是碎片小，内存利用率高
实现了离散分配
无外部碎片

缺点：

需要专门的硬件支持，尤其是快表
不支持动态链接，不易共享

分段存储管理
引入原因：

更自然组织信息：通过段名访问程序段和数据段
信息共享和共享：段是信息的逻辑单位，页只是存放信息的物理单位
动态增长：数据段事先无法知道大小
支持运行时动态链接

组织方式

段：定义一组逻辑信息，段+段内偏移量

对于32位的机器，段号：24-31位，段内偏移量：0-23位

从0开始编址
长度：由段定义的逻辑信息决定
每个逻辑段庄在到一段动态内存区域

段表：记录逻辑段和物理段的对应情况
段号+段长+段首址+控制信息

段表寄存器中存放段表的起始地址和段表长度
检查段号和段内偏移量越界：非法产生越界错误
检查访问控制字段：确定是否合法


优点：

便于模块化设计
便于动态链接
便于共享与保护
无内部碎片

缺点：

地址转换需要硬件支持（段表寄存器）
分段最大尺寸受主存可用空间的限制
有外部碎片

段页式存储管理
分段和分页的比较



方面
分页
分段




从设计目的来看
页是信息的物理单位，分页的目的是实现离散分配，减少内存的外部碎片，提高内存的利用率。或者说，分页仅仅是由于系统管理的需要而不是用户的需要。
段则是信息的逻辑单位，它含有一组意义相对完整的信息。分段的目的是为了能更好地满足用户的需要。


从系统实现上看
页的大小固定且由系统决定，由系统把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而在系统中只能有一种大小的页面；
而段的长度却不固定，决定于用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。


从功能实现上看
不易共享和运行时动态链接
易于共享和运行时动态链接


从编址方式来看
分页的作业地址空间是一维的，即单一的线性地址空间，程序员只需利用一个记忆符，即可表示一个地址；
分段的作业地址空间则是二维的，程序员在标识一个地址时，既需给出段名，又需给出段内地址。



段页式存储管理

采用分段方法组织用户程序，用户程序采用模块化设计，用若干段划分
采用分页方法分配和管理内存，内存分成若干页框，程序每个段风格成若干页后装入内存

逻辑地址：段号s+段内页号p+页内偏移量w

检查段号，段表访问控制字段，页号是否越界
页内偏移量送入物理地址的低端


优点

离散存储
内存利用率高
便于保护和共享，支持动态链接
无外部碎片

缺点

地址转换复杂
有内部碎片

虚拟存储方式
虚拟存储方式由虚拟内存机制实现
虚拟内存
硬件和控制结构
理论依据
常规的存储管理技术：

一次性：需要作业全部装入内存运行
驻留性：作业装入内存后，一直驻留内存直到作业结束
难以满足大作业运行需求和大量作业并发，对于已装入内存的代码利用率低

程序的局部性原理：在一段较短时间内，程序的执行仅局限于某个部分，相应地访问的存储空间也局限于某个区域

时间局限性：下一次指令执行，数据访问集中在较短时间内;
空间局限性：下一次执行指令，数据访问集中在较小的区域；

程序运行特点：

大部分时间顺序执行
即使有跳转，也仍局限在某些函数下
许多循环结构下，少量指令多次执行
对数据结构的操作往往局限于小范围

虚拟内存方案：

将当前要执行的部分页/段读入内存，就可以运行程序
缺页/段时，处理器临时通知；
暂不使用的页/段换出内存；

这表明虚拟内存方案是可行的；
虚拟存储器
功能：

请求调入和置换：从逻辑上对内存容量加以扩充
总容量由内存容量和外存容量之和决定
运行速度接近内存，位成本接近外存

特征

离散性:程序在内存中离散存放
局部性:进程无需全部驻留内存,只需载入必要的进程空间
对换性:允许进程在运行过程中换入、换出
虚拟性:能够从逻辑上扩充内存容量,使用户所看到的内存远大于内存容量

硬件支持：

相当数量的外存
一定容量的内存
请求分页或分段的页表或段表机制
缺页或缺段机构
地址变换机构

常见技术

请求分页存储管理
请求分段存储管理
请求段页式存储管理

较小的页面有利于减少页内零头，但是可能导致页表过大，降低命中率；
较大的页面，内外存交换效率高，但是带来额外开销；
需要一种tradeoff机制；
二级页表
快表TLB
原理：基于局部性原理，提高地址变换速度，为进程页表设置一个专用的高速缓冲存储器（Translation Lookaside Buffer）；
地址转换：

分离提取页面号+页内偏移
检查页面号是否合法，非法报越界错误
根据页面号检索快表

若命中， 提取页框号，进入5；
若未命中，重新检索页表，结果载入快表，替换许久不用的表项


检查访问控制字段，非法则报错
计算物理地址：页框页面大小+页内

若页表存放在虚存中,则要实现一次页面访问需两次访问 物理内存  存

第一次是访问页表,确定所存取页面的物理地址;
第二次根据该地址存取页面数据。

操作系统软件
原理：

建立在分页机制上：页面，页框和页表
请求调页和页面置换功能：部分页面载入内存，对换机制和将页面作为换入换出的基本单位

页表机制
&lt;页号&gt;&lt;页框号&gt;&lt;状态位P&gt;&lt;访问字段A&gt;&lt;修改位M&gt;&lt;外存地址&gt;

状态位：指示该页是否调入内存
访问字段：记录指定时间段的访问次数；
修改位：该页调入内存后是否被修改
外存地址：用于指出该页在外存上的地址

缺页中断机制
每当要访问的页面不在内存中，产生缺页中断，请求OS调入；

在指令执行期间产生和处理中断信号；
一次指令执行期间，可能产生多次缺页中断；
带快表的基本分页地址：
缺页中断处理
页面换出



置换策略
概念
置换策略包括分配页面，调入页面和置换页面的内容

分配页面：如何为每个进程分配页面
调入页面：何时调入页面，从哪调入页面和调入哪些页面
置换页面：交换区如何组织，换出页面的选择和换出实现

分类
页面分配策略

固定分配:进程分配到的物理块在进程运行期间不再改变
可变分配:进程运行期间根据情况增加或减少物理块

置换策略

局部置换:发生缺页时选择进程自己的物理块置换
全局置换:可以将os的空闲物理块分配给缺页进程，也可以别的进程持有的物理块置换到外存后分配给缺页进程

可组合出以下三种适用的策略

固定分配局部置换
可变分配局部置换
可变分配全局置换

页面调入
何时调入页面：

预调页策略：准确度不高
请求调页策略：发现缺页再调入，系统开销较大

调入哪些页面：

请求调页策略：调入发生缺页的页面
预调页策略：调入临近页面

调页的位置：

对换区：修改过的页被换出时入对换区，比较快
文件区：比较慢
UNIX方式

页面换出

通常为全局置换
调页且发现无空闲页框时，交换进程周期性检测

页面置换

查找所需页在磁盘上的位置
查找一个空闲页框，如果有空闲页框，就使用它；如果没有空闲页框，就选择一个页面并淘汰之；
将淘汰页面的内容写到磁盘上，改变页表
将所需页读入（新）空闲页框，改变页表
重启用户进程


置换算法
概念：选择换出页面的算法
评价标准：页面交换的频率
设计目标：优先换出不再访问的页面和最久不访问的页面
设计原则：基于过于页面访问行为预测将来的页面访问
最优置换算法OPT
基本思想：换出不再访问的页面，换出下次访问距离当前时间最长的页面
评价：

属于理想算法，通过未来页面走向选择被淘汰的页面，可以保证最少的缺页中断次数
需要知道未来访问的顺序，不可能实现，是其他算法的baseline

例子
发生缺页中断次数：9
页面置换次数：6

先进先出算法FIFO
基本思想：换出最早调入内存的页面
实现：采取链表结构
评价：

简单易于实现
未考虑程序的时间局部性原理
存在Belady现象：随着分配的页框数增加，缺页中断次数反而增加

例子
发生缺页中断次数：14
页面置换的次数：11

最近最久未使用算法LRU
基本思想：时间局部性原理
算法：选择最近一段时间最长时间没有被访问过的页面淘汰
实现：寄存器表+双向链表
评价：

性能较好，因为基于时间的局部性原理
开销过大，需要统计页面的访问时间信息，获取最久未使用页面，又是页面数过大，寄存器表不现实；

例子：
发生缺页中断的次数：12
页面置换的次数：9

时钟置换算法CLOCK Not Recently Used
基本思想：对LRU算法的近似，换出最近未访问的页面的NRU算法；
实现：

每个页面设置访问位R，访问时置1
页框内所有页面保存在环形链表中
发生缺页中断时，优先检查表指针指向页面，若R=0，淘汰页面；R=1，清除R位，前向移动指针，找到访问位为0的页面后换出；

评价：

算法简单
性能和置换间的间隔密切相关，过大过小可调整随机选择换出页面
未考虑页面修改情况


对页面修改进行改进：页面分类

最近未被访问，未被修改：最佳淘汰页
最近未被访问，但已被修改
最近被访问，未被修改
最近被访问且被修改

改进实现：

选择1类页面
若失败，寻找第2类页面，并把扫描过的页面访问位置0
若步骤2失败，回到步骤1

缺页率
发生缺页的次数/总访问次数

页面置换算法
页面大小
进程所占的页框数
程序本身

矩阵int a[100][100]以行优先进行存储。有一请求分页存储管理系统,物理内存共有3页,其中1页用来存放程序,其余2页用于存放数据。假设程序已在内存中占1页,其余2页空闲;数组中的元素按行编址存放。
for (i=0; i&lt;=99; i++)	for (j=0; j&lt;=99; j++)		a[i][j]=0;		for (j=0; j&lt;=99; j++)	for (i=0; i&lt;=99; i++)		b[i][j]=0;
假定两个内存页，每页200个数据；
程序A对数组的访问顺序与存储顺序一致，每访问2行数组元素就会产生一次缺页中断， 故缺页中断次数为50
程序B对数组的访问顺序与存储顺序不一致，每访问 数组元素就会产生一次缺页中断，故缺页中断次数为5000
平均访问时间：

缺页率为
内存访问时间为
发生缺页时访问时间为

有效访问时间构成：

缺页服务时间
进程重新执行时间
页面调入时间（主要）：寻道时间+旋转时间+数据传送时间

工作集
进程对地址空间的访问不均匀，在确定的时间内，进程往往只访问固定的几个页面；
工作集：在某段时间间隔内，进程实际要访问的页面的集合

进程分配的页框数不能少于工作集大小
不同时刻，进程的工作集大小可能不同，系统根据缺页率动态调整进程的分配页框数

缺页率和物理块数关系

抖动/颠簸thrashing
抖动是虚拟存储的典型问题

页面被频繁地换入换出，缺页率增加
内存有效存取时间加长
系统吞吐量骤减，系统难以完成任务

原因：

CPU利用率低，调度程序增加并发，导致内存不足，缺页，I/O忙碌，CPU空闲
多道程序并发度高，每个进程分配的页框数数目少


抖动的预防

采取局部置换策略：某进程发生缺页时，仅在自己内存空间范围内置换页面，创建新进程不会几张其他进程的内存空间
CPU调度程序采取工作集算法：防止调入过多的新任务，每个进程应具有超过其工作集大小的页框数
L=S准则：发生缺页的平均时间L等于处理缺页故障的平均时间S，此时系统具有最好的并发度
挂起若干进程

请求分页存储管理
优点

存在页内碎片，但碎片相对较小，内存利用率较高
实现了离散分配
无外部碎片
提供了虚拟存储器，使大作业可以在较小的实际内存中运行
并发度高

缺点

必须有相应的硬件支持
不支持动态链接，不易实现共享
可能发生系统抖动现象

原理

建立在基本分段机制上:

程序的逻辑地址空间被划分为若干个大小不同的段
每个逻辑段装载到一段连续的物理内存区域
段表记录逻辑段和物理段的对应情况


引入请求调度和分段置换机制

部分逻辑段载入内存
对换机制
以段作为换入或换出的基本单位



段表机制
段表寄存器地址组成如下：
&lt;段号&gt;&lt;段长&gt;&lt;段首址&gt;&lt;存取方式&gt;&lt;访问位A&gt;&lt;修改位M&gt;&lt;状态位P&gt;&lt;增补位&gt;&lt;外存地址&gt;

访问字段A：用于记录本段在一段时间内被访问的次数
修改位M：表示该段在调入内存是否被修改
状态位P：用于指示本段是否调入内存
增补位：特殊字段，用于表示本段在运行时是否动态增长
外存地址：指示本段在外存中的地址；

缺段中断
每当所要访问的段不在内存时，便产生缺段中断，请求OS 将所缺之段调入内存。
段中断不会发生一条指令被分割在两个段的情况；

地址转换
访问一个段地址[s][w]时，检查三种条件是否发生错误：

w超过段长：报越界错误
存取方式位不符合：触发中断保护
检查段s是否在主存：缺段中断处理


动态链接&amp;链接中断
动态链接实现：请求分段存储管理
程序运行时，只讲主程序段装配好，调入内存，其他段在运行时装配完成；
调用新段时，将新段装配好并链接主段；
段页式虚拟存储技术

建立在段页式存储技术之上

程序的逻辑空间划分为若干大小不同的段
每个段划分为若干固定大小的页面
物理内存划分为若干固定大小的页框
页面可以载入任意页框——页表记录载入情况


引入请求调页和页面置换机制

部分页面载入内存
对换机制
以页面作为换入或换出的基本单位


地址变换：先查段表，再查该段的页表

共享和保护
整个系统共享一张共享段表：段本身信息，引用者信息；
共享段表地址组成：
&lt;段名&gt;&lt;段长&gt;&lt;内存地址&gt;&lt;状态&gt;&lt;外存起始地址&gt;&lt;共享进程计数count&gt;&lt;状态&gt;&lt;进程名&gt;&lt;段号&gt;&lt;存取控制&gt;
共享段的分配：第一次访问需要分配内存，增加共享段表，修改进程段表，后续访问无需分配内存；
保护：

段号越界检查
段内页号越界检查

其中环保护中，内环可访问外环数据，外环请求内环服务；

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>System</tag>
      </tags>
  </entry>
  <entry>
    <title>I/O 管理</title>
    <url>/2025/07/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F5-IO%E8%AE%BE%E5%A4%87/</url>
    <content><![CDATA[概述
I/O设备
I/O外设大致分为三类

人可读：比如显示器，键盘，鼠标
机器可读：比如磁盘驱动 器、USB密钥、传感器、控制器和执行器。
通信：比如数字线路驱动 器和调制解调器

这些设备可能的主要差别在数据传输速率，控制复杂度，传输单位，数据表示，错误条件等等各有不同；
或者分成两类

面向块：信息保存在块中，块的大小通常是固定的，传送过程中一次传送一个块，比如磁盘，USB智能卡等
面向流：以字节流的方式输入/输出数据，比如终端，打印机，网卡，鼠标等

由于设备具有差异性，设备被设计为不直接和CPU通信，而是与设备控制器通信，在I/O设备应该包含和设备控制器的接口；
I/O设备发给控制器的信号有三种：

数据信号：双向，有缓存。
控制信号：控制器发给设备；要求其完成相关操作。

状态信号：设备发给控制器，后者“显示”。
设备控制器
Device Controller的组成

设备控制器与CPU的接口：数据线，地址线，控制线
设备控制器与I/O设备的接口：每个接口包含数据、命令、状态三类信号的交换
I/O逻辑：接受I/O命令并译码


Device Controller的基本功能：

接受和识别命令：应该有相应的寄存器存放命令；
数据交换：实现CPU与设备控制器，设备控制器和I/O设备之间的数据交换；
标识和报告设备的状态：通过状态寄存器记录
地址识别
数据缓冲
差错控制

I/O控制方式
常见的I/O控制包含四种技术：程序控制I/O、中断驱动控制I/O，直接存储器访问(DMA)，包括I/O通道控制
程序控制I/O
程序控制I/O(Programmed I/O)典型的方式是 轮询(Polling);
处理器代表一个进程给I/O模块发送一个I/O命令, 该进程进入忙等待，直到操作完成才能继续执行。

CPU需要花费代价不断查询I/O状态，CPU花费极大

流程图如下所示

中断控制I/O
中断： 一个进程占有处理器运行时，由于自身或外界的原因 （出现了某事件）使运行被打断。让操作系统处理所出 现的事件，处理完中断事件之后，再让被打断的进程继续运行；

外部中断事件：比如计算机故障中断，输入输出中断
内部中断：比如由地址越界，除数为0等造成的程序性中断事件，系统调用中断(访管中断)；

中断源：引起中断的事件；
中断处理程序：对出现的事件进行处理的程序；以下是一个可能的流程图

中断响应：处理器每执行完一条指令后，硬件的中断装置立即检查有无 中断事件发生，若有中断事件发生，则暂停现行进程的执行， 而让操作系统的中断处理程序占用处理器；

首先检查是否有中断事件发生，并确定中断的原因。
若有中断事件发生，则保护好被中断进程的断点以及其他 一些信息(上下文)，以便进程在适当时候能继续执行。
根据中断原因找到中断处理程序并启动中断处理程序工作。

中断寄存器：如果有外部中断事件出现，而外部中断源又各不相同，需要用寄存器记录原因。例如以下8259A寄存器图示

中断向量表：在微机中将中断源统一编号，不同的中断源有不同的中 断类型编号；每一个中断类型号对应一个中断处理程序。 中断向量表中存放各个中断处理程序的入口地址。 在计算机系统初始化时，根据设备处理程序在内存中的位置，由引导程序完成中断向量表的建立。
中断优先级：中断优先级是按中断事件的重 要性和紧迫程度来确定的。中断装置是按预定的顺序响应同时出现的中断事件，这个顺序可以由编程实现。下图是一个可能系统实现

中断控制I/O: 处理器代表进程向I/O模块发送I/O命令

该指令是非阻塞的：处理器继续执行该指令的后续命令
该指令是阻塞的：处理器下个指令来自操作系统，将当前进程阻塞并调度其他进程(当前进程发生了中断);

直接内存访问控制
直接内存访问(Direct Memory Access, DMA)用于实现控制内存和I/O模块之间的数据交换。

处理器向DMA发送请求
整个数据块传送结束后请求中断

设计目的：进一步减少CPU对I/O的干预；
特点：

数据传输的基本单位是数据块，即CPU与I/O设备之间， 每次传送至少是一个数据块；
所传送的数据是从设备直接送入内存的，或者从内存送 到设备输出；
仅在传送一个或多个数据块的开始和结束时，才需CPU 干预，整块数据的传送是在通道控制器的控制下完成的；

组成：

主机和DMA控制器接口
DMA控制器和块设备接口
I/O控制逻辑

实现：在DMA控制器中设置四类寄存器，即命令/状态寄存器(CR), 内存地址寄存器(MAR), 数据寄存器(DR),数据计数器(DC);
一个典型的DMA框图如下：

DMA工作流程如下：DMA可以模拟处理器，实际上也能像处理器一样获得系统总线的控制权

I/O通道
I/O 通道方式(I/O channel) 是DMA 方式的发展，实际上属于DMA的一种；


它可进一步减少 CPU 的干预，即把对一个数据块的读(或写)为单位的干预减少为对一组数据块的读(或写)及有关的控制和管理为单位的干预。


可实现CPU、通道和I/O 设备三者的并行操作，从而 更有效地提高整个系统的资源利用率。


通道： 一种特殊的执行I/O指令的处理机，与CPU共享内存， 可以有自己的总线。


字节多路通道 ：这是一种按字节交叉方式工作的通道。每一个子通 道连接一台I／O设备，并控制该设备的I／O操作。 这些子通道按时间片轮转方式共享主通道。只要字节多路通道扫描每个子通道的速率足够快， 而连接到子通道上的设备的速率不是太高时，便不致丢失信息，适用于低、中速设备。



数组选择通道：数组选择通道可以连接多台高速设备，但是只有一 个分配型子通道，一段时间内只能执行一道通道程序。某台设备占用该通道后，即使无数据传送，通道被闲置，也不允许其他设备使用该通道，直至设备传送完毕释放该通道。 缺点是利用率低。


数组多路通道：数组多路通道将数组选择通道传输速率高和字节多路通道能使各子通道分时并行操作的优点相结合。 数组多路通道含有多个非分配型子通道，既具有很高的数据传输速率，又有较高的通道利用率。广泛应用于连接多台高、中速外围设备，数据传送 方式按数组方式进行。


通道程序：通道是通过执行通道程序，并与设备控制器共同实现 对I/O设备的控制的。 通道程序是由一系列通道指令（或称为通道命令）所 构成的
通道的设计可以解脱CPU对I/O的组织管理，更好地处理终端命令；CPU只需发送I/O命令给通道，通道通过调用内存中的相 应通道程序完成任务。
在I/O通道设计中，可能存在瓶颈问题：

原因：通道不足
解决的最有效办法不是增加通道，而是增加设备到主机间的通路


设别的硬件层次
I/O子系统分类

用户层I/O软件：实现与用户交互的接口，用户可直接调用在用户层提供的、 与I/O操作有关的库函数，对设备进行操作；
设备独立性软件：用于实现用户程序与设备驱动器的统一接口、设备命令、 设备保护，以及设备分配与释放等，同时也为设备管理和数据传送提供必 要的存储空间。
设备驱动程序：硬件相关，具体实现OS对设备发出的操作指令，驱动I/O设备工作。每一类设备有一个设备驱动程序。比如我们插入U盘时，系统会弹 出安装驱动，安装完成后，这个驱动程序不会消失，而是运行在后台进程。 无论你用的是正版金士顿还是盗版，用的是东芝还是闪迪，驱动程序都是 一类，系统中驱动U盘的都是相同的驱动程序。
中断服务程序
硬件：这里的硬件也需要单独说明，是因为这里是指代I/O设备，有不同之 处。分为两个部分：机械部件和电子部件。


设备管理软件
设计目标

与具体设备无关
统一命名
对错误的处理
缓冲技术
设备的分配和释放
I/O 控制方式

软件层次结构

要使设备按用户的要求工 作，必须对与设备接口的 通道和控制器等进行程序 编制，通过程序实现对设 备的控制。
为了方便用户使用还必须 给出调用接口或命令接口。
为了更有效的利用设备还 必须研究管理技术和算法。

设备驱动程序
功能

接收由设备独立性软件发来的命令和参数，并将命令中的 抽象要求转换为具体要求。
检查用户I/O 请求的合法性。
发出I/O 命令。
及时响应由控制器或通道发来的中断请求，并根据其中断 类型调用相应的中断处理程序进行处理。 根据用户的I/O 请求，自动地构成通道程序。

处理过程：

对指定的设备进行初始化：在执行输入或输出之前完成必要的准备工作
将抽象要求转换为具体要求：用户及上层软件对设备控制器的具体情况毫无了解，因 而只能向它们发出抽象的要求，但又无法传送给设备控制器。因此，就需要能将这些抽象要求转换为具体要求。 在OS中只有设备驱动程序才同时了解抽象要求和设备控制器中的寄存器情况；也只有它才知道数据和参数应分别送到哪个寄存器。例如，将抽象要求中的盘块号转换为磁盘的盘面、磁道 号及扇区。这一转换工作只能由设备驱动程序来完成。
检查I/O请求的合法性：对于任何输入设备都只能完成一组特定的功能，如该设备 不支持这次I/O请求，则认为这次I/O请求非法。
读出和检查设备的状态：要启动某个设备进行I/O操作，其前提条件应是该设备正处 于空闲状态。
传送必要的参数 ：有许多设备，特别是块设备，除必须向其控制器发出启 动命令外，还需传送必要的参数。
启动I/O设备：在完成上述各项准备工作后，设备驱动程序可以向控制 器中的命令寄存器传送相应的控制命令。设备驱动程序发出I/O命令后，基本的I/O操作是在设备 控制器的控制下进行的。

提高设备管理性能的相关技术
I/O缓冲概述
操作系统设计I/O机制时，有两个主要目标：

效率：I/O操作是计算机系统的瓶颈，
通用性：处理器能用统一的方式看待I/O设备，操作系统能统一管理I/O设备和操作的方式；

一个简单的层次结构是设置逻辑I/O，设备I/O，调度和控制，实现用户进程和硬件的交互；
设计缓冲区是操作系统提高I/O效率的机制；
设计缓冲区的主要原因：

缓和CPU与I／O设备间速度不匹配的矛盾。
减少对CPU的中断频率，放宽对CPU中断响应时间的 限制。
提高CPU和I／O设备之间的并行性。

单缓冲
在单缓冲情况下，每当用户进程发出一I/O请求时，操 作系统便在主存中为之分配一缓冲区。
假设输入时间为，计算时间为,数据传送时间(数据从缓冲区复制到用户内存)为,输入和计算并行，系统对于每一块的处理时间为；

双缓冲
在设备输入时,先将数据送入第一缓冲区，装满后便转向 第二缓冲区。此时操作系统可以从第一缓冲区中移出数 据，并送入用户进程。
在双缓冲时，如果假设缓冲区的数据传送到用户区时间 远小于输入时间或计算时间，系统处理一块数据的 最大时间可粗略地认为，。如果＜，可使磁 盘数据连续输入；如果＞，可使CPU不必等待数据输 入。
假设一个两台机器的通信场景，单缓冲无法实现双方同时向对方发送数据，若为每个机器设置发送缓冲区和接受缓冲区，就能实现双向的数据传输；

循环缓冲
循环缓冲可以解决输入输出速度差异很大的问题，遵循生产者-消费者模型实现对资源的互斥共享；
组成：

多个缓冲区：每个缓冲区的大小相同；
多个指针：指示计算进程下一个可用缓冲区G 的指针Nextg, 指示输入进程下次可用的空缓冲区R 的指针Nexti, 指示计算进程正在使用的缓冲区C 的指针Current。


缓冲池
缓冲池是各种系统的流行技术，在池中设 置了多个可供若干个进程共享的缓冲区。
组成：

空缓冲队列emq:由空缓冲区所链成的队列。
输入队列inq:由装满输入数据的缓冲区所链成的队列。
输出队列outq:由装满输出数据的缓冲区所链成的队列。
四种工作缓冲区：收容输入数据，提取输入数据，收容输出数据，提取输出数据


设备分配及算法
表结构
在进行设备分配时，通常都需要借助于一些表格的帮助。 在表格中记录了相应设备或控制器的状态及对设备或控制 器进行控制所需的信息。

设备控制表DCT: 系统为每一个设备都配置了一张设备控制表，用于记 录本设备的情况;
控制器控制表COCT
通道控制表 CHCT
系统设备表SDT



设计原则
设备的固有属性：共享+虚拟+独享
设备分配时应考虑的因素： 设备的固有属性、分配算法、安全性、独立性


同步是安全的分配方式：当进程发出一个I/O后，即blocked，直 到其I/O完成，打破了请求并保持条件，缺点是CPU、I/O串行工作，进程进展缓慢
异步是不安全的分配方式，进程执行效率高，但是要进行安全性检查；


分配算法：FIFO， 优先权
SPOOLing技术
假脱机操作(Simultaneaus Periphernal  Operating  On-Line, SPOOLing)技术：是用于将 I/O 设备进行虚拟化的技术。在主机的直接控制下，实现脱机输入、输出功能。此时的外围操作与CPU对数据的处理同时进行.可以实现将一台物理I/O设备虚拟为多台逻 辑I/O设备，同样允许多个用户共享一台物理I/O设备；
SPOOLing技术是实现Linux中’一切皆文件’和虚拟设备的基础,欺骗进程使进程认为自己都拥有设备资源；
组成：

输入井和输出井：在磁盘上开辟的2个大存储空间，模拟输入和输出设备；
输入缓冲区和输出缓冲区：内存中，输入缓冲区用于暂存由输入设备送来的数据，以后再传送到输入井。输出缓冲区用于暂存从输出井送来的数据， 以后再传送给输出设备。
输出进程SPi：模拟脱机输入时的外围控制机，将用户要求的数据从输入机通过输入缓冲区再送到输入井，当 CPU 需要输入数据时，直接从输入井读入内存。
输出进程SPo：模拟脱机输出时的外围控制机，把用户要求 输出的数据先从内存送到输出井，待输出设备空闲， 再将输出井的数据经过输出缓冲区送到输出设备上。


比如共享打印机场景中，利用SPOOLing技术可以将打印机改造成多个用户共享的设备，比如某一打印word的进程，调用了统一的接口，然后进入内核。内核例程负责将 word 想要打印的内容做成一个打印申请表，将这个申请表放入打印输出队列中（这个队列在输出井中）。然后由输出进程从打印队列中取打印申请表，根据表格内容将用户数据从磁盘中取出放入内存输出缓冲区，然后再输出到 I/O 设备中。输出进程会不断的查看打印输出队列，直到队列为空，则输出进程被阻塞。
特点：

提高了I／O的速度：缓和了CPU与低速I／O设备之间速度不匹配的矛盾
将独占设备改造为共享设备
实现了虚拟设备功能 SPOOLing系统实现了将独占设备变换为若干台对应的逻 辑设备的功能

I/O设备调用
磁盘
原理
磁盘(disk) 的组成

包括一或多个物理盘片，每个磁盘片分一个或两个存储面(Cylinder)
每个磁头(Head)负责读写一条磁道，一般每条磁道又被逻辑上划分成8个扇区(Sector)
扇区是磁盘存储数据的最小单位，一般用逻辑块号(LBN)标识,每次读写至少一个扇区的数据；
块(block)是文件系统逻辑上的一段存储空间，通常具有整数个扇区；

下图是一个柱面和一面盘面的组成


块号=柱面号×柱面扇区数+磁头号×盘面扇区数+盘扇号;
柱面扇区数=盘面数×盘面扇区数；
柱面号=块号/柱面扇区数;
磁头号=块号MOD柱面扇区数 / 盘面扇区数;
扇区号=块号MOD柱面扇区数MOD盘面扇区数;

类型：读写前磁头必须位于磁道的开始处

固定头磁盘： 每个磁道上有一个磁头，快。
移动头磁盘： 每个盘面仅有一个磁头，慢。

磁盘性能参数
寻道时间Ts：磁头定位到磁道的时间，记磁盘启动时间为S，磁道数为n，则满足Ts=O(n)+S;
旋转延迟Tr：指定扇区旋转到磁头下的时间，若转速为r，则均值Tr=r/2；
存取时间：达到读写正确位置的时间，Ts+Tr;
传输时间Tt：磁头定位完成后，数据传输所用时间，读写字节数为b，每道上的字节数为N，Tt=b/rN;
访问时间：Ta=Ts+Tr+Tt,对于特定磁盘，只有集中存放数据，集中读写才能提高传输效率;
磁盘的I/O很慢，往往成为瓶颈，有如下方式提高磁盘I/O速度

提前读/延迟写：访问频率高的磁盘块放在替换队列的尾部，减少回写 次数。
优化物理块分布：减少磁头移动距离，如簇分配就是将一个簇分为多个连续块
虚拟盘(RAM): 由用户控制；

磁盘高速缓存
磁盘高速缓存(disk cache)：形式上是磁盘，物理上是驻留在内存的盘块，大小可固定也可以设计为可变；

数据交付：磁盘高速缓存中的数据传送给请求者进程，先查缓存、后查磁盘并更新缓存，一般可分为数据交付和指针交付；
置换算法：应考虑局部性原理，访问频率，可预见性，数据一致性等原则，如最近最久未使用LRU，最近未使用NRU，最少未使用LFU等
周期性写回磁盘：比如以windows为例的ms-dos操作系统采用写穿透方式；

磁盘调度
为减小寻道时间，对于磁盘的请求队列来说，I/O请求可能来自多个进程，若随机从队列中选择项目，性能很差；
可设计如下算法：以请求序列为为190，97， 90，45，150，32，162， 108，112，80，磁盘共200个柱面，磁头现在在98号柱面上为例


先来先服务FCFS：根据进程请求访问磁盘的先后次序进行调度
公平、简单，且每个进程的请求都能依次地得到处理， 不会出现某一进程的请求长期得不到满足的情况，但是平均寻道时间可能较长；



最短服务时间优先SSTF：总是从等待访问者中挑选寻 找时间最短的那个请求先执行， 而不管访问者到来的先后次序，可能由磁臂黏着现象；



电梯调度扫描SCAN
总是从移动 臂当前位置开始沿着臂的移动 方向去选择离当前移动臂最近 的那个柱面的访问者，如果沿 臂的移动方向无请求访问时， 就改变臂的移动方向再选择。



循环扫描CSACAN
该算法不考虑等待访问者的先 后次序，总是从0号柱面开始向 里扫描，按照各访问者所要访 问的柱面位置的次序去选择访 问者。移动臂到达最后一个柱 面后，立即带动读写磁头快速 返回到0号柱面。



N步扫描NStepSCAN
将磁盘请求队列分成若干个长度为N 的 子队列，磁盘调度将按FCFS 算法依次处理这些子队列。 而每处理一个队列时又是按SCAN 算法，对一个队列处理 完后，再处理其他队列。


FSCAN
FSCAN  只将磁盘请求队列分成两个子队列。一个是由当前所有请求 磁盘I/O 的进程形成的队列，由磁盘调度按SCAN 算法进 行处理。在扫描期间，将新出现的所有请求磁盘I/O 的进程 ，放入另一个等待处理的请求队列。这样，所有的新请求都 将被推迟到下一次扫描时处理


设备管理接口
操作系统为设备管理定义两种接口:

驱动程序接口：介于驱动程序与操作系统内核之间的接口驱动程序模块及优 化的管理模块接口，这些模块构成操作系统中的输入和输出 内核,实现了对设备操作和控制，提高了对设备的利用率；
设备管理器：应用编程接口（API），即提供了一组函数，这组函数是用 于为进程服务,实现用户输入输出意图；

I/O设备的操作通过一组固定的入口点进行，这组入口点是 指向每个设备驱动程序提供的一些子程序。服务于I/O请求 的子程序，又称为I/O系统调用。
在不同的系统给出的调用的形式不一样
设备管理器包含有打开函数和关 闭函数：打开函数能分配设备和初始化设备，以便做好对该设备 使用的准备工作。关闭函数用于释放设备，则应由描述子反映出该设备不 能被使用的状态。设备管理器提供读设备函数和写设备函数。



磁盘冗余阵列
它是利用一台磁盘阵列控制器，来统一管理和控制一 组(几台到几十台)磁盘驱动器，组成一个高度可靠的、 快速的大容量磁盘系统。
并行交叉存取（条化存取）

系统将每一盘块中的数据分为若干个子盘块数据，再把每一个子盘块的数据分别存储到各个不同磁盘中的相同位置上；
当要将一个盘块的数据传送到内存时， 采取并行传输方式，将各个盘块中的子盘块数据同时 向内存中传输，从而使传输时间大大减少。

RAID0级：

无冗余，无校验，分布式存储，低可靠性，低价格
仅提供了并行交叉存取，它虽能有效地提高磁盘I/O 速度，但并无冗余校验功能，致使磁盘 系统的可靠性不好。只要阵列中有一个磁盘损坏，便会 造成不可弥补的数据丢失

RAID1级：

分布存放，镜像冗余，不校验
读性能比 RAID 0好 (选择寻道时间小的磁盘访问)，写性能比 RAID 0差，存储开销大，可靠性高

RAID2级：

采用海明码进行校验，每两块数据盘就有一 块校验盘(海明校验码)：当数据损坏时通过校验码可恢复 损坏磁盘上的数字，每次只能传输2路数据，因数据盘就 两块。
可进行并存并取。

RAID 3 级

并行传输
存在奇偶校验盘来完成数据校验功能；
常用于科学计算和图像 处理

RAID4级：

使用了独立访问技术，在独立访问阵列中， 每个磁盘独立的运转，因此不同的I/O请求可以并行的得 到满足

RAID 5 级：

这是一种具有独立传送功能的磁盘阵列。每 个驱动器都各有自己独立的数据通路，独立进行读/写， 且无专门的校验盘。
用来进行纠错的校验信息，是以螺 旋(Spiral)方式散布在所有数据盘上。
RAID 5 级常用于 I/O 较频繁的事务处理中。

RAID 6 级和RAID 7 级。在 RAID 6 级的阵列中，设置 了一个专用的、可快速访问的异步校验盘。该盘具有独立 的数据访问通路，具有比RAID 3 级及RAID 5 级更好的 性能，但其性能改进得很有限，且价格昂贵。RAID 7 级 是对RAID 6 级的改进，在该阵列中的所有磁盘，都具有 较高的传输速率和优异的性能。
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>System</tag>
      </tags>
  </entry>
  <entry>
    <title>文件系统</title>
    <url>/2025/07/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F6-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[概述
文件
文件中常保存的信息：

基本信息：文件名、文件类型、文件组织
地址信息：卷、起始地址、使用大小、分配大小
访问控制信息：所有者、访问信息、许可的行为
使用信息：数据创建、创建者身份、最后一次读 访问的日期、最后一次读用户的身份、最后一次 修改的日期、最后一次修改者的身份、最后一次 备份的日期、当前使用

文件(file)的属性

长期存在：文件存储在硬盘或其他辅存中，用户退出 系统时文件不会丢失
进程间共享：文件有名字，具有允许受控共享的 相关访问权限
结构化：取决于具体的文件系统，一个文件具有针对某 个特定应用的内部结构

文件系统
文件系统(file system)是操作系统的重要组成部分 ，允许用户创建成为文件的数据集；
文件类型

按用途分类：系统文件/用户文件/库文件
按数据形式分类：源文件/目标文件/可执行文件
按存取控制属性分类：只执行文件/只读文件/读写文件
按组织和处理方式分类：普通文件/目录文件/特殊文件

文件系统模型

管理对象：文件，目录，磁盘存储空间
对象操作和管理的软件集合：实现文件系统的功能
文件系统接口：命令接口/程序接口

文件操作
文件系统不但提供存储数据（组织为文件）的手段，而且 提供一系列对文件进行操作的功能接口。

创建文件
删除文件
打开文件
关闭文件
读文件，写文件
截断文件
设置文件读写位置...

组织结构
文件结构
文件：具有文件名的一组相似记录的集合

域：基本的数据单元，一个域包含一个值，定长或变长
记录：一组相关域的集合，定长或变长，通常包含长度域

逻辑结构：从用户观点出发所观察到的文件组织形式，是用户可 以直接处理的数据及其结构，它独立于文件的物理特 性，又称为文件组织。
物理结构：指文件在外存上的存储组织形式。
文件系统架构

设备驱动：程序直接和外围设备或其通道通信，驱动负责启动设备上的IO操作，处理IO请求的完成
基本文件系统：物理IO层，处理磁盘间交换的数据块，操作系统关注这些块在辅存和缓冲区的位置
逻辑IO：使得用户程序能访问记录，记录必须组成块进行IO操作
文件组织：用户访问文件的方法

文件组织
堆
堆是最简单的文件组织形式

数据按它们到达的顺序被收集。
堆的目的仅仅是积累大量的数据并 保存
堆文件没有结构，堆对记录的访问是通过穷举查找方式进行的。

顺序文件

每条记录都使用一种固定的格式
所有记录都具有相同的长度 由相同 ，并且 数量、长度固定的域按特定 顺序组成
每个域的域名和长度是该文件结构 的属性。
关键域是记录的唯一标识，记录按关键域来存储

在顺序文件中，逻辑记录的顺序：

串结构：按照记录录入的时间排序
按关键字排序：有利于提高查询速度

对顺序文件的读写：

定长记录：易于定位，可随机读取
变长记录：不易定位，只能顺序读取
维护一个日志文件log：用于存放将更新到主文件的记录 。

优点：

批处理时效率是所有逻辑文件中最高的
可存在于磁带上

缺点：

交互应用时“效率低”（如要查找单个记录），尤其 是对变长记录的顺序文件。
增加、删除记录涉及到排序问题，开销大。

索引顺序文件
索引顺序文件是克服顺序文件缺点的常用办法

保留顺序文件的关键特征：记录按照关键域的顺序组织
用于支持随机访问的文件索引：提供了快速接近目标 记录的查找能力
溢出文件：类似于顺序文件中使用的日志文件，但溢 出文件中的记录可根据它前面记录的指针进行定位


检索文件：

利用用户(程序)所提供的关键字以及某种查找 算法去检索索引表
找到该记录所在记录组中第一个 记录的表项，从中得到该记录组第一个记录在主文件 中的位置。
再利用顺序查找法去查找主文件，从中找到所要求的 记录。

对于有N条记录的顺序文件中，设定一个M项的索引文件，索引的关键域均匀分布在主文件中，找到某条记录平均需要在索引文件中访问O(M/2)次，在主文件平均访问O(N/2M)次，索引顺序文件组织的开销为O(M/2+N/2M), 顺序文件组织查找某条记录平均开销为O(N/2);
索引文件
顺序文件和索引顺序文件都只允许按记录的唯一关键字检索记 录，这不符合某些应用需要按多个字段检索记录的要求;
采用多索引的结构，成为查找条件的每个域都可能有一个索引;

完全索引：包含主文件中每条记录的索引项
部分索引：只包含那些有感兴趣域的记录的索引项

特点：

建立有序的索引表，查找很快，提高了速度，增加了存储开销(索引文件);
增、删记录时，对索引表作相应的修改

note:有时删除文件可能只是删除了其索引,这也是利用某些软件可以找回删除文件的原因；

直接或散列文件
而对于直接文件，则可根据给定的记录键值，直接获 得指定记录的物理地址。换言之，记录键值本身就决 定了记录的物理地址。
这是目前应用最为广泛的一种直接文件，它利用Hash  函数(或称散列函数)，可将记录键值转换为相应记录的 地址。
存储空间管理
文件分配方法
连续分配： 连续分配是指在创建文件时，给文件分配一组连续的块。 以该方式管理的文件称为连续文件，可采用紧缩技术整理；

优点：简单、容易实现，对于顺序文件，能很快检索文件中的数据块,连续读/写 多个数据块内容时，性能较好。
缺点：它不利于文件尺寸的动态增长，该分配方案可能会导致磁盘碎片，严重降低外存空间的 利用率。

链式分配：为文件分配非连续的若干数据块，数据块之间用指针相连，，以该方式管理的文件称为链接 文件，包含隐式链接和显式链接；

隐式链接：在文件目录的每个目录项中都须含有指向链接文件第一 个盘块和最后一个盘块的指针，文件目录表中有start块号，每块中有下一块号；只适合于顺序访问，对随机访问效率低，可靠性差
显式链接：把用于链接文件各物理块的指针，显式地存放在内存 的一张链接表中（整个磁盘仅设置一张）。查找在内存中进行，由于分配给文件的所有盘块号都放在该表中，故把该 表称为文件分配表FAT(File Allocation Table)；
优点：链接分配技术不要求文件存储到彼此相邻的数据块中， 消除连续分配引起的碎片，提高了外存空间的利用率。能适应文件尺寸的动态增长。
缺点：对于随机存取却相当低效，局部性原理不再适用；

索引分配：每个文件在文件分配表中存在一个一级索引，文件每个分区在索引上都有一个表项
空闲空间管理方法


位示图法：


每一位对应一个磁盘 块。位的值为0或1，分别表示磁盘块空闲，或磁盘块已分配；


利用位表容易找到一个或一组空闲盘块  位表适合于以上各种文件分配方法 ；


位表很小，可以装入内存；




链接空闲区

每个空闲分区包含一个指向下一个分区的指针，并 记载分区大小
无空闲分区表空间开销
适合于各种文件分配方法
若每次分配一个磁盘块，则可取空闲分区链的第一 个盘块进行分配，并调整空闲分区链首指针和分区 链大小
若采用可变分区法，可用首次适应算法，从链表头 开始查找，找到的第一个适合的分区则可分配，然 后调整空闲分区链首指针和分区链大小



索引

将空闲分区视为文件，按文件存储空间分配法为空 闲分区建立索引
索引表中为每一个空闲分区建立一个索引项
为可变分区建立索引比为磁盘块建立索引效率高
适合于各种文件分配法



空闲块列表

在这种方法中，每块都指定一个序号，所有空闲 块的序号保存在磁盘的一个保留区中。
两种有效技术把该表一小部分保存到内存中：将表看作堆栈/FIFO队列；



文件目录管理
文件目录
有的 系统将其中部分信息保存在文件头部，只将一些 必要信息如文件名、文件大小、外存中的存储位 置等保存在文件目录中；
典型操作： 查找、创建文件、删除 文件、显示目录、修改目录
管理要求：实现“按名存取”，提高对目录的检索速度，文件共享，允许文件重名
文件控制块和索引结点
文件控制块(file control block, FCB):用于描述和控制文件的数据结构,用于记载文件 在内存中的使用情况;

基本信息类：文件名，文件物理位置，文件逻辑结构，文件的 物理结构
存取控制类信息：权限
使用信息：记录信息，如日期等

索引结点：包含文件描述信息，把文件名与文件描述信息分开，在文件目录中的每个 目录项仅由文件名和指向该文件所对应的 i 结点的指 针所构成。目录结构

磁盘索引结点：包含文件主标识，文件类型，文件存取权限，物理地址，文件长度，连接（共享）计数，存取时间等；
内存索引结点：文件打开后，将磁盘索引结点的内容部分或全部子集 拷贝到内存，并增加以下内容：编号，状态，共享计数，逻辑设备号，链接指针

目录结构


单级目录结构：所有用户的全部文件目录保存在一张目 录表中，每个文件的目录项占用一个表项，目录项中主要记载的信息有：文件名及扩展名，文件 的物理地址，其它属性，如文件长度、建立日期、文 件类型等
优点：简单且按名存取
缺点：查找速度慢，不允许重名，不便于实现文件共享；


两级目录结构：每一个用户建立一个单独的用户文件目录UFD，再 建立一个主文件目录MFD。在主文件目录中，每个用 户目录文件都占有一个目录项，其目录项中包括用户 名和指向该用户目录文件的指针
优点：提高了检索目录的速度，在不同的用户目录中，可以使用相同的文件名，不同用户还可使用不同的文件名来访问系统中的同 一个共享文件


树型目录结构：
主目录在这里被称为根目录，把数据文件称为树叶， 其它的目录均作为树的结点
路径名：从树的根（即主目录）开始，把全部目录文件名与数 据文件名，依次地用“/”连接起来，即构成该数据文件 的路径名
工作目录：即当前目录，进程对各文件的访问都相对于“当前目录”而进行， 通常称为相对路径。


增加目录：在用户要创建一个新文件时，只需查看在自己的 UFD及其子目录中，有无与新建文件相同的文件名。 若无，便可在UFD或其某个子目录中增加一个新目 录项。
删除目录：例如Linux中，不删除非空目录rmdir如果该目录内包含文件或子目录，系统会拒绝执行删除操作,可删除非空目录rm -r在尝试删除一个目录时，即使该目录内包含文件或子目录，系统也会允许执行删除操作
目录查询技术
过程：文件名-目录项（FCB）或索引结点-盘块号-启动磁盘-驱动程序
例如查询：/usr/ast/mbox

根中得usr的索引结点号6
6中得usr目录文件为132#
132#中得/usr/ast的索引结点是26
26中的/usr/ast目录文件中406#
406#中得/usr/ast/mbox的索引结点是60
60中得/usr/ast/mbox的物理地址

FAT文件系统
早期的MS-DOS采用FAT12,后演变为FAT16,在windows95和98中升级成FAT32；
FAT12：以盘块为基本分配单位，每个分区设置两张文件分配表FAT1,FAT2,系统设置文件分配表FAT，在 FAT 的每个表项中存放下一个盘块号；当达到文件尾的时候，存入0xFFF，标志结束

为了适应更大容量的磁盘，因而以簇为单位进行分配， 簇越小磁盘浪费的空间就越小；
簇一般由2n个盘块组成，与扇区的数量、磁盘容量的大小 直接有关
对所允许的磁盘容量存在着严重的限制，虽然可以用继续增加簇的大小来提高所允许的最大磁 盘容量，但随着支持的硬盘容量的增加，相应的簇内 碎片也将随之成倍地增加。


FAT16： FAT 表的宽度增至16 位，最大表项数将增至个 ，此时便能将一个磁盘分区分为个 簇。可以管理的最大分区空间为(1&lt;&lt;16 )×64 ×512B =  2048 MB

当磁盘容量迅速增加时，如果再继续使用FAT16， 由此所形成的簇内碎片所造成的浪费也越大。(簇越 大，一般磁盘的碎片就越多

FAT32: FAT32保留扇区的数目默认为32个而不是FAT16的1个

FAT32的根目录等同于普通的文件;
根目录储在分区内可 寻址的任意簇内，不过通常根目录是最早建立的
根目录下的所有文件及其子目录在根目录的文件目录表 FDT中都有一个“目录项”，系统以32个字节为单位进 行目录文件所占簇的分配，因此32个扇区的根目录FDT 最多可以记录32*512/32=512个文件或子目录。
DATA区是实际的文件和目录数据存储的区域，它占据 了分区的绝大部分。 每个簇只能被一个文件占有，因而常常文件的尾部会出 现不可利用的空间，所以簇越大，文件数目越多时，零 头就越多，造成资源浪费，因此簇的大小不应该太大。FAT32采用4KB的簇的大小。
不能采用太小的单位进行分配。如采用大小为512B的 扇区管理会增加FAT表的项数，对大文件存取增加消耗 ，文件系统效率不高

文件系统格式化

格式化程序并没有把DATA区的数据清除，只是重写了 FAT表而已，至于分区硬盘，也只是修改了MBR和 DBR，绝大部分的DATA区的数据并没有被改变;
因而 进行上述操作后，数据仍然可以得到恢复


NTFS文件系统

使用了64 位磁盘地址;
很好地支持长文件名;
具有系统容错功能;
提供了数据的一致性;

磁盘组织:以簇作为磁盘空间分配和回收的基本单位,卷上簇的大小称为“卷因子”（一个簇包含2n个 盘块）,对于簇的定位，采用逻辑簇号LCN和虚拟簇号VCN进行的。
文件组织：在NTFS 中，以卷为单位，将一个卷中的所有文件信 息、目录信息以及可用的未分配空间信息，都以文件 记录的方式记录在一张主控文件表MFT中。卷中的每个文件作为一条记录，在MFT 表中占有一行， 其中还包括MFT 自己的这一行。每行大小固定为1  KB，每行称为该行所对应文件的元数据(metadata)， 也称为文件控制字。 NTFS 文件不能被FAT 等文件系统所存取，缺乏兼容性。文件通过主文件表（MFT）来确定其在磁盘上的存储 位置。主文件表是一个对应的数据库，由一系列的文 件记录组成--卷中每一个文件都有一个文件记录（对于 大型文件还可能有多个记录与之相对应）。NTFS卷上的每个文件都有一个64位（bit）称为文件引 用号（File Reference Number，也称文件索引号）的 唯一标识。文件引用号由两部分组成：一是文件号， 二是文件顺序号。NTFS使用逻辑簇号（Logical Cluster Number，LCN）和 虚拟簇号（Virtual Cluster Number，VCN）来进行簇的定 位。LCN是对整个卷中所有的簇从头到尾所进行的简单编 号。VCN则是对属于特定文件的簇从头到尾进行编号，以 便于引用文件中的数据。VCN可以映射成LCN，而不必要 求在物理上连续。
文件系统结构：

启动扇区文件$BOOT位于磁盘头部，$BOOT中包含 MFT的位置数据。
主文件表索引的第一个文件为$MFT。主文件的每一个 表项表示一个文件索引，每个文件索引由一系列的属 性组成。


NTFS元文件: MFT的前16个元数据文件非常重要，为了防止数据的丢失， NTFS系统在该卷文件存储部分的正中央对它们进行了备份。

MFT中的第1个记录就是MFT自身;
由于MFT文件本身 的重要性，为了确保文件系统结构的可靠性，系统专门 为它准备了一个镜像文件$MftMirr，也就是MFT中 的第2个记录。
第3个记录是日志文件$LogFile。该文件是NTFS为 实现可恢复性和安全性而设计的。当系统运行时NTFS 就会在日志文件中记录所有影响NTFS卷结构的操作， 包括文件的创建和改变目录结构的命令，例如复制，从 而在系统失败时能够恢复NTFS卷。
第4个记录是卷文件$Volume，它包含了卷名、被 格式化的卷的NTFS版本和一个标明该磁盘是否损坏的 标志位。
第5个记录是属性定义表$AttrDef，其中存放了卷所支持的所有文件属性， 并指出它们是否可以被索引和恢复等;
第6个记录是根目录（\），其中保存了存放于该卷根目 录下所有文件和目录的索引。在访问了一个文件后， NTFS就保留该文件的MFT引用，第二次就能够直接进 行对该文件的访问
第7个记录是位图文件$Bitmap。NTFS卷的分配状 态都存放在位图文件中，其中每一位（bit）代表卷中的 一簇，标识该簇是空闲的还是已被分配了的，由于该文 件可以很容易的被扩大，所以NTFS的卷可以很方便的 动态的扩大，而FAT格式的文件系统由于涉及到FAT表 的变化，所以不能随意的对分区大小进行调整。
第8个记录是引导文件$Boot，它是另一个重要的 系统文件。
第9个记录是坏簇文件$BadClus，它记录了磁盘上 该卷中所有的损坏的簇号，防止系统对其进行分配使用。
第10个记录是安全文件$Secure，它存储了整个卷 的安全描述符数据库。NTFS文件和目录都有各自的安 全描述符，为了节省空间，NTFS将具有相同描述符的 文件和目录存放在一个公共文件中。
第11个记录为大写文件$UpCase， 该文件包含一个大小写字符转换表。
第12个记录是扩展元数据目录$Extended metadata directory。
第13个记录是重解析点文件$Extend\$Reparse


Linux文件系统
Linux是一个unix类操作系统,用EXT2文件系统结构,以下是查找文件的过程

当访问一个文件时，通过文件名在“目录表”中查到 其“索引节点号”。
通过“索引节点号”查“索引节点表”。
通过“索引节点表”得到其“索引节点”；
通过索引节点得到文件数据所在位置

EXT2文件系统的物理结构：整个盘卷由多个数据块组构成。一个数据块代表一个 文件系统

超级块：存储着描述文件系统大小和形状的基本信息；
组描述符：描述它的数据结构。（块位图大小、索引节 点位图大小、索引节点表大小、空闲块数、空闲索引节 点数、已用目录数等重要信息）；
块位图：描述了该块组中数据块空间的使用情况，在数 据块分配和数据块撤销时使用；
索引节点位图：描述了该块组索引节点表所占空间的信 息，在索引节点的分配和撤销中使用；
索引节点表：记录了本块组中索引节点集合；
数据块：用于存放文件数据；


EXT2的目录

一个文件对应有一个目录项；
目录项包含该文件对应的索引节点号、文件名、名字 长度等信息；
目录是一些特殊的文件，称为目录文件，其中包含了 该目录下所有文件的目录项集合。


EXT2的索引节点

Mode：用户拥有的权限r,w,e
Owner Information：文件或目录所有者的用户和组标 识符
Size：文件大小
Timestamps：索引节点建立的时间和索引节点最后修 改的时间
Data blocks：描述文件的数据块


文件控制块

当打开一个EXT2文件时，把要打开文件的管理控制信 息从辅存的目录项和索引节点中读到内存，形成FCB， 并将该FCB的地址以一个文件描述符（FD）的形式返 回给用户进程;
根据FD可获得文件的描述信息,通过这些信息用户可对实际物理文件进行操作

linux的虚拟文件系统VFS: 将实际的文件系统 的数据结构转换成统一的内存VFS的数据结构来兼容多种 文件系统类型


数据缓存：任何一个从块设备中读取的数据块或者往块设备中写 入的数据块都要通过缓存，缓存中的数据块是以拥有此数据块的设备的设备标识 符和缓冲区的块号来唯一标识的；

空闲的缓冲区链表
非空闲的缓冲区：由指针数组构成的散列表， 散列表中hash值由设备的标识符和数据块的块号产生 的，表中的指针指向具有相同hash值的缓冲区。


缓冲区的状态类型：clean,locked,dirty,shared, unshared
bdflush守护进程: 使用bdflush内核守护进程来完成缓存管理,在系统启动时作为一个系 统的线程运行，在大部分时间中，此守护进程都处 于睡眠状态，等待系统中被改动的数据块缓冲区的 数量增大到一定的值，bdflush守护进程将被唤醒,任务是当缓存中被改动的缓 冲区数量太多时，提供一个管理功能


索引结点缓存：索引节点缓存可以加快对系统中文件的存取,使用散列表实现，表项的hash值是通 过索引节点号和存储文件系统的物理设备号计算出来的， 各表项指向具有相同hash值的VFS索引节点链表的指针。
操作：如果系统在索引节点缓存中找到索引节点，那么此索 引节点的计数器将加1，表明又有一个进程在使用该 索引节点。否则，系统必须申请一个空闲的VFS索引 节点，系统读取该索引节点到内存缓存。如果系统已经没有可分配的空闲索引节点时，那么必 须查找一个已用的索引节点，将那些用户计数器为0 的索引节点重新分配（说明系统中没有任何进程正在 使用这些索引节点），一些非常重要的索引节点，如文件系统的根目录索引 节点，它们的索引节点计数器总是大于0，以保证永 远不能被重新分配。不论用什么方法找到一个新的索引节点，系统都必须 调用一个特殊的子程序来把实际文件的信息添加到此 索引节点中。当向新的索引节点中写入信息时，锁定此索引节点， 将索引节点计数器置为1，直到索引节点中的信息写完 后，再解锁。如果它被锁定时，则其他需要访问该索引节点必须等 到解锁后才能进行。


目录缓存：为了加速对常用目录的存取， VFS维护一个两层LRU目录 缓存链表。 目录缓存包括一个散列表， 表的hash值由设备号和目录 名来计算，每个表项指向具 有相同hash值的目录缓存链 表的指针。当读取一个目录时，目录的 详细信息将添加到目录缓存 中



]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>System</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库理论</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%930-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%90%86%E8%AE%BA/</url>
    <content><![CDATA[数据库是什么
数据库：长期存储在计算机内，有组织，可共享的海量数据集合
数据库相关理论及相关问题：

数据模型，规范化理论：如何组织这些数据?
数据定义和操作语言；如何存取和操作数据？
数据安全：哪些人可以操作这些数据？
并发控制：多人如何操作统一数据？
数据恢复：出现故障怎么办？
数据挖掘：如何分析数据和发现数据价值？

数据库相关人员职责：

数据库开发者
数据库设计者
数据库管理员
数据库实现者

数据概念
数据
数据是一种符号序列，它的内容是事物特性的反映，能被计算机识别，存储；
数据的类型：

数字，字母，文字
图形， 图像，声音…

信息
信息是经过加工处理的数据，是数据的具体含义；
数据和信息的联系：

数据是信息的载体，数据是信息的外延；
信息是数据的具体含义，信息是数据的内含；
信息是抽象的，不随数据形式而变化；
信息对应的数据表现形式具有可选择性；

知识
知识是有用的信息；
知识获取的过程既是从大量、已知信息出发、根据事物之间的固有联系和规律，提出有价值、有意义的信息
数据库概念
数据库DB
数据库是长期储存在计算机内、有组织的、可共享的大量数据集合。

按一定的数据模型组织，描述和存储；
可为各种用户共享；
冗余度小；
数据独立性高；
易拓展；

数据库管理系统DBMS
定义：一个能让用户定义，创建和维护数据库以及控制对数据库访问的软件系统；
功能


数据库定义DDL：对各级数据库模式进行精确定义（create, alter, drop），包括创建模式，数据库，表，视图；


数据操纵DML：对数据库中的数据进行处理(select, insert, update, delete)，包括增加、删除、修改、查询；


数据库运行控制DCL：数据库恢复，数据库并发控制，数据完整性控制，数据安全性控制(grant, revoke)


数据库的维护功能：

初始数据的载入；
数据库的转储；
数据库性质监视，分析功能；



数据字典DD：存放数据库的三级模式的描述


数据库系统
定义：引入数据库后的计算机系统；

硬件
软件（数据库，数据库管理系统和相关软件）
用户（数据库管理员，数据库开发者， 最终用户）

一般认为DBS包含DB，DBMS，但是DB和DBMS没有包含关系；
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库管理技术</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%931-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[问题和挑战
数据库管理技术研究研究如何对数据进行科学管理，从而为人们提供可共享的、安全的、可靠的数据；
数据库管理技术可能面临的挑战：垃圾信息，数据类型多样化和一体化，数据库安全......
发展阶段：人工管理文件系统数据库系统关系数据库非关系型数据库（NoSQL，Not Only SQL）​​分布式关系数据库(new SQL)；
发展历程
人工管理
计算机主要用于科学计算，软件只有汇编语言，尚无数据管理方面的软件，数据处理方式基本是批处理，比较原始；

计算机系统不提供对用户数据的管理功能。
数据不能共享。
不单独保存数据;

文件系统
计算机不仅用于科学计算，还利用在信息管理方面，软件领域出现了操作系统和高级软件

数据以文件形式保存
程序与数据之间具有“设备独立性”
数据冗余、不一致、数据联系弱

数据库系统

数据结构面向全组织
数据冗余小，易扩充
数据独立于程序
统一的数据管理功能，包括数据的安全性控制、数据的完整性控制及并发控制

网状数据库
最早的网状数据库管理系统 IDS；
数据库标准的制定DBTG，首次提出了数据库三层体系结构；
层次数据库
IBM公司研制成功第一个层次数据库IMS
数据不在存储在文件中，树/图的结构存储数据
程序和数据完全分离
关系数据库
简单统一的数据结构， 描述性的SQL查询语言
关系数据库的不足

结构约束严格，不能满足非结构化数据处理的需求
SQL语言不支持复杂的数据分析

关系数据库内部扩展

对象模型和XML模型
专用系统：One-size-dose-not-fit-all

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>视图与索引</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%9310-%E8%A7%86%E5%9B%BE%E4%B8%8E%E7%B4%A2%E5%BC%95/</url>
    <content><![CDATA[视图
创建视图
特点：

虚表，从一个或几个基本表导出的表；
只存放视图的定义，不会出现数据冗余
基表中数据发生变化，从视图查询出数据也随之改变
视图建立后，用户可以像基表一样对视图查询

优点：

限制用户直接存取基表的某些列或记录，从而为基表带来附加的安全性；
视图可定义在多个基表上或其他视图上，通过视图可得到多个表经计算后的数据，从而隐藏数据的复杂性；

作用：

视图能够简化用户的操作：当视图中数据不是直接来自基本表时，定义视图能够简化用户的操作

基于多张表连接形成的视图
基于复杂嵌套查询的视图
含导出属性的视图


视图使用户能以多种角度看待同一数据：视图机制能使不同用户以不同方式看待同一数据，适应数据库共享的需要
视图能够对机密数据提供安全保护

对不同用户定义不同视图，使每个用户只能看到他有权看到的数据
通过WITH CHECK OPTION对关键数据定义操作时间限制


利用视图可以清晰地表达查询：复杂查询分步实现；

创建视图
CREATE VIEW &lt;视图名&gt; [列名1，…] AS &lt;子查询&gt;

省略列名时，则由子查询中SELECT目标列中的诸字段组成
明确指定视图的所有列名:
DBMS执行CREATE VIEW语句时只是把视图的定义存入数据字典，并不执行其中的SELECT语句。
在对视图查询时，按视图的定义从基本表中将数据查出。
子查询可以是任意复杂的SELECT语句，但通常不允许含有ORDER BY子句和DISTINCT短语

删除视图
语法：
DROP VIEW &lt;视图表&gt;
更新视图
由于视图是不存储数据的虚表，数据是来自其他基表部分数据，对视图的更新最终是对基表的更新。

对于直接CURD生成的基表，其视图只读；
对于采取统计查询/聚集查询的基表，其视图可删除，不可修改；
对于采取表达式计算的列，其更新不允许；

索引
概念
类似于词典的索引,索引是关于数据位置信息的关键字表。

数据库中的索引是一个表中所包含的值的列表，其中注明了表中包含各个值的记录所在的存储位置。
可以为表中的单列或多列创建索引;
索引通常采用采用B树，B+树或哈希表等结构。
数据库系统检索数据时，根据索引提供的信息，可以直接找到与该条件临近的数据区，而不是一条一条记录地比较，因此可提高查询速度；

使用索引

建立索引是加快查询速度的有效手段
索引由DBMS内部实现，属于内模式范畴
建立索引：DBA或表的属主根据需要建立，有些DBMS自动建立以下列上的索引: PRIMARY KEY和 UNIQUE
维护索引：DBMS自动完成
使用索引：DBMS自动选择是否使用索引以及使用哪些索引

聚簇索引
建立聚簇索引后，基表中数据也需要按指定的聚簇属性值的升序或降序存放。

在一个基本表上最多只能建立一个聚簇索引
用途：对于某些类型(范围查找)的查询，可以提高查询效率
适用范围：很少对基表进行增删操作，很少对其中的变长列进行修改操作
语法：

CREATE CLUSTERED INDEX Stusname ON Student(Sname);
非聚簇索引

数据存储在一个地方，索引存储在另一个地方，索引带有指针指向数据的存储位置;
索引中的项目按索引键值的顺序存储，而表中的信息按另一种顺序存储（也可以由聚簇索引规定）。
在搜索数据值时，先对非聚集索引进行搜索，找到数据值在表中的位置，然后从该位置直接检索数据。
由于索引包含描述查询所搜索的数据值在表中的精确位置的条目，这使非聚集索引成为精确匹配查询的最佳方法。
关键字为NONCLUSTERED

单列索引

普通索引：允许在定义索引的列中插入重复值和空值；
唯一值索引：唯一索引确保索引列不包含重复值，在多列唯一索引的情况下，该索引可以确保索引列中每个值组合是唯一的
主键索引：不允许为空的唯一索引；

组合索引
在表中的多个字段组合上创建索引；
CREATE [UNIQUE][CLUSTERED / NONCLUSTERED] INDEX &lt;索引名&gt; ON &lt;表名&gt; (列名1);
删除索引
删除索引语法：DROP INDEX &lt;索引名&gt;
删除索引实例:DROP INDEX &lt;索引名&gt;
索引的原则

选择数据量较大的表建立索引
选择列中的数据多而杂的列建立索引
建立索引的数量要适量

索引要占用磁盘空间
维护索引结构系统要花费一定的开销
仅用来查询的表来讲课建立多个索引，对更新操作比较频繁的表少建立索引


优先考虑主键列建立索引
选择合适的时机建立索引

建立索引应选择在表中装入数据之后
如果要保证装入数据的唯一性，在装入数据前建立唯一性索引



]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>断言与参照完整性</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%9311-%E6%96%AD%E8%A8%80%E4%B8%8E%E5%8F%82%E7%85%A7%E5%AE%8C%E6%95%B4%E6%80%A7/</url>
    <content><![CDATA[完整性约束
控制机制
完整性约束是加在数据库模式上的一个具体条件，规定什么样的数据能够存储到数据库中；
定义机制：

约束条件：数据模型的组成部分，约束数据库的寓意
DBMS提供定义数据库完整性约束条件，并作为模式的一部分存入数据库

检查机制：

检查用户发出的操作是否违背了完整性约束条件

违约反应：

发现用户的操作请求使数据违背了完整性约束条件，则采取一定的动作保证数据完整性；

分类

主键约束PRIMARY KEY ：一个关系仅一个，属性非空
唯一约束UNIQUE：一个关系可声明多个，可为空，允许多个空值，不能定义在被主键约束的属性上
非空约束NOT NULL
自定义约束CHECK
参照完整性约束FOREIGN KEY
断言ASSERTION

还可以根据位置分类为列级，行级和表级约束；以下是一些表建立的约束的例子
CREATE TABLE Diagnosis&#123;DGno VARCHAR(10) PRIMARY KEY,Pno VARCHAR(10) NOT NULL,Dno VARCHAR(10) NOT NULL,Symptom VARCHAR(100),Diagnosis VARCHAR(100),DGtime DATETIME,Rfee DECIMAL(18,2) NOT NULL&#125;;CREATE TABLE Doctor&#123;Dno VARCHAR(10),Dname VARCHAR(50) NOT NULL,Dsex VARCHAR(2) CHECK( Dsex IN (‘男’, ‘女’)),Dage INT CHECK( Dage &gt; 0 AND Dage &lt;60),Ddeptno VARCHAR(10),Dlevel VARCHAR(50),Dsalary DECIMAL(18,2),PRIMARY KEY(Dno),&#125;;CREATE TABLE RecipeDetail&#123;Rno VARCHAR(10),Mno VARCHAR(10) NOT NULL,Mamount DECIMAL(18,0),PRIMARY KEY(Rno,Mno),CHECK (Mno IN (SELECT Mno FROM Medicine))//这是参照完整性约束，允许出现其他关系的子查询&#125;;
以下是断言的格式和一个例子
CREATE ASSERTION fk_DiagnosisCHECK ( NOT EXISTS( SELECT * FROM Diagnosis WHERE Dno NOT IN(SELECT DnoFROM Doctor))); CREATE ASSERTION &lt;断言名&gt; CHECK&lt;谓词&gt;Create assertion salarycheck check(Not exists(Select * from Doctor xWhere Dsalary &gt;= some ( select Dsalary from Doctor y Where x.Deptno=y.Deptno and y.Dno =(Select Manager from Dept Where x.Deptno =Dept.Deptno)));
参照完整性
概念
给定关系R，S，若存在R.A参照S.B

R是参照表，S为被参照表
A取值要么为空，要么来自于S.B
A为外码
B是S的主码
若两张表的属性有参照完整性约束，在创建R表声明

REDERENCES S(B)FOREIGN KEY(A) REFERENCES S(B)
可见对R和S的删除，更新，插入都有可能触发完整性违约；

DELETE FROM S
UPDETE S.B
UPDETE R.A
INSERT TO R

策略

受限策略RESTRICTED:系统的默认方式，出现违约时，系统拒绝执行
置空策略SET-NULL：根据环境的语义，外码可能为空
级联策略CASCADE：不用拒绝用户操作请求的处理方式
定义方式ON (DELETE|UPDATE) (SET NULL|CASCADE)

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>触发器与游标</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%9312-%E8%A7%A6%E5%8F%91%E5%99%A8%E4%B8%8E%E6%B8%B8%E6%A0%87/</url>
    <content><![CDATA[触发器
概念
触发器

一组SQL语句
当插入，更改，删除，事件发生的时候，触发器自动执行
用以维护数据完整性，或者其他数据处理工作
属于动态完整性约束

分类
根据事件分类

DML触发器：发生数据操作事件时调用，包括INSERT UPDATE DELATE
DDL触发器：发生数据定义事件调用，包括CREATE DROP DELETE
根据发生时间和操作分类
AFTER触发器：是最常见的触发器，在事件执行之后检查触发条件，若满足则调用触发器
BEFORE触发器：在事件执行之前检查触发条件，若满足则调用触发器
INSTEAD OF触发器：一般用于视图，事件执行之前检查触发条件，若满足，则用触发器定义的操作代替原来的数据更新操作
根据执行粒度分类
语句级触发器：执行完一条SQL语句，是DBMS的默认值，关键字为FOR EA CH STATEMENT
元祖级触发器：在每一行触发FOR EACH ROW

触发器操作
创建触发器
Create｜Replace Trigger &lt;触发器名&gt;Before|After|Instead Of &lt;事件子查询&gt;[ For Each Row ]When ( &lt;条件&gt;)&lt;数据操作&gt;;
删除触发器
DROP Trigger &lt;触发器名&gt;
使用触发器可以容易实现参照完整性；
游标
定义
声明游标DECLARE
打开游标OPEN
从一个游标中逐条获取并处理记录信息FETCH
关闭游标CLOSE
以下是一个例子：
Open GPA36;Fetch Next From GPA36 IntomsID, msName,mGPA,mcName,mmajor;Close GPA36;
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>存储过程与函数</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%9313-%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E4%B8%8E%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[存储过程
定义
创建存储过程
CREATE|RPLACE Procedure &lt;过程名&gt;ASDECLARE &lt;变量声明&gt;BEGIN&lt;ACTION&gt;END;
调用存储过程
CALL &lt;过程名&gt;；
删除存储过程
DROP Procedure &lt;过程名&gt;；
参数

输入参数IN：将存储过程外部的值传递给存储过程使用；
输出参数OUT:存储过程在执行时，将中间结果赋值给OUT参数，存储过程执行完后，外部用户通过OUT参数获得执行存储过程结果
输入输出参数INOUT:既作为输入参数，同时在执行过程中也会将中间结果输出给外部用户；

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>事务与并发调度</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%9314-%E4%BA%8B%E5%8A%A1%E4%B8%8E%E5%B9%B6%E5%8F%91%E8%B0%83%E5%BA%A6/</url>
    <content><![CDATA[事务并发
某些突发故障可能导致数据库产生不一致的结果；并发执行应用可以提高性能，但是有可能带来数据操作结果不符合预期
数据库的更新：

读数据库：将数据库中数据先从磁盘读入内存，然后再将值赋予另一个变量；
写数据库：现将变量的值写入内存，然后再有内存写入磁盘；
数据库更新应该权衡减少在磁盘上的I/O&amp;防止数据不一致

概念
事务是用户定义的一个数据库操作序列

这些工作是原子的，要么全做，要么全不做，是不可分割的工作单位；
一个事务可以是一条SQL语句，一组SQL语句或整个程序
一个应用程序可以包含事务

定义
在SQL中可以显式定义
BEGIN TRANSACTION 	&lt;SQL1&gt;	&lt;…&gt;	COMMIT|ROLLBACKEND TRANSACTION
没有显式定义事务时，DBMS按缺省方式自动划分事务
特性ACID

原子性Atomicity：

事务的所有操作在数据库中要么全部正确反映，要么全部不反应；
系统崩溃后，DBMS将恢复或撤销系统崩溃前处于活动状态的事务对数据库产生的影响，从而保证事务的原子性
事务管理部件处理


一致性Consistency：

事务完成时，必须所有数据具有一致的状态；
一般由开发者确保


隔离性Isolation：

当多个事务并发执行时，一个事务的执行不能被其他事务干扰
解决前面提到的并发执行带来的错误问题
交错调度的效果应该和某个串行调度结果是一致的
并发控制部件处理


持续性Durability：

一个事务一旦提交，它对数据库中的数据的改变应该是永久性的，即使系统可能出现故障
恢复管理部件负责



事务并发
概念
并发执行的优点：改善系统的资源利用率，减少短事务的等待时间
调度：一个或者多个事务的操作按时间排序的一个序列
不受控制的事务调度问题：

丢失更新
读脏数据
不可重复读
幻读

原因：事务ACID特性中隔离性被破坏
隔离级别
如何实现事务隔离？

串行：每个事务一次顺序执行
并行但控制：事务之间并发执行，收到DBMS调整事务调度




隔离级别
丢失更新
读脏数据
不可重复读
幻读




读未提交
解决





读提交
解决
解决




重复读
解决
解决
解决



序列化
解决
解决
解决
解决



读未提交Read Uncommitted
一个事务可以读取另一个未提交事务的数据
读提交Read Committed
一个事务要等另一个事务提交后才能读取数据
重复读Repeatable Read
在开始读数据时，不允许修改操作
序列化Serializable
最高的事务隔离级别，事务在这个级别下串行化执行，在该级别下性能最低
可串行化调度
概念
事务交叉调度结果与某一个串行调度结果相同
调度可串行化意味着保持着数据库的一致性，DBMS需要事务调度管理

事务并发完全交给操作系统并不可靠
调度不一定能保持数据库一致
DBMS对事务运行加以控制，确保一致性

数学化表示



操作
简写




读READ
R


写WRITE
W


事务T写数据库元素x
WT(x)


事务T读数据库元素x
RT(x)


调度（事务序列）
S = ….



指令冲突
指令冲突性：调度中两个事务发生冲突，意味着

必须对同一数据对象进行操作
两个指令有一个写操作

冲突等价：对于调度S中属于不同事务的两条操作指令是不冲突的，则可以交换两条指令的执行顺序，得到一个新的调度S‘，称两个调度冲突等价
冲突可串行化：若一个冲突等价于一个串行调度，则这个调度是冲突可串行化的；

冲突可串行是可串行性的充分条件

视图等价：对于同一事务集，若两个调度和视图等价

在任何事务保证美俄事务读取相同的值，
写入数据库最终状态也是一样的；

视图可串行化：若某个调度视图等价于一个串行调度，则称这个调度是视图可串行化的；

若调度是冲突可串行化的，则一定是视图可串行化的
反之未必

前驱图precedence graph
定义有向前驱图


顶点为调度S的事务


表示先于对应的指令执行，且二者存在某一对冲突指令


若前驱图存在环，则调度S不是可串行化的；


若前驱图不存在环，表示调度是冲突可串行化的


一个拓扑排序意味调度一个等价的串行调度


]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库恢复技术</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%9315-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[故障恢复
如何应对系统故障：

提高系统的可靠性
在系统故障发生后，把数据库恢复到一致状态
恢复的关键问题是如何建立冗余数据，以及利用冗余数据实施数据库恢复
恢复技术：
记录日志文件
数据转储

日志
日志概念
日志是用来记录事务对数据库的更新操作的文件，是日志记录的序列

事务标识符：执行写操作的唯一标识符
数据项标识符：事务操作对象的唯一标识符
前像（BI）：更新前数据的旧值；
后像（AI）：更新后数据的新值；

记录形式

&lt;T START&gt;:事务T开始
&lt;T COMMIT&gt;：事务T提交
&lt;T ABORT&gt;：事务T中止
&lt;T,X,V1,V2&gt;：事务T对数据项X写，前像为V1，后像为V2

日志要求

每次事务执行写操作，必须在数据库修改前建立此次修改前的日志记录
日志必须存储在稳定的存储器上
稳定存储器中的日志记录顺序必须与写入缓冲区的日志记录顺序完全一样
一般来说，日志的记录遵循日志先写规则：在贮存中的数据块输出到数据库之前，所有可数据块中数据有关的日志记录必须已经输出到稳定存储器上
写日志的方式：
后像后写
后像前写
后像前后写

后像后写
恢复数据库的步骤

从后向前扫描数据库，将提交的事务放入队列redolist中
从前往后扫描日志，对遇到的每一个&lt;T,X,V1&gt;记录

若不是队列中的事务，则无事发生
若是队列中的事务，将数据项写为V1


对每个未完成的事务，在日志写入一个&lt;T,ABORT&gt;的记录并刷新日志

后像前写
事务恢复过程：Undo，将事务T更新的所有数据项的值设为旧值；
简化日志记录内容：

每一条日志记录内容为&lt;T,X,V1&gt;
需要省去新值字段；
事务T对数据项X执行写操作，写前的旧值为V1
恢复管理器执行：
对日志从后往前扫描，将&lt;T,COMMIT&gt;记录的事务放入redo-list队列
重新对日志文件从后往前扫描
对每一个&lt;T,X,V1&gt;记录，若T在redo-list队列中，则恢复管理器忽略它；若不在，则将这个数据项改为旧值V1

后像前后写
后像在事务提交前后写入数据库，提交的时机应该和设置的缓存大小有关;
理论上事务应该按照非窃取强制写的方式刷新数据库，以保证原子性和一致性；
但是后像前后写可能存在4种组合方式刷新数据库；

被修改的数据项写入磁盘的时机既可能在提交前，也可能在提交后；
日志更新记录表示：&lt;T,X,V1,V2&gt;
有些数据库实现直接构建redo-log和undo-log，而不是维护redo-list和undo-list
窃取方式写日志一定包含undo操作，非强制方式写日志一定包含redo操作
执行规则：日志先写，被更新数据项写入磁盘，更新记录&lt;T,X,V1,V2&gt;必须已经写到稳定存储器上
恢复管理器步骤：
对日志文件从前往后扫描，将有&lt;T,COMMIT&gt;记录和没有&lt;T,COMMIT&gt;记录的事务分别放入两个队列：redo-list，undo-list
从前往后扫描日志，执行redo-list
从后往前扫描日志，执行undo-list

等幂操作
恢复机制应该是等幂的，也就是恢复过程中再次发生崩溃，恢复机制仍然可以重新恢复，前一次恢复过程是否更新为旧值或新值无关紧要；

多次执行操作与执行一次操作的效果完全相同
无论redo和undo，恢复的步骤都是等幂的；
注意这时，redo-log内容属于逻辑日志，undo-log内容应该属于物理日志；

检查点
提交一致性检查点：

新的事务不能开始，直到检查点完成
现有事务继续执行直到中止或提交，将相关数据以及日志写入稳定存储器；
将checkpoint写入稳定存储器

高速缓存一致性检查点：

新的事务不能开始到检查点完成
已存在的事务不允许执行新的更新操作
将当前日志和数据写入磁盘
将&lt;checkpoint，T-list&gt;写入稳定存储器

数据转储
数据转储是数据库恢复中采用的技术

定期将整个数据库复制到其他介质保存起来
备用的数据文本称为后备副本
静态转储
在系统中无运行事务时进行转储
转储开始时数据库处于一致性状态
转储期间不允许对数据库任何存取和修改
优点：实现简单
缺点：降低了数据库的可用性，转储必须等待事务结束，新的事务必须等待转储结束
动态转储
转储过程和事务并发进行，允许对数据库进行存取和修改
优点：无需等待正在运行的事务结束，不会影响新事物的运行
缺点：不能保证副本的数据正确有效
利用带台转储得到的副本进行恢复，需要建立转储期间的日志活动
后备副本+日志文件才能将数据库恢复到某一时刻的正确状态
完全转储: 每次转储全部数据库
增量转储: 只转储上次转储后更新过的数据
从恢复角度看，使用完全转储得到的后备副本进行恢复往往更方便
但如果数据库很大，事务处理又十分频繁，则增量转储方式更实用更有效

恢复策略
故障分类
事务故障

逻辑错误：事务由于内部条件（如非法输入、溢出等）无法继续正常执行
系统错误：系统进入一种不良状态（如死锁），事务无法继续正常执行
事务故障使得事务无法达到预期的终点，数据库可能处于不一致的状态。恢复机制强行回滚该事务，撤销该事务对数据库做的任何修改
系统故障
包括硬件故障、数据库软件或操作系统的漏洞造成的系统停止运转。它导致系统易失性存储器中的内容丢失，事务处理停止，但非易失性存储器中的内容不会受到破坏
介质故障
在数据传送操作过程中由于磁头损坏或故障造成磁盘块上的内容丢失
需使用其他非易失性存储器上的数据库后备副本进行故障的恢复

事务故障恢复
恢复技术：利用日志文件

后像后写：发生故障时数据库中的数据并没有发生变化，所有数据项的修改只是在日志文件中有记录。恢复管理器忽略这些未完成的事务
后像前写：发生故障时，系统可能已将部分或全部数据项的修改写入磁盘，使用日志文件撤销（UNDO）此事务对数据库的修改。
后像前后写：发生故障时系统仍可能已将部分数据项的修改写入磁盘。使用日志文件撤销（UNDO）此事务对数据库的修改
一般通过日志文件，需要维护redo-list和undo-list
当系统崩溃重新启动时，它构造两个队列：undo-list存放需要撤销的事务标识符，redo-list存放需要重做得事务标识符
这两个队列刚开始时都是空的
队列构造步骤如下

系统反向扫描日志，直到发现第一个记
对每一个&lt;Ti，COMMIT&gt;记录，将Ti加入redo-list
对每一个&lt;Ti，START&gt;记录，如果Ti不属于redo-list，则将Ti加入undo-list



系统故障恢复

利用日志文件：
后像后写
后像前写
后像前后写

介质故障恢复

装入最近的完全转储后备副本：若数据库副本是动态转储的，还需要同时装入转储开始时刻的日志文件副本，利用恢复系统故障的方法将数据库恢复到某个一致性状态
如果有后续的增量转储，按照从前往后的顺序，根据增量转储来修改数据库
装入转储结束后的日志文件副本，重做已完成的事务

首先反向扫描日志文件，找出故障发生时已经提交的事务，将事务标识符写入redo-list
然后正向扫描日志文件，对redo-list中的所有事务进行redo操作



]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库安全</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%9316-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%89%E5%85%A8/</url>
    <content><![CDATA[概念
数据共享必然带来数据安全问题，我们认为只允许有合法使用权限的用户允许访问他存取的数据；
数据库系统的安全保护措施是否有效是数据库系统主要的指标，数据库的安全性和计算机系统的安全是紧密联系、互相支持的；
数据库可能的破坏方式

数据库被无意破坏

并发存取引起的数据异常
数据分布存储的不一致问题
逻辑错误造成更新事务未遵守数据一致原则
事务处理中系统崩溃


数据库被恶意破坏

未经授权的读取，修改和破坏数据



对策：

针对无意破坏：完整性约束控制，并发控制，数据库恢复
针对恶意破坏：数据库访问控制，身份鉴定，安全审计，数据加密

数据库安全性：保护数据库，防止因为用户非法使用造成数据的泄露，破坏或更改；
数据的保密：用户合法访问到机密数据后能否保证不泄密，需要指定法律等规则保证；
计算机系统安全性：

保护系统中的硬件，软件和数据，防止因为偶然或恶意的原因使得系统被破坏，数据更改或泄露；
需要建立立体防御：进不来、看不见、看不懂、改不掉、跑不了
可能包括三类安全性问题：技术安全，管理安全和政策法律

数据库系统的安全框架：

网络系统层次

物理层面上避免入侵者进行物理破坏；
网络层面上采用防火墙、入侵检测技术等手段阻止外部入侵。


操作系统层次

操作系统安全策略、安全管理策略和数据安全


数据库系统层次

用户标识和鉴别、存取控制、数据分级、视图机制、审计、数据加密



自主访问控制
概念
主体(Subject): 提出访问资源具体请求，是某一操作动作的发起者, 可能是某一用户，也可以是用户启动的进程、服务和设备等
客体(Object): 被访问资源的实体，所有可以被操作的信息、资源、对象都可以是客体, 可以是信息、文件、记录等集合体，也可以是网络上硬件设施
控制策略(Attribution):主体对客体的相关访问规则集合，即属性集合, 访问策略体现了一种授权行为，也是客体对主体某些操作行为的默认
自主访问控制的特点：

控制方式是自主的

由客体的属主对自己的客体进行管理
由属主自己决定是否将自己的客体访问权或部分访问权授予其他主体
在自主访问控制下，用户可以按自己的意愿，有选择地与其他用户共享他的文件


可以在主体之间相互转让权限的访问控制

对用户访问数据库中各种资源（包括表、视图、程序等）的权利（包括创建、查询 、更新、执行等）的控制
一个用户建立了一个数据对象就自动具有了对这个数据对象的所有权利
同一用户对于不同的数据对象有不同的存取权限，不同的用户对同一对象也有不同的权限，用户还可将其拥有的存取权限转授给其他用户


C2级，灵活

权限

访问数据权限

SELECT:允许读取数据，不能修改数据
INSERT：允许插入新数据，不能修改已有数据
UPDATE：允许修改数据，不能删除数据
DELETE：允许删除数据


修改模式权限

INDEX：允许建立/删除索引
CREATE：允许建立表
ALTER：允许对表属性增加删除
DROP：允许删除表


其他

CONNECT: 允许连接数据库
REFERENCE:允许根据表的完整性约束中引用一个参照关系
USAGE: 授权用户使用指定域
TRIGGER：授权用户定义表中触发器
EXECUTE：授权用户执行函数/过程
UNDER：授权用户建立类的子类



授权
赋予用户一定权利，已操作数据对象

对象创建者自动拥有其所有权限
授权可由DBA授予，也可以由对象创建者授予

语法如下：
GRANT &#123;all privileges|privilege&#123;. privilege….&#125;&#125; ON [TABLE] tablename|viewname TO [PUBLIC|user_name&#123;,user_name…&#125;] [WITH GRANT OPTION]
授权的粒度：用于指定可以操作的数据对象的范围

关系数据库中的数据对象粒度：数据库/表/属性列/行
它是衡量授权机制是否灵活的一个重要指标
授权定义中数据对象的粒度越细，即可以定义的数据对象的范围越小，授权子系统就越灵活 ，但系统定义与检查权限的开销会相应增大
能否提供与数据值有关的授权反映了授权子系统精巧程度

视图授权

对视图也应可以授权
要授予其他用户与访问视图相关的权利，授权者必须拥有该视图（而且在视图所引用基本表或视图上有必要的权限）或已经通过WITH GRANT  OPTION被授予了这些权限
若要在一个视图上授予插入、删除或更新权限，视图必须是可更新的
用户要建立视图，首先必须要有对所引用基本表或视图的SELECT权利

收回权限
从一个用户那里收回权限可能导致其他用户也失去该权限。这一行为称为级联回收 CASCADE。在大多数数据库系统中，级联回收是默认行为。
语法如下：
REVOKE [WITH GRANT OPTION FOR]&#123;ALL PRIVILEGES|privilege&#123;. Privilege….&#125;&#125; ON [TABLE] tablename|viewname FROM [PUBLIC|user_name&#123;,user_name…&#125;] [RESTRICT|CASCADE]
示例：
GRANT SELECT ON RecipeDetail TO LiXia；GRANT SELECT ON RecipeMaster TO LiXia WITH GRANT OPTION；GRANT UPDATE（Mprice） ON Medicine TO WangHao；GRANT REFERENCE（Mno）ON Medicine TO ZhangYang；GRANT INSERT，DELETE ON RecipeDetail TO MengFan WITH GRANT OPTION；REVOKE SELECT ON RecipeDetail FROM LiXia；REVOKE UPDATE（Mprice）ON Medicine FROM WangHao；REVOKE GRANT OPTION FOR SELECT ON RecipeMaster FROM LiXia；REVOKE SELECT ON RecipeMaster FROM LiXia RESTRICT；
授权图
用授权图来表示授权在用户之间的传递，图中的结点表示用户，如果用户将权限传递给了，则在图中增加一条 边。图的根是DBA 或对象创建者
用户具有授权当且仅当存在从授权图的根到代表该用户的结点的路径;
上述示例的授权图和收回权限图如下：

授权方法
RBAC方法：基于角色的授权
根据管理中相对稳定的职权和责任来划分角色

将访问许可权分配给一定的角色
用户通过饰演不同的角色获得访问许可权。

角色可以看作是一组操作的集合，不同的角色具有不同的操作集。
角色是访问控制中访问主体和受控对象之间的一座桥梁（授权模板）；
角色与用户关系：一个用户可经授权而拥有多个角色，一个角色可有多个用户组成 ；
角色与许可关系：每个角色拥有多种许可，每个许可也可以授权给多个不同的角色，每个操作可施加与多个客体，每个客体可接受多个操作；
例如


创建角色CREATE ROLE Admin;


角色授权GRANT SELECT ON RecipeMaster TO Admin;


角色授权给用户或其他角色：
GRANT Admin TO LiXia; CREATE ROLE Manager; GRANT Admin to Manager; GRANT Manager TO WangHao;


强制访问控制
MAC的特征：

对所有主体（系统中的活动实体，如用户）及其所控制的客体（如进程、文件、基 表、视图等）实施强制访问控制
B1级，严格
每一个数据对象被标以一定的密级，每一个用户也被授予某一个级别的许可证，对 于任意一个对象，只有具有合法许可证的用户才可以存取

敏感度标记（Label）

对于主体和客体，DBMS为它们每个实例（值）指派一个敏感度标记
敏感度标记级别：绝密，机密，可信，公开
主体的敏感度标记称为许可证级别，客体的敏感度标记称为密级
MAC机制就是通过对比主体的Label和客体的Label，最终确定主体是否能够存取客体

强制存取控制规则

仅当主体的许可证级别大于或等于客体的密级时，该主体才能读取相应的客体
仅当主体的许可证级别小于或等于客体ee的密级时，该主体才能写相应的客体

DAC与MAC共同构成DBMS的安全机制

先进行DAC检查，通过DAC检查的数据对象再由系统进行MAC检查
只有通过MAC检查的数据对象方可存取。

审计
审计是一种事后追责手段，体现在以下操作：

启用一个专用的审计日志（Audit Log），将用户对数据库的所有操作记录在上面
DBA可以利用审计日志中的追踪信息，找出非法存取数据的人
C2以上安全级别的DBMS必须具有审计功能，体现“跑不了”

审计负荷：

审计很费时间和空间
DBA可以根据应用对安全性的要求，灵活地打开或关闭审计功能 ，执行SET AUDIT ON/OFF

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>数据模型</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%932-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[概念
数据模型用来抽象、表示和处理现实世界的数据和信息；
数据模型就是现实世界的模拟：

真实地模拟现实世界；
能为人工所理解；
易于在计算机实现；

现实世界中的客观对象抽象为概念，把概念模型转换为某一DBMS支持的数据模型，概念模型是现实世界到机器世界的一个中间层次；
层次

概念模型CDM

面向现实世界建模
主要用来描述现实世界的概念化结构，与具体的DBMS无关；
常用E-R模型表达


逻辑模型LDM

面向用户建模
是具体的DBMS所支持的数据模型（网状/层次/关系/面向对象）


物理模型PDM

面向具体的DBMS，也面向机器
描述数据在存储介质上的组织结构



三要素

数据结构

与数据类型、内容、性质有关的对象，如关系模型中的域、属性、关系等
与数据之间联系有关的对象
数据结构是对系统静态特征的描述


数据操作

数据操作是指对数据库中各种对象的实例允许执行的操作的集合，包括操作及有关的操作规则
数据库主要有检索和更新（插入、删除、修改）两大类操作
数据模型必须定义这些操作的含义、符号、规则及实现操作的语言
数据操作是对系统动态特性的描述


数据的约束条件

数据的约束条件是一组完整性规则的集合。
完整性规则是指给定的数据模型中的数据及其联系所具有的制约和依存规则，以保证数据的正确、有效、相容。
提供定义完整性约束条件的机制



类型

层次模型：用树来表示实体和实体间的联系；
网状模型：一个联系可以被称为一个系，每个系至少由两种记录类型组成：一种等同于层次模型中父节点的首记录另一种等同于层次模型中子节点的属记录
关系模型：关系模型是目前应用最广泛的数据模型，采用关系模型作为数据的组织方式，常用表描述；
半结构化模型：包括XML模型，
键值对型：如Redis；
文档型：如MongoDB；
列存：如Habse；
图型：如NEO4J；

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库体系和结构</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%933-%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BD%93%E7%B3%BB%E5%92%8C%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[数据库架构
数据库架构的演变有两种趋势：

单机架构--多机架构
集中式--共享存储


单机架构
优点：部署简单，容易实现一致性；
缺点：拓展性差，系统故障导致数据丢失；

主备架构
优点：数据可靠性增强；
缺点：数据开销大，IO性能瓶颈；

主从架构
优点：IO性能提高
缺点：存储开销大，数据同步开销大

多主架构
优点：部署简单，容易实现事务一致性；
缺点：拓展性差，系统故障导致数据丢失；

Share-Nothing
优点：良好水平拓展，数据多副本存储，无需共享存储
缺点：计算和存储能力同时拓展灵活不足，分布式查询，分布式事务开销大；

Shared-Disk
优点：兼容性好，容易垂直拓展；
缺点：节点拓展能力受存储限制，及IO依赖共享存储设备；

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>数据模式</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%934-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[模式(Schema)

数据库逻辑结构和特征的描述
反映的是数据结构及其联系
模式是相对稳定的

实例(Instance)

模式的一个具体值
反应数据库的某一时刻的状态
实例随数据的更新而变动
同一模式可以有很多实例

三级模式
模式


数据库中全体数据的逻辑结构和特征的描述,所有用户的公共数据视图，综合了所有用户的需求


数据在数据库内部的表示方式

记录的存储方式（顺序，b树，hash）
索引的组织方式
数据是否压缩存储
数据是否加密
数据存储记录结构的规定



地位：一个数据库只有一个模式，是数据库系统模式结构的中间层

与数据的物理存储细节与硬件环境无关
与具体的应用程序，开发工具和高级语言无关



定义：数据库逻辑结构；

数据项的名字，类型，取值范围；
表结构的定义
数据的联系，数据有关的安全性，完整性要求



DBMS提供数据定义语言DDL来描述逻辑模式


外模式


数据库用户使用的局部数据的逻辑结构和特征的描述

模式的子集，与某一应用的数据的逻辑表示
不同用户的外模式可以不同
sql定义的视图



地位：介于模式和应用之间


模式与外模式：一对多，一个数据库可以有多个外模式，对模式中同一数据，在外模式中结构，类型，长度都可以不同


内模式

是数据物理结构和存储方式的描述

一个数据库只有一个内模式
是数据在数据库内部的表示方式


举例：存储方式，索引的组织方式，是否压缩存储，是否加密，数据存储记录结构的规定

模式/模式映射

定义外模式与模式之间的对应关系
每个外模式对应一个外模式/模式映射
保证数据的逻辑独立性，外部模式不受概念模式的变化影响；

模式/内模式映射

模式/内模式映射定义了数据全局逻辑结构与存储之间的对应关系
数据库中模式/内模式映射是唯一的
保证了数据的物理独立性

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>关系模式</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%935-%E5%85%B3%E7%B3%BB%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[关系数据模型

关系实例

关系实例由命名的若干列和行的表
行也称为元组
元组的数目成为基数
列一般需要命名


关系模式

关系名R，属性列表U，域D，属性到域的映射DOM，属性约束F
可以用五元组表示，也可以简单地用三元组，二元组表示；
关系必须是规范化的

1NF：关系的每个分量必须是不可分的（不允许表中有表）；
2NF，3NF，BCNF：更高级的设计模式




优点：理论严格，线性结构简单，数据独立性，安全性和完整性；
缺点：对现实世界表达能力弱，存取对用户透明，查询效率不如NoSQL，只有固定的操作集，不能很好地支持商业规则；

关系数据库
关系数据库是 关系的有限集合；

数据库模式：关系模式的集合；
数据库实例：对应关系实例的集合；

关系：


关系是笛卡尔积的一个有意义的子集，有对应的关系名；


一个关系是一张 没有重复行，重复列 的二维表；

实体本身的数据；
实体之间的联系；



元组： 表中的一行，表示一个实体
属性：表中的一列，有属性名
域：属性的取值范围
分量：元组中的属性值


以下是有关术语理论和实践不同的表述：



理论
实现




关系
表


元组
记录


属性
字段


分量
单元格



关系的三要素

数据结构
关系操作
数据约束

数据结构

键

唯一区分不同元组的属性；
又称关键字，码；


候选键

在关系中能唯一区分确定不同元组的属性；
包括在候选键的属性称为主属性；
不包括在候选键的属性称为非主属性；


主键

当多个候选键存在时，选定一个作为主键；
每个关系中，主键是唯一的；


外键

在关系中并非键，但在另一个关系中的主键；



关系操作
关系的操作：集合操作，包括查询，投影，连接，除，并，交，差
数据约束
关系的完整性规则：对关系的某种约束条件，保证数据库值的数据的正确性和一致性；

实体完整性：主键非空；
参照完整性：外键要么为空值，要么来自于被参照关系表中的某个原则的主键值；
用户定义的完整性：各种商业规则

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>关系代数理论</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%936-%E5%85%B3%E7%B3%BB%E4%BB%A3%E6%95%B0%E7%90%86%E8%AE%BA/</url>
    <content><![CDATA[概述
域（Domain）：由属性构成，是属性的所有取值，一组具有相同数据类型的值的集合；
关系：是域作笛卡尔积后的，有一定意义的，有限的子集；

关系名，应该和其他关系不重名；
单元格包含一个原子值；
同一关系中属性不同名
统一属性的值取自相同的域；
不应该有重复原则；
属性的顺序并不重要；
元组的顺序一般也不重要；

关系是一张二维表，每一行对应一个元组，每个列对应一个属性域；
集合运算
关系和关系运算符组合的有意义的表达式；
一次一关系：

关系运算操作数：关系
关系运算结果：关系
这说明关系运算是一个闭包；

关系名
最简单的表达式：(关系名，表示拷贝)
并
至少在两个关系出现一次的元组集合

相容性：

一般指有相同的数据结构（属性要同名）
广义上，对应属性来自相同的域，两个关系的属性数量相同；
语义一致


差
属于但不属于的元组集合

差运算也要求相容性；

交
既属于又属于的元组集合

注意交集可以用差集表示出来：


笛卡尔积
属性求全集的操作，关系是笛卡尔积的子集


选择
从关系中找出满足给定条件的所有元组称为选择

从行的角度进行的运算，即水平方向抽取元组
经过选择运算得到的结果可以形成新的关系，其关系模式不变，是原
关系的一个子集


垂直方向规模变小

投影
从关系中挑选若干属性组成的新的关系

从列的角度进行的运算，即垂直方向抽取元组
投影的结果中要去掉相同的行


水平方向规模变小；
投影的结果需要自动去重，因此垂直方向也有可能变少；

条件连接（57f6bde9-9939-4687-bd5b-d548d0b52389连接）
任何一个连接可以用笛卡尔积和选择关系来表示；
记为比较运算符，为等号时称为等值连接，为上度数相等且可比较的属性列：

自然连接：从广义的笛卡尔积选取相同属性列上取值相等的元组，去掉重复行：

自然连接中相等的分量必须时相同的属性组；
先计算笛卡尔积，选择同时出现在和中相等的元组，去掉所有重复属性；

自然连接和等值连接的区别：

自然连接是某种特殊的等值连接；
两个关系中进行比较的分量必须是相同的属性组；
结果重复列去掉；

外连接
左外连接
左外连接(left outer join):左外连接返回左表中的所有记录，以及右表中满足连接条件的记录。
如果右表中没有满足条件的记录，结果会包括左表中的记录，右表的对应字段值为 null

右外连接
右外连接(right outer join):右外连接返回右表中的所有记录，以及左表中满足连接条件的记录。
如果左表中没有满足条件的记录，结果会包括右表中的记录，左表的对应字段值为 null

全外连接
全外连接(full outer join):返回左表和右表中的所有记录，以及左右表中满足连接条件的记录。
如果左表或右表中没有满足条件的记录，结果会包括表中未匹配的记录，对应另一表的字段值为 NULL
⟗
重命名运算
对模式名和属性名重命名：

特殊的，对模式重命名和对属性名如下：
，
重命名运算符的作用：

统一集合运算两端的关系模式
自连接

除法
象集：给定关系，为属性组，当时，在中的象集(Image Set)如下：

象集表示中属性组上值为的各个元组在分量上的集合；
除法：
给定关系，其中


为属性组；


中出自相同的域；


,其中满足中满足下列条件的元组在上的 投影



查询优化
关系数据库管理系统首先将用户的 ＳＱＬ语句转换为等价的关系代数表达式，然后利用系统信息和上面介绍的运算律进
行优化；
若选择运算与广义笛卡儿积满足交换律，则选择运算应该尽可能最先执行，因为选择运算减少了数据，而笛卡儿积应尽可能后执行，因为广义笛卡儿积会产生大量的组合数据．
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库设计</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%937-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[数据库设计
数据库设计：根据用户需求研制数据库结构的过程

数据库结构设计：针对给定的应用环境，进行数据库的模式和子模式设计，包括概念设计，逻辑设计和物理设计，属于静态模型设计
数据库行为设计：确定数据库用户的行为和动作，属于动态模型设计

设计方法：直观设计，New orleans方法，基于实体-关系的方法，3NF设计方法，面向对象的方法（ODL），辅助软件CASE...
设计过程

需求分析：明确系统需要完成的任务
概念设计：将现实世界抽象地理解和表达
逻辑设计：概念模型转换具体的数据模型
物理设计:逻辑模型转化为确定的物理存储结构
实现阶段:进行数据库的构建工作，包括数据库的应 用程序开发和调试，数据的录入
运行和维护阶段:数据进行备份和维护，以保证数据库系统的效率

概念设计
概念模型：生成能准确反映用户组织和实用信息需求的抽象信息结构

真实充分地反映现实世界
易于理解更改和转换
描述概念模型最常用的工具：实体-关系模型；
易于转换成关系、网状、层次等各种数据模型

概念数据模型

面向用户、面向客观世界的模型
用来描述现实世界的概念化结构，与具体DBMS无关
概念数据模型必须转换成逻辑数据模型才能在DBMS中实现

E-R图
ER图是一种面向问题的概念模型，只关心现实世界的事物，特征和联系，用简单的图形方式描述显示世界的数据

实体：用 矩形框 表示
联系：一个或多个实体之间的关联关系，用菱形表示 ，用无向边连接
属性：用椭圆表示，现实世界的事物尽量看作属性，属性不能有需要描述的性质，不能与其他实体具有联系；

数量关系表示

一对一联系：对于实体A中的每一个实体，实体B中至多有一个实体与之联系，反之亦然；

完全一对一：,严格的对应关系；
不完全一对一：


一对多联系：对于实体A中的每一个实体，实体B中有多个实体与之联系，对于实体B中的每一个实体，实体A中至多有一个实体与之联系；
多对多联系：对于实体A中的每一个实体，实体B中有多个实体与之联系，反之亦然

属性分类


简单属性/复合属性


单值属性/多值属性：多值属性用双椭圆表示，一般需要转化成弱实体，用双线矩形表示，其联系用双菱形框表示


派生属性：通过具有相互依赖的属性推导出来的属性称为派生属性，用虚线椭圆形与实体相连


空值属性


设计方法

自顶向下：采用总分方式将大的概念模式逐步分解为更详细的较小划分模式
逐步扩张：逐步扩张 采用了层状扩展的方式，先定义出用户需求中核心的概念结构，然后在此基础上向 外扩展，逐步将非核心的需求融入到模式中，最终完成系统的概念结构设计
自底向上：首先构建起局部概念模式，然后再向上组合成全局模式
数据抽象：对需求分析阶段收集到的数据进行分类、组织，确定实体，实体的属性和联系数量关系

分类：定义某一类概念作为现实世界的彝族对象的类型，抽象了对象值和型之间的语义
聚集：定义了某一类型的组成成分，抽象了对象内部类型和成分的语义
概括/继承：定义类型之间的某一子集联系，抽象了类型之间的语义



ER图绘制步骤


选择局部应用


逐一设计分ER图


集成分图，进行合并和修改；

：实体在不同层抽象成不同的类型，不同的ER图联系数量关系不同



逻辑设计

逻辑设计依赖于实现的DBMS基础
逻辑设计的任务是为了概念结构设计阶段生成的全局ER图转换成特定DBMS支持的数据模型

ER模式向关系模型的转换

实体联系和属性转换成关系的集合表示
实体-关系模式，实体属性-关系属性，关系的键-实体的键
联系相连的实体的键转换成关系模式的最佳实践：

1:1的联系：与任意一端的关系模式合并
1:n的联系：既可以独立，也可以和n端合并
m:n的联系：转换成一个关系模式，需要识别外码
在ER图中，用下划线表示主码，波浪线表示外码



模式优化
用关系理论规范化理论对关系数据模型进行优化

确定范式的使用
实现规范化
反范式设计

物理设计

存储结构的设计：数据存放的位置，确定系统的配置
存取方法的设计：

聚簇：节省存储空间，提高查询速度
索引：提高检索速度，避免重复值的记录，保证数据完整性
基于HASH：计算Hash值获得存取地址



]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库范式</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%938-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%8C%83%E5%BC%8F/</url>
    <content><![CDATA[数学表示
关系模式的五元组表示：

：关系名
：组成该关系的属性名集合
：属性组U中属性所来自的域
：属性向域的映象集合
：属性间数据的依赖关系集

对于一个简化的关系模式三元组表示：

数据依赖是现实世界属性相互联系的抽象
数据依赖是数据内在的性质
数据依赖是寓意的体现
规范化解决的问题是如何构造合适的关系模式

设计好的模式：大模式的分解，信息完整
模式的分解：自动化，模式设计包含所有信息，按照一定规则分解的小模式没有数据冗余和更新异常
数据依赖

函数依赖FD：一个关系表中属性之间的联系
多值依赖MVD：关系中属性之间在语义上的关联特性

函数依赖
对于关系模式,,设是关系中的任意两个元组；
称函数依赖于,称为决定因子，称为依赖因子，若,则;

对于,这种情况视为平凡函数依赖
由于不反映新的寓意，所以函数依赖一般指非平凡的；

完全依赖/部分依赖
对于是关系的不同属性集，满足；
若,称完全函数依赖于,否则称为部分依赖
传递依赖
对于是关系的三个不同的属性集
若,有, 称传递依赖于

某一个属性列唯一，那么这个属性可以决定其他属性
这个属性的任意超集也可以决定其他属性

逻辑蕴含
对于关系上的依赖集
若在上也成立，称逻辑蕴含,记为
也就是说，一个函数依赖可以由其他函数推出，那么这个函数依赖被视为多余的；
对于函数依赖的闭包，定义为


这个集合定义了由给定函数依赖集能够推导出所有的函数依赖
根据一直的函数依赖集，推导出其他函数依赖的规则称为推理规则
由已知函数依赖集推导闭包是NPC问题；

Armstrong公理
闭包中的函数依赖可以通过三个关系找出，这样的推导是正确且完备的，不过从找到对应的闭包是一个NPC问题；

自反性：
增广性：
传递性：
合并性：
伪传递性：
分解性：
复合性：
通用一致性：

属性集闭包
定义以下的属性集闭包：

属性集的闭包是P问题；能使用Armstrong规则推导出的充分必要条件为;
属性集闭包算法：
X_clo := Xdo&#123;	if A→B,A⊆X+		X+ = X+ ⋃ B&#125;while(X+ changes)
最小依赖集
函数依赖集逻辑等价记作；
是的两个函数依赖集，若,称是等价的函数依赖集；
最小依赖集定义如下：

;
每个函数依赖的右边是单属性；
没有冗余的函数依赖；
每个函数依赖左边没有冗余的属性

最小依赖集算法：

计算等价的，要求的每个依赖集右边为单属性；
消除中每个函数依赖左边的冗余属性
消除中的冗余的函数依赖

候选码
若为中的属性或者属性结合，若,则为的候选码；
若候选码多于一个，可选定一个当作主码(primary key)

单个属性是码，称为单码
整个属性组是码，称为全码

模式分解
函数依赖可以引起的数据冗余和更新异常等问题，需要对关系模式进行分解
关系模式的分解就是用两个或两个以上关系来替换，分解后的关系模式的属性集都是中属性的子集，其并集与的属性集相同
具体来说，对属性集,关系模式,若用一组关系模式的集合来取代,则称此关系模式的的一个分解，记作
关系模式分解的两个特性实际上涉及两个数据库模式的等价问题

数据等价是指两个数据库实例应表示同样的信息内容，如果是无损分解，那么对关系反复的投影和连接都不会丢失信息；
依赖等价是指两个数据库模式应有相同的依赖集闭包。在依赖集闭包相等 情况下，数据的语义是不会出错的

保持依赖
设是的一个分解；是的一个FD集；
如果

称分解保持函数依赖集
无损分解
对于关系模式,其一个函数依赖集为,其一个模式分解为,
若对于中满足的每一个关系，均有

则称分解是相对于依赖集的一个无损连接分解，否则则是有损分解；
利用Chase算法将关系模式一分为二，判断是否为无损分解；
设是关系模式的一个分解，则是无损分解的充分必要条件为以下关系满足其一即可

模式分解能消除数据冗余和操作异常现象， 分解以后，检索需要作笛卡尔集或连接操作，带来时间开销，为了消除冗余和异常，对模式的分解是值得的；
范式
范式是关系的状态，也是衡量关系模式的好坏的标准，一个规范化的方式有最小的数据冗余
除了与援助进行连接的外键之外，数据库实例中的其他属性值不能被复制
1NF
在每个关系模式每个属性值都是不可再分的原子值；1NF是关系模式应具有的最起码条件；
换言之，1NF要求不存在表中之表；

2NF
在1NF的基础上，消除了部分依赖导致的冗余和操作异常，2NF是通往更高范式的中间步骤，它消除了1NF存在的部分问题,但仍可能出现冗余和异常；
如果关系模式且每个非主属性完全依赖于候选码，称满足2NF；

以下简单情况必定满足2NF

R的码是单码
R的码是全码
R是二元关系

2NF分解算法：


对于关系模式，主键为，上存在函数依赖，其中是非主属性，
则是部分依赖，进行分解

,主键为
，主键为，外键为



若仍然不是2NF，重复上述分解过程


3NF
若关系模式，而且每个非主属性都不传递依赖于的候选码，称属于3NF；
定理：若是3NF，必有是2NF
证明：对于关系模式，主键为，若存在部分依赖,意味着R上存在函数依赖，其中是非主属性，，可以看成,这样特殊的传递依赖;
以下的简单情形必定满足3NF;

关系模式是全码；
所有二元关系；

3NF分解算法：


对关系模式，主键为，上存在FD：,其中非属性，不是候选键, 说明是传递依赖，进行如下分解


，主键为


，主键为，外键为




若不是3NF，继续进行如上分解


分解的原则应该从传递依赖链的尾部开始；
BCNF
BCNF，也称修正3NF，若关系模式R是1NF，而且每个属性都不传递依赖于R的候选码，那么称R是BCNF；

非主属性对每一个码都是完全函数依赖；
非主属性对不包含它的码也是完全函数依赖；
没有任何属性完全依赖于非码的任何一组属性；

关系为单码，并且已经是3NF，那么关系一定是BCNF；
BCNF分解算法

对于关系模式R，R上成立的函数依赖集F，找到最小依赖集；
将最小依赖集中左部相同的FD用合并性合并，
对最小依赖集中的每个FD 构成模式
对于生成的模式集中，若每个模式不包含R的候选码，此时将候选码作为一个模式放入模式集中

不过这样的分解可能是有损的，违背了我们分解的初衷；
反范式
提高查询效率，采用空间换时间的实现思路；

存在频繁查询时，可以容忍适当的冗余设计，目的是减少多表关联 查询，提高效率
有些信息频繁变动，需要保存历史信息反范式化一定要适度，并且在原本已满足三范式的基础上再做调整的

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL基础</title>
    <url>/2025/07/02/%E6%95%B0%E6%8D%AE%E5%BA%939-SQL%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[特点

高度统一：集DDL，DML，DCL于一体
高度非过程化：只需要提出做什么，无需声明怎么做
面向集合的操作：操作的对象和结果均为集合
两种使用方法：自主式使用（CLI，GUI），嵌入式语言

核心命令

DDL：CREATE DROP ALERT
DML:  SELECT INSERT UPDATE DELETE
DCL:   GRANT REVOKE

数据类型



数据类型
声明




数字
NUMERIC，DECIMAL， INTERGER，SMALLINT，FLOAT，DOUBLE，REAL


字符串
CHAR， VARCHAR， TEXT


二进制串
BINARY，VARBINARY，BLOB


布尔类型
BOOLEAN


日期时间
DATE，TIME，DATETIME，TIMESTAMP


时间间隔
INTERVAL


XML文本
XML



聚集函数
聚集函数可以直接对查询结果进行统计
但是只能出现在SELECT的后面，而且只会返回一个元组



函数
返回值




CHAR_LENGTH(string)
字符串长度


LOWER(string)
字符串全部转换为小写


UPPER(string)
字符串全部转换为大写


SUBSTRING(source, n, len)
取长度为len的子串


MAX(column)
制定列的最大值


MIN(column)
制定列的最小值


AVG(column)
制定列的平均值


SUM(column)
制定列的总和


CURRENT_DATE()
当前日期


COUNT(*)
计算总行数


COUNT(EXP)
计算非空行数



与关系代数的联系



关系运算符
SQL关键字




选择
WHERE


投影
SELECT


笛卡尔积
FROM



数据查询
关键字



类型
命令




无条件查询
SELECT... FROM


条件查询
SELECT...FROM...WHERE


列的别名
... AS ...


带表达式的查询
SELECT 


字符串匹配
LIKE


结果去重
DISTINCT


结果排序
ORDER BY



无条件查询
SQL语句：SELECT &lt;字段列表&gt; FROM &lt;表名&gt;
可以用*表示所有列名；
例如查询所有医生的信息：
SELECT * FROM Doctor;
结果如下：

条件查询
SQL语句：SELECT &lt;字段列表&gt; FROM &lt;表名&gt; WHERE &lt;查询条件&gt;
条件之间的连接可以使用以下的连接运算符：

例如：查询年龄小于或等于40岁的男医生信息
SELECT *  FROM  Doctor  WHERE Dsex=&#x27;男&#x27; AND Dage&lt;=40 ;
结果如下：

列的别名
改变查询显示列的标题，用关键字AS,跟在SELECT的属性后面；
SQL语句：SELECT &lt;字段1&gt; AS &lt;别名1&gt;,..., &lt;字段吗&gt; AS &lt;别名m&gt; FROM &lt;表名&gt;
例：查询医生姓名和职称并重命名
SELECT Dname AS 医生姓名, Dlevel 专业职称 FROM Doctor;
结果如下：

查询表达式
查询条件可以用表达式表示
例：在药品信息表中，查询药品单价提高15%后超过30元的药品信息
SELECT Mno 编号，Mname 药品名，Mprice 单价，Mprice*1.15 调整单价 FROM medicine  WHERE Mprice*1.15&gt;=30;
字符串匹配
字符串的模式匹配：正则表达式支持

%:表示任意长度（包括长度为0）的字符串
_：表示任意单个字符

例如：查询职称为副某的医生信息
SELECT *  From Doctor  Where Dlevel Like &#x27;副%&#x27;;
结果去重
使用DISTINCT合并查询结果的重复记录
例如：查询部门编号
SELECT DISTINCT Ddeptno FROM Doctor; 
结果排序
使用ORDER BY

系统缺省为升序排序ASC
也可以设定为降序DESC

例如：按部门编号升序而按年龄降序查询医生信息
SELECT * From Doctor  ORDER BY Ddeptno ASC ,Dage DESC ;
统计查询
统计查询是通过聚集函数实现的；它可以对查询结果直接进行统计；

聚集函数一般忽略空值；
选项DISTINCT表示只计算不同的记录值，不计入重复值和空行；
一次聚集函数返回一条记录

分组查询：使用GROUP BY，对所查询的表按字段进行分组，值相同的在一组，和聚集函数一起使用，聚集函数对每一组产生一个统计结果
分组筛选:使用HAVING子句，选出复合条件的统计分组，放在GROUPBY子句后
例如：
查询申请了计算机专业总申请数量
查询各个专业总申请数量;
计算机专业申请者数量大于等于2的高校；
SELECT COUNT(*) FROM Apply WHERE Major=&#x27;计算机&#x27;;SELECT COUNT(*)  FROM Apply  sID cID GROUP BY major;SELECT cID, COUNT(DISTINCT sID) FROM Apply WHERE Major=&#x27;计算机&#x27; GROUP BY cID HAVING COUNT(DISTINCT sID) &gt;=2;
连接查询
连接满足查询条件或结果来自多个表；
连接同名之短时需要消除歧义；
连接条件的不同特点：等值连接，非等值连接，自然连接，自连接
内连接
找出符合条件的共有记录，

FROM R1, R2 WHERE R1.A1 &lt;比较运算符&gt; R2.A2
FROM R1 INNER JOIN R2 ON + R1.A1 &lt;比较运算&gt; R2.A2
FROM R1 INNER JOIN R2 USING(A1)

等值连接
例如：
在医生基本信息表中，需要查询患者的每个处方用药信息;
SELECT RecipeDetail.* Medicine.* FROM RecipeDetail, Medicine WHERE RecipeDetail.Mno=Medicine.Mno;
自然连接
要求连接列的列名相同，并且查询结果列不重复 NATURE JOIN
例如：在医院信息数据库中，需要查询开出处方的医生信息。
SELECT Rno,Pno,Dno,Dname,Dsex,Dage,Ddeptno,DlevelFROM RecipeMaster R NATUAL JOIN Doctor D FROM RecipeMaster R NATUAL JOIN Doctor DSELECT Rno,Pno,D.Dno,Dname,Dsex,Dage,Ddeptno,Dlevel 
自连接
支持表自身的连接,即同一张表的两个副本之间的连接
例如：在医院部门表中，需要医院的各部门名称和上级部门名称
SELECT First.DeptName 部门名称,Second.DeptName 上级部门FROM Dept First ,Dept SecondWHERE First.ParentDeptNo=Second.DeptNo
外连接
左外连接：LEFT OUTER JOIN
右外连接：RIGHT OUTER JOIN
全外连接：FULL OUTER JOIN
不一定所有数据库支持外连接；
嵌套查询
在一个查询语句中包含另一个完整的查询语句；
外层的查询：父查询
内层的查询：子查询
子查询的结果作为主查询条件的一部分；

不相关子查询：子查询条件不依赖于主查询，独立执行，顺序从内至外；
相关子查询：子查询依赖于主查询，子查询需要引用主查询的表
例如：

SELECT sID,sName，GPAFROM Student NATURAL JOIN ApplyWHERE cID=‘10614’AND GPA&gt;（SELECT AVG(GPA)FROM Student NATURAL JOIN Apply WHERE cID=‘10614’）;SELECT sID,sName，GPAFROM Student NATURAL JOIN Apply AWHERE AND GPA&gt;（SELECT AVG(GPA)FROM Student NATURAL JOIN Apply B WHERE A.cID=B.cID）;
子查询结果是一个关系，可以利用集合运算符

IN/NOT IN: 测试一个元素是否属于一个集合
EXISTS/NOT EXISTS：测试一个集合是否为空
关键字在父查询的FROM子后

SELECT sName FROM Student WHERE sIDIN( SELECT sID FROM ApplyWHERE major=‘计算机’);SELECT sName FROM Student S1WHERE NOT EXISTS( SELECT * FROM Student S2WHERE S2.GPA&gt;S1.GPA);
谓词

与集合所有元素比较ALL
例如GPA最高的学生姓名SELECT sName FROM Student WHERE GPD &gt;= ALL (SELECT GPA FROM Student)
与集合中任意一个元素比较
例如GPA最高的学生姓名SELECT sName FROM WHERE NOT GPA &lt; ANY (SELECT GPA FROM Student)

应该优先选择子查询而不是连接查询

查询多次带来的IO开销不可忽略
连接查询在内部有查找优化（索引+二分），性能并不是线性相乘

数据更新
插入操作
引入关键字：INSERT INTO … VALUES
格式如下

表名：指要插入数据的目标表
列名：指定表的目标列，参数省略时默认全部列
值表：具体要插入的值

INSERT INTO &lt;表名&gt; [(&lt;列名&gt;)] VALUES (&lt;值表&gt;)
增加操作
格式为

select子句中选择的列应该和列名保持对应
类型和长度兼容，列名可以不同

INSERT INTO &lt;表名&gt; [(&lt;列名&gt;)] &lt;select子句&gt;
修改操作
引入关键字UPDATE
格式为
UPDATE &lt;表名&gt; SET &lt;列1&gt;=&lt;表达式1&gt;, &lt;列2&gt;=&lt;表达式2&gt;,…[WHERE]
数据删除
引入关键字DELETE
格式为
DELETE FROM &lt;表名&gt; WHERE &lt;条件&gt;]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>数理逻辑</title>
    <url>/2025/07/05/%E6%95%B0%E7%90%86%E9%80%BB%E8%BE%91/</url>
    <content><![CDATA[命题
命题是指具有确切真值的判断语义；

原子命题：无法分解为更简单命题的命题；
复合命题：可以继续被分解的命题；

命题应该用大写的字母表示；
联结词



联结词
表示
真值




否定联结词

为真当且仅当为假


合取联结词

为真当且仅当均为真


析取联结词

为真当且仅当其一为真


蕴含联结词

为假当且仅当为真，为假


等价联结词

为真当且仅当同为真或者同为假



进一步，复合命题可以表示为原子命题和联结词的组成；
命题公式
对于一个常值命题而言，它的真值不是真就是假；
对于一个任意的，没有赋予内容的原子命题，称其为命题变量，如果它没有确切的真值，真值取决于命题的内容；
命题公式可由如下规则生成：

命题变元本身是一个公式；
若是一个公式，则也是公式；
若是一个公式，则也是公式；
联结词的使用有限次；

对于是含有命题变元的公式，记为
指定的一组真值，称这组真值是的一个解释;
分类
对于命题公式;

重言式：若的所有解释下真值为真；
矛盾式：若的所有解释下真值为假；
可满足式：至少存在一种解释,使得在下为真；

若对于两个命题公式,它们出现的命题变元为,对于个每一种解释，的真值相同，称是等价的，记作;

显然不是联结词，而是一种等价关系；
满足自反性，对称性，传递性；
当为重言式时，

对于等价关系可以暴力的使用真值表加以验证；
代入定理：
对于命题公式,对于任意的命题公式;
如果是重言式或者矛盾式，
对于也是重言式或者矛盾式；
替换定理
设Ｇ是Ｇ的子公式，Ｈ是任意的命题公式，在Ｇ中凡出现Ｇ_1，处都
以替换，由此得到新的命题公式Ｈ，若,则
范式
文字：命题变元，或者命题变元的否定；
子句：有限个文字的析取式
短语：有限个文字的合取式
析取范式：有限个短语的析取式；
合取范式：有限个短语的合取式；
主析取范式：每一个短语都是最小项；
定理：对于任意的命题公式，都存在与其等价的析取范式和合取范式；
proof:可分为如下三步逐步转化：


消去等价关系和蕴含关系



将否定移动到命题变元前面



重复利用分配律



推理理论
形式证明：

前提：已知的命题公式；
结论：从前提出发利用推理规则推出的命题公式

通过形式证明可以的出有效结论，我们不关心前提时都为真，只关注推理的真实性；
对于公式，称为的逻辑结果，当且仅当对于任意的解释，若同时满足,则满足，记作

此时称这个是有效的，
称为一组前提；
称为结论，或者逻辑结果；

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Discrete-Mathematics</tag>
      </tags>
  </entry>
  <entry>
    <title>有限自动机</title>
    <url>/2025/06/20/%E6%9C%89%E9%99%90%E8%87%AA%E5%8A%A8%E6%9C%BA/</url>
    <content><![CDATA[有限自动机
形式定义
在词法分析中，有限自动机 (Finite Automata, FA) 是识别词素模式的核心理论基础。
有限自动机可以非常高效地处理输入字符流，判断它们是否符合某个模式，比如正则语言 (Regular Languages)。
对于一个有限自动机(FA),定义如下：

字符集  :规定自动机输入的字符范围；
状态集合  :DFA有向图上的顶点；
唯一起始状态  :  ,为自动机的起点，转移到其他状态；
接受状态集合  : 满足  ;
转移函数  : 输入为当前状态和读入字符，输出为下一步状态，为DFA有向图的边；

定义自动机,若其能识别字符串,则，否则为不接受/识别；
一个NFA接受字符串，当且仅当对应的转换图存在一条从开始状态到某个接受状态的路径，路径上的标号组成该字符串；
若状态不存在对字符的转移，定义为 ,也代指无法转移中任何一个状态；
正则语言
不确定的有限自动机(NFA)对边上的标号没有任何限制，一个符号标记离开同一状态的多条边，并且空串也可以当作标号；
确定有限自动机(DFA)对每个状态和字母表的每个符号，DFA有且仅有一条离开该状态，以该符号为标号的边；
DFA和NFA能识别的语言集合是相同的，也正好是能用正则表达式描述的语言的集合，我们统称为正则语言(regular language);
子集构造技术
我们可以尝试将DFA或者NFA表示为一张转换图

结点表示状态；
带标号的边表示自动机的转换函数；同一个符号可以标记同一状态出发到达多个目标状态的多条边，一条边的标号可以是字母表的符号或者空串；

对于正则表达式(a|b)*abb，下图给出了NFA示意图和对应的状态转换表；


DFA相较于NFA，具有如下特性，区别在于转换函数：

没有输入空串的转换动作；
对于每个状态和每个输入符号，有且仅有一条标号的边离开;

下图给出了正则表达式(a|b)*abb对应的DFA；

我们可以通过子集构造(subset construction)技术，实现从NFA到DFA的转换；
对于输入的NFA，定义三类操作

closure(T)：找到状态集合通过NFA中不经过有意义的符号转换可以到达的状态集合；显然;
move(T,a)：找到T中某个状态s出发通过标号a的转换可以到达的NFA状态集合；



在上图的例子中，MOVE({0,1,2,4,7}, a)={3, 8};MOVE({6},ε) = {1,7};closure({0}) = {0,1,7,2,4}; closure({6})={6,1,7,2,4},closure({3,8})={3,8,6,1,7,2,4};

计算closure的算法如下：

算法流程如下：
输入：NFA可表示为;
输出：等价的DFA，表示为

，起初只有一个元素,，且未加标记；
两个FA的字符表相同；
;


过程如下图：

值得注意的是，该算法维护了一张表格Dtran；

最后输出的DFA如下图：

DFA构造
自动机在词法分析中的工作流程: 🚶➡️🪙

定义模式: 使用正则表达式为每种记号类型（如标识符、数字、关键字、操作符）定义模式。
构造自动机:

为每个正则表达式构造一个 NFA。
将所有 NFA 合并为一个大的 NFA（通过引入新的起始状态和到各个 NFA 起始状态的 ε-转移）。
将合并后的 NFA 转换为一个 DFA (例如，使用子集构造法)。
（可选但推荐）最小化该 DFA,指消除死状态；




DFA运行


词法分析器从 DFA 的起始状态开始。


逐个读取输入字符流中的字符。


根据当前状态和输入字符，DFA 转换到下一个状态。


如果 DFA 到达一个**接受状态 **，这意味着已经识别出一个与该接受状态关联的模式的词素。

最长匹配原则 (Longest Match Principle): 如果输入串的多个前缀都能匹配一个或多个模式，词法分析器会选择匹配最长可能词素的那个。
例如，如果 if 是关键字，iffy 是标识符，输入 iffy 时，会匹配 iffy 而不是 if。



如果 DFA 在某个点无法进行有效转换（即卡在某个非接受状态，且没有对应当前输入字符的转移），或者输入结束但未处于接受状态，则可能发生词法错误。


]]></content>
      <tags>
        <tag>Coursework</tag>
      </tags>
  </entry>
  <entry>
    <title>梯形积分公式和Simpson积分公式</title>
    <url>/2025/07/05/%E6%A2%AF%E5%BD%A2%E7%A7%AF%E5%88%86%E5%85%AC%E5%BC%8F%E5%92%8CSimpson%E7%A7%AF%E5%88%86%E5%85%AC%E5%BC%8F/</url>
    <content><![CDATA[Background
在实际工程中许多函数的原函数并不容易求出，因此对它们使用Newton-Lebniz公式是相当困难的，因此衍生出数值积分，基本思想就是对于一个黎曼可积分的函数，不断细分积分区间对小面积求和得到定积分的近似值；
但是过于细致的区间划分会导致大量资源的消耗，因此这篇文章旨在介绍一种启发式的办法来使得误差控制在我们接收范围内同时减少对计算资源的消耗；
由于对数值分析的了解还不够，不少内容只能留坑了；
启发式的策略主要有以下几种：

误差估算与细分
在自适应梯形积分中，可以利用Richardson外推或其他误差估计技术估算当前的误差。如果对某个区间的误差估计超出了预期阈值，只有这些区间会被进一步细分，从而减少不必要的计算。
局部适应性
对于有急剧变化或高度非线性的函数，使用相同数量的区间可能会导致某些部分的误差大于其他部分。在这种情况下，可以设计算法以更高的密度对这些特定区域进行采样，同时对函数较为平缓的部分进行较少的采样。同时，也应该自适应的调整步长，在函数变化剧烈的地方采用较小的步长，而在平缓区域使用较大的步长。
多步骤递增
不是一开始就使用非常高的划分数，可以从一个较小的区间数开始，并逐步增加，直到满足精确度要求，以此来优化计算时间。
停止准则的动态调整
动态调整误差阈值，可以在算法运行过程中根据已经计算的结果和剩余区间来适应性地调整。

Content
梯形积分
在matlab中有一个现成的函数可供调用：
Q=trapz(x,y)表示y在x细分下的梯形积分，注意Q求出来并不是真实精确的积分结果；
梯形公式将图像线性近似，并用线下方的梯形面积替代积分面积：


其中如果将区间细化为,那么计算结果为



用matlab实现如下：
x=linspace(0,pi,3);y=sin(x);my_trapz_res=my_trapz(x,y)trapz_res=trapz(x,y)function res=my_trapz0(f,a,b)res=(b-a)*(f(b)+f(a))/2;endfunction res=my_trapz(x,y)%x,y传入的应该是一对长度相等的向量n=length(x);res=0;for i=2:nres=res+(x(i)-x(i-1))*(y(i)+y(i-1))/2;endend
从结果上看到，和官方提供的函数并无多大区别：
my_trapz_res =    1.5708trapz_res =    1.5708
在自适应梯形积分中，可以利用Richardson外推或其他误差估计技术估算当前的误差。如果对某个区间的误差估计超出了预期阈值，只有这些区间会被进一步细分，从而减少不必要的计算。（留坑）
自适应Simpson积分公式
在Simpson积分中，将图像近似为一个二次函数,那么积分可以做如下近似：


我们也采用变步长的启发式策略：

对于一个极小的区间认为他的Simpson值加上误差容忍可以近似为积分值；
二分区间分别计算左边区间的Simpson值和右边区间的Simpson值
如果两值加起来与整个区间Simpson值差距不超过15倍得误差容忍度，就认为这个区间足够小，返回这个小区间得积分值；
否则需要继续递归，返回区间的左边积分值加上右边积分值；

matlab程序如下：
quad(@(x)sin(x),0,pi)my_quad(@(x) sin(x),0,pi)function res=my_simpson(f,a,b)res=(b-a)*(f(a)+f(b)+4*f((a+b)/2))/6;endfunction res=my_quad(f,a,b,tol)if nargin==3    tol=10^(-6);endmid=(a+b)/2;quad_all=my_simpson(f,a,b);quad_l=my_simpson(f,a,mid);quad_r=my_simpson(f,mid,b);if(abs(quad_l+quad_r-quad_all)&lt;15*tol)     res=quad_l+quad_r+(quad_l+quad_r-quad_all)/15; else     res=my_quad(f,a,mid,tol)+my_quad(f,mid,b,tol);endend
可以看到和官方提供的quad函数没有太大差距：
ans =    2.0000ans =    2.0000
洛谷模板题
请注意，自适应simpson公式数值积分适用于精度要求低，被积函数平滑性较差的数值积分；
高精度Lobatto积分法
留坑，暂时找不到资料
Remark
这里大多数数值积分的介绍都缺少一点理论知识，等哪天补一补数值计算再回来填坑了；
其中的启发式算法还是很不错的；
]]></content>
  </entry>
  <entry>
    <title>程序设计语言</title>
    <url>/2025/06/20/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%AD%E8%A8%80/</url>
    <content><![CDATA[语言处理器 ⚙️
概述
通常来说，一个编译器(compiler) 👨‍💻➡️💻 将程序设计语言翻译成被计算机执行的形式；

阅读宿主语言(host language)，通过宿主机器(host machine)，翻译成等价的目标语言。
需要将翻译过程的错误抛出 ⚠️。
如果目标语言是机器可执行的语言程序，执行目标程序，可以处理用户的输入得到输出。

解释器(interpreter) 🗣️ 逐行执行：

没有显式的翻译步骤，直接解释执行源程序。
利用用户的输入，执行源程序中的操作，得到输出。

比较来看，编译器编译后运行获得输出相对较快 🚀，但是解释器错误诊断和调试通常更好 👍。
若编译程序生成宿主机执行的机器代码，称为自驻留的编译程序；若编译程序是用源语言编写的，则为自编译的编译程序；若编译程序生成的不是宿主机执行的机器代码，称为交叉编译；
这里详细介绍交叉编译：
在一个Host平台上生成另一个Target平台可执行代码的编译过程，常用于嵌入式开发、跨平台应用构建等场景，通常出于以下考虑：

资源限制：目标设备（如物联网设备）无法运行完整编译器
效率需求：在高性能Host平台编译可加速构建过程
跨平台支持：为Windows/MacOS/Linux生成多平台二进制文件

在C和C++的实践中，通常使用CMake等工具链实现交叉编译，而在一些语言(比如Golang)的编译器天然支持交叉编译选项；
结构
一个预处理器(preprocessor) 🧩：


负责将独立文件中的源程序多个模块组合在一起；


根据编译选项，选择条件编译；


删除注释，合并空白符；

大部分语言允许此法单元之间出现任意数量的空白，注释也当空白处理；



将宏 (macro) 的缩写转化成源语言语句。

比如C语言中遇到 #include &lt;iostream&gt; 负责将 iostream 库中的内容组合到目标程序；
遇到 #define PI 3.14159，则会将文件中的 PI 替换成 3.14159。



汇编器(assembler) 🛠️：

处理编译器产生的汇编语言程序。
生成可重定位的机器代码 (object code)。
大型程序一般多个文件分部分编译，这些可重定位的机器代码和库文件需要连接到一起。

链接器(linker) 🔗：

一个文件的代码可能引用另一个文件定义的符号 (如函数或变量)。
链接器解决这些外部内存地址的问题，将多个目标文件和库文件合并成一个可执行文件。

加载器(loader) 🚀：

将可执行文件从磁盘加载到内存中准备执行。


流程
编译器将源程序映射为语义等价的目标程序，由两部分构成：

前端/分析(analysis):将源程序分解，加上先验的语法结构

创建源程序的中间表示；
创建符号表(symbol table);
报语法错误；


后端/综合(synthesis): 输入中间表示和符号表，输出期待的目标程序；


具体分工如下：

词法分析 (Lexical Analysis) 🧐: 读入源程序字符流，将其组织成有意义的词素 (lexeme) 序列，然后为每个词素生成并输出一个记号 (token) 流。例如，将 count = count + 5; 转换为 id(count), assign_op, id(count), add_op, number(5), semicolon。
语法分析 (Syntax Analysis) 🌳: 根据词法分析器产生的记号流，使用语言的语法规则 (grammar) 来构造程序的层次结构，通常表示为一棵语法树 (syntax tree) 或分析树 (parse tree)。这一步检查程序的结构是否正确。(参考 [[第2章-语法分析#语法树|语法树]])
语义分析 (Semantic Analysis) 🤔: 使用语法树和符号表中的信息来检查源程序是否与其语言定义的语义一致。主要任务包括类型检查 (type checking)，确保操作符和操作数类型兼容，以及其他静态检查（如变量声明、函数参数匹配等）。同时收集类型信息供后续阶段使用。
中间代码生成 (Intermediate Code Generation) ⚙️: 在将源程序翻译成目标代码之前，许多编译器会先生成一个明确的、机器无关的中间表示 (Intermediate Representation, IR)。常见形式有三地址码 (three-address code)，它易于生成和优化。
代码优化 (Code Optimization) ✨: (可选阶段) 尝试改进中间代码，以产生性能更好（运行更快、占用内存更少、能耗更低等）的目标代码。优化可以在不同层面进行，如局部优化、全局优化、循环优化等。
代码生成 (Code Generation) 💻: 将（优化后的）中间代码映射到目标机器的指令集。此阶段涉及指令选择 (instruction selection)、寄存器分配 (register allocation) 和指令调度 (instruction scheduling)。最终为每个变量选择内存地址或寄存器。

符号表
符号表(symbol table)是供编译器用于保存有关源程序构造的各种信息的数据结构；
声明周期
符号表在分析阶段逐步收集，用于生成目标代码；

每项包含一个与标识符有关的信息，如词素，类型，存储位置；
需要支持同一个标识符的多重声明；
每个带有声明的程序块都有自己的符号表，因此需要对每个作用域建立单独的符号表；


数据结构
一个典型的符号表链如下:

一个典型的符号表Env的实现

C语言编译器示例 🔬
现在我们拥有一个main.c文件，内容如下：
#define MYMAX 20int add(int a, int b)&#123;    return a + 2 * b + MYMAX;&#125;;int main() &#123;    int c = 0;    c = add(1, 2);    return 0;&#125;
预处理
执行命令gcc -E -o hello.i hello.c,得到文件hello.i，内容如下，这样我们完成了文件通过了预处理器，完成了预处理的步骤，这一步不处理语法错误，执行预处理指令,可以看到MYMAX替换成20了；
# 0 &quot;main.c&quot;# 0 &quot;&lt;built-in&gt;&quot;# 0 &quot;&lt;command-line&gt;&quot;# 1 &quot;/usr/include/stdc-predef.h&quot; 1 3 4# 0 &quot;&lt;command-line&gt;&quot; 2# 1 &quot;main.c&quot;int add(int a, int b)&#123;    return a + 2 * b + 20;&#125;;int main() &#123;    int c = 0;    c = add(1, 2);    return 0;&#125;
编译
执行命令gcc -S -o main.s main.i，得到文件main.s，内容如下，这样的汇编语言程序结果和硬件架构相关；
	.file	&quot;main.c&quot;	.text	.globl	add	.type	add, @functionadd:.LFB0:	.cfi_startproc	endbr64	pushq	%rbp	.cfi_def_cfa_offset 16	.cfi_offset 6, -16	movq	%rsp, %rbp	.cfi_def_cfa_register 6	movl	%edi, -4(%rbp)	movl	%esi, -8(%rbp)	movl	-8(%rbp), %eax	leal	(%rax,%rax), %edx	movl	-4(%rbp), %eax	addl	%edx, %eax	addl	$20, %eax	popq	%rbp	.cfi_def_cfa 7, 8	ret	.cfi_endproc.LFE0:	.size	add, .-add	.globl	main	.type	main, @functionmain:.LFB1:	.cfi_startproc	endbr64	pushq	%rbp	.cfi_def_cfa_offset 16	.cfi_offset 6, -16	movq	%rsp, %rbp	.cfi_def_cfa_register 6	subq	$16, %rsp	movl	$0, -4(%rbp)	movl	$2, %esi	movl	$1, %edi	call	add	movl	%eax, -4(%rbp)	movl	$0, %eax	leave	.cfi_def_cfa 7, 8	ret	.cfi_endproc.LFE1:	.size	main, .-main	.ident	&quot;GCC: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0&quot;	.section	.note.GNU-stack,&quot;&quot;,@progbits	.section	.note.gnu.property,&quot;a&quot;	.align 8	.long	1f - 0f	.long	4f - 1f	.long	50:	.string	&quot;GNU&quot;1:	.align 8	.long	0xc0000002	.long	3f - 2f2:	.long	0x33:	.align 84:
汇编
执行命令gcc -c -o main.o main.s，得到main.o文件，编辑器已经不可查看了,而且系统也不能执行该文件，内容为机器码；
不可执行的原因是还未进行重定位操作，数据的地址没有确定；
链接
执行命令gcc -o main main.o，得到最终的可执行文件main;
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Compilers</tag>
      </tags>
  </entry>
  <entry>
    <title>测度论预备知识</title>
    <url>/2025/07/05/%E6%B5%8B%E5%BA%A6%E8%AE%BA%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[σ 代数，可测空间，随机事件
设是一个样本空间(或任意一个集合),是的某些子集组成的集簇.如果满足：





若,则


若则


则称为代 数 。称为可测空间，​中的元素称为随机事件；

一个事件应该理解成一个集合，它可以用若干样本点表示；

Property

​.
对集合的可数交，可数并，差，补运算封闭；

生成 σ 代数, Borel σ 代数
以的某些子集为元素的集合称为上的)集类。对于上的任一非空集类,存在包含的最小代数，称为由生成的代数，记为​
为包含的代数
设。由所有半无限区间生成的代数称为上的 Borel 代数，记为, 其中的元素称为 Borel 集合。类似地，可定义上的 Borel 代数。
Mark
如何理解最小？对于.
Example
对样本空间,随机事件,写出以下集簇的最小代数：

.


概率空间，事件，概率
设是可测空间， 是定义在上的实值函数。如果

(非负性)
(规范性)
(可列可加性)对两两互不相容事件,(即当时)有


则称是上的概率，称为概率空间，中的元素称为事件，称为事件的概率.
Property





(有限可加性)若且有





(单调性)若则,


(概率加法定理)​


Jordan公式：.


若则​

    证明
    不妨设不等式右端小于$+\infty.$构造互斥事件序列$\{E_n\}$,其中
$$E_n=\left\{\begin{matrix}A_1,&amp;n=1,\\A_n-\bigcup_{i=1}^nA_j,&amp;n&gt;1.\end{matrix}\right.$$
于是有$E_n\subseteq A_{n\text{,并且}\bigcup_{i=1}^nE_i}=\bigcup_{i=1}^nA_i,\bigcup_{i=1}^\infty E_i=\bigcup_{i=1}^\infty A_i$,从而
$$P\left(\bigcup_{i=1}^\infty A_i\right)=P\left(\bigcup_{i=1}^\infty E_i\right)=\sum_{i=1}^\infty P(E_i)\leq\sum_{i=1}^nP(A_i).$$



事件的极限
事件的单调性：若对每个,有或 , 则称事件序列为单调增(或单调降)。
对单调增或单调降序列,我们分别令或 称为的极限，通常记为或
设为一事件序列。令

分别称其为​的上极限和下极限。
若,则称极限存在，用表示
Mark
如何理解上极限，下极限？

上极限：全体出现在无穷个中的元素；
下极限：全体只在有限个中不存在的元素；

使属于无穷多个有至多不属于有限多个
Property


若 且 , 则​

    证明
    设$\{A_n\}$是单调增序列，构造互斥事件序列$\{B_n\}$,其中
$$B_n=\begin{cases}A_1,&amp;n=1,\\A_n-A_{n-1},&amp;n&gt;1.\end{cases}$$
于是有$\bigcup_{i=1}^nA_i=\bigcup_{i=1}^nB_i$ 及$\bigcup_{i=1}^\infty A_i=\bigcup_{i=1}^\infty B_i$,故
$$\begin{aligned}P\left(\lim_{n\to\infty}A_n\right)&amp;=P\left(\bigcup_{i=1}^\infty A_i\right)=P\left(\bigcup_{i=1}^\infty B_i\right)=\sum_{i=1}^\infty P(B_i)\\&amp;=\lim_{n\to\infty}\sum_{i=1}^nP(B_i)=\lim_{n\to\infty}P\left(\bigcup_{i=1}^nB_i\right)\\&amp;=\lim_{n\to\infty}P\left(\bigcup_{i=1}^nA_i\right)=\lim_{n\to\infty}P(A_n).\end{aligned}$$



(Borel-Cantelli第一引理)设是一列事件，若, 则 ​.​
证明
    易知$\bigcup_{i=n}^\infty A_i$是关于$n$的单调减序列，故
$$\begin{aligned}0\leq P(\lim_{i\to\infty}\sup A_i)&amp;=P\left(\bigcap_{n=1}^\infty\bigcup_{i=n}^\infty A_i\right)=P\left(\lim_{n\to\infty}\bigcup_{i=n}^\infty A_i\right)\\&amp;=\lim_{n\to\infty}P(\bigcup_{i=n}^\infty A_i)\leq\lim_{n\to\infty}\sum_{i=n}^\infty P(A_i)=0.\end{aligned}$$
从而得证.



(Borel-Cantelli第二引理)设是一列事件，若, 则 ​​.


随机变量，分布函数
设是概率空间，是定义在上取值于实数集的函数， 如果对任意实数, ,则称是上的随机变量，简称为随机变量.

称为随机变量​的分布函数.
若向量满足对所有的都是随机变量，则称为多维随机变量，也称随机向量.
多维随机变量,的维联合)分布函数写作

这里为正整数，
Property


对每个变量都是单调的；


对每个变量都是右连续的；


,





边缘分布，联合密度
设为的联合分布函数.对 , 的边缘分布为

如果

对所有的  存在，则称函数为​的联合密度函数，并且

Mark
并非所有分布都具有概率密度，比如Cantor分布；
示性函数
任意事件 的示性函数为:没发生发生了
若 , 则 是随机变量;
若, 则 不是随机变量.
给定 和事件序列 , 若  且, 则称为  的一个 划分 .
若  是 的一个划分, 则 是随机变量, 其中 .
Riemann-Stieltjes积分
设 为有限区间的一个分割，为上的实值函数。令

和。如果当时，极限

存在，且与分割的选择以及的取法无关，则称该极限值为函数关于 在上的 Riemann-Stieltjes积分，记为

Property

(线性性质)
(区间可加性
,其中均可为有限数或无穷大.

若单调不减,,则 

数学期望,方差，原点矩
是随机变量的分布函数，其数学期望定义为

方差定义为

阶原点矩定义为

中心矩定义为

协方差定义为

阶混合矩定义为，混合中心矩定义为​
Mark


期望有可能是不存在的，比如Cauchy分布：



概率论版本的Jesen不等式如下：
对于(是凸函数),有



对于全排列的置换 ,满足的下标个数为，


矩母函数
若随机变量的分布函数为,则称

为的矩母函数.
Property



矩母函数存在时，将唯一决定分布，也即矩母函数和分布唯一对应
若概率密度存在，则是的Laplace变换

特征函数
若随机变量的分布函数为,则称

为的 特 征 函 数 .
Property


分布函数由其特征函数唯一决定.如果有概率密度则就是的Fourier变换



(有界性)


(共轭对称性)


(一致连续性)


(线性变换)设,则的特征函数是


两个相互独立的随机变量之和的特征函数等于它们的特征函数之积.


(非负定性)对于任意的正整数,任意实数及复数​,有



设随机变量有阶矩存在，则它的特征函数可微分次，且当时，有



特征函数可作如下带皮阿诺型余项的Taylor展开：



收敛性
几乎必然收敛
设是随机变量序列，若存在随机变量使得

则称随机变量序列 几 乎 必 然 收 敛 (或以概率1收敛于), 记为 ​
等价命题：当且仅当对任意的有

Mark
事件发生的概率是1，几乎是一个必然事件，我们认为事件几乎处处成立；

考虑喂养一个宠物，并将该宠物每天消耗的食物量记为Xn.虽然Xn是不可预测的，但我们可以非常确定有一天该数字将变为零，并且此后将永远保持为零；
假设一个人每天早上抛七枚硬币。硬币每出现一个正面，当天下午他都会向慈善机构捐赠一块钱。然而，如果某一天硬币的结果全是反面，他就会永远停止捐赠。设为慈善机构每天从他那里收到的金额。我们几乎可以肯定，有一天这个金额将为零，并在那之后永远保持为零。然而，当我们考虑任何有限的天数时，终止条件不会发生的概率不为零（虽然这个概率极小）;

依概率收敛
设是随机变量序列,若存在随机变量,使得​,有

则称随机变量序列依概率收敛于, 记为​.
Mark
随着事件序列的进展，‘不寻常‘的结果发生的概率越来越小；
假设随机数生成器生成0到1之间的伪随机浮点数.设为生成器输出的数字，由于伪随机数是确定性生成的，因此其下一个值并不是真正随机的。假设当观察一系列随机生成的数字时，可以推断出它的模式并对下一个随机生成的数字是什么做出越来越准确的预测。令为在观察前个随机数后对下一个随机数的值做的猜测。随着对生成器的模式越来越了解，猜测也将变得更加准确，的结果会收敛到的结果。
Property

随机变量序列的充分必要条件是的任意子序列都包含几乎必然收敛于的子序列;

p​次平均收敛
称随机变量 ,如果其满足  ;
设随机变量序列,随机变量,若有

则称随机变量序列 次 平均收敛于.记作
依分布收敛
设是分布函数列，如果存在一个单调不减函数, 使得在的所有连续点上均有

则称 弱 收 敛 于 ,记 为 
设随机变量的分布函数分别为及,，则称依分布收敛于,记为​
Mark








，
定义
验证序列

满足构造要求



定义
验证序列

满足构造要求


独立性
设为个事件，如果对任何及1, 有

则称 相互独立.
设维随机变量的联合分布函数为,若对所有实数组均有

成立，其中 是关于的边缘分布，则称相互独立。
Property


​两两独立不一定相互独立.








条件概率，全概率公式，Bayes公式
设是一个事件，且. 则 事 件发生的条件下事件发生的条件概率为

全概率公式:
设是的一个有限划分，且则有

贝叶斯公式:
设 是的一个有限划分，且如果,则

条件期望,条件方差，全期望公式
设是连续型随机变量，其联合概率密度函数。对固定的若满足,给定时，的条件概率定义为：

称作在的条件下，随机变量的条件概率密度.称

为在的条件下，随机变量​的 条 件 期 望 .
称

为在  的条件下，随机变量的 条 件 方 差.
Property


(全期望公式)​.








如果, 则.


如果与}独立,则.


.特别地,.





​
是所有用来近似中效果最好的.





(全方差定理)​


随机过程
设是 概 率 空 间 , 是一参数集。若对每一个 是 上的随机变量，则称随机变量族​为 随 机 过 程 .
Mark

观察随机过程的两种视角：对于随机过程

固定,是定义在上的样本函数，称作实现；
固定,是定义在​上的随机变量，称作状态；



有限维分布(簇)，Kolmogorov定理,数字特征
对任意有限个,定义随机过程的维 分 布 函 数 

随机过程的所有的一维分布，二维分布，维分布等的全体

称为随机过程​ 的 有 限 维 分 布 簇 .
Property


对称性：对的任一排列，有



相容性：对,有



Kolmogorov定理描述如下事实：
设分布函数族 满足上述的对称性和相容性，则必存在一个随机过程使

恰好是的有限维分布簇.
有限维分布簇完整地描述了随机过程的概率性质，但是实际过程中几乎无法得到完整的分布簇，因此采用数字特征描述随机过程也许是更好的办法.

均值函数：
方差函数：
协方差函数：
自相关函数：

严平稳过程，宽平稳过程
如果随机过程对任意的和任意的 均满足与 具 有 相 同的联合分布，记为

则称​为 严 平 稳 过 程 .
如果随机过程的所有二阶矩都存在，并且均值函数,协方差函数只与时间差有关，则
称为 宽 平 稳 过 程.
Mark


严平稳过程的有限维分布关于时间平移不变；


严平稳过程的主要性质和选取的起始点无关而和变量之间的距离有关；


宽平稳过程的协方差函数可以记为,因为\gamma(s,t+s)=\gamma(0,t),s,t\in\mathbb{R};


宽平稳过程：是偶函数，​,且具有非负定性，也即对于任意时刻和实
数，有


    证明
    $\mathbf A=(a_1,a_2,...,a_n),\mathbf Z=(E[t_1]-\mu,E[t_2]-\mu,...,E[t_n]-\mu)$
    $0\le Var(\mathbf A^T \mathbf Z)=A^TE[ZZ^T]A=\sum_{i=1}^N\sum_{j=1}^Na_ia_j\gamma(t_i-t_j)$



遍历性
设为一平稳过程，若

或当参数空间为时，

则称的 均 值 有 遍 历 性 .
若

或当参数空间为时，

则称的 协 方 差 有 遍 历 性.
若随机过程的均值和协方差函数都具有遍历性，则称此随机过程有遍历性.
均值遍历性定理：


设是平稳过程，其协方差函数为,则的均值有遍历性的充分必要条件是



设是平稳序列，其协方差函数为则的均值有遍历性的充分必要条件是




Proof
首先，计算的均值和方差。记

则有

进而

在上述积分中，做变换\begin{cases}\tau=t-s\v=t+s\end{cases},则变换的 Jacobi 行列式值为：J=\left|\begin{array}{cc}1&amp;-1\1&amp;1\end{array}\right|^{-1}=\dfrac{1}{2}
积分区域变换为顶点分别在轴和 轴上的菱形区域

由于是偶函数，故


推论

若,则均值遍历性定理成立.
对于平稳序列而言,若​,则均值遍历性定理成立.

平稳增量，独立增量
如果对任何随机变量是相互独立的，则称 为 独 立 增 量 过 程 .
如 果 对 任 何 ,有 ,则称为是平稳增量过程.
有独立增量和平稳增量的过程称为平稳独立增量过程.
Property


假设是一个独立增量过程，则具有平稳增量的充分必要条件是：其特征函数具有可乘性，即



设是 一 个 平 稳 独 立 增 量 过 程 , 

​

其中​均是常数。

proof:注意到

这是Cauchy方程，简单验证连续性即可；
其次,假设，



]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Random Process</tag>
      </tags>
  </entry>
  <entry>
    <title>组合计数</title>
    <url>/2025/07/05/%E7%BB%84%E5%90%88%E8%AE%A1%E6%95%B0/</url>
    <content><![CDATA[加乘原理
乘法原理：完成一个工程需要分  个步骤， 代表第  个步骤的不同方法数目。那么完成这件事共有  种不同的方法。
加法原理：完成一个工程可以有  类办法， 代表第  类方法的数目。那么完成这件事共有 ​ 种不同的方法。
例题(快速幂)：计算
int pow(int x,int y)&#123; 	int res=1;	x%=p;	for(;y;y&gt;&gt;=1,x=x*x%p) if(y&amp;1) res=res*x%p;    return res;&#125;
排列数
从  个不同元素中，任取 （）个元素按照一定的顺序排成一列，叫做从  个不同元素中取出  个元素的一个排列；
从  个不同元素中取出 () 个元素的所有排列的个数，叫做从  个不同元素中取出  个元素的排列数，用符号 表示。

组合数
从  个不同元素中，任取  个元素组成一个集合，叫做从  个不同元素中取出  个元素的一个组合；
从  个不同元素中取出  个元素的所有组合的个数，叫做从  个不同元素中取出  个元素的组合数，用符号  来表示；

例题：计算
int inv(int x,int p)&#123; //求逆元	return pow(x,p-2);&#125;fac[0]=1;for(int i=1;i&lt;=n;i++) fac[i]=fac[i-1]*i; //预处理出阶乘return ((fac[n]*inv(fac[m],p))%p*inv(fac[n-m],p))%p;
圆排列
 个人全部来围成一圈，所有的排列数记为 。考虑其中已经排好的一圈，从不同位置断开，又变成不同的队列。
所以有

由此可知部分圆排列的公式：

抽屉原理
将  个物体，划分为  组，那么至少存在一个分组，含有大于或等于  个物品。
推广的形式也可以使用反证法证明：若每个分组含有小于  个物体，则其总和  矛盾。
此外，划分还可以弱化为覆盖结论不变。
给定集合 , 一个  的非空子集构成的簇 

若满足  则称为  的一个覆盖（cover）；
若一个覆盖还满足  则称为  的一个划分。

鸽巢原理可以有如下叙述：对于  的一个覆盖  有至少一个集合  满足 。
容斥原理
设 U 中元素有 n 种不同的属性，而第 i 种属性称为 ，拥有属性  的元素构成集合 ，那么

即

证明：
对于每个元素使用二项式定理计算其出现的次数。对于元素，假设它出现在  的集合中，那么它的出现次数为

于是每个元素出现的次数为 1，那么合并起来就是并集;
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Discrete-Mathematics</tag>
      </tags>
  </entry>
  <entry>
    <title>词法分析</title>
    <url>/2025/06/20/%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[词法分析
概述
词法分析(Lexical Analysis / Scanning)是编译过程的第一个阶段。
它接收源程序的字符流 (character stream)作为输入，并将其组织成一系列有意义的词素 (lexeme)。随后，对于每个词素，词法分析器会生成一个记号 (token) 作为输出，传递给语法分析器。
这个记号就是一个词法单元，就是一个带有附加信息的终结符号；
核心任务 🎯
扫描源程序的字符串,按照词法规则,识别出单词符号作为输出;

读取输入: 逐个读取源程序中的字符。
识别词素: 将字符组合成词素(Lexeme) 📜，源程序中与某个记号的模式匹配的实际字符序列。例如，在语句 count = count + 5; 中, count, =, +, 5, ; 都是词素。词素内部的空格通常被忽略（除非它们是字符串字面量的一部分或用于分隔词素）。
生成记号: 为每个识别出的词素生成一个记号；

记号 (Token) 🪙: 一个抽象的符号，代表一类词法单元。通常表示为一个二元组：(token-name, attribute-value)。

token-name: 词法单元的类别，如 identifier, keyword, operator, number, punctuation。
attribute-value (可选): 指向符号表中关于这个词素的条目。对于标识符，它可能是标识符的字符串；对于数字，它可能是数值。对于关键字或操作符，此字段可能为空或不使用。


模式(Pattern) 🧩: 描述一个记号的词素可能具有的形式的规则。通常用正则表达式来定义。例如，一个标识符的模式可能是"一个字母后跟零个或多个字母、数字或下划线"。



举例说明 🌰
考虑以下C语言语句:
result = initial_value + rate * 60;
词法分析器会将其转换为如下的记号流 (token stream):

词素 result  ➡️ 记号 &lt;id, "result"&gt;
词素 =       ➡️ 记号 &lt;assign_op&gt;
词素 initial_value ➡️ 记号 &lt;id, "initial_value"&gt;
词素 +       ➡️ 记号 &lt;add_op&gt;
词素 rate    ➡️ 记号 &lt;id, "rate"&gt;
词素 *       ➡️ 记号 &lt;mul_op&gt;
词素 60      ➡️ 记号 &lt;number, 60&gt;
词素 ;       ➡️ 记号 &lt;semicolon&gt;

其他职责 🛠️

去除空白和注释: 词法分析器通常会跳过源程序中的空格、制表符、换行符和注释，因为它们通常不影响程序的语义（除非它们用于分隔词素）。
错误报告 ⚠️: 报告词法错误，例如遇到不符合任何模式的字符（如非法符号）。
与符号表交互 📇: 将标识符等词素的属性信息存入符号表。

在编译过程中，词法分析可以仅仅执行一次；

也可以执行多次；

数据结构🧱
enum kind &#123;IF, LPAREN, ID, INTLIT, …&#125;;struct token &#123;	enum kind k;	char* lexme;&#125;
在多数程序语言设计中，单词种类一般有如下种类：

标识符：标识符、常量由用户定义/使用, 语言未加限制,只规定了相应的词法规则；
关键字，运算符，分界符：数目是确定的，每个单词与其类别码一一对应，因此采取一字一码，即第二元可以空缺；
常量：整型、实型、字符型、布尔型等分类

词法分析器
输入 &amp; 输出 &amp; 流程


读入源字符串


输出二元式序列


包括单词符号 + 种别


如果有错误，则改输出错误信息

格式：LINE &lt;id&gt;: &lt;error info&gt;
一般有三种错误：非法字符，冒号不匹配，标识符长度溢出





进入一个阶段，需要先检查错误信息


peek技术
在决定像语法分析器返回token之前，词法分析器可能需要预先读入一些字符；

比如遇到&gt;后需要检查下一个是否是=,标识符是否在下一位结束等；

一个通用的预读办法是使用输入缓冲区，由于通常只需预读一个字符，所以缓冲区大小为1，即将下一个输入字符保存在一个变量peek中;
当词法单元返回一个token时，peek要么保存了该token的词素后面一个字符，要么为空白符；
我们可以使用一个指针跟踪已经被分析的输入部分，放回缓冲区通过回移指针实现；
对于大型编译器的实现，往往采用双缓冲技术；
解析常量
当输入流中出现一个数位序列时，词法分析器将它解析为一个数字常量；

解析关键字和标识符
关键字也满足标识符组成规则：开头为字母或下划线，往后为数字或下划线或字母；通常实践下，词法分析器使用一个表保存在字符串，后续通过引用操作字符串；
词法分析器在初始化应该在构建关键字表(reserve table)，每一项包括保留的字符串和对应的词法单元；还有空的标识符表words;

当读到一个可以组成标识符的词素时，应该先检查关键字表；
检索到，则返回关键字表中的词法单元；
否则，与words交互，查到返回位置编号，否则将它存入符号表并返回新编号；


扫描算法

基于状态转换的框架


当前字符：用一个变量cha记录


case：当前字符的值识别不同类型单词


每个状态对应于一段代码：


分支状态：if或case语句


循环状态：while语句




进入某个接受状态时，某个单词识别结束。

终态：return语句
错误



注意自动机状态有错误标记*


实现原理
算法需要设计如下变量和函数：

cha:最新读入的字符；顺便维护所在wei'zhi
token:已读入的字符串；
getchar(): 从源程序文件读入下一个字符；
getnbc(): 读入非空白字符；
concat(): 把cha加入到token的末尾；
isLetter(): 判断是否为字母；
isDigit(): 判断是否为数字；
reverse():  对token查关键字表，查到返回关键字的编码种类，否则返回0表示不是任何单词符号；
retract(): 回退字符，把刚读入的cha中的字符回退到输入字符串中，cha置空；
buildList(): 对token查符号表，查到返回位置编号，否则将它存入符号表并返回新编号；
dtb(): 将token的数字串转换成二进制，查常数表；查到返回位置编号，否则将它存入常数表并返回新编号；
return()-&gt;(num, value): 返回编码种类 + 位置编号
error(): 处理可能的词法错误；

可能存在一类词法错误，比如写错关键字，标识符带有空格，这种错误一般会推迟到语法分析抛出；
词法分析程序作为语法分析程序的一个子程序，当语法分析需要下一个新单词时，就调用该程序，从输入字符串中识别一个单词后返回。
词法分析程序另一种被调用方法，这一般是主流实践；

被编译程序只调用一次
增加一个大循环（文件是否结束）
return改为 向文件写入二元式；
该文件保存所有的二元式，语法分析程序通过该文件获取单词；

词法错误
比如以下程序片段
fi(a == b) ...
词法分析器无法判断if是否拼写对，它会将fi识别成一个普通标识符，可能有两种场景

未定义标识符：如果该符号之前没有定义过，而fi前面没有声明语句，就会直接抛出该错误；
其他：如果已经被定义过了，则词法分析不报错，推迟到语法分析处理错误；

如果遇到所有词法单元模式均无法与剩余的输入前缀匹配，则词法分析器将陷入恐慌，无法继续处理；
一般会执行一个恐慌恢复策略：从剩余输入中不断删除字符，直到输入开头出现一个正确的词法单元为止；
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Compilers</tag>
      </tags>
  </entry>
  <entry>
    <title>语义分析</title>
    <url>/2025/06/20/%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[语义
定义：语言的单词符号和语法单位的作用和意义的规则组合；
一般用自然语言描述语义，使用抽象机(grammar abstract machine)的行为来描述语言语法单位的作用和意义，GAM主要用于实现惰性求值和图归约；
GAM
组件

存储区：分为代码段和数据段；

代码段存放执行的指令代码的内容不允许修改；
数据段存放必要的信息和程序中的数据；


控制器
处理器
指令指针ip：指向代码段单元的地址，表示当前指令；自增操作：ip = ip + 4表示指针指向下一条指令，如果每条指令占4个字节的话；

工作方式
GAM一旦启动，由专门的装入程序将待运行的程序装入代码存储区，并设置ip指向第一条指令，并执行如下操作

执行ip指向的当前指令；
若ip指向STOP指令，则终止执行；
若指令未修改ip，则ip自增，指向下一条指令；
若修改了ip，则跳转到修改后ip指向的指令；

语义分析
语义分析(semantic analyzer)使用语法树和符号表检查源程序是否和语言定义的语义一致，同时收集类型信息；语义定义了程序的含义；
主要工作分为

静态语义检查：类型检查(type checking)，控制流检查，一致性检查等
语义处理：自动类型转换(coercion)，说明语句登记信息，执行语句生成中间代码等

静态检查一般由编译器前端完成，抛出特定类型错误；

语法检查：部分包括在语法分析的文法中的语法要求；
类型检查：部分语言实现自动类型转换(coercion)；
左值和右值：考虑运算符的结合问题；

符号表
形式
符号表中每个名字对应一个表项，包括名字域和信息域；

信息域设置若干子域和标志位，包括属性，类型，长度，相对地址，形参标志，说明标志，赋值标志等；
每个表项的组成和长度可能是不同的，需要采用简洁表技术；

符号表
符号表除了记录名字本身而外,还记录了与名字关联的各种属性信息。
每个名字对应一个表项，一个表项包括名字域和信息域。信息域通常设若干子域及标志位，其内容可以是和名字有关的任何信息，比如类型,种属,长度,相对地址，形参标志,说明标志,赋值标志等。
结构
实现结构可以采取线性表，或者Hash表实现；
语义分析
语义分析(semantic analyzer)使用语法树和符号表检查源程序是否和语言定义的语义一致，同时收集类型信息；

类型检查(type checking)
自动类型转换(coercion)

语义定义了程序的含义；
语法制导翻译
定义
上下文无关文法不仅可以描述一个语言的语法，还可以制导程序的翻译过程，这种技术称为 语法制导翻译(syntax-directed translation);
一个属性(attribute)是指某个与程序构造相关的量；

比如表达式的数据类型，生成代码的指令数；在语法分析树上体现为结点上标记了相应的属性值，这样的树也称作注释分析树；

对于一个语法制导定义(syntax-directed definition)实现了

将每个文法符号和一个属性集合相关联;
把产生式和一组语义规则(semantic rule)相关联;


换而言之，为每个产生式配上一个语义子程序 ,在语法分析过程中,使用一个产生式进行匹配或归约后；
就调用相应的语义子程序，进行语义分析。
对于一个语法制导的翻译方案(translation scheme)，定义为将程序片段附加到一个文法的各个产生式的表示法；

在语法分析使用一个产生式时，相应的程序片段将被执行；
顺序组合这些方案，执行可以得到源程序的翻译结果；
根据产生式，生成了中间代码,语法分析完成时，也就获得了完整的与源代码等价的中间代码。

对注释语法树来说

一次深度优先遍历，会自顶向下地计算子结点属性后，得出根节点的属性值；
可采用前序遍历和后序遍历的方式，根据相关动作执行时间来定义结点次序

语法制导翻译方案是一种在文法产生式中附加程序片段来描述翻译结果的表示方法；

语义动作：被嵌入到产生式体中的程序片段称为语义动作；
生成翻译方案的语法分析树时，需要为每个语义动作构造一个额外的，产生式头部的子节点；
在一次后续遍历中，先所有执行语义动作，然后访问没有语义动作的子节点；

比如在LR分析过程中，使用一个产生式进行句柄的规约后，调用该产生式的响应的语义子程序，完成语义分析；

包括语义检查和语义处理；
核心是生成中间代码；
在分析过程中每一次规约时，必须保存语义值；

考虑一个翻译方案
expr -&gt; expr + term &#123;print(&#x27;+&#x27;)&#125;	   |expr - term &#123;print(&#x27;-&#x27;)&#125;	   |termterm -&gt; 0 &#123;print(&#x27;0&#x27;)&#125;	   |1 &#123;print(&#x27;1&#x27;)&#125;	   ...	   |9 &#123;print(&#x27;9&#x27;)&#125;

通过拓展文法得到一个翻译器，我们可以拓展一个预测分析器来获得一个语法制导翻译器；
消除左递归
将上述翻译方案的左递归消除后
expr -&gt; term restrest -&gt; + term &#123;print(&#x27;+&#x27;)&#125; rest	   |- term &#123;print(&#x27;-&#x27;)&#125; rest	   |εterm -&gt; 0 &#123;print(&#x27;0&#x27;)&#125;	   |1 &#123;print(&#x27;1&#x27;)&#125;	   ...	   |9 &#123;print(&#x27;9&#x27;)&#125;

消除尾递归
若过程体执行的最后一条语句时对该过程的递归调用，则称这个调用是尾递归的(tail recursive);
对于一个没有参数的尾递归调用可以改写为迭代；
调用符号表
符号表的作用是将信息从声明的地方传递给实际使用的地方；
分析标识符的声明时，定义一个语义动作将有关从符号表中取出这个给标识符的信息；
中间表示形式 &amp; 虚拟机
后缀表示
对于我们熟悉的一个中缀表达式,其后缀表示(postfix notation)/逆波兰表示(reverse Polish notation)定义如下，记作


若是一个变量或常量,则;


若是形如的表达式，则



若是形如的表达式，则


如上性质表明后缀表达是一种无括号的数学表达式表示法，其核心为运算操作符后置，无需括号也可明确运算顺序；
这样的数据结构可以对应一类栈式自动机；
抽象语法树(abstract syntax tree)

内部节点代表程序构造;
每个内部结点和一个运算符关联；没有对应于单产生式，也没有空产生式；

树型结构包括语法分析树和抽象语法树；实际上，抽象语法树的结构不会被存储在特定数据结构中，在编译过程中，它被假装构造出来，伴随着三地址代码的生成；
当语法树生帮助生成的三地址代码构造成功后就会释放那部分树；
三地址代码 &amp; 四元式
三地址代码时最重要的线性表示形式；通常包括一个操作码op,和三个操作数x,y,z，使用相对地址表示；

二元运算类语句的一般形式为x:= y op z或者(op,x,y,z); 对于运算类操作，y,z指出运算的两个对象，x用来存放运算的结果，op为二元算术或逻辑运算符;
一元运算类赋值语句   x:=op z,op为一元运算符，如一元负uminus，逻辑否定not，类型转换itr等
复制类赋值语句x:=y
无条件转移语句goto L,流程转移到序号为L的语句
条件转移语句if x rop y goto L或if a goto L,rop为关系运算符  &lt;、&lt;=、==、&gt;、&gt;=、&lt;&gt;
若x和y满足关系rop，或a为true时，就转向执行序号为L的语句,否则顺序执行下一语句。

四元式顺序和表达式计值顺序一致;四元式之间通过临时变量实现关联。使用ip表示四元式编号(序号,从1开始)
特别的，我们约定(itr, x, _, t)的含义是将符号表入口x的整数变量转换为实数类型t；(rti, x, _, t)的含义是将符号表入口x的实数变量转换为整数类型t；
翻译
语义变量和语义过程



语义
类别
作用




i.NAME
语义变量
表示变量的标识符字符串


E.PLACE
语义变量
表示变量在符号表的地址或整数编码


newtemp()
语义过程
创建临时变量，返回整数编码


entry(i)
语义过程
为变量i查符号表


emit(res, s1, op, s2)
语义过程
产生三地址语句res:=s1 op s2，同时ip自增，这里s1,s2都是指符号表某个地址


error()
语义过程
报语义错误


enter(name, type, offset)
语义过程
将变量的名字，类型和相对地址写入符号表


backpatch(r, ip)
语义过程
把r为链首的三地址语句转移地址填为ip的当前值


merge(p1,p2)
语义过程
将p1,p2为链首的两条链拼接起来



翻译说明语句
对于单个变量的说明，文法表示为
S → MDM → εD → D;D | i:TT → real | integer | ↑T1
则产生的说明语句子程序/方案为
(1) M → ε &#123;OFFSET = 0;&#125;(2) D → i:T &#123;enter(i.NAME, TYPE, OFFSET); OFFSET := OFFSET + T.WIDTH;&#125;(3) T → real | integer | ↑T1 &#123;T.TYPE=..., T.WIDTH=...&#125;(4) D → D;D &#123;&#125;(5) S → MD &#123;&#125;
翻译赋值语句
对于赋值简单变量，文法表示为
S → AA → i := EE → E1 op E2 | -E1 | (E1) | i
对于已经声明的变量，应该先查找变量名表；
对于赋值语句的翻译，需要进行类型检查和自动类型转换，翻译的顺序按照语法制导来，产生的说明语句子程序/方案为
S → A &#123;S.CHAIN = 0;&#125;A → i := E &#123;P = entry(i.NAME); if(P != 0) &#123;emit(:=,E.PLACE,_, i);&#125; else error(); &#125; E → E1 op E2 &#123;E.PLACE = newtemp(); &#123;check&#125;emit(E.PLACE, E1.PLACE(), op, E2.PLACE()); &#125;E → -E1 &#123;E.PLACE = newtemp(); emit(E.PLACE, unimus, E1.PLACE);&#125;E → (E1) &#123;E.PLACE = E1.PLACE; &#125;E → i &#123;P = entry(i.NAME); if(P != 0) &#123;E.PLACE = P;&#125; else error();&#125;
其中{check}表示类型检查的步骤，具体来说是个形如以下(op为+)的过程；
E.place :=newtemp( );if E1.type=integer and T.type=integer then   begin emit(+i,E1.place,T,place, E.place);   	    E.type:=integer   endelse if E1.type=real and T.type=real then     begin emit(+r,E1.place,T.place, E.place);     	E.type:=real     endelse if E1.type=integer then    begin t:=newtemp( );    	emit(itr,E1.place,_,t);    	emit(+r,t,T.place, E.place);    	E.type:=real    endelse 	begin          t:=newtemp( );         emit(itr,T.place,_,t);                                              emit(+r,E1.place,t, E.place);         E.type:=real      end
布尔表达式的翻译
我们考虑位于控制语句中的布尔表达式，在读到转移语句的时候，具体转移的目的地尚不可知，暂记为0；
对于布尔变量和布尔表达式对应的语义子程序都有4步，对真假分别判断；
B → b&#123; B.T = ip; emit(if b goto 0); B.F = ip;emit(if b goto 0);&#125;B → a op b&#123; B.T = ip; emit(if a op b goto 0); B.F = ip;emit(if b goto 0);&#125;
无条件转移语句的翻译
通常goto语句的产生式如下，也可能具有如下的向前转移和向后转移形式；
label → i:S → goto label;L:...goto L;goto K;...K:
条件跳转语句的翻译
条件跳转语句的复杂之处在于嵌套；我们考虑如下产生式
S → MS1M → if B then

整个语句翻译完成后，仍然不确定B.F，只能将它作为S.CHAIN暂时保留下来，那么对应的语义子程序为
(1) M → if B then &#123;backpatch(B.T, ip); M.CHAIN = B.F&#125;(2) S → MS1 &#123;S.CHAIN = merge(S1.CHAIN, M.CHAIN);&#125;
对于更复杂的嵌套情况

S → NS2N → MS1 else M → if B then
我们需要更多的合并和跳转的操作
(1) M → if B then &#123;backpatch(B.T, ip); M.CHAIN = B.F&#125;(2) N → MS1 else &#123;q = ip; emit(goto 0); backpatch(M.CHAIN, ip); N.CHAIN = merge(S1.CHAIN, q);&#125;(3) S → NS2 &#123;S.CHAIN = merge(S2.CHAIN, M.CHAIN);&#125;
while语句的翻译

根据文法建立子程序
(1) W → while &#123;W.CODE = ip;&#125; // 这里的CODE只是个标签(2) D→ while B do &#123;backpatch(B,T, ip); D.CHAIN=B.F; D.CODE=W.CODE;&#125;(3) S → DS &#123;backpatch(S1.CHAIN, D.CODE); emit(goto D.CODE); S.CHAIN=D.CHAIN;&#125;
for语句的翻译
for语句的目标结构如下图所示,一个典型的文法结构为S→ for i:=E1 step E2 until E3 do S1

相当于实现语句
i:=E1;goto over;again: i = i + E2;over: if i &lt;= E3 then 		S1;		goto again;
(1) F1 → for i:=1 &#123;	P = entry(i.NAME);	emit(:=, 1,_, P);	F1.PLACE = P;		F1.CHAIN = ip; // 代表标签over	emit(goto 0);  // 向后转移，不知道over的入口等待回填		F1.AGAIN = ip; // 上一步ip自增，就代表again的入口&#125;(2) F2 → F1 step 1 &#123;	F2.AGAIN = F1.AGAIN;	F2.PLACE = F1.PLACE;		emit(F2.PLACE, F2.PLACE, + , 1);	backpatch(F1.CHAIN, ip); //此时ip已加1，代表over的入口，可以回填&#125;(3) F3 → F2 to N &#123;	F3.AGAIN = F2.AGAIN;	F3.CHAIN = ip; // F3的出口取决于S1，暂时未知，等待回填	emit(if F2.PLACE &gt; N goto 0;) // 直接用F2.PLACE，因为没有更新操作&#125;(4) S → F3 do S1 &#123;	emit(goto F3.AGAIN);	backpatch(S1.CHAIN, F3.AGAIN); // 向前转移，S1上链上语句转移到again		S.CHAIN = F3.CHAIN; // 获得程序的出口,但是依然未知&#125;
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Compilers</tag>
      </tags>
  </entry>
  <entry>
    <title>软件工程绪论</title>
    <url>/2025/07/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B0-%E7%BB%AA%E8%AE%BA/</url>
    <content><![CDATA[软件
1946年，世界上第一台计算机诞生；
1958年，John Wilder Tukey正式提出软件的概念；
软件是指计算机程序及其相关文档的集合。它是由一系列指令和数据组成，用于实现特定的功能或解决特定的问题。
软件可以运行在计算机上，通过执行程序中的指令来完成各种任务。

程序：按事先设计的功能和性能需求执行序列
数据：程序能正常操作信息的数据结构；
文档：与程序开发、维护和使用有关的图文材料

软件的特点

软件是开发的或者是工程化的，并不是制造的
软件生产是简单的拷贝
会多次修改
软件开发环境影响较大
开发时间和工作量难以估计
几乎没有客观衡量标准
测试困难
不会磨损和老化
维护易带来新的问题

软件的双重作用

提供计算能力的一种产品，产生、管理、获取、修改、显示或传输信息；
开发其他软件产品的工具

软件的分类

按软件功能分类：系统软件，支撑软件，应用软件；
按服务对象分类：项目软件，产品软件；

软件的发展
软件迅速发展的原因：计算需求， 嵌入需求，业务需求，架构需求；

个体化：1950s-1960s;
作坊式：1960s-1970s;
工程化：1970s-1980s;
产业化：至今；

软件危机
软件危机是指计算机软件开发和维护过程中所遇到的一系列严重问题。
1968年 NATO 会议提出“软件危机；
软件危机具体表现

项目超出预算
项目超过计划完成时间
软件运行效率很低
软件质量差
软件通常不符合要求
项目难以管理并且代码难以维护
软件不能交付

软件危机发生原因

客观上：软件本身特点

逻辑部件多
规模庞大


主观上：不正确的开发方法

忽视需求分析
错误认为软件开发等于程序编写
轻视软件维护



软件工程
消除软件危机的解决方案是采用软件工程的方法：用现代工程的概念原理、技术和方法去指导软件的开发、管理和维护；
IEEE将软件工程定义为

实践上：应用系统化的 、 学科化的 、 定量的方法 来开发 、 运行和维护软件 ；
研究上：对上述各种方法的研究 ；

软件工程的目标是在给定的时间和预算内，按照用户的需求，开发易修改、高效、可靠、可维护、适应力强、可移动、可重用的软件 。
软件工程的三要素

工具：它为软件工程的过程和方法提供自动化或半自动化的工具支持。
方法：软件工程方法是完成软件工程项目的技术手段。
过程：过程贯穿软件开发的各个环节，在各环节之间建立里程碑；

软件工程的四个阶段

传统的软件工程；
对象工程；
过程工程；
构件工程；

软件工程的基本原则

使用阶段性生命周期计划的管理
进行连续的验证
保证严格的产品控制
使用现代编程工具 工程实践
保持清晰的责任分配
用更好更少的人
保持过程改进

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Software-Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>软件过程模型</title>
    <url>/2025/07/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B1-%E8%BD%AF%E4%BB%B6%E8%BF%87%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[软件生命周期
定义：软件产品或软件系统从设计、投入使用到被淘汰 的全过程。

软件过程
定义： 软件过程定义了软件生产的一些列活动，这些活动贯穿于软件开发的全过程

沟通：包括软件设计者和客户，客户提出需求，软件设计者收集材料或其他活动
计划：讨论使用什么方法实现需求
建模：设计模型满足需求
构造：编码和测试
部署：软件交付给客户

三个流派：


能力成熟度模型CMM：


CMU-SEI的CMM是公认的有关软件工程和管理实践的最好的软件过程。


为评估软件组织的生产能力提供了标准，为提高软件组织的生产过程指明了方向。


CMM1初始级：有能力的核心成员发挥；
CMM2可重复级：基本的项目管理；
CMM3已定义级：过程标准化，开发过程实现标准化和文档化；
CMM4量化管理级：产品和过程已建立了定量的质量目标；
CMM5优化级：持续的过程改进，可集中精力改进过程，采用新技术、新方法；







ISO 9000质量标准


软件计数软件过程评估：SPICE


CMM的关键过程域：



CMM
过程




CMM2:可重复阶段
1.需求管理： requirement management2.软件项目计划： software project planning3.软件项目跟踪和监督： software project tracking oversight4.软件子合同管理： software subcontract management5.软件质量保证： software quality assurance6.软件配置管理： software configuratione management


CMM3:已定义阶段
1.组织过程焦点： organization process focus2.组织过程定义： organization process definition3.培训大纲： training program4.集成软件管理： intergrated software management5.软件产品工程： software product engineering6.组间协调： intergroup coordination7.同行评审： peer review


CMM4:已管理阶段
1.定量管理过程： quantitative process management2.软件质量管理： software quality management


CMM5:优化阶段
1.缺陷预防： defect prevention2.技术改革管理： technology change management3.过程更改管理： process change management



软件过程模型
软件过程模型是软件开发全部过程、活动和任务的 结构框架；
它能直观表达软件开发全过程，明确规定要完成的主要活动、任务和开发策略。软件过程模型也常称为： 软件开发模型，软件生存周期模型，软件工程范型；
常见过程模型：

瀑布模型
增量模型
演化过程模型
喷泉模型
…

瀑布模型
软件开发过程与软件生命周期一致，也是经典的生命周期模型[Winston, 1970];
经典的瀑布模型

特点：

阶段间具有顺序性和依赖性；
推迟实现的观点；
每个阶段必须完成规定的文档；每个阶段结束前完成文档审查，及早改正错误。

带反馈的瀑布模型

主要问题：线性过程太理想化

各个阶段的划分完全固定，阶段之间产生大量的文档，极大地增加了工作量；
由于开发模型是线性的，用户只有等到整个过程的末期才能见到开发成果，从而增加了开发的风险；
早期的错误可能要等到开发后期的测试阶段才能发现，进而带来严重的后果。

瀑布模型适用于系统需求明确，技术成熟，工程管理较为严格的场合；
增量过程模型
增量过程模型是一种非整体开发的模型，是一种进化式的开发过程。
它允许从部分需求定义出发，先建立一个不完整的系统，通过测试运行这个系统取得经验和反馈，进一步使系统扩充和完善。如此反复进行，直至软件人员和用户对所设计的软件系统满意为止。

特点：

增量适用于小而可用的软件，在前面增量的基础上开发后面的增量
每个增量的开发可用瀑布或快速原型模型
快速迭代

优点：

增量包概念的引入，以及它不需要提供完整的需求。只要有一个增量包出现，开发就可以进行。
在项目的初始阶段不需要投入太多的人力资源。
增量可以有效地管理技术风险。

缺点：每个增量必须提供一些系统功能，这使得开发者很难根据客户需求给出大小适合的增量。
快速应用开发模型（RAD）
作为增量过程模型的一种，是一个增量过程模型，强调短暂的开发周期。
RAD 模型是瀑布模型的“高速”变体，通过基于组件的构建方法实现快速开发。如果需求以及项目范围得到明确界定， RAD 能使开发团队在很短的时间内（如 60 到 90 天）建立一个“全功能系统”。

缺点：

对大型项目而言 RAD 需要足够的人力资源。
开发者和客户都要实现承诺，否则将导致失败。
并非所有系统都适合（不能合理模块化的系统、高性能需求并且要调整构件接口的、技术风险很高的系统均不适合）。

演化模型
演化模型包括原型模型和螺旋模型，思想是首先实现软件最核心的最重要的功能；


原型模型：客户定义一个总体目标集，但是他们并不清楚系统的具体输入输出；或开发者不确定算法的效率、软件与操作系统是否兼容以及客户与计算机交互的方式。


缺点：设计者在质量和原型间有所折衷，客户意识不到一些质量问题；



螺旋模型：结合了瀑布模型和原型模型的特点，强调风险管理，适用于大型系统的开发；





制定计划：确定软件目标，选定实施方案，弄清项目开发的限制条件。
风险分析：分析所选方案，考虑如何识别和消除风险。
实施工程：实施软件开发。
客户评估：评价开发工作，提出修正建议。


优点：

支持用户需求的动态变化。
原型可看作形式的可执行的需求规格说明，易于为用户和开发人员共同理解，还可作为继续开发的基础，并为用户参与所有关键决策提供了方便。
螺旋模型特别强调原型的可扩充性和可修改性，原型的进化贯穿整个软件生存周期，这将有助于目标软件的适应能力。
螺旋模型为项目管理人员及时调整管理决策提供了方便，进而可降低开发风险。



缺点：

如果每次迭代的效率不高，致使迭代次数过多，将会增加成本并推迟提交时间；
使用该模型需要有相当丰富的风险评估经验和专门知识，要求开发队伍水平较高。



适用场合：支持需求不明确、特别是大型软件系统的开发，并支持面向规格说明、面向过程、面向对象等多种软件开发方法，是一种具有广阔前景的模 型。




喷泉模型
喷泉模型是一种以 用户需求 为动力，以 对象 为驱动的模型，主要用于描述 面向对象 的软件开发过程。

优点：该模型的各个阶段没有明显的界限，开发人员可以同步进行开发，可以提高软件项目开发效率，节省开发时间，适应于面向对象的软件开发过程。
缺点：由于喷泉模型在各个开发阶段是重叠的，在开发过程中需要大量的开发人员，因此不利于项目的管理。此外这种模型要求严格管理文档，使得审核的难度加大，尤其是面对可能随时加入各种信息、需求与资料的情况。
基于构件的模型
四阶段：

需求
组件分析：根据需求规格搜索可满足该需求的组件。通常情况下，没有完全匹配的情况，因而组件通常需要加以修改。
系统设计：与其它模型的系统设计有所不同，因为该模型是基于重用的。设计者必须考虑到重用的概念，但遗憾的是，如果没有可重用的组件，还要设计新的软件。
开发和集成：在这个阶段，组件集成到系统中。

优点：

组件的重用，降低了成本和风险，节约了时间；

缺点：

模型复杂
导致需求的折衷，进而导致系统不能完全符合需求
无法完全控制所开发系统的演化
项目划分的好坏直接影响项目结果的好坏

敏捷开发模型
是一种从 90 年代开始逐渐引起广泛关注的一些新型软件开发方法。


迭代与增量开发：敏捷开发将整个软件项目分成多个小的迭代（通常是2到4周），每个迭代都是一个完整的开发周期，包括需求分析、设计、编码、测试和交付。在每个迭代结束时，都会交付一个可以运行的产品版本，这个版本可能是部分功能的实现，但能够为用户或利益相关者提供价值。


重视客户和用户的反馈：敏捷开发模型注重与客户和用户的频繁沟通和合作。在每个迭代结束时，团队会向客户展示当前的成果，并根据他们的反馈调整下一步的开发方向。这种方式使得项目可以快速适应需求的变化，确保最终交付的产品更符合用户期望。


跨职能团队：敏捷团队通常是小型的、跨职能的团队，包含开发人员、测试人员、产品经理和用户代表等。这种团队结构使得每个人都能为产品的不同方面贡献力量，并能快速响应问题和需求。


自组织和自管理：敏捷强调团队的自组织能力，团队成员可以根据需求自行安排工作，决定如何实现目标。管理者不会详细指挥每个步骤，而是让团队在一定框架下自行运作，这有助于提升团队的灵活性和响应速度。


持续改进：敏捷开发鼓励持续的反思和改进。团队在每次迭代结束后通常会进行一个回顾会议（Retrospective），讨论在过去的迭代中哪些方面做得好，哪些方面可以改进，以便在下一次迭代中做得更好。


早期和持续的交付：敏捷模型的目标是尽可能早地向用户提供有价值的软件。团队会在项目的早期阶段就交付一个可工作的系统，并在后续的迭代中不断增加新功能。


适应性：敏捷方法强调对变化的接受，认为变化是不可避免的。无论是需求变化还是市场变化，敏捷团队都能快速调整计划和优先级，以适应新的形势。


常见框架：敏捷开发模型下有多种实施框架，其中最常见的包括Scrum、Kanban和Extreme Programming（XP）。这些框架提供了具体的流程和实践，帮助团队有效地进行敏捷开发。


工作方式透明：敏捷团队通过每日站会（Daily Stand-up Meeting）等方式，让所有团队成员了解彼此的工作进展，暴露潜在的问题，并快速做出调整，确保项目的顺利进行。


文档减少，但非无文档：与传统的瀑布模型相比，敏捷开发减少了过多的文档要求，更注重可交付的软件。然而，敏捷并不排斥文档，而是提倡根据项目实际需求编写足够的文档。


优点：

快速响应变化，适应市场需求
早期交付可用的产品，增加市场竞争力
增强团队协作，减少沟通障碍
持续改进，确保产品质量不断提升

缺点：

需求变化频繁时，可能导致开发团队的工作压力增大
需要高效的沟通和跨职能合作，否则可能影响效率
项目初期规划不够详细，可能增加项目后期的复杂性

如何选择过程模型？

软件开发模型是不断发展的，各种软件开发模型各有优缺点
选用时不必拘泥于某种模型，可组合多种模型， 也可根据实际创建新的模型

参考原则

在前期需求明确的情况下，尽量采用瀑布模型或改进的瀑布模型。
在用户无系统使用经验，需求分析人员技能不足情况下一定要借助原型。
在不确定因素很多，很多东西前面无法计划的情况下尽量采用增量迭代和螺旋模型。
在需求不稳定的情况下尽量采用增量迭代模型。
在资金和成本无法一次到位的情况下可采用增量模型，软件产品多个版本进行发布。
对于完成多个独立功能开发可以在需求分析阶段就进行功能并行，但每个功能内部都应该遵循瀑布模型。
对于全新系统的开发必须在总体设计完成后再开始增量或并行。
对于编码人员经验较少的情况下建议不要采用敏捷或迭代等生命周期模型。
增量、迭代和原型可以综合使用，但每一次增量或迭代都必须有明确的交付和出口原则。

参考原则：

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Software-Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>软件维护技术</title>
    <url>/2025/07/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B10-%E8%BD%AF%E4%BB%B6%E7%BB%B4%E6%8A%A4%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[概念
定义：由于软件产品出现问题 或需要改进，而对代码及相关文档进行 修改，其目的是对现有软件产品进行修 改的同时保持其完整性。
必要性

改正错误；
改善设计；
实现软件的改进；
能与其他系统进行交互；
能够为使用不同的硬件、软件、系统的新性能以及通讯设备等而对软件进行改进；
能够完成遗留程序的移植；
软件推出使用；

成本
软件维护阶段一般要消耗软件生命周期中经费开支的大部分；
维护的类型

纠错性维护：在软件交付使用后，因开发时测试的不彻底、不完全，必然会有部分隐藏的错误遗 留到运行阶段。这些隐藏下来的错误在某些特定的使用环境下就会暴露出来，为了识别和纠正软件错误、改正软件性能上的缺陷、排除实施中的误用，应当进行 的诊断和改正错误的过程就叫做纠错性维护。
适应性维护：在使用过程中， 外部环境（新的硬、软件配置）或者数据环境（数据库、数据格式、数据输入/输出方式、数据存储介质）可能发生变化，为使软件适应这种变化，而去修改软件的过程就叫做适应性维护
完善性维护：在软件的使用过程中，用户往往会对软件提出新的功能与性能要求，为了满足这些要求，需要修改或再开发软件，以扩充软件功能、增强软件性能、改进加工效率、提高软件的可维护性，这种情况下进行的维护活动叫做完善性维护。 实践表明，在几种维护活动中，完善性维护所占的比重最大，即大部分维护工作是改变和加强软件，而不是纠错。完善性维护不一定是救火式的紧急维修，而可以是有计划、有预谋的一种再开发活动。事实证明，来自用户要求扩充、加强软件功能、性能的维护活动约占整个维护工作 的50％。
预防性维护：预防性维护是为了提高软件的可维护性、可靠性等，为以后进一步改进软件打下良 好基础，其定义为：采用先进的软件工程方法对需要维护的软件或软件中的某一部 分（重新）进行设计、编制和测试。


维护活动的困难性

配置管理工作不到位
人员变动造成的影响
许多软件的可读性差
任务紧、时间急的情况下处理维护请求

维护中面临的问题
技术上，问题可能有对程序的理解困难，重新测试，作影响分析，以及软件的可维护性差的问题；
影响分析的目标：

决定改变的范围：这对合理计划和完成工作有重要意义
对完成工作所需的资源进行精确的估计
分析改变的费用/效益比
由于对软件进行变更往往是牵一发而动全身 的，因此如果给出了一个变更，必须考虑到 与之相关的其他复杂情况

决定软件可维护性的主要因素：可理解性，可测试性，可修改性，可移植性，可重用性
影响软件可维护性的维护环境因素：软件维护文档，软件运行环境，维护组织，软件维护质量
管理上，可能包括契合目标的组织，人力资源，过程，如何组织维护活动，外包
估算费用，可采用如下参数模型

是维护用的总工作量，是生产性工作量，是经验常数，是复杂程度，是维护人员对软件的熟悉程度；
有时费用也可以由专家判断，根据其他类似的工程类推和工作分解结构；
软件维护模型和技术
软件维护 过程模型：

软件维护技术包括：程序理解，软件再工程
程序理解
主要工具包括代码浏览工具Source Insight...
程序理解的任务：以软件维护、升级和再工程为目的，在不同的抽象级别上建立基本软件的概念模型，包括从代码本身的模型到基本应用领域的模型，即建立从问题 /应用域到程序设计/实现域的映射集
具体包括


通过检查单个的程序设计结构，程序被表示成抽象语法树、符号表或普通源文本


尽量做到程序隐含信息的显性表示及程序内部关系的可视化


从源代码中提取信息，并存放在通用的数据库中，然后通过查询语言对数据库进行查询


检查程序构造过程中的结构关系，明确表示程序组成部分之间的依赖关系。


识别程序的高层概念，如标准算法、数据结构、语法及语义匹配等。


软件再工程：指对现有软件进行仔细审查和改造，对其进行重 新构造，使之成为一个新的形式，同时包括随之产生的对新形式的实现。


软件再工程
模型图
定义：软件再工程（Re-engineering）指对现有软件进行仔细审查和改造，对其进行重 新构造，使之成为一个新的形式，同时包括随之产生的对新形式的实现

库存目录分析
对软件组织的每个应用系统都进行预防性维护是不现实的，也是不必要的。
一般说 来，下述3类程序有可能成为预防性的对象：

该程序将在今后数年内继续维护的对象
当前正在成功地使用着该程序
可能在最近的将来要对该程序做较大程度的修改或扩充

应该仔细的分析库存目录，按照业务重要程度、寿命、当前可维护性、预期的修改 次数等标准，把库中的应用小排序，从中选出再工程的侯选者，然后合理地分配再 工程所需要的资源
文档重构
老程序固有的特点缺乏文档，根据具体情况可采用下述3种方法之一来处理这个问 题：

如果一个程序是相对稳定的，正在走向生命的终点，而且可能不会再修改它，则不必为它 建立文档
为了便于今后的维护，必须更新文档，但是由于资源有限，应该采用“使用时建立文档” 的方法，也就是说，不是一下子把某应用系统的文档全部都重建起来，而是只建立系统中 当前正在修改的那些部分的完整文档。
如果某应用系统是用户完成业务工作的关键，而且必须重构全部文档，则仍然应该尽量把 文档工作减少到必需的最小量

逆向工程
软件的逆向工程是，分析程序以便在比源程序更高的抽象层次上创建出程序的某种 描述的过程，也就是说，逆向工程是一个恢复设计结果的过程。软件逆向工程是分析目标系统，识别系统的 构件及其交互关系，并且通过高层抽象或其他形式来展现目标系统的过程。 对逆向工程而言，抽象的层次、完备性、工具与分析人员协同工作的程度、过程的 方向性等因素是需要考虑的。

逆向工程的主要内容包括


数据的逆向工程:数据的逆向工程发生在不同的抽象层次 ,包括内部数据结构的逆向工程 ，数据库结构的逆向工程 ▪
对新数据模型实施再工程

构造一个初始的对象模型
确定候选键
精化实验性的类
定义一般化关系
找出关联关系



处理的逆向工程：为了理解过程抽象，需要在不同的抽象级别（系统级、程序级、构件级、模式级和 语句级）分析代码

对大型系统，通常用半自动方法完成逆向工程
使用自动化工具帮助软件工程师理 解现有代码的语义，然后将该过程的结果传递给重构和正向工程工具以完成再工程 过程。



用户界面的逆向工程：包括解决以下问题

界面必须处理的基本动作是什么？
系统对这些动作的行为反应的简要描述是什么？
有哪些界面的等价概念是相关的？



逆向工程的工具一般包括：

静态模型逆向工具 ：Rational Rose ，Rigi ， JBPAS
动态模型逆向工具 ：SCED ，ISVis ， Borland Together

代码重构
某些老程序的体系结构比较合理，但是，一些模块的编码方式却是难于理解、测试 和维护的。
在这种情况下，可以重构这些模块的代码，通常，代码重构并不修改程序的体系结构，它只关注个体模块的设计细节以及在模 块中定义的局部数据结构。
如果重构扩展到模块边界之外并涉及软件体系结构，则重构变成了正向工程。
数据重构
对数据体系结构差的程序很难进行适应性和完善性维护，因此，数据体系结构比源 代码对程序的长期生存力有更大的影响。
数据重构是一种全范围的再工程活动，由于数据结构对程序体系结构及程序中的算法有很大影响，对数据的修改必然会导 致程序体系结构或代码层的改变
正向工程
正向工程也称为革新或改造。
正向工程过程应用现代软件工程的概念、原理、技术和方法，重新开发现有的某些 应用系统。
在大多数情况下，经过正向工程过程后得出的软件，不仅重新实现了现有系统的功 能，而且增加了新功能，提高了整体性能
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Software-Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>软件管理技术</title>
    <url>/2025/07/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B11-%E8%BD%AF%E4%BB%B6%E7%AE%A1%E7%90%86%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[概念
定义
计划、协调、度量、监控、控制及报告等管理方法在软件开 发和维护中的具体应用，以保证整个过程是系统的、有原则 的、可量化的
四要素4P


人员People：关键业务领域：招聘、选拔、绩效管理、培训、 薪酬、职业发展、组织和工作设计、团队/文化的发展。一个项目管理的好坏，很大程度就体现在团队的建设和管理上。人力资源管理成熟度模型（PCMM） PCMM是通过对人力资源管理的如人力资源规划、薪酬管理、绩效管理、组织管理、职 业规划、培训管理、知识管理等模块，按初始级、重复级、定义级、定量级和优化级这五 个递进层级进行详细描述和分级，建立企业人力资源管理的成熟程度评价模型，以此来对 企业目前人力资源管理现状进行评级，寻找不足和差距，以此来明确未来的发展方向。
用人的原则：人和人是不一样的，知识、技能可以培训而改变，但人格是很难改变的 ，应该用人之所长
项目中的三架马车：项目负责人，职能部门经理，项目成员；
项目目标包括：商业目标，过程目标，行为目标
如果各个因素的目标一致程度很大 对于项目成功的支持就越大
团队成长如下图所示



产品Product：在策划一个项目以前，应当建立产品的目标和 范围，应考虑其他解决办法，以及技术和管理应当被约束。
在项目活动中，直接构造产品所需的工程活动比例是最高的。
不同类型的产品所需要的工程活动特征也不一样，分为核心类产品开发，产品的客户化开发，系统的应用集成


过程Process：软件开发的一个全面计划。


项目Project：理解成功项目管理的关键因素，掌握项目计划、 监控和控制的一般方法


软件度量
含义
一种量化衡量方法,使得人们可以理解和把握软件项目的(生产)效率(或者所需要的劳动量)
目的

描述（项目和过程）
评估（状态和质量）
预测（为计划）
改进（产品质量和过程性能）

软件质量和组织绩效的决定因素
关键因素：过程、人、产品、技术。
过程处于三角的中心，连接其它三个因素；

分类

面向规模的度量：一定时间产生的代码行数， 执行速度，文件页数，错误和缺陷数
面向功能的度量：功能性，可靠性，可维护性，复杂性，效率，其他质量指标
面向对象的度量
面向用例的度量

直接测量
这是一种基于规模的度量，比如基于代码行的度量
优点

LOC、KLOC和相关度量容易计算
许多现有的软件估算模型都使用LOC和KLOC作为一项重要输入
有大量的关于LOC的文献和数据

缺点

LOC依赖于使用的语言，这对短小精悍的程序不利
不太适用于非过程化语言
LOC在设计完成的时候才能计算，估算需要一定程度的细节，而这些细节可能很难获得， 例如，项目计划人员难于在分析和设计完成之前估算LOC

间接度量
一般指功能点度量，功能点数从直接度量软件信息域和评估软件复杂性的经验量化关系中获得
步骤： 先算未调整功能点总计数UFC ，再算功能点FP

一般指复杂性调整值，一般有14项，取值在0~5；

系统需要可靠的备份和恢复么？
需要进行数据通信么？
有分布式处理功能么？
性能重要么？
将该系统运行在一个现有的操作系统中么？
系统要求在线输入数据么？
在线输入数据要求在多个屏幕和操作 之间建立输入事务么？
主文件是否在线更新？
输入、输出、文件或查询是否复杂？
内部处理是否复杂？
代码是可重用的么？
设计中包括数据（流程）转换或安装 么？
系统要为不同的机构设计不同的安装 方法么？
应用程序便于变更么？易于用户使用 么？

面向功能点的度量标准 计算：

每FP的错误数，即总的错误数除以总的FP数。
每FP的缺陷数，即总的缺陷数除以总的FP数。
每FP的文档页数，即总的文档页数除以总的FP数。
每人月的FP数，即总的FP数除以总的人月数

有趣的是，代码行数和功能点之间的关系依赖于编程语言；
项目估算
项目成本模型遵循以下经验公式：


常量A:由组织实践和软件类型决定
常量B：取值在;
常量M：反应产品，过程和人力属性
Size是软件代码规模的估算，也可以是功能点和目标点

算法成本估算示意图

不同软件开发阶段的估算的不确定性

COCOMO模型
COCOMO（构造性成本模型）是一个经验模型, 通过收集大量的软件项目（63个） 的数据而获得。
它已得到广泛的证明。可用于公共领域并且很多公共和商业工具都支持它。
应用广泛，并得到了不同组织的评价。
有较长的历史，于1981年第一次实例化；

项目计划
软件开发项目的进度安排有两种方式：

系统最终交付日期已经确定，软件开发部门必须在规定期限内完成；
系统最终交付日期只确定了大致的年限，最后交付日期由软件开发部门确定。

进度安排落空，会导致市场机会的丧失，使用户不满意，而且也会导致成本的增加。
因此，在考虑进度安排时，要把工作量与花费时间联系起来，合理分配工作量, 利 用进度安排的有效分析方法严密监控软件开发的进展情况，使软件开发进度不致拖延；
当几个人共同承担软件开发项目中的某一任务时，人与人之间必须通过交流来解决各自承担任务之间的接口问题，即所谓通信问题。
通信需花费时间和代价，会引起软件错误增加，降低软件生产率。
若两个人之间需要通信，则称在这两个人之间存在一条通信路径。如果一个软件开 发小组有n 个人，每两人之间都需要通信，则总的通信路径有n(n-1)/2 (条)。

一个软件任务由一个人单独开发，生产率最高；
而 对于一个稍大型的软件项目，一个人单独开发，时间太长。因此软件 开发小组是必要的。
但是，开发小组不宜太大，成员之间避免太多的通信路径。
在开发进程中，切忌中途加人，避免太多的生产率损失。

任务的确定和并行：

当参加同一软件工程项目的人数不止一人的时候，开发工作就会出现 并行情形。
软件开发进程中设置许多里程碑
里程碑为管理人员提供了指示项目 进度的可靠依据。
软件工程项目的并行性提出了一系列的进度要求。


进度安排的方法：甘特图， PERT技术和CPM方法等

可以把用于一般开发项目的进度安排的技术和工具应用于软件项目。
为监控软件项目的进度计划和工作的实际进展情况，为表现各项任务 之间进度的相互依赖关系，需要采用图示的方法。
在图示方法中，必须明确标明：

各个任务的计划开始时间，完成时间；
各个任务完成标志（即○文档编写和△评审）；
各个任务与参与工作的人数，各个任务与工作量之间的衔接情况；
完成各个任务所需的物理资源和数据资源



甘特图
在甘特图中，每一任务完成的标准，不是以能否继续下一阶段任务为标准，而是以 必须交付应交付的文档与通过评审为标准。因此在甘特图中，文档编制与评审是软 件开发进度的里程碑。

PERT技术和CPM方法
PERT技术叫做计划评审技术，CPM方法叫做关键路径法，它们都是安排开发进度， 制定软件开发计划的最常用的方法。 它们都采用网络图来描述一个项目的任务网络，也就是从一个项目的开始到结束， 把应当完成的任务用图或表的形式表示出来。


项目的追踪和控制
软件项目管理一项重要工作就是在项目实施过程中进行追踪和控制：

定期举行项目状态会议。由每位项目成员报告其进展和遇到的问题。
评价在软件工程过程中所产生的所有评审的结果。
确定由项目的计划进度所安排的可能选择的正式的里程碑。
比较在项目资源表中所列出的每一个项目任务的实际开始时间和计划开始时间。
非正式地与开发人员交谈，以得到他们对开发进展和刚冒头的问题的客观评价。
当问题出现的时候，项目管理人员必须实行控制以尽快地排解问题

软件项目的组织与计划

制定计划
软件项目组织的建立
人员配备

制定计划
软件开发项目的计划涉及到实施项目的各个环节，带有全局性质。

计划的合理性和准确性往往关系着项目的成败。
计划应力求完备。要考虑到一些未知因素和不确定因素，考虑到可能的修改。
计划 应力求准确。尽可能提高所依据数据的可靠程度。

指定计划目标和进行风险分析

制定计划的目的就是要回答：这个软件项目的范围是什么？需要哪些资源？花费多 少工作量？要用的成本有多少？以及进度如何安排等等一系列问题。
这步工作应当以系统计划为基础，以系统规格说明为依据。
在开发工作尚未开始之前，准确回答这些问题是十分困难的。需要通过以往的开发 经验做出估算，很难达到准确。
从估算出发，项目必然带有一定的风险。估算的准确性越差，风险也就越大。研制 的软件项目越复杂，规模越大，结构化程度越低，资源、成本、进度等因素的不确 定性越大，承担这一项目所冒的风险也越大。
组织软件项目必须事先认清可能构成风险的因素，并研究战胜风险的对策，只有这 样才能避免出现灾难性的后果，取得项目预期的成果。

软件计划的类型

项目实施计划（软件开 发计划） ：这是软件 开发的综 合性计划， 通常应包 括任务、 进度、人 力、环境、 资源、组 织等多个 方面。
质量保证计划 ：把软件开 发的质量 要求具体 规定为每 个开发阶 段可以检 查的质量 保证活动。
软件测试计划 ：规定测试 活动的任 务、测试 方法、进 度、资源、 人员职责 等。
文档编制计划 ：综合支持计 划 软件分发计 划 规定所开 发项目应 编制的文 档种类、 内容、进 度、人员 职责等。 规定对用 户进行培 训的目标、 要求、进 度、人员 职责等。
用户培训计划  ：软件开发 项目完成 后，如何 提供给用 户。 规定软件 开发过程 中所需要 的支持， 以及如何 获取和利 用这些支 持

项目实施计划中任务的划分
如何进行工作划分是实施计划首先应解决的问题。常用的计划结构有：


阶段项目计划：按软件生存期，把开发工作划分为若干阶段，对每一阶段工作做出计划。 再把每一阶段工作分解为若干任务，做出任务计划。还要把任务细分为若干步骤，做出步 骤计划。


任务分解结构WBS：按项目的实际情况进行自顶向下的结构化分解，形成树形任务结构。进一 步把工作内容、所需工作量、预计完成的期限也规定下来。



任务责任矩阵：在任务分解的基础上，把工作分配给相关的人员，用一个矩阵形表格表示 任务的分工和责任。



软件项目组织建立
开发组织采用什么形式，要针对软件项目的特点来决定，同时也与参与人员的素质 有关。


组织原则 ：

尽早落实责任：在软件项目工作开始时，要尽早指定专人负责。使他有权进行管理，并对任务的完成负全责。
减少接口：一个组织的生产率随完成任务中存在的通信路径数目增加而降低。 要有合理的人员分工、好的组织结构、有效的通信，减少不必要的生产率的损失。
责权均衡：软件经理人员所负的责任不应比委任给他的权力还大。



组织结构的模式

按课题划分的模式 把软件开发人员按课题组成小组，小组成员自始至终参加所承担课题的各项任务。他们应负责 完成软件产品的定义、设计、实现、测试、复查、文档编制、甚至包括维护在内的全过程。
按职能划分的模式 把参加开发项目的软件人员按任务的工作阶段划分成若干个专业小组。要开发的软件产品在每 个专业小组完成阶段加工（即工序）以后，沿工序流水线向下传递。例如，分别建立计划组、需求 分析组、设计组、实现组、系统测试组、质量保证组、维护组等。各种文档资料按工序在各组之间 传递。
矩阵形模式 这种模式实际上是以上两种模式的复合。一方面，按工作性质，成立一些专门组，如开发组、 业务组、测试组等；另一方面，每一个项目又有它的经理人员负责管理。每个软件人员属于某一个 专门组，又参加某一项目的工作。




程序设计小组的组织形式
小组内部人员的组织形式对生产率也有影响。现有的组织形式有三种。 （1）主程序员制小组 （2）民主制小组 （3）层次式小组



]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Software-Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>需求分析</title>
    <url>/2025/07/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B2-%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[概述
定义

确认系统必须具备的功能、性能、系统要求的运行环境，预测发展的前景；
以一种清晰，简洁，一致性且无二义性的方式，对待开发系统中各个有意义的方面的陈述的集合；

原因

需求分析错误和变更导致软件开发失败占软件失败因素1/3：缺少用户的输入，不完整的需求和规格说明书，需求和规格说明书变更；
希望对开发进行指导；
希望开发人员对用户要求理解；
希望用户理解开发人员；
测试部门有理可依；

过程

需求确认

获取-提炼-描述-验证


需求变更

随着开发过程，实时发生；
变更管理是将个人、团队和组织从现有状态转移/过渡到期望状态的结构化方法。 它授权雇员接受并理解当前业务环境中的变更。
在项目管理中，变更管理是指项目 变更被引入和接受后的项目管理过程，管理和控制需求基线的过程
需求变更控制系统 ：一个正式的文档，说明如何控制需求变更，建立变更审批系统



任务

建立分析模型：清晰准确的语言描述需求；
编写需求说明：《需求规格说明书》

分类

功能性需求：描述系统应该做什么，为用户和其它系统完成的功能，提供的服务（典型的是IPO：Input输入,Output输出,Process处理，以及数据存储,计算方式）；
非功能性需求：必须遵循的标准，外部界面的细节，实现的约束条件，质量属性（比如可拓展性，有效性...）

步骤

需求获取

软件需求的来源以及获取需求的方法
来源：用户目标，领域知识，投资者，运行环境，组织环境；
需求获取技术：采访，设定情景，原型，会议，观察商业过程和工作流


需求提炼

对应用问题和环境进行理解和分析，为问题设计的信息，功能和系统行为建立模型，将用户需求明确化，完全化
核心：建立分析模型
采用多种形式描述需求，建立需求的多种视图，解释更深的问题；
明确哪些需求更重要，尽早对项目达成共识


需求描述：

编写《需求规格说明书》SRS
对待开发系统的行为的完整描述，包含功能性需求和非功能性需求
完成的基本标志：形成完整规范的需求规格说明书；
SRS是为了用户和软件开发者双方对软件初始规定有共同理解，成为开发的基础


需求验证

后续开发发现前期需求文档的错误，返工的代价很大
有效性检查：检查不同功能使用不同功能的有效性
一致性检查：需求不应该冲突
完备性检查：应该包括所有用户想要的功能和约束
可行性检查：保证技术可实现
需求验证技术：需求评审，原型，编写测试用例，用户手册，自动化一致性分析



需求分析模型

当前系统-物理模型：模型化；
物理模型-逻辑模型：抽象化；
逻辑模型-逻辑模型：理解需求，表达需求；
逻辑模型-物理模型：实例化；
物理模型-目标系统：具体化；

分析建模

结构化分析模型：结构化，模块化，自顶向下
面向对象模型：5层次（主题层，对象类曾，结构层，属性层，服务层）5活动（标识对象类，标识结构，定义主题，定义属性，定义服务）
面向过程模型；

分析模型描述工具：

数据流图，数据字典和加工规约
控制流图，控制规约和状态变迁图
E-R图
用例图，对象关系图，对象行为图

需求建模工具




面向对象
面向过程




数据模型
实体-联系图（ERD），数据字典（DD）
类图，类关系图


功能模型
数据流图（DFD）
用例图


行为模型
状态变迁图（STD）
活动图，时序图，状态图



软件需求规格说明原则

描述做什么而不是怎样实现；
系统定义语言；
若软件是大型系统的一个元素，那么大系统也将包括在内；
系统运行环境；
认识模型；
可操作；
容许不完备性和扩充；
局部化和耦合；

结构

引言

需求分档的目的；
文档约定；
预期的读者和阅读建议；
产品范围；
参考文献；


综合描述

产品前景
产品功能与优先级
用户特征
运行环境
设计与实现上的限制
假设和依赖性


需求描述

功能需求
数据需求
性能需求
外部接口
设计约束
软件质量属性


附录（词汇表，分析模型，待定问题列表）
索引

面向过程的需求分析
结构化分析方法

面对数据流进行需求分析的方法；
适合于数据处理类型的需求分析；
建立模型：

功能模型：数据流图（DFD）
数据模型：数据字典（DD），实体联系图（ERD），
行为模型：状态变迁图（STD）




数据流图
基本成分

数据加工：表示对数据进行的操作；
外部实体：数据源和终点，表示位于系统之外的信息提供者或使用者；
数据流：表示数据和数据流向, 由一组固定成分的数据组成；
数据存储：表示需要保存的数据流向；


数据流

流向：

加工之间
加工与数据存储
加工和外部实体


命名：

具体意义的名字；
现有系统已有的名字


注意：

不需要激发条件；
不要动词（控制流）



合法的数据流：

非法的数据流：

数据加工

编号：说明层次分解的位置（分层DFD）
命名：顶层为项目名，避免只用动词，可以用操作+对象


数据存储

一般局限在某几层，命名和数据流相似；
流向存储或从存储流出的数据流不必命名；

DFD的表示方法

只描述数据的流动；
分为多层，子图和父图表示，逐步展开数据流的细节；
先画顶层DFD，自顶向下进行；
先考虑稳定状态，忽略系统的工作条件，出错处理，随时准备重画；

局部数据存储，只有出现在接口处的才有必要画出来；
字图图号为父图的加工号，顶层不编号；
默认原则：

父图-子图平衡：父图输入输出数据流 = 子图输入输出数据流
局部数据存储：出现在加工之间的接口时，才画出来
编号：子图图号为分解的父图中的加工号，同级子图在最后以数字序号区别，顶层不编号
分解程度合适：一般设定深度为层，各章各数据流图加工数目为

改进原则：


检查正确性


数据不守恒：某个加工输出的数据没有响应的数据来源，可能某个数据流被遗漏了；一个加工的输入并没有被用到；


数据存储的使用：判断是否存在只写不读，或者只读不写的数据存储


父图-子图平衡




提高可理解性

简化加工之间的联系：应该尽量减少加工返回输入输出数据流的数目，数据流越少，数据越独立；
注意分解的均匀；
适当的命名；



重新分解：子图发现问题后应该对父图重新分解


面向对象的需求分析
统一建模语言UML
UML是面向对象的系统分析与设计的建模语言，统一了面向对象建模的基本概念、术语及其图形符号，为不同领域的人员提供一个交流的标准。

系统及其边界


目的：识别什么在系统内，什么在系统外，进而识别出系统的职责；


典型的系统边界：硬件设备，组织，部门


方框代表边界


参与者actor

系统之外的需要用系统或者与系统交互的东西；
表示形式：actor，lable，decoration
小人表示actor

用例use case

系统，子系统或者类和外部的参与者交互的动作序列的说明；
包括可选的动作序列，会出现异常的动作序列；
用例是系统提供给外部可感知的功能单元，描述使用的情况；
目的：定义清晰的系统行为，但不解释系统的内部结构
椭圆+动宾结构：创建索引...

如何获取use case

参与者希望系统执行的任务；
参与者在系统访问的信息；
外界信息如何提供给系统；
系统的什么事情告知参与者；
如何维护系统；

用例特点

用例从使用系统的角度描述系统；
用例描述了用户提出了可见需求，对应具体的用户目标，注意：非功能性需求就是不可见的，登陆也一般不是具体的用户目标；
用例是对系统的动态描述，属于UML的动态建模部分；
识别用例时一个常见的错误是：把用例当成是单独的步骤、操作或事务的处理。

用例图中的关系

关联：参与者和其参与的用例之间的通信途径；
泛化：一般和特殊之间的关系，其中特殊用例继承了一般用例的特性并增加了新的特性
包含：其中一个用例的行为包含另一个用例，在基础用例上插入附加的行为，并且具有明确的描述
扩展：在基础用例上插入基础用例不能说明的扩展部分

关联association

泛化generalization

子用例继承父用例的行为和含义；
子用例也可以新增或覆盖父用例的行为和含义


包含include

箭头由基本用例指向被包含用例；
被包含用例在基本用例执行时必须被执行；
被包含用例也可单独执行;
如果两个以上的用例有共同的功能，则可以将这个功能分解到另一个用例中．
一个用例的功能太多时，可以用包含关系建模两个小用例。


扩展extend

箭头由拓展用例指向基本用例；
扩展用例无法单独被执行；
一个基本用例执行时，可以执行、也可以不执行扩展用例部分；
基本用例必须声明若干扩展点，扩展用例只能在扩展点增加新的新为和含义；

用例描述
主要组成

易犯的错误

只描述系统的行为，没有描述参与者的行为；
只描述参与者行为，不描述系统的行为；
在用用例描述中设计用户界面的设计
描述冗长

用例识别的两种方法：

基于参与者：识别与系统相关的参与者，对于每个参与者，识别出他们发起或参加的执行过程
基于执行过程：

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Software-Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>面向过程的需求分析</title>
    <url>/2025/07/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B3-%E9%9D%A2%E5%90%91%E8%BF%87%E7%A8%8B%E7%9A%84%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[结构化分析方法

面对数据流进行需求分析的方法；
适合于数据处理类型的需求分析；
建立模型：

功能模型：数据流图（DFD）
数据模型（数据对象描述）：数据字典，实体联系图（ERD），
行为模型：状态变迁图（STD）


结构化分析方法就是用抽象模型的概念，按照软件内部数据传递、变换 的关系，自顶向下逐层分解，直到找到满足功能要求的所有可实现的软件为止

数据流图

数据加工
数据源、终点（外部实体）
数据流
数据存储文件


数据流

表示数据和数据的流向；
两个加工可有多股数据流；
数据流的命名：具体意义的名字，现有系统已有的名字
不需要激发条件，不要动词（控制流）

数据加工

表示对数据的操作；
编号：说明层次分解的位置（分层DFD）
命名：顶层为项目名，避免只用动词

数据存储

表示数据的流向
存储和加工的方向；
一般局限在某几层；
命名和数据流相似；
流向存储或从存储流出的数据流不必命名；

数据流图DFD
局部数据存储，只有出现在接口处的才有必要画出来；
字图图号为父图的加工号，顶层不编号；
一般DFD的默认原则：

一般设定深度为3-5层；
各章各数据流图加工数目为7-2 - 7+2

DFD的改进原则：
检查正确性：数据守恒，数据存储的使用，子图和父图的平衡

数据不守恒：某个加工输出的数据没有响应的数据来源，可能某个数据流被遗漏了；一个加工的输入并没有被用到；
数据存储的使用：判断是否存在只写不读，或者只读不写的数据存储
简化加工之间的联系

应该尽量减少加工返回输入输出数据流的数目，数据流越少，数据越独立；
注意分解的均匀；


适当的命名；
重新的分解：子图发现问题后应该对父图重新分解；

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Software-Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>面向对象的需求分析</title>
    <url>/2025/07/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B4-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[统一建模语言UML
概念


系统及其边界


目的：识别什么在系统内，什么在系统外，进而识别出系统的职责；


典型的系统边界：硬件设备，组织，部门


方框代表边界




参与者actor

系统之外的需要用系统或者与系统交互的东西；
表示形式：actor，lable，decoration
小人表示actor



用例use case

系统，子系统或者类和外部的参与者交互的动作序列的说明；
包括可选的动作序列，会出现异常的动作序列；
用例是系统提供给外部可感知的功能单元，描述使用的情况；
目的：定义清晰的系统行为，但不解释系统的内部结构
椭圆+动宾结构：创建索引...



如何获取use case

参与者希望系统执行的任务；
参与者在系统访问的信息；
外界信息如何提供给系统...

用例做需求分析的特点

用例从使用系统的角度描述系统；
用例描述了用户提出了可见需求，对应具体的用户目标，比如非功能性需求就是不可见的，登陆也一般不是具体的用户目标；
用例是对系统的动态描述，属于UML的动态建模部分；

用例图中的关系

关联：参与者和其参与的用例之间的通信途径；
泛化：一般和特殊之间的关系，子用例继承父用例的行为和含义，子用例也可以新增或覆盖父用例的行为和含义
包含：其中一个用例的行为包含另一个用例，箭头由基本用例指向被包含用例，被包含用例在基本用例执行时必须被执行
扩展：拓展关系中，基本用例必须声明若干扩展点，扩展用例只能在扩展点增加新的新为和含义，箭头由拓展用例指向基本用例，扩展用例无法单独被执行；

用例描述的常见错误

只描述系统的行为，没有描述参与者的行为；
只描述参与者行为，不描述系统的行为；
在用用例描述中设计用户界面的设计
描述冗长

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Software-Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>系统设计概述</title>
    <url>/2025/07/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B5-%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[概述
软件设计：软件系统或组件的架构，构件，接口和其他特性的定义过程以及过程的结果

软件工程生命周期的一个活动
进行软件编码的基础
需求分析被转化成软件的内部结构
是连接用户需求和软件技术的桥梁

设计工程的活动包括以下：

顶层设计（架构设计）：描述软件的顶层架构和组织，划分不同的组件
详细设计：描述各个组件以便编码实现

软件设计主要为分解设计（将软甲映射为各个组件），可以包括系列模式设计
设计过程和质量
好的设计特点

设计必须实现在分析模型中包含的所有明确要求，必须满足客户所期望的所有隐含要求；
设计必须对编码人员、测试人员及后续的维护人员是可读可理解的；
设计应提供该软件的完整视图，从实现的角度解决数据、功能及行为等各领域方面的问题

设计指导原则

设计应该是一种架构
设计应该是模块化的
设计应该包含数据、体系结构、接口和组件各个方面

应该设计出系统所用的数据结构
应该设计出展现独立功能特性的各组件
应该设计出各组件与外部环境连接的各接口


设计由软件需求分析过程中获得信息驱动，采用可重复使用的方法导出
设计应该采用正确清楚的表示法

设计质量属性

功能性
易用性
可靠性
性能
可支持性：扩展性，适应性，可维护性

设计模型
模型输入：软件需求的数据模型，功能模型和行为模型
分类：数据设计，架构设计，接口设计，组件设计
分析模型到设计模型的转化
抽象
含义：忽略具体的信息，将不同事物看作相同事物的过程
抽象机制：参数化，规范化
规范化抽象：

数据抽象：描述数据对象的冠名数据集合
过程抽象：具有明确和有限功能的指令序列

体系结构
定义：软件整体结构和这种结构为系统提供概念上完整性的方式，可以通过以下模型表达

结构模型
框架模型
动态模型
过程模型
功能模型

设计模式
在给定上下文环境中一类共同问题的共同解决方案
微观结构：

实体模式
结构模式
行为模式
例如抽象工厂：提供一个创建一系列相关或仙湖依赖对象的接口，而无需制定他们具体的类

模块化
含义：软件被划分命名和功能相对对的多个组件，通过这些组件的集成来满足问题的需求
软件模块性：程序可悲之能管理的单一属性
模块化的理论依据：基于人类解决问题的观测数据
模块化的设计标准：

分解性：可分解为子问题
组合性：组装成可重用的组件
可理解性：可作为独立单元理解
连续性：需求小变化只影响单个模块
保护：模块内异常只影响自身
模块化和软件成本存在最小代价区间

信息隐藏
原则：模块应该具有彼此相互隐藏的特性，模块定义和设计时应当保证模块内信息不可以被不需要这些信息的模块访问
特点：抽象有助于定义构成软件的过程实体，信息隐藏原则定义和隐藏了模块内的过程细节和模块内的本地数据结构；
功能独立
含义：每个模块只负责特定的子功能，并且从程序结构的其他部分看，该模块具有简单的接口
好处：易于开发和维护
标准：模块独立性强=高内聚低耦合

内聚性：模块的功能相对强度
耦合性：模块之间的依赖程度

精化
含义：逐步求精的过程
与抽象的关系：抽象使设计使设计师确定过程和数据，精化有主语设计者在设计过程中揭示底层细节
重构
含义：不改变组件功能和行为条件下，简化组件设计的一种重组技术
方法：检查现有设计的冗余情况，未使用的设计元素，无效的算法，较差的构件方式或不恰当的数据结构，或者任何其他可优化设计的问题
设计技术
数据设计
含义：数据设计构建高层抽象的数据模型和信息模型
概念：

数据建模：数据字典，ER图，类图
数据结构：计算机存储和组织数据的方式
数据库：按照数据结构来组织，存储和管理数据的仓库
数据仓库

数据设计原则：

应用于功能和行为系统分析的原则也应适用于数据设计
所有的数据结构及其对应的操作都应该确定
建立数据字典并在数据定义和程序设计中应用
低层次的数据设计应该推迟到设计的后期过程
数据结构的表示应该只对直接使用数据结构中数据的模块可见
开发有用的数据结构及其对应操作的程序库
软件设计和编程语言应该支持抽象数据类型的定义与实现

概念数据模型
ER模型，描述实体，联系和属性；
物理数据模型
类图
体系结构设计
含义

系统需要执行的函数功能组件集（如数据库、计算模块）
组件之间通信、协同和合作的连接器
组件集成构成系统的约束
设计人员通过分析系统组成部分的已知特性，理解其整体特性的语义模型分析

风格和模式
数据中心架构

数据流系统架构

调用和返回架构

面向对象架构

层次架构

界面设计
原则

允许用户操作控制
减少用户记忆负担
保持界面一致

部署设计
含义

以部署环境创建开始，在整个生命周期阶段中处于逻辑设计和技术需求阶段
部署环境包含整个解决方案的逻辑架构和服务质量（QoS）需求
部署架构设计是一个反复迭代的过程，通常需要多次查看QoS要求和多次检查先前的设计，需要考虑了服务质量QoS需求的相互关系，平衡取舍相关问题成本以实现最佳解决方案，最终满足项目的业务目标
输出
部署架构
实施规范
实施计划：迁移计划，安装计划，用户管理计划，测试计划，滚动淘汰计划，灾难恢复计划，操作计划（运行书），培训计划
部署设计方法：
一般方法：估计处理器需求，估计安全传输的处理器需求，可用性和可拓展性的备份服务
设计分析：识别瓶颈，优化资源，管理风险

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Software-Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>面向对象的系统设计</title>
    <url>/2025/07/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B6-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[面向对象设计活动
包括系统架构设计，用例设计，类设计，数据库设计，用户界面设计；
架构设计
架构设计的目的是要勾画出系统的总体结构，这项工作由经验丰富的架构设计师主 持完成。

输入：用例模型、分析模型
输出：物理结构、子系统及其接口、概要的设计类


步骤


构造系统的物理模型

首先用UML的配置图（部署图）描述系统的物理架构
将需求分析阶段捕获的系统功能分配到这些物理节点上
配置图上可以显示计算节点的拓扑结构、硬件设备配置、通信路径、各个节点上运 行的系统软件配置、应用软件配置



设计子系统


对于一个复杂的软件系统来说，将其分解成若干个子系统，子系统内还可以继续划 分子系统或包，这种自顶向下、逐步细化的组织结构非常符合人类分析问题的思路； 每个子系统与其它子系统之间应该定义接口，在接口上说明交互信息，注意这时还不要描述子系统的内部实现，可用UML组件图表示；


划分各个子系统

按照功能划分，将相似的功能组织在一个子系统中；
按照系统的物理布局划分，将在同一个物理区域内的软件组织为一个子系统；
按照软件层次划分子系统，软件层次通常可划分为用户界面层、专用软件层、通用软件层、 中间层和数据层



定义子系统之间的关系


定义子系统的接口


每个子系统的接口上定义了若干操作，体现了子系统的功能，而功能的具体实现方 法应该是隐藏的，其他子系统只能通过接口间接地享受这个子系统提供的服务，不 能直接操作它。


如果两个子系统之间的关系过于密切，则说明一个子系统的变化会导致另一个子系 统变化，这种子系统理解和维护都会比较困难。


解决子系统之间关系过于密切的办法基本上有两个：
重新划分子系统，这种方法比较简单，将子系统的粒度减少，或者重新规划子系统的内容， 将相互依赖的元素划归到同一个子系统之中；
定义子系统的接口，将依赖关系定义到接口上






非功能需求设计

分析阶段定义了整个系统的非功能需求，在设计阶段要研究这些需求，设计出可行 的方案
非功能需求包括系统的安全性、错误监测和故障恢复、可移植性和通用性
具有共性的非功能需求一般设计在中间层和通用应用层，目的是充分利用已有构件， 减少重新开发的工作量。



用例设计
进一步细化用例：

根据分析阶段产生的高层类图和交互图，由用例设计师研究已有的类，将它们分配 到相应的用例中
检查每个用例功能，依靠当前的类能否实现，同时检查每个用例的特殊需求是否有 合适的类来实现
细化每个用例的类图，描述实现用例的类及其类之间的相互关系，其中的通用类和 关键类可用粗线框区分，这些类将作为项目经理检查项目时的重点。

步骤：

通过扫描用例中所有的交互图识别参与用例解决方案的类。在设计阶段完 善类、属性和方法。例如，每个用例至少应该有一个控制类，它通常没有属性而只有方法，它本身不完成什么具体的功能，只是起协调和控制作用；
每个类的方法都可以通过分析交互图得到，一般地检查所有的交互图发送给某个类的所有 消息，这表明了该类必须定义的方法
添加属性的类型、方法的参数类型和方法的返回类型
添加类之间的关系，包括关联、依赖、泛化等。

类设计
类是包含信息和影响信息行为的逻辑元素。
类的符号是由三个格子的长方形组成， 有时下面两个格子可以省略。 ▪

最顶部的格子包含类的名字，类的命名应尽量用应用领域中的术语，有明确的含义， 以利于开发人员与用户的理解和交流。
中间的格子说明类的属性。
最下面的格子是 类的操作行为。


类图中的基本关系

关联关系
聚合关系
组合关系
依赖关系
泛化关系

分析类图示例：

设计类图

如何寻找实体类

实体类用于对必须存储的信息和相关行为进行建模
实体类源于业务模型中的业务实体，但是对于系统结构的优化，可以在后续的过程中被分拆和合并

如何寻找边界类

参与者与用例之间应当建立边界类
用例与用例之间如果有交互，应当为其建立边界类
如果用例与系统边界之外的非人对象有交互，应当为其建立边界类
在相关联的业务对象有明显的独立性要求，即它们可能在各自的领域内发展和变化， 但又希望互不影响时，也应当为它们建立边界类

如何寻找控制类

控制类来源于对用例场景中动词的分析和定义
控制类主要起到协调对象的作用，例如从边界类通过控制类访问实体类，或者实体类通过控制类访问另一个实体类
如果用例场景中的行为在执行步骤、执行要求或者执行结果上具有类似的特征，应当合并或抽取超类

详细设计一个类的步骤

定义类的属性

用所选择的编程语言定义每个类的属性。类的属性反映类的特性，通常属性是被封装在 类的内部，不允许外部对象访问
分析阶段和概要设计阶段定义的一个类属性在详细设计时可能要被分解为多个，减小属性的表示粒度有利于实现和重用。
但是一个类的属性如果太多，则应该检查一下，看能否分离出一个 新的类。
如果一个类因为其属性的原因变得复杂而难于理解，那么就将一些属性分离出来形成一个新的类。
通常不同的编程语言提供的数据类型有很大差别，确定类的属性时要用编程语言来约束可用的 属性类型。
定义属性类型时尽可能使用已有的类型，太多的自定义类型会降低系统的可维护性 和可理解性等性能指标。
类的属性结构要坚持简单的原则，尽可能不使用复杂的数据结构


定义类的操作

由构件工程师为每个类的方法设计必须实现的操作，并用自然语言或伪代码描述操 作的实现算法。一个类可能被应用在多个用例中，由于它在不同用例中担当的角色 不同，所以设计时要求详细周到。
分析类的每个职责的具体含义，从中找出类应该具备的操作。
阅读类的非功能需求说明，添加一些必须的操作。
确定类的接口应该提供的操作。这关系到设计的质量，特别是系统的稳定性，所以确定类接口操作要特别小心。
逐个检查类在每个用例实现中是否合适，补充一些必须的操作。
设计时不仅要考虑到系统正常运行的情况，还要考虑一些特殊情况，如中断/错误处理等


定义类之间的关系

设置基数：一个类的实例与另一个类的实例之间的联系。
使用关联类：可以放置与关联相关的属性。



UML顺序图
顺序图

强调消息时间顺序的交互图
顺序图描述了对象之间传送消息的时间顺序，用来表示用例中的行为顺序
顺序图将交互关系表示为一个二维图，图形上看起来是一张表；

显示的对象沿横轴排列，从左到右分布在图的顶部
消息则沿着纵轴按时间顺序排序
使图尽量简洁为布局依据



示例

组成


对象：

顺序图中对象的符号和对象图中对象所用的符号一样；
将对象置于顺序图的顶部意味着在交互开始的时候对象就已经存在了，如果对象的 位置不在顶部，那么表示对象是在交互的过程中被创建的；
活动者和对象按照从左到右的顺序排列 ，一般最多两个活动者，他们分列两端；
启动这个用例的活动者往往排在最左边；接 收消息的活动者则排在最右端；
对象从左到右按照重要性排列或按照消息先后顺序排列。
命名：包括对象名和类名，类名（匿名对象），对象名（不关心类）



生命线

每个对象都有自己的生命线，用来表 示在该用例中一个对象在一段时间内的存在
生命线使用垂直的虚线表示
如果对象生命期结束，则用注销符号表示
对象默认的位置在图顶部，表示对象 在交互之前已经存在
如果是在交互过程中由另外的对象所 创建，则位于图的中间某处。



消息

面向对象方法中，消息是对象间交互信息的主要方式
结构化程序设计中，模块间传递信息的方式主要是过程（或函数）调用
对象A向对象B发送消息，可以简单地理解为对象A调用对象B的一个操作
顺序图中，尽力保持消息的顺序是从左到右排列的
一个顺序图的消息流开始于左上方，消息2的位置比消息1低，这意味着消息2的顺 序比消息1要迟
顺序图中消息编号可显示，也可不显示。协作图中必须显示。
在UML中，消息使用箭头来表示，箭头的类型表示了消息的类型
消息的类型

简单消息
同步消息：同步消息最常见的情况是调用，即消息 发送者对象在它的一个操作执行时调用 接收者对象的一个操作，此时消息名称 通常就是被调用的操作名称。当消息被处理完后，可以回送一个简单 消息，或者是隐含的返回。
异步消息：异步消息表示发送消息的对象不用等待回应的返回消息，即可开始另一个活动。异步消息在某种程度上规定了发送方和接收方的责任，即发送方只负责将消息发送到接收 方，至于接收方如何响应，发送方则不需要知道。对接收方来说，在接收到消息后它既可 以对消息进行处理，也可以什么都不做。
反身消息：顺序图建模过程中，一个对象也可以将 一个消息发送给它自己，这就是反身消 息；如果一条消息只能作为反身消息，那么 说明该操作只能由对象自身的行为触发。 这表明该操作可以被设置为私有属 性，只有属于同一个类的对象才能够调用它。在这种情况下，应该对顺序图进行彻底 的检查，以确定该操作不需要被其他对 象直接调用。
返回消息：返回消息是顺序图的一个可选择部分， 它表示控制流从过程调用的返回。一般可以缺省，隐含表示每一个调用都有一个配对的调用返回。 是否使用返回消息依赖于建模的具体/ 抽象程度。如果需要较好的具体化，返 回消息是有用的；否则，主动消息就足 够了。





激活

激活表示该对象被占用以完成某个任务，去激活指的则是对象处于空闲状态、在等 待消息。
在UML中，为了表示对象是激活的，可以将该对象的生命线拓宽成为矩形。其中 的矩形称为激活条(期)或控制期，对象就是在激活条的顶部被激活的，对象在完成 自己的工作后被去激活
特点：

当一条消息被传递给对象的时候，它会触发该对象的某个行为，这时就说该对象被激活了
在UML中，激活用一个在生命线上的细长矩形框表示
矩形本身被称为对象的激活期或控制期，对象就是在激活期顶端被激活的
激活期说明对象正在执行某个动作。当动作完成后，伴随着一个消息箭头离开对象的生命 线，此时对象的一个激活期也宣告结束。






对象的创建

顺序图中的对象的默认位置是在图的顶部，如果对象在这个位置上，那么说明在发送消息 时，该对象就已经存在了
如果对象是在执行的过程中创建的，那么它的位置应该处在图的中间部分


对象的撤销

在处理新创建的对象，或顺序图中的其他对象时，都可以发送“destroy”消息来撤销对象；
要想说明某个对象被撤销，需要在被撤 销对象的生命线末端放一个“×”符号 进行标识


建模特点

对系统动态行为建模的过程中，当强调按时间展开信息的传送时，一般使用顺序图 建模技术。
一个单独的顺序图只能显示一个控制流。
一般情况下，一个完整的控制流是非常复杂的，要描述它需要创建很多交互图（包 括顺序图和协作图），一些图是主要的，另一些图用来描述可选择的路径和一些例 外，再用一个包对它们进行统一的管理。

建模的参考策略

设置交互的语境，这些语境可以是系统、子系统、类、用例和协作的一个脚本。
识别对象在交互语境中所扮演的角色，根据对象的重要性及相互关系，将其从左至右放置在顺序图的顶 部。
设置每个对象的生命线。通常情况下，对象存在于整个交互过程中，但它们也可以在交互过程中创建和 撤销。对于这类对象，在适当的时刻设置它们的生命线，并用适当的构造型消息显示地说明它们的创建 和撤销。
从引发某个消息的信息开始，在生命线之间画出从顶到底依次展开的消息，显示每个消息的内容标识。
设置对象的激活期，可视化消息的嵌套或可视化实际计算发生时的时间点。
如果需要设置时间或空间的约束，可以为每个消息附上合适的时间和空间约束。
如果需要形式化的说明某控制流，可以为每个消息附上前置和后置条件。

建立顺序图的步骤

确定交互的范围；
识别参与交互的对象和活动者；
设置对象生命线开始和结束；
设置消息；
细化消息。

示例：

面向对象的设计原则
面向对象设计的特点

面向对象设计强调定义软件对象，并且使这些软件对象相互协作来满足用户需求。
面向对象分析和设计的界限是模糊的，从面向对象分析到面向对象设计是一个逐渐 扩充模型的过程。分析的结果通过细化直接生成设计结果，在设计过程中逐步加深 对需求的理解，从而进一步完善需求分析的结果。
分析和设计活动是一个反复迭代的过程。
面向对象方法学在概念和表示方法上的一致性，保证了各个开发阶段之间的平滑性。

面向对象设计的四个层次

确定系统的总体结构和风格，构造系统的物理模型，将系统划分成不同的子系统。
中层设计：对每个用例进行设计，规划实现用例功能的关键类，确定类之间的关系。
进行底层设计：对每个类进行详细设计，设计类的属性和操作，优化类之间的关系。
补充实现非功能性需求所需要的类。

设计高质量的软件系统

对接口进行设计
发现变化并封装它
先考虑聚合再考虑继承

强内聚
类内聚：设计类的原则是一个类的属性和操作全部都是完成某个任务所必须的， 其中不包括无用的属性和操作。
弱耦合
在面向对象设计中，耦合主要指不同对象之间相互关联的程度。
如果一个对象过多 地依赖于其它对象来完成自己的工作，则不仅使该对象的可理解性下降，而且还会增加测试、修改的难度，同时降低了类的可重用性和可移植性。
对象不可能是完全孤立的，当两个对象必须相互联系时，应该通过类的公共接口实 现耦合，不应该依赖于类的具体实现细节。
耦合方式

交互耦合：如果对象之间的耦合是通过消息连接来实现的，则这种耦合就是交互耦合。在设计时应该尽量减少对象之间发送的消息数和消息中的参数个数，降低消 息连接的复杂程度。
继承耦合：继承耦合是一般化类与特殊化类之间的一种关联形式，设计时应该适 当使用这种耦合。在设计时要特别认真分析一般化类与特殊化类之间继承关系，如 果抽象层次不合理，可能会造成对特殊化类的修改影响到一般化类，使得系统的稳 定性降低。另外，在设计时特殊化类应该尽可能多地继承和使用一般化类的属性和 服务，充分利用继承的优势。

可重用性
软件重用是从设计阶段开始的，所有的设计工作都是为了使系统完成预期的任务， 为了提高工作效率、减少错误、降低成本，就要充分考虑软件元素的重用性。

尽量使用已有的类，包括开发环境提供的类库和已有的相似的类；
如果确实需要创建新类，则在设计这些新类时考虑将来的可重用性。

设计一个可重用的软件比设计一个普通软件的代价要高，但是随着这些软件被重用 次数的增加，分摊到它的设计和实现成本就会降低。
框架
框架是一组可用于不同应用的类的集合。
框架中的类通常是一些抽象类并且相互有 联系，可以通过继承的方式使用这些类。
一般不会直接去修改框架的类，而是通过继承或聚合为应用创建合适的GUI类。
]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Software-Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>面向过程的系统设计</title>
    <url>/2025/07/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B7-%E9%9D%A2%E5%90%91%E8%BF%87%E7%A8%8B%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[总体设计

首先研究、分析和审查数据流图。从软件的需求规格说明中弄清数 据流加工的过程，对于发现的问题及时解决。
然后根据数据流图决定问题的类型。数据处理问题典型的类型有 两种：变换型和事务型。针对两种不同的类型分别进行分析处理。
由数据流图推导出系统的初始结构图。
利用一些启发式原则来改进系统的初始结构图，直到得到符合要 求的结构图为止。
修改和补充数据词典。

系统结构图
模块

传入模块：从下属模块取得数据，经过某些处理，再将其传送给上级模块。 它传送的数据流叫做逻辑输入数据流。
传出模块：从上级模块获得数据，进行某些处理，再将其传送给下属模块。 它传送的数据流叫做逻辑输出数据流。
变换模块：它从上级模块取得数据，进行特定的处理，转换成其它形式，再 传送回上级模块。它加工的数据流叫做变换数据流。
协调模块：对所有下属模块进行协调和管理的模块。


变换分析
变换型数据处理问题的工作过程大致分为三步，即取得数据，变换数据和给出数据。
相应于取得数据、变换数据、给出数据，变换型系统结构图由输入、中心变换和输出等三部分组成。
变换分析方法由以下四步组成：

重画数据流图；
区分有效（逻辑）输入、有效（逻辑） 输出和中心变换部分；
进行一级分解，设计上层模块；
进行二级分解，设计输入、输出和中心 变换部分的中、下层模块。

注意：

在选择模块设计的次序时，必须对 一个模块的全部直接下属模块都设计完 成之后，才能转向另一个模块的下层模 块的设计；
在设计下层模块时，应考虑模块的 耦合和内聚问题，以提高初始结构图的 质量。
使用“黑箱”技术: 在设计当前模块时，先把这个模块的所有下层模块定义成“黑 箱”，在设计中利用它们时，暂时不考虑其内部结构和实现。在这一步定义好的“黑 箱”，在下一步就可以对它们进行设计和加工。这样，又会导致更多的“黑箱”。最 后，全部“黑箱”的内容和结构应完全被确定。
在模块划分时，一个模块的直接下属模块一般在5个左右。如果直接下属模块超过 10个，可设立中间层次。
如果出现了以下情况，就停止模块的功能分解：

模块不能再细分为明显的子任务；
分解成用户提供的模块或程序库的子程序；
模块的界面是输入／输出设备传送的信息；
模块不宜再分解得过小。




事务分析
接受一项事务，根据事务处理的特点和性质，选择分派一个适当的处理单元，然后给出结果。
在事务型系统结构图中，事务中心模块按所接受的事务 的类型，选择某一事务处理模块执行。各事务处理模块 并列。每个事务处理模块可能要调用若干个操作模块， 而操作模块又可能调用若干个细节模块。
在很多软件应用中，存在某种作业 数据流，它可以引发一个或多个处 理，这些处理能够完成该作业要求 的功能。这种数据流就叫做事务。
与变换分析一样，事务分析也是从 分析数据流图开始，自顶向下，逐 步分解，建立系统结构图。
过程：

识别事务源：利用数据流图和数据词典，从问题定义和需求分析的结果中，找出各种需要处理的事 务。通常，事务来自物理输入装置。有时，设计人员还必须区别系统的输入、中心加 工和输出中产生的事务。
规定适当的事务型结构：在确定了该数据流图具有事务型特征之后，根据模块划分理论，建立适当的事务型结 构。
识别各种事务和它们定义的操作：从问题定义和需求分析中找出的事务及其操作所必需的全部信息，对于系统内部产生 的事务，必须仔细地定义它们的操作。
注意利用公用模块 在事务分析的过程中，如果不同事务的一些中间模块可由具有类似的语法和语义的若 干个低层模块组成，则可以把这些低层模块构造成公用模块
对每一事务，或对联系密切的一组事务，建立一个事务处理模块；如果发现在系 统中有类似的事务，可以把它们组成一个事务处理模块；
对事务处理模块规定它们全部的下层操作模块
对操作模块规定它们的全部细节模块


混合结构分析
变换分析是软件系统结构设计的主要方法。
一般，一个大型的软件系统是变换型结构和事务型结构的混合结构。
所以，我们通常利用以变换分析为主、事务分析为辅的方式进行软件结构设计
组件设计
结构化组件设计
组件级设计也称为过程设计，位于数据设计、体系结构设计和接口设计完成之后；
任何程序总可以用三种结构化的构成元素来设计和实现

顺序：任何算法规约中的核心处理步骤
条件：允许根据逻辑情况选择处理的方式
重复：提供了循环

详细设计工具可以分为以下三类：

图形设计符号：流程图、盒图等
表格设计符号：决策表等
程序设计语言：PDL等

流程图
利用各种方块图形、线条及箭头等符号来表达解决问题的步骤及进行的顺序；
流程图是算法的一种表示方式。
标准作业流程是企业界常用的一种作业方法，其目的在使每一项作业流程均能清楚呈现，任何人只要看 到流程图，便能一目了然，有助于相关作业人员对整体工作流程的掌握。
优点

所有流程一目了然，工作人员能掌握全局。
更换人手时，按图索骥，容易上手。
所有流程在绘制时，很容易发现疏失之处，可适时予以调整更正，使各项作业更为 严谨。

基本符号


基本结构

顺序结构：处理程序顺序进行
选择结构：包括0二元选择，多重选择，流程依据某些条件，依条件是否成立，分别进行不同处理程序。
循环结构

while-do结构，依据条件是否成立，决定执行的情况。当条件 成立时，不断重复执行处理程序，直到停止执行的条 件成立后，即离开重复执行，至下一个流程。
do-while结构，：重复执行处理程序，直到条件变成假（false）为止。



绘制原则

各项步骤有选择或决策结果，如“可/否”、“通过/不通过”或其他相对文字时，请检查校正流程是否 有遗漏，以避免悬而未决的状况。
流程图符号绘制排列顺序，为由上而下，由左而右。
处理程序可用阿拉伯数字，从1开始，依处理程序排列顺序编号，并以文字依处理程序功能命名。
相同流程图符号宜大小一致。
路径符号宜避免互相交叉。
同一路径符号的指示箭头应只有一个。
开始符号在流程图中只能出现一次，但结束符号则不限。若流程图能一目了然，则开始符号和结束符号 可省略。
选择结构与重复结构的选择或决策条件，文字叙述应简明清晰，路径加注“是”、“否”或其它相对性 文字指示说明。
流程图中若有参考到其他已定义流程，可使用已定义处理程序符号，不必重复绘制。
流程图若一页绘制不下，可以使用分级分页绘制方式，并在处理程序编号上表示其级别

盒图（N-S图）
五种基本控制结构有五种图形构件表示：

决策表

判定表用于表示程序的静态逻辑
在判定表中的条件部分给出所有的两分支判断的列表，动作部分给出相应的处理
要求将程序流程图中的多分支判断都改成两分支判断

PDL(伪代码)
PDL是一种用于描述功能模块的算法设计和加工细节的语言，称为程序设计语言。它是一种伪码。
伪码的语法规则分为“外语法”和“内语法”。

PDL具有严格的关键字外语法，用于定义控制结构和数据结构
同时它的表示实际 操作和条件的内语法又是灵活自由的，可使用自然语言的词汇。

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Software-Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>软件测试概论</title>
    <url>/2025/07/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B8-%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E6%A6%82%E8%AE%BA/</url>
    <content><![CDATA[软件质量保证与测试相关概念
软件质量
定义：明确表示是否包含功能和性能需求，明确记载开发标准和所有专业开发软件的期望的隐性特点
关键点

软件测试时软件质量测量的基础
缺乏规定的一致性就是缺乏软件的质量
制定标准会定义软件工程发展的标准，引导软件工程经理

软件质量保证
质量保证含义：系统地监测评估一个工程的方方面面，以最大限度的提高正在由生产过程中实现的质量的最低标准
原则：

适合用途：产品符合预期目的
一次成功：错误产品应该被淘汰

软件质量保证SQA：

活动：审查，监督，审核
过程监控：一个确保采取适当步骤来进行的过程中所遵循的SQA 活动
审核：用来审查管理、技术和流程，以保证提供的质量和软件产品的状态指示

软件测试
定义：

在某种指定的条件下对系统或组件操作，观察或记 录结果，对系统或组件的某些方面进行评估的过程。
分析软件各项目以检测现有的结果和应有结果之间 的差异（即软件缺陷），并评估软件各项目的特征 的过程。

软件缺陷

软件未实现产品说明书的功能；
未实现产品说明书未明确提及但是应该实现的目标
产品说明书指明不能出现的错误
软件实现了产品说明书未提到的功能
软件难以理解，不易使用，运行缓慢等等最终用户认为不好

验证Verification/确认Validation
验证：保证软件特定开发阶段的输出已经正确完整地实现了规格说明
确认：对于每个测试级别，都要检查 开发活动的输出是否满足具体客户的需求或与这些特定级别相关的需求
在实际生产中，开发者参照的规格说明不一定等同于客户的具体需求；
测试&amp;质量保证

软件测试人员的目标是尽早找出软件缺 陷，并确保缺陷得以修复
软件质量保证人员的主要职责是创建和 执行改进软件开发过程并防止软件缺陷 发生的标准和方法

质量/可靠性


功能性functionality


效率efficiency


可移植性portability


可靠性reliability：利用平均无故障时间和平均修复时间



可维护性maintainability


可用性usability


调试/测试
共同点：处理软件缺陷和查看代码的过程
区别：

测试的目标是发现软件缺陷的存在
调试的目标是定位和修复缺陷

目标

确认系统满足其预期的使用和用户的需要。
确认解决了所需解决的问题；
为测试的过程建立责任和可解释性；
便于及早发现软件和系统的异常；
及早提供软件和系统的性能评估；
为管理提供真实信息，以决定在当前状态下发布产品在商业上的风险；
鉴别出程序在功能等方面的异常集聚之处。

原则

穷尽测试是不可能的
测试无法显示潜伏的软件缺陷
测试活动应该尽早进行
软件缺陷具有群聚性
注意杀虫剂现象：测试用例应该具有某种随机策略
尽量由独立的测试团队进行测试

测试用例
定义：

测试输入
执行条件
预期结果

测试用例是为特定的目的开发的，例如执行特定的程序路径与验证指定的需求相符合
软件测试的评估准则

覆盖率： 给定一个测试需求集合TR 和一个测试集合T，覆盖率可以定义为T 满足的测试需求占TR 总数 的比例。
故障插入：用于评价遗留在一个程序中的故障的数量和种类。 具体而言，在测试前被有意地插入一些故障到程序中，在测试执行中，有一部分插入的故障 会因测试而显露出来，但可能一些故障在测试中没有暴露出来，仍存在于程序中。
变异分值：程 序进行两个或更多个变异，然后用同样的测试用例执行测试，可以评估这些测试用例探测程 序变异间的差异的能力。

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Software-Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>软件测试技术</title>
    <url>/2025/07/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B9-%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[分类

白盒测试：考虑系统或组件的内部机制的测试形式（如分支测试、路径测试、语句测试等）
黑盒测试：忽略系统或组件的内部机制，仅关注于那些响应所选择的输入及相应执行条件的输出的测试形式
灰盒测试：多用于集成测试阶段，不仅关注输出、输 入的正确性，同 时也关注程序内部的情况。

白盒测试
概念
此方法把测试对象看做一个透明的盒子，允许测试人员利用程序内部的逻辑结构及有关信息，设计或选择测试用例， 对程序所有逻辑路径进行测试。
通过在不同点检查程序的状态，确定实际的状态是否与预期的状态一致。因此白盒测试又称为结构测试或逻辑驱动测试。
原则：

程序模块所有独立执行路径至少测试一次
对于逻辑判定，真假至少都扯一次
在循环的边界和运行的边界执行循环体
测试内部数据结构的有效性

逻辑覆盖
逻辑覆盖是以程序内部的逻辑为基础的设计测试用例的技术；
语句覆盖
语句覆盖就是设计若干个测试用例， 运行被测程序，使得每一可执行语句至少执行一次。
分支覆盖
设计若干测试用例，运行被测程序使得程序的每个判断条件的取真分支和取假分支至少经历一次；

分支覆盖又称为判定覆盖

条件覆盖
设计若干测试用例，运行被测程序使得判断中的每个条件取值至少执行一次
条件组合覆盖
设计足够多的测试用例，运行被测程序，使得每个判断所有可能条件取值组合至少执行一次；

取决于条件最多的判断框；
这个判断框条件数为,则要设计个用例；

控制流图覆盖测试
控制流图覆盖测试将代码转化成控制流图，也属于白盒测试；
控制流图的画法：每个结点表示一个或多个无分支的PDL语句，箭头为边，代表控制流的方向；


在选择或多分支结构中，分支的汇聚处应有一个汇聚结点；
边和结点圈定的区域叫做区域，当对区域计数时，图形外的区域也应记为一个区域；
如果判断中的条件表达式是复合的，则需要改为一系列只有单个条件的嵌套的判断。
程序的入口和出口应该占用一个结点，一段无分支的串行代码应该合并；

以下是一个程序流图和其控制流图的对应关系

结点覆盖
对于图G 中每个语法上可达的节点，测试用例所执行的测试路径的集合中至少存 在一条测试路径访问该节点。
显然，节点覆盖和语句覆盖是等价的。
边覆盖
对于图G 中每一个可到达的长度小于等于1的路径，测试用例所执行的测试路径 的集合中至少存在一条测试路径游历该路径。
显然，边覆盖包含节点覆盖，且边覆盖也可以实现分支覆盖。
路径覆盖
路径覆盖测试就是设计足够的测试用例，覆盖程序中所有可能的路径；
基本路径测试方法把覆盖的路径数压缩到一定限度内，程序中的循环体最多只执行 一次；
在程序控制流图的基础上，分析控制构造的环路复杂性，导出基本可执行路径 集合，设计测试用例的方法。
设计出的测试用例要保证在测试中，程序的每一个可 执行语句至少要执行一次。
环路复杂性
环路复杂性给出了确保程序的每个可执行语句至少执行一次的用例数上界；
一条独立路径指在控制流图中，从起点到终点的一条路径，该路径至少包含一条新的边（即之前没有经过的边）。换句话说，独立路径是无法通过其他路径的线性组合来得到的。
环路复杂性给出了程序基本路径集中的独立路径条数；


e为图中边的数目
n为节点数目
p为连接组件数，若图为连通的，p=1
d为决策结点数

在拓朴学上这也是图的区域数
确定线性独立路径基本集合
算法：

从源节点（控制流图的入口点）开始， 一直走到汇节点（控制流图的出口 点）。该路径作为基线路径；
接下来，重新回溯基线路径，依次 “翻转”在判断节点上原来选择的路 径。即当遇到节点的出度大于等于2 时，必须选择不同的边；
重复以上过程，直到得到的路径数目 等于V(G)

导出测试用例
导出测试用例，确保基本路径集的每一条路径的执行。

根据判断结点给出的条件，选择适当的数据以保证某一条路径可以被测试到——用逻辑覆盖方法。
每个测试用例执行之后，与预期结果进行比较。如果所有测试用例都执行完毕，则可以确信程序中所有的可执行语句至少被执行了一次。
一些独立的路径往往不是完全孤立的，有时它是程序正常的控制流的一部分，这时，这些路径的测试可以是另一条路径测试的一部分。

黑盒测试
概念
这种方法是把测试对象看做一个黑盒子，测试人员完全不考虑程序内部的逻辑结构和内部特性，只依据程序的需求规格说明书，检查程序的功能是否符合它的功能说明。
黑盒测试又叫做功能测试或数据驱动测试，主要是在程序接口上测试：

是否有不正确或者遗漏的功能；
接口上输入能否正确接受，能否输出正确结果；
数据结构错误或者数据文件访问错误
性能是否能满足要求
是否有初始化或终止性错误

在测试中，穷尽测试是不可能的，因此需要某些合适的方法

等价类划分
边界值分析
状态测试

等价类划分
最典型的黑盒测试划分，完全不考虑程序的内部结构，只依据程序的规格说明来设计测试用例；
等价类划分会把所有可能输入数据划分成若干部分，从每个部分少数有代表性的数据作为测试用例；

有效等价类：合理的有意义的输入数据构成集合
无效等价类：不合理的，无意义的输入数据构成集合；

划分等价类的原则：

输入条件规定了取值范围，则可以确定一个有效等价类和两个无效等价类，比如区间
若输入条件规定输入值的集合，即「必须如何」，则可划分一个有效和一个无效等价类
若输入条件是一个布尔量，则可以确定一个有效等价类和一个无效等价类；
若规定了输入数据的一组值，且程序对每个输入值分别处理，则可以为每个输入值建立等价类，这组之外的值建立一个无效等价类，它是所有不允许输入值的集合；
若规定了输入数据必须遵循的约束规则，则可以确定一个有效等价类和若干个无效等价类
确定测试用例的原则：
建立等价类表：输入条件+有效等价类+无效等价类，并为每个等价类设定编号；
设计新的测试用例，使其尽可能多地覆盖尚未被覆盖的有效等价类，重复直到所有有效等价类被覆盖；
设计新的测试用例，使其仅覆盖一个尚未覆盖的无效等价类，重复直到说欧无效等价类被覆盖；

边界值分析方法
根据软件测试的经验，大量的错误发生在输入或者输出的边界上，而不是输入的范围的内部，因此针对边界情况设计的测试用例十分有用；

边界值：对于输入等价类和输出等价类而言，稍高于边界值或稍低于边界值的一些特定情况；
应该确定边界情况，选取刚刚等于，刚刚大雨或刚刚小于边界的值作为测试数据，而不是选取等价类的典型值；

状态测试
黑盒测试阶段，程序内部的逻辑结构无从得知，因此只能对状态的测试间接加以验证；
软件状态：软件当前所处的条件或模式，通常访问所有状态是可实现的，但是很难走完所有分子来达到某种状态，必须选择重要内容来测试；
建立状态转换图：

表示软件可能进入的每一种独立状态；
找出从一种状态转入另一种状态需要的输入和条件；
找出进入或退出某种状态时设置的条件和输出结果；

根据转换图设计用例：

每种状态至少访问一次
看起来时最常见的状态转换
状态间最不常用的分支
测试所有错误状态和返回值
测试状态的随机转换

静态分析
不实际运行程序，通过检查和阅读发现错误和评估代码质量的软件测试技术；

对代码标准以及质量监控提高代码的可靠性
尽可能今早通过源代码检查发现缺陷
组织代码审核定位易产生错误的模块

这实际上是非常有效的质量保证手段，其通用评审过程包括计划，概述，准备，评审会议，返工，跟踪；
主要内容：检查需求，设计和代码
类型：同事审查（用于初次审查），走查（开发组内部进行），审查（会议形式，由开发组，测试员和产品经理等联合进行）
测试策略
概念
测试策略为开发人员，质量保证组织和客户提供路线图，规定了测试的主要步骤；
测试策略必须和测试计划， 用例设计，执行和结果数据收集和分析结合在一起；
测试策略应该具有足够的灵活性，必要时应该有足够的可塑性来应对大软件系统；
测试策略要足够严格，保证项目对整个进程进行合理的计划和跟踪管理；
V模型
V 模型非常明确地标明了测试过程中存在的不同级别，并且清楚地描述了这些测试阶
段和开发过程期间各阶段应关系：

单元测试的主要目的是验证软件模块是否按详细设计的规格说明正确运行。
集成测试主要目的是检查多个模块间是否按概要设计说明的方式协同工作。
系统测试的主要目的是验证整个系统是否满足需求规格说明。
验收测试从用户的角度检查系统是否满足合同中定义的需求，以及以确认产品是否能符合业务上的需要。

基本步骤

计划和准备

制定计划
编写与评审测试用例
编写测试脚本和准备测试环境


执行阶段

搭建环境、构造测试数据
执行测试并记录问题
和开发人员一起确认问题
撰写测试报告


返工和回归性测试

潜在问题

在着手开始测试之前，要对产品的需求进行量化。
明确指出测试目标。
为每类用户建立描述交互场景的用例。
建立一个强调“快速循环测试”的测试计划。
设计一个能够测试自身是否“强壮”的软件。
在进行测试之前，对软件进行有效的正式技术审核。
使用正式技术审核来评估测试策略和测试用例本身。
为测试过程建立一种持续的改进方法。

单元测试
概念
单元测试又称模块测试，是针对软件设计的最小单位 ─ 程序模块，进行正确性检
验的测试工作。其目的在于发现各模块内部可能存在的各种差错。
单元测试需要从程序的内部结构出发设计测试用例。多个模块可以平行地独立进行单元测试。
单元的内涵

单元测试的主要依据
单元级测试工具：C++Test，JUnit，NUnit

主要内容：

进入条件和退出条件
进入条件：

被测代码编译链接通过
被测代码静态检查工具检查通过
已完成至少一轮代码检视或走读
单元测试用例的检视通过
单元测试代码写完并通过检测

退出条件：

所用测试用例执行通
单元测试覆盖率达到预定要求
单元测试未被执行的代码进行正式审查

主要内容
模块接口测试
在单元测试的开始，应对通过被测模块的数据流进行测试。测试项目包括：

调用本模块的输入参数是否正确；
本模块调用子模块时输入给子模块的参数是否正确；
全局量的定义在各模块中是否一致；

局部数据结构测试
检查如下方面：

不正确或不一致的数据类型说明
使用尚未赋值或尚未初始化的变
错误的初始值或错误的缺省值
变量名拼写错或书写错
不一致的数据类型
全局数据对模块的影响

路径测试
选择适当的测试用例，对模块中重要的执行路径进行测试。

应当设计测试用例查找由于错误的计算、不正确的比较或不正常的控制流而导致的错误。
对基本执行路径和循环进行测试可以发现大量的路径错误。

错误处理测试

出错的描述是否难以理解
出错的描述是否能够对错误定位
显示的错误与实际的错误是否相符
对错误条件的处理正确与否
在对错误进行处理之前，错误条件是否已经引起系统的干预等

边界测试

注意数据流、控制流中刚好等于、大于或小于确定的比较值时出错的可能性；
如果对模块运行时间有要求的话，还要专门进行关键路径测试，以确定最坏情况下和平均意义下影响模块运行时间的因素。

用例设计
在单元测试时，测试者需要依据详细设计说明书和源程序清单，了解该模块的I/O条件和模块的逻辑结构，主要采用白盒测试的测试用例，辅之以黑盒测试的测试用例，使之对任何合理的输入和不合理的输入，都能鉴别和响应。
环境
模块并不是一个独立的程序，在考虑测试模块时，同时要考虑它和外界的联系，用一些辅助模块去模拟与被测模块相联系的其它模块。

驱动模块 (driver)
桩模块 (stub)


集成测试
集成测试就是将软件集成起来后进行测试。又称为子系统测试、组装测试、部件测试等。

集成测试主要可以检查诸如两个模块单独运行正常，但集成起来运行可能出现问题的情况
集成测试是一种范围很广的测试，当向下细化时，就成为单元测试。

值得注意的是，在实际工作中，常常是综合使用自底向上和自顶向下的集成方法。

例如，按进度选择优先测试已经完成的模块
如果已完成的模块所调用的模块没有完成，就采用自顶向下的方法，打桩进行测试
如果已经完成模块的上层模块没有完成，可以采用自底向上集成方式。

自顶向下集成
这种组装方式将模块按系统程序结构，沿控制层次自顶向下进行集成。从属于主控模块的按深度优先方式（纵向）或者广度优先方式（横向）集成到结构中去。

自顶向下的集成方式在测试过程中较早地验证了主要的控制和判断点。
选用按深度方向集成的方式，可以首先实现和验证一个完整的软件功能。
缺点是桩的开发量较大

自底向上集成
自底向上集成方法是从软件结构最底层的模块开始，按照接口依赖关系逐层向上集成以进行测试。

由于是从最底层开始集成，对于一个给定层次的模块，它的子模块（包括子模块的所有下属模块）已经集成并测试完成，所以不再需要使用桩模块进行辅助测试。在模块的测试过程中需要从子模块得到的信息可以直接运行子模块得到。
自底向上的集成方法的优点是每个模块调用其他底层模块都已经测试，不需要桩模块；
缺点:每个模块都必须编写驱动模块；缺陷的隔离和定位不如自顶向下。

SMOKE方法
构造：将已经转换为代码的软件构件集成；
一个构造包括所有的数据文件、库、可复用的模块以及实现一个或多个产品功能所需的工程化构件。

设计一系列测试以暴露影响构造正确地完成其功能的错误。其目的是为了发现极有可能造成项目延迟的业务阻塞错误。
每天将该构造与其他构造，以及整个软件产品集成起来进行冒烟测试。这种集成方法可以是自顶向下，也可以自底向上。
特别关注更改过的代码。

用例设计

首先应考虑为通过性测试设计用例，用来验证需求和设计是否得到满足、软件功能是否得到实现。可以考虑等价类分法、场景分析法、状态图法等
其次考虑为失效性测试设计用例，主要以已知的缺陷空间为依据设计测试用例。可以考虑边界值法、错误猜测法、因果图法和状态图法等
也应强调覆盖率的要求。集成测试的覆盖率有接口覆盖率，接口路径覆盖率等。
注意接口有显性和隐性之分。函数调用（API）接口属于显性接口，而消息、网络协议等都属于隐性接口。

系统测试
概念
系统测试是从用户使用的角度来进行的测试，主要工作是将完成了集成测试的系统在真实的运行环境下进行测试，用于功能确认和验证。

系统测试基本上使用黑盒测试方法
系统测试的依据主要是软件需求规格说明

系统测试在软件开发过程中属于必不可少的一环，是软件质量保证的最重要环节。

从测试的内容上看，系统测试针对的是外部输入层的测试空间，如果不进行系统测试，那么外部输入层向接口层转换的代码就没有得到测试。此外，许多功能是系统所有组件相互协调中得到的，只能在系统测试级别进行观察和测试。
从测试的角度上看，在单元测试和集成测试阶段，测试针对的是各级技术规格说明，即从软件开发者的技术观点的角度考虑的。而系统测试是从客户的观点来考虑系统是否完全正确地满足了需求。

功能测试
在规定的一段时间完成运行软件的所有功能，以验证软件系统有无严重错误
性能测试
性能测试是要检查系统是否满足在需求说明书中规定的性能。特别是对于实时系统或嵌入式系统。常常需要与压力测试结合起来进行，并常常要求同时进行硬件和软件检测。

通常，对软件性能的检测表现在以下几个方面：响应时间、吞吐量、辅助存储区，例如缓冲区、工作区的大小等、处理精度，等等。
性能测试工具：LoadRunner、PerformanceRunner等

压力测试
压力测试是要检查在系统运行环境不正常乃至发生故障的情况下，系统可以运行到何种程度的测试。例如：

把输入数据速率提高一个数量级，确定输入功能将如何响应。
设计需要占用最大存储量或其它资源的测试用例进行测试。
设计出在虚拟存储管理机制中引起“颠簸”的测试用例进行测试。
设计出会对磁盘常驻内存的数据过度访问的测试用例进行测试。
压力测试的一个变种就是敏感性测试。在程序有效数据界限内一个小范围内的一组
数据可能引起极端的或不平稳的错误处理出现，或者导致极度的性能下降的情况发生。此测试用以发现可能引起这种不稳定性或不正常处理的某些数据组合。

压力测试工具：JMeter等
恢复测试
恢复测试是要证实在克服硬件故障(包括掉电、硬件或网络出错等)后，系统能否常地继续进行工作，并不对系统造成任何损害。为此，可采用各种人工干预的手段，模拟硬件故障，故意造成软件出错。并由此检查：

错误探测功能──系统能否发现硬件失效与故障；
能否切换或启动备用的硬件；
在故障发生时能否保护正在运行的作业和系统状态；
在系统恢复后能否从最后记录下来的无错误状态开始继续执行作业，等等。
掉电测试：其目的是测试软件系统在发生电源中断时能否保护当时的状态且不毁坏数据，然后在电源恢复时从保留的断点处重新进行操作。

安全测试
安全性测试是要检验在系统中已经存在的系统安全性、保密性措施是否发挥作用，有无漏洞。
力图破坏系统的保护机构以进入系统的主要方法有以下几种：

正面攻击或从侧面、背面攻击系统中易受损坏的那些部分；
以系统输入为突破口，利用输入的容错性进行正面攻击；
申请和占用过多的资源压垮系统，以破坏安全措施，从而进入系统；
故意使系统出错，利用系统恢复的过程，窃取用户口令及其它有用的信息；
通过浏览残留在计算机各种资源中的垃圾（无用信息），以获取如口令，安全码，译码关键字等信息；
浏览全局数据，期望从中找到进入系统的关键字；
浏览那些逻辑上不存在，但物理上还存在的各种记录和资料等
安全性测试工具：NMAP、Nessus、Appscan等

验收测试
在通过了系统的有效性测试及软件配置审查之后，就应开始系统的验收测试。
验收测试是以用户为主的测试。软件开发人员和QA（质量保证）人员也应参加。

由用户参加设计测试用例，使用生产中的实际数据进行测试。
在测试过程中，除了考虑软件的功能和性能外，还应对软件的可移植性、兼容性、可维护性、错误的恢复功能等进行确认。

确认测试应交付的文档有：

确认测试分析报告
最终的用户手册和操作手
项目开发总结报告。

主要形式：

根据合同进行的验收测试：重复执行相关的测试用例
用户验收测试：客户和最终用户不同
现场测试：客户代表执行，分为α 测试和β 测试

α 测试
在软件交付使用之后，用户将如何实际使用程序，对于开发者来说是无法预测的。
α测试是由一个用户在开发环境下进行的测试，也可以是公司内部的用户在模拟实际操作环境下进行的测试。
α测试的目的是评价软件产品的FLURPS（即功能、局域化、可使用性、可靠性、性能和支持）。尤其注重产品的界面和特色。
α测试可以从软件产品编码结束之时开始，或在模块（子系统）测试完成之后开始，也可以在确认测试过程中产品达到一定的稳定和可靠程度之后再开始。
β测试
β测试是由软件的多个用户在实际使用环境下进行的测试。这些用户返回有关错误信息给开发者。
测试时，开发者通常不在测试现场。因而，β测试是在开发者无法控制的环境下进行的软件现场应用。
在β测试中，由用户记下遇到的所有问题，包括真实的以及主观认定的，定期向开发者报告。
β测试主要衡量产品的FLURPS。着重于产品的支持性，包括文档、客户培训和支持产品生产能力。
只有当α测试达到一定的可靠程度时，才能开始β测试。它处在整个测试的最后阶段。同时，产品的所有手册文本也应该在此阶段完全定稿。
回归测试
在软件测试的各个阶段，在修正发现的软件缺陷或增加新功能时，变化的部分必须进行再测试。此外，对软件进行修改还可能会导致引入新的软件缺陷以及其他问题。
为解决这些问题，需要进行回归测试。

回归测试是指有选择地重新测试系统或其组件，以验证对软件的修改没有导致不希望出现的影响，以及系统或组件仍然符合其指定的需求。
回归测试可以在所有的测试级别执行，并应用于功能和非功能测试中。
回归测试应该尽量采用自动化测试。

回归测试范围：

缺陷再测试：重新运行所有发现故障的测试，而新的软件版本已经修正了这些故障。
功能改变的测试：测试所有修改或修正过的程序部分。
新功能测试：测试所有新集成的程序。
完全回归测试：测试整个系统。

]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Software-Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>集合论</title>
    <url>/2025/07/05/%E9%9B%86%E5%90%88%E8%AE%BA/</url>
    <content><![CDATA[集合基础
集合（set）由指定范围内的某些特定对象聚集在一起构成;
指定范围内的每一个对象称为这个集合的元素(element)。
通常用大写字母表示集合,用小写字母表示元素;
集合的三大特征：互异性，确定性，无序性；
描述集合的方法：

枚举法：＝，，，
隐式法（叙述法）:＝
归纳法 : 基础+归纳+极小性(指出集合的界限)；
递归指定：通过计算规则定义集合中的元素
文氏图：一般用平面上的圆形或方形表示一个集合，而集合中的元素用小圆点来表示。

集合和元素的关系

属于集合，记为;
不属于集合，记为;

不含任何元素的集合称作空集，记作​;
外延性原理：＝当且仅当与具有相同的元素，否则，​。
集合和集合的关系：

包含关系：对任意，如，则;
相等：，
真包含关系：对任意，如，则,并且，，但是

空集是一切集合的子集,是绝对唯一的；
全集是指在一个相对固定的范围内，包含此范围内所有元素的集合，是相对唯一的，
基数：集合中元素的数目称为集合的基数(base number)，记为​;
根据基数是否有限可以将集合分为有限集和无限集；
把的所有不同子集构成的集合叫做的幂集(power set)，记为或;其符号化表示为
＝
设，是两个集合，若在，之间存在一一映射的关系：
：
则称与是等势的(equipotential)，记为：
凡是与自然数集合等势的集合，统称为可数集合,基数记作；

有理数集合必是可数集合;
两个有限集合等势当且仅当它们有相同的元素个数；
有限集合不和其任何真子集等势；
可数集合可以和其可数的真子集等势。

开区间称为不可数集合,基数记作​;

凡是与开区间(0,1)等势的集合都是不可数集合;
是一个不可数集合

集合恒等式


等幂律:；；


交换律:


结合律:；；


恒等律:；；


零律:；；


分配律:


吸收律:；


；


；


；


；


  ；


否定律：      ；


DeMorgan律：；


矛盾律： ＝；


排中律：＝。


]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Discrete-Mathematics</tag>
      </tags>
  </entry>
  <entry>
    <title>高级语言程序设计</title>
    <url>/2025/06/20/%E9%AB%98%E7%BA%A7%E8%AF%AD%E8%A8%80%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[语言设计 🎨
定义
程序设计语言是一组规则的集合，可以看作 语言 = 语法 + 语义

字母表的定义
词法规则：单词符号的形成规则，比如关键字，标识符，运算符，常量，分界符
语法规则：语法单位的形成规则，比如表达式，语句，函数，程序
语义规则：包括但此符号和语法单位的含义规则；
语用规则：语义规则的发展和延申；
其他规则：包括类型使用规则，参数传递规则，作用域规则；

历史发展

第一代语言 (1GL) 🤖: 机器语言 (Machine Language)

直接由计算机硬件执行的二进制指令。


第二代语言 (2GL) 🛠️: 汇编语言 (Assembly Language)

使用助记符表示机器指令，需要汇编器转换为机器语言。


第三代语言 (3GL) 🚀: 高级程序设计语言 (High-Level Languages)

如 C, C++, Java, Python, Fortran, COBOL。更接近人类语言，具有更强的抽象能力，可移植性更好。
包括命令式和过程式


第四代语言 (4GL) 📊: 为特定应用领域设计的语言 (Domain-Specific Languages - DSLs)

如 SQL (数据库查询), MATLAB (数值计算)。通常用于特定问题领域，提供更高层次的抽象。
包括说明性语言，超高级语言


第五代语言 (5GL) 🧠: (概念较模糊，通常指用于人工智能和逻辑编程的语言，如 Prolog，或基于约束求解的语言)

包括函数式，逻辑式语言



范式分类


强制式语言 (Imperative Languages) ➡️:

描述计算过程如何执行，通过一系列改变程序状态的命令来完成任务。
如 C, C++, Java, Pascal, Fortran。



声明式语言 (Declarative Languages) 📜:

描述计算应该做什么，而不是如何做。程序的执行逻辑由语言的解释器或编译器负责。
子范式包括：

函数式语言 (Functional Languages) λ: 如 Haskell, Lisp, Scheme, F#, Scala。计算被视为数学函数的求值，强调无副作用和不可变性。
逻辑式语言 (Logic Languages) 💡: 如 Prolog。基于形式逻辑规则进行推理。
数据流语言 (Dataflow Languages): 如部分响应式编程框架。





冯诺依曼语言 (Von Neumann Languages) 🏛️:

程序设计语言的计算模型基于冯诺依曼计算机体系结构（即，指令和数据存储在同一内存中，CPU按顺序执行指令）。大多数强制式语言属于此类。
在命令式语言上的表现为：变量，赋值。重复



面向对象语言 (Object-Oriented Languages) 🧩:

基于"对象"概念进行编程，对象包含数据（属性）和操作数据的代码（方法）。支持封装、继承、多态。
如 Java, C++, Python, Ruby, Smalltalk。



脚本语言 (Scripting Languages) 🐍:

通常是解释执行的，语法相对简单，用于编写"脚本"来自动化任务、快速原型开发或作为大型应用的扩展语言。
如 Python, JavaScript, Perl, Ruby, PHP, Shell。



逻辑式语言

数理逻辑，谓词演算



对象式语言

抽象数据类型



语言设计实践
静态/动态
静态策略 (Static Strategy) 🧊: 指语言的某个方面或问题在编译时刻 (compile time) 就可以确定或处理。

例如：C语言的变量类型是静态确定的（静态类型检查），大多数内存分配（全局/静态变量）在编译时规划。

动态策略 (Dynamic Strategy) 🔥: 指语言的某个方面或问题必须等到运行时刻 (run time) 才能确定或处理。例如：C语言中的动态内存分配 (malloc, free)，某些面向对象语言中的方法动态分派 (dynamic dispatch)。
C语言主要是一种静态类型的编译型语言，但它也提供了一些动态特性（如 void* 指针的灵活性，动态内存分配）。
若绑定(Binding)在编译时完成，且在运行时不会改变，则成为静态绑定，若绑定在运行时完成，则成为动态绑定；

语言实现采用编译还是解释方式，强相关于变量与类型绑定规则；
静态绑定语言是面向编译的语言
动态绑定语言是面向解释的语言

变量/赋值
变量是对若干个存储单元的抽象，用名字来标识；

一个存储单元至少有一个字节；一个变量至少占用一个存储单元；
作用域：可绑定静态作用域或动态作用域，依此划分为全局变量，局部变量，非局部变量；
生存期：变量绑定于存储区的时间区间，分配指变量获得存储区，变量长度为变量对应存储单元的个数；

全局变量静态分配；
局部变量和非局部变量可静态分配和动态分配(自动、显式请求)；
匿名变量：通过指针实现访问，属于动态分配


值：存储区的内容，二进制编码；
类型：变量值按照所绑定的类型解释；

赋值是对修改存储单元内容的抽象；
初始化问题：不同语言规定不同；
环境/状态
环境 (Environment) 🗺️: 在程序执行的某一点，环境是一个从名字 (identifier) 到存储位置 (storage location/address) 的映射。它定义了哪些名字是可见的以及它们所代表的实体（如变量、函数）。
状态 (State) 🔄: 在程序执行的某一点，状态是一个从存储位置 (storage location/address) 到其值 (value) 的映射。它反映了程序当前内存中存储的数据。
环境将名字映射到左值 (L-values) (表示位置)，状态将左值映射到其对应的右值 (R-values) (表示内容)。
静态作用域/块 (Static Scoping / Blocks)
静态作用域 (Static Scoping / Lexical Scoping) 📖:

一个声明的作用域（即该声明有效的程序文本区域）由其在源代码中的位置决定，可以在编译时通过分析程序文本来确定。
C语言采用静态作用域。当引用一个名字时，编译器会查找包含该引用的最内层词法块中的声明，然后是外层块，直至全局作用域。

块 (Block) {}:
在C语言中，一对花括号 { ... } 定义了一个块。在块内声明的变量（局部变量）其作用域仅限于该块及其内部嵌套的块，从声明点开始到块结束。
动态作用域 (Dynamic Scoping)📞

一个名字的引用会解析到程序执行时调用栈 (call stack) 上最近的、活动的该名字的声明。
作用域取决于函数调用的顺序，而不是它们在源代码中的词法位置。
C语言不使用动态作用域。一些早期的Lisp方言、Perl（通过 local 关键字）曾使用或支持动态作用域。动态作用域通常会使程序更难理解和维护。

显式访问控制 (Explicit Access Control) 🛡️

(此概念主要用于支持面向对象的语言如 C++, Java，C语言本身对结构体成员没有显式访问控制关键字)
在C++等语言中，关键字 public, private, protected 用于控制类成员的访问权限，以实现封装 (encapsulation)：

私有 (private): 成员只能被其所在的类的成员函数访问。
保护 (protected): 成员可以被其所在的类的成员函数以及其派生类 (子类) 的成员函数访问。
公共 (public): 成员可以从任何地方访问。


C语言中，虽然没有这些关键字用于结构体成员，但可以通过 static 关键字限制全局变量和函数的作用域到当前文件（文件作用域），提供一种模块级别的封装。结构体成员默认是"公共"的。

参数传递机制 (Parameter Passing Mechanisms) 🎁
值调用 (Call by Value):

实际参数的值被复制到函数的形式参数中。函数内部对形式参数的修改不影响调用者处的实际参数。
C语言默认采用值调用。

引用调用 (Call by Reference) 🔗:

传递的是实际参数的地址（或一个指向实际参数的引用）。函数内部对形式参数的修改会影响调用者处的实际参数。
C语言通过传递指针并解引用来模拟引用调用 (e.g., void swap(int *a, int *b)).
C++ 提供了真正的引用类型 (e.g., void swap(int &amp;a, int &amp;b)).

名调用 (Call by Name) 📝:

一种较早的参数传递机制 (如 Algol 60)。实际参数的表达式在每次于函数体中被引用时，都会在调用者的环境中重新求值。可以想象成文本替换（但有作用域处理，类似无冲突的宏）。
由于其复杂性和潜在的性能问题及副作用，现代语言中已不再采用。

共享调用 (Call by Sharing / Call by Object / Call by Object-Sharing): 常见于Python, Java (对象类型), Ruby等。函数接收的是对象引用的副本。如果对象是可变的，函数内部通过该引用修改对象会影响原始对象。如果函数给形式参数赋一个新的引用（指向不同对象），原始对象的引用不受影响。
别名 (Aliasing) 🎭


别名 (Aliasing): 当同一个内存位置可以通过两个或多个不同的名字（标识符、指针、引用）来访问时，就发生了别名。


例如，在C中：
int x = 10;int *p1 = &amp;x;  // p1 指向 xint *p2 = p1;  // p2 也指向 x (通过 p1)// 此时，x, *p1, *p2 都是访问同一内存位置的别名*p1 = 20;      // x 的值变为 20// printf(&quot;%d&quot;, *p2); // 会输出 20


别名会使程序分析、理解和优化更加复杂，因为一个变量的修改可能会通过一个看似不相关的名字隐式地影响到其他部分的代码。编译器在进行优化时需要保守地处理可能存在别名的情况。


数据类型
抽象
数据类型本质上是对存储器中存储的数据进行的抽象，包含一组值和一组操作;
根据语言面向的机器和语言面向的领域，可抽象为三个层次

内部类型：基本表示不可见，能进行静态类型检查，编译时可确定无二义性操作，允许运算符的重载，实现精度控制
用户定义类型：提供数据的组合/聚合机制

笛卡尔积：比如C中的结构体
有限映像：从定义域的优先级和到至于的有限集合，值域对象通过下标变量方式对应，下标有编译时绑定，对象建立时绑定，对象处理时绑定三种策略
序列：任意多个数据项组成，数据项成为序列的成分，类型相同
递归：数据类型包含属于同一种类型的成分，通常利用指针实现，直接递归通常不被允许
判定或：根据不同的成员构造机制，比如联合类型union
幂集：类型所有子集的集合


抽象数据类型

C语言数据类型
在C语言中，实现如下数据类型

值得注意的是，在C语言中

联合类型是不安全的
文件类型FILE被视作字符字节的序列；
不允许定义空类型变量，只能定义空类型指针；
不支持幂集

类型检查
定义：对数据操作和对应类型是否匹配的一致性检查

例子：非法运算，赋值，形参实参是否匹配
动态检查：编程方便，但是影响力可靠性，降低了执行效率
静态检查：使得程序更加有效

语言按照类型检查可以分为

无类型语言：没有任何数据类型，如一些函数式语言和泛函程序设计语言
弱类型语言：类型检查部分或全部在运行时完成，如Python
强类型语言：所有类型检查在编译时完成，如C

类型转换
一般语言提供类型转换机制

隐式/自动转换：比如FORTRAN语言
显式/强制转换：比如Golang，在C语言中两者都有

类型转换可能发生在以下场景：

混合运算
表达式值赋值给变量
实参想函数传形参
函数返回值

控制结构
控制结构规定了程序语句和程序单元的执行流程和控制戒指；
语句级控制结构：基本的，有一定意义的抽象控制结构，具体来说是对PC + 1指令的抽象 &amp; GOTO指令的抽象，相对于显式控制结构更好；

顺序：通常带有结束标记；
选择：单选，二选一，多选一(比如多层嵌套或者switch的简洁表达)
循环：计数器制导，条件制导，
最终由条件转移和无条件转移的指令实现，由编译器生成，用户不可见

单元级控制结构：在程序顺序执行的过程中，遇到一个分程序，就建立一个新的引用环境，并执行这个分程序；显式调用单元，把控制从一个单元转移到另一个单元


显式调用从属单元：比如C中的函数，单元间的通信，可使用参数传递实现，也可以通过全局变量和非局部变量实现



异常处理：导致程序正常执行中止的事件，要靠发信号来引发，用异常条件来表示。


协同程序



并发
并发提供了同时执行多个程序单元的途径，是多处理器和分布式系统的重要基础。
C语言没有原生支持，但是可以通过操作系统提供或者第三方库提供实现，比如pthread.h


]]></content>
      <tags>
        <tag>Coursework</tag>
        <tag>Compilers</tag>
      </tags>
  </entry>
</search>
